{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/FinRL_StockTrading_NeurIPS_2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
    "\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)   \n",
    "* [RLlib Section](#7)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "ef0ba8d0-f57a-4c74-bb0b-46737762677d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
      "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to /tmp/pip-req-build-8i1_yu6g\n",
      "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-8i1_yu6g\n",
      "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
      "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
      "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "  Running command git clone -q https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.19.5)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.1.5)\n",
      "Collecting stockstats\n",
      "  Downloading stockstats-0.3.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.1.67-py2.py3-none-any.whl (25 kB)\n",
      "Collecting elegantrl\n",
      "  Downloading elegantrl-0.3.2-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 2.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.17.3)\n",
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-1.3.0-py3-none-any.whl (174 kB)\n",
      "\u001b[K     |████████████████████████████████| 174 kB 65.2 MB/s \n",
      "\u001b[?25hCollecting ray[default]\n",
      "  Downloading ray-1.9.1-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 57.6 MB 1.4 MB/s \n",
      "\u001b[?25hCollecting lz4\n",
      "  Downloading lz4-3.1.10-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 42.9 MB/s \n",
      "\u001b[?25hCollecting tensorboardX\n",
      "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 71.5 MB/s \n",
      "\u001b[?25hCollecting gputil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "Collecting exchange_calendars\n",
      "  Downloading exchange_calendars-3.5.tar.gz (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 35.6 MB/s \n",
      "\u001b[?25hCollecting alpaca_trade_api\n",
      "  Downloading alpaca_trade_api-1.4.3-py3-none-any.whl (36 kB)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting jqdatasdk\n",
      "  Downloading jqdatasdk-1.8.10-py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 57.3 MB/s \n",
      "\u001b[?25hCollecting wrds\n",
      "  Downloading wrds-3.1.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.6.4)\n",
      "Requirement already satisfied: setuptools>=41.4.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (57.4.0)\n",
      "Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.37.0)\n",
      "Collecting pre-commit\n",
      "  Downloading pre_commit-2.16.0-py2.py3-none-any.whl (191 kB)\n",
      "\u001b[K     |████████████████████████████████| 191 kB 55.1 MB/s \n",
      "\u001b[?25hCollecting pybullet\n",
      "  Downloading pybullet-3.2.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (90.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 90.8 MB 244 bytes/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (1.10.0+cu111)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (4.1.2.30)\n",
      "Collecting box2d-py\n",
      "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 50.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.5.0)\n",
      "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2018.9)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.4.1)\n",
      "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.11.2)\n",
      "Collecting empyrical>=0.5.0\n",
      "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.9.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.0.18)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.4.2)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.6.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (0.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.23.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.2.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.2.5)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.3.3) (0.16.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (1.1.0)\n",
      "Collecting websocket-client<2,>=0.56.0\n",
      "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
      "\u001b[?25hCollecting PyYAML==5.4.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 52.7 MB/s \n",
      "\u001b[?25hCollecting msgpack==1.0.2\n",
      "  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
      "\u001b[K     |████████████████████████████████| 273 kB 60.4 MB/s \n",
      "\u001b[?25hCollecting aiohttp==3.7.4\n",
      "  Downloading aiohttp-3.7.4-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 55.5 MB/s \n",
      "\u001b[?25hCollecting websockets<10,>=8.0\n",
      "  Downloading websockets-9.1-cp37-cp37m-manylinux2010_x86_64.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 48.7 MB/s \n",
      "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (3.10.0.2)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 56.6 MB/s \n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 57.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (21.2.0)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 68.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 28.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 21.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 11.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 70.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 24.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 14.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 65.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.85-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 59.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.84-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.83-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.82-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.81-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.80-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 35.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.79-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.78-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 20.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.77-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.76-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.75-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.74-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 34.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.73-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.72-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.71-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.70-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.69-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.68-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 60.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.67-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.66-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.65-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.64-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.63-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.62-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.61-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.60-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 57.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.59-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.58-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.57-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.56-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.55-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.54-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.53-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.52-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.51-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.6 MB/s \n",
      "\u001b[?25hCollecting aiodns>=1.1.1\n",
      "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 60.7 MB/s \n",
      "\u001b[?25hCollecting cryptography>=2.6.1\n",
      "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 42.6 MB/s \n",
      "\u001b[?25hCollecting pycares>=4.0.0\n",
      "  Downloading pycares-4.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (291 kB)\n",
      "\u001b[K     |████████████████████████████████| 291 kB 44.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt->finrl==0.3.3) (2.21)\n",
      "Collecting pyluach\n",
      "  Downloading pyluach-1.3.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.11.2)\n",
      "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.2.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.3) (1.4.27)\n",
      "Collecting thriftpy2>=0.3.9\n",
      "  Downloading thriftpy2-0.4.14.tar.gz (361 kB)\n",
      "\u001b[K     |████████████████████████████████| 361 kB 50.4 MB/s \n",
      "\u001b[?25hCollecting pymysql>=0.7.6\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (1.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (4.8.2)\n",
      "Collecting ply<4.0,>=3.4\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (3.6.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.0)\n",
      "Collecting cfgv>=2.0.0\n",
      "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (0.10.2)\n",
      "Collecting identify>=1.0.0\n",
      "  Downloading identify-2.4.1-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 7.2 MB/s \n",
      "\u001b[?25hCollecting virtualenv>=20.0.8\n",
      "  Downloading virtualenv-20.11.0-py2.py3-none-any.whl (6.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5 MB 39.6 MB/s \n",
      "\u001b[?25hCollecting nodeenv>=0.11.1\n",
      "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (3.4.0)\n",
      "Collecting distlib<1,>=0.3.1\n",
      "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
      "\u001b[K     |████████████████████████████████| 461 kB 32.3 MB/s \n",
      "\u001b[?25hCollecting platformdirs<3,>=2\n",
      "  Downloading platformdirs-2.4.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (0.7.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.11.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (8.12.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.42.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (3.17.3)\n",
      "Collecting redis>=3.5.0\n",
      "  Downloading redis-4.1.0-py3-none-any.whl (171 kB)\n",
      "\u001b[K     |████████████████████████████████| 171 kB 57.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (2.6.0)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.12.0)\n",
      "Collecting aioredis<2\n",
      "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.6 MB/s \n",
      "\u001b[?25hCollecting py-spy>=0.2.0\n",
      "  Downloading py_spy-0.3.11-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 50.8 MB/s \n",
      "\u001b[?25hCollecting colorful\n",
      "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[K     |████████████████████████████████| 201 kB 70.8 MB/s \n",
      "\u001b[?25hCollecting aiohttp-cors\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (5.2.1)\n",
      "Collecting aiosignal\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist\n",
      "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
      "\u001b[K     |████████████████████████████████| 192 kB 7.1 MB/s \n",
      "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
      "  Downloading gpustat-1.0.0b1.tar.gz (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 213 kB/s \n",
      "\u001b[?25hCollecting opencensus\n",
      "  Downloading opencensus-0.8.0-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 53.5 MB/s \n",
      "\u001b[?25hCollecting hiredis\n",
      "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 2.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (7.352.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (5.4.8)\n",
      "Collecting blessed>=1.17.1\n",
      "  Downloading blessed-1.19.0-py2.py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 4.8 MB/s \n",
      "\u001b[?25hCollecting deprecated>=1.2.3\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]->finrl==0.3.3) (21.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[default]->finrl==0.3.3) (1.13.3)\n",
      "Collecting opencensus-context==0.1.2\n",
      "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.3) (1.26.3)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.35.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.53.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.4.8)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.8.9)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (2.7.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (0.2.9)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.1.1)\n",
      "Collecting int-date>=0.1.7\n",
      "  Downloading int_date-0.1.8-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting mock\n",
      "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.4 MB 45.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.3) (0.0.10)\n",
      "Building wheels for collected packages: finrl, elegantrl, pyfolio, empyrical, exchange-calendars, gputil, thriftpy2, gpustat\n",
      "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for finrl: filename=finrl-0.3.3-py3-none-any.whl size=3885640 sha256=1667a85b9c8c0a7a8efbf04d5ebf154d5d1ea119a32e922d094820030ce0e7e4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/17/ff/bd/1bc602a0352762b0b24041b88536d803ae343ed0a711fcf55e\n",
      "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for elegantrl: filename=elegantrl-0.3.2-py3-none-any.whl size=168744 sha256=7773813204e1a2954730bd149444640d5155458fc82b6910ec4e661879797016\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/99/85/5e/86cb3a9f47adfca5e248295e93113e1b298d60883126d62c84\n",
      "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75775 sha256=e3753b24d032afc5ef0b133c50557002ca9fed8416e2205e1547fc81af5c124a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/ef/09/e5/2c1bf37c050d22557c080deb1be986d06424627c04aeca19b9\n",
      "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39777 sha256=6cc78a6b3f88187e2798221487acba0361bb1d094b6c82496348fb4c85f7686b\n",
      "  Stored in directory: /root/.cache/pip/wheels/d9/91/4b/654fcff57477efcf149eaca236da2fce991526cbab431bf312\n",
      "  Building wheel for exchange-calendars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for exchange-calendars: filename=exchange_calendars-3.5-py3-none-any.whl size=179487 sha256=3d877d78e29a28c4b098f4a0b1d0106458d7f73b52f6c7a43d0757d55c11d44b\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/21/43/b6ae2605dd767f6cd5a5b0b70c93a9a75823e44b3ccb92bce7\n",
      "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=33dcd980f1b32f0582d029fcef126ae53327fb90724eee8c33bc3b4dbebda4b1\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
      "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for thriftpy2: filename=thriftpy2-0.4.14-cp37-cp37m-linux_x86_64.whl size=940507 sha256=429244bf5fd89014c79f01bf0e4a59477258cd2b88978e3125b54f4bd62a88f5\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/f5/49/9c0d851aa64b58db72883cf9393cc824d536bdf13f5c83cff4\n",
      "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gpustat: filename=gpustat-1.0.0b1-py3-none-any.whl size=15979 sha256=b831a9dba6682b3e0a7ae05d7c2ba465918426c72474917e56e0850ac8c73263\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/16/e2/3e2437fba4c4b6a97a97bd96fce5d14e66cff5c4966fb1cc8c\n",
      "Successfully built finrl elegantrl pyfolio empyrical exchange-calendars gputil thriftpy2 gpustat\n",
      "Installing collected packages: multidict, yarl, lxml, deprecated, async-timeout, redis, PyYAML, pycares, ply, platformdirs, opencensus-context, msgpack, hiredis, frozenlist, distlib, blessed, aiohttp, websockets, websocket-client, virtualenv, thriftpy2, tensorboardX, stable-baselines3, ray, pymysql, pyluach, pybullet, py-spy, psycopg2-binary, opencensus, nodeenv, mock, int-date, identify, gpustat, empyrical, cryptography, colorful, cfgv, box2d-py, aiosignal, aioredis, aiohttp-cors, aiodns, yfinance, wrds, stockstats, pyfolio, pre-commit, lz4, jqdatasdk, gputil, exchange-calendars, elegantrl, ccxt, alpaca-trade-api, finrl\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.2.6\n",
      "    Uninstalling lxml-4.2.6:\n",
      "      Successfully uninstalled lxml-4.2.6\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.3\n",
      "    Uninstalling msgpack-1.0.3:\n",
      "      Successfully uninstalled msgpack-1.0.3\n",
      "Successfully installed PyYAML-5.4.1 aiodns-3.0.0 aiohttp-3.7.4 aiohttp-cors-0.7.0 aioredis-1.3.1 aiosignal-1.2.0 alpaca-trade-api-1.4.3 async-timeout-3.0.1 blessed-1.19.0 box2d-py-2.3.8 ccxt-1.61.51 cfgv-3.3.1 colorful-0.5.4 cryptography-36.0.1 deprecated-1.2.13 distlib-0.3.4 elegantrl-0.3.2 empyrical-0.5.5 exchange-calendars-3.5 finrl-0.3.3 frozenlist-1.2.0 gpustat-1.0.0b1 gputil-1.4.0 hiredis-2.0.0 identify-2.4.1 int-date-0.1.8 jqdatasdk-1.8.10 lxml-4.7.1 lz4-3.1.10 mock-4.0.3 msgpack-1.0.2 multidict-5.2.0 nodeenv-1.6.0 opencensus-0.8.0 opencensus-context-0.1.2 platformdirs-2.4.1 ply-3.11 pre-commit-2.16.0 psycopg2-binary-2.9.2 py-spy-0.3.11 pybullet-3.2.1 pycares-4.1.2 pyfolio-0.9.2+75.g4b901f6 pyluach-1.3.0 pymysql-1.0.2 ray-1.9.1 redis-4.1.0 stable-baselines3-1.3.0 stockstats-0.3.2 tensorboardX-2.4.1 thriftpy2-0.4.14 virtualenv-20.11.0 websocket-client-1.2.3 websockets-9.1 wrds-3.1.1 yarl-1.6.3 yfinance-0.1.67\n"
     ]
    }
   ],
   "source": [
    "## install finrl library\n",
    "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "10b08480-3a0c-4826-8e51-f94ce97ab84a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zj/anaconda3/envs/finrl/lib/python3.7/site-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.finrl_meta.preprocessor.tusharedownloader import TushareDownloader\n",
    "from finrl.finrl_meta.data_processors.processor_alpaca import AlpacaProcessor\n",
    "from finrl.finrl_meta.data_processors.processor_wrds import WrdsProcessor\n",
    "from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading_conservative import StockTradingEnvCon\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.finrl_meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot2 import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "5302d7c0-1c68-4c6e-b30e-b1395bdc109e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-01-01'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py TRAIN_START_DATE is a string\n",
    "config.TRAIN_START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FUnY8WEfLq3C",
    "outputId": "35dd8c5b-d58f-49b8-e4df-ae7e122448cd"
   },
   "outputs": [],
   "source": [
    "# from config.py TRAIN_END_DATE is a string\n",
    "# config.TRAIN_END_DATE\n",
    "# df2=TushareDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "83c7f894-3757-473b-8afb-a904e6caabda",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = YahooDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "7a991dfe-f39c-40db-ec44-7c416cdce7dc"
   },
   "outputs": [],
   "source": [
    "# print(config_tickers.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "5267773c-399c-4ec9-d4d5-13ab1e4cced0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94360, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./1.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "210fade5-e912-40df-be99-4ad00bdb9d2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600</td>\n",
       "      <td>AXP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100</td>\n",
       "      <td>BA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400</td>\n",
       "      <td>CAT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date       open       high        low      close  \\\n",
       "0           0  2008-12-31   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31  43.700001  45.099998  43.700001  30.628819   \n",
       "\n",
       "      volume   tic  day  \n",
       "0  607541200  AAPL    2  \n",
       "1    6287200  AMGN    2  \n",
       "2    9625600   AXP    2  \n",
       "3    5443100    BA    2  \n",
       "4    6277400   CAT    2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmKP-1ii3RLS",
    "outputId": "0708badb-77ef-4c86-f77c-6525f0e8934d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fe = FeatureEngineer(\n",
    "#                     use_technical_indicator=True,\n",
    "#                     tech_indicator_list = config.INDICATORS,\n",
    "#                     use_vix=True,\n",
    "#                     use_turbulence=True,\n",
    "#                     user_defined_feature = False)\n",
    "\n",
    "# processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Kixon2tR3RLT"
   },
   "outputs": [],
   "source": [
    "# list_ticker = processed[\"tic\"].unique().tolist()\n",
    "# list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "# combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "# processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "# processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "# processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "# processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "grvhGJJII3Xn",
    "outputId": "733758c3-3552-4aa5-e1f9-789bd4ce0c92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AXP</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>BA</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CAT</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CRM</td>\n",
       "      <td>7.712500</td>\n",
       "      <td>8.130000</td>\n",
       "      <td>7.707500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>5367600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>16.180000</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.120001</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>37513700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CVX</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>74.629997</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>9964300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>DIS</td>\n",
       "      <td>22.570000</td>\n",
       "      <td>22.950001</td>\n",
       "      <td>22.520000</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>9012100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>GS</td>\n",
       "      <td>82.239998</td>\n",
       "      <td>86.150002</td>\n",
       "      <td>81.120003</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>14894100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic       open       high        low      close  \\\n",
       "0           0  2008-12-31  AAPL   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  AMGN  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31   AXP  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31    BA  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31   CAT  43.700001  45.099998  43.700001  30.628819   \n",
       "5           5  2008-12-31   CRM   7.712500   8.130000   7.707500   8.002500   \n",
       "6           6  2008-12-31  CSCO  16.180000  16.549999  16.120001  11.787783   \n",
       "7           7  2008-12-31   CVX  72.900002  74.629997  72.900002  43.314438   \n",
       "8           8  2008-12-31   DIS  22.570000  22.950001  22.520000  19.538342   \n",
       "9           9  2008-12-31    GS  82.239998  86.150002  81.120003  69.224182   \n",
       "\n",
       "        volume  day  macd   boll_ub   boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0  607541200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "1    6287200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "2    9625600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "3    5443100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "4    6277400.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "5    5367600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "6   37513700.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "7    9964300.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "8    9012100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "9   14894100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma   vix  turbulence  \n",
       "0      2.606277      2.606277  40.0         0.0  \n",
       "1     43.924454     43.924454  40.0         0.0  \n",
       "2     14.908465     14.908465  40.0         0.0  \n",
       "3     32.005894     32.005894  40.0         0.0  \n",
       "4     30.628819     30.628819  40.0         0.0  \n",
       "5      8.002500      8.002500  40.0         0.0  \n",
       "6     11.787783     11.787783  40.0         0.0  \n",
       "7     43.314438     43.314438  40.0         0.0  \n",
       "8     19.538342     19.538342  40.0         0.0  \n",
       "9     69.224182     69.224182  40.0         0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full=pd.read_csv('./2.csv')\n",
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TOhcryx44bb"
   },
   "source": [
    "## Training data split: 2009-01-01 to 2020-07-01\n",
    "## Trade data split: 2020-07-01 to 2021-10-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "ca8d1a43-ffc3-4fc3-efa9-4de9a9065842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83897\n",
      "9744\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, '2009-01-01','2020-07-01')\n",
    "trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "p52zNCOhTtLR",
    "outputId": "b3ad3e10-376f-4186-f875-0331708c5e14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121795</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>UNH</td>\n",
       "      <td>288.570007</td>\n",
       "      <td>296.450012</td>\n",
       "      <td>287.660004</td>\n",
       "      <td>287.776794</td>\n",
       "      <td>2932900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>303.925869</td>\n",
       "      <td>271.251255</td>\n",
       "      <td>52.413046</td>\n",
       "      <td>-25.838431</td>\n",
       "      <td>1.846804</td>\n",
       "      <td>288.020689</td>\n",
       "      <td>281.001438</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121796</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>V</td>\n",
       "      <td>191.490005</td>\n",
       "      <td>193.750000</td>\n",
       "      <td>190.160004</td>\n",
       "      <td>190.737244</td>\n",
       "      <td>9040100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.048786</td>\n",
       "      <td>198.750528</td>\n",
       "      <td>185.041391</td>\n",
       "      <td>53.021033</td>\n",
       "      <td>-51.550760</td>\n",
       "      <td>2.013358</td>\n",
       "      <td>191.485037</td>\n",
       "      <td>181.677683</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121797</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>VZ</td>\n",
       "      <td>54.919998</td>\n",
       "      <td>55.290001</td>\n",
       "      <td>54.360001</td>\n",
       "      <td>50.376743</td>\n",
       "      <td>17414800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.437111</td>\n",
       "      <td>53.918425</td>\n",
       "      <td>48.729324</td>\n",
       "      <td>48.097044</td>\n",
       "      <td>-51.018262</td>\n",
       "      <td>8.508886</td>\n",
       "      <td>51.012123</td>\n",
       "      <td>51.464679</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121798</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WBA</td>\n",
       "      <td>42.119999</td>\n",
       "      <td>42.580002</td>\n",
       "      <td>41.759998</td>\n",
       "      <td>39.035732</td>\n",
       "      <td>4782100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.083986</td>\n",
       "      <td>42.609305</td>\n",
       "      <td>36.487095</td>\n",
       "      <td>48.830181</td>\n",
       "      <td>-14.508130</td>\n",
       "      <td>1.500723</td>\n",
       "      <td>39.135190</td>\n",
       "      <td>38.935129</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121799</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WMT</td>\n",
       "      <td>119.220001</td>\n",
       "      <td>120.129997</td>\n",
       "      <td>118.540001</td>\n",
       "      <td>116.121765</td>\n",
       "      <td>6836400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.886569</td>\n",
       "      <td>119.473758</td>\n",
       "      <td>113.510454</td>\n",
       "      <td>48.159665</td>\n",
       "      <td>-69.938795</td>\n",
       "      <td>3.847271</td>\n",
       "      <td>117.787627</td>\n",
       "      <td>119.723273</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        date  tic        open        high         low  \\\n",
       "2892      121795  2020-06-30  UNH  288.570007  296.450012  287.660004   \n",
       "2892      121796  2020-06-30    V  191.490005  193.750000  190.160004   \n",
       "2892      121797  2020-06-30   VZ   54.919998   55.290001   54.360001   \n",
       "2892      121798  2020-06-30  WBA   42.119999   42.580002   41.759998   \n",
       "2892      121799  2020-06-30  WMT  119.220001  120.129997  118.540001   \n",
       "\n",
       "           close      volume  day      macd     boll_ub     boll_lb  \\\n",
       "2892  287.776794   2932900.0  1.0 -0.019475  303.925869  271.251255   \n",
       "2892  190.737244   9040100.0  1.0  1.048786  198.750528  185.041391   \n",
       "2892   50.376743  17414800.0  1.0 -0.437111   53.918425   48.729324   \n",
       "2892   39.035732   4782100.0  1.0 -0.083986   42.609305   36.487095   \n",
       "2892  116.121765   6836400.0  1.0 -0.886569  119.473758  113.510454   \n",
       "\n",
       "         rsi_30     cci_30     dx_30  close_30_sma  close_60_sma    vix  \\\n",
       "2892  52.413046 -25.838431  1.846804    288.020689    281.001438  30.43   \n",
       "2892  53.021033 -51.550760  2.013358    191.485037    181.677683  30.43   \n",
       "2892  48.097044 -51.018262  8.508886     51.012123     51.464679  30.43   \n",
       "2892  48.830181 -14.508130  1.500723     39.135190     38.935129  30.43   \n",
       "2892  48.159665 -69.938795  3.847271    117.787627    119.723273  30.43   \n",
       "\n",
       "      turbulence  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "k9zU9YaTTvFq",
    "outputId": "72213585-39a3-4bff-c031-874ec0ca06f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "7f228183-abe3-4477-f574-3c9b25c62cd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "1f54d044-e2d3-4a34-c041-e913d686654e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "e_train_gym_conservative = StockTradingEnvCon(df = train, **env_kwargs)\n",
    "e_train_gym_conservative.value_history.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64EoqOrQjiVf"
   },
   "source": [
    "## Environment for Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "deeaef07-afda-4ca1-fea8-99384224c7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))\n",
    "env_train_con, _ = e_train_gym_conservative.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "364PsqckttcQ"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "agent_con = DRLAgent(env = env_train_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Model 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "a90a7a60-21a5-47e1-b683-1f7cbb4b8bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0GVpkWGqH4-D",
    "outputId": "570d540f-abe9-402b-e0cc-f9b007228e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 67         |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | -1.41      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -72.8      |\n",
      "|    reward             | 0.19451597 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.68       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 68         |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | -0.115     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -70.2      |\n",
      "|    reward             | -1.4624771 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.55       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0.198    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -167     |\n",
      "|    reward             | 5.02583  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 21.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -30.9    |\n",
      "|    reward             | 5.606354 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 368       |\n",
      "|    reward             | -7.546301 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 164       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0.0793    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 145       |\n",
      "|    reward             | 0.4507672 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 15        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | -0.0998    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -78.4      |\n",
      "|    reward             | -2.1521304 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 5.52       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0.00557     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 10.6        |\n",
      "|    reward             | -0.80710465 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 2.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 70.3        |\n",
      "|    reward             | -0.11950674 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 3.94        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -35.7      |\n",
      "|    reward             | -4.1389766 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.35       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -245     |\n",
      "|    reward             | 6.363784 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 38.5     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -63.1      |\n",
      "|    reward             | 0.07753525 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.93       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | -0.000831 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 48.9      |\n",
      "|    reward             | -4.088032 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 8         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 179       |\n",
      "|    reward             | 2.0626597 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 40.8      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 169       |\n",
      "|    reward             | 4.8591986 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 21.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 85.1       |\n",
      "|    reward             | 0.85958314 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 6.29       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -141     |\n",
      "|    reward             | 5.65319  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 51.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -41       |\n",
      "|    reward             | 1.1973313 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.57      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -26.6      |\n",
      "|    reward             | 0.36287376 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.68       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40         |\n",
      "|    explained_variance | -0.0091     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -83.6       |\n",
      "|    reward             | -0.30971453 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 13.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 204       |\n",
      "|    reward             | 1.7650424 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 30.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 158        |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | -153       |\n",
      "|    reward             | -7.5710273 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 23.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | -2.04e+03  |\n",
      "|    reward             | -14.886115 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3e+03      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 51        |\n",
      "|    reward             | 0.0559524 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.94      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -46.7     |\n",
      "|    reward             | -0.434364 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 5.71      |\n",
      "|    reward             | 4.8586307 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.131     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 194        |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -13.8      |\n",
      "|    reward             | -0.4118847 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.392      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 201       |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 328       |\n",
      "|    reward             | 1.0554261 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 66.3      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 209       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0.88      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -116      |\n",
      "|    reward             | 2.3091433 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 9.5       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 216        |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | -20.7      |\n",
      "|    reward             | 0.38583377 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.509      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 223        |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | 43.7       |\n",
      "|    reward             | -0.3664559 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 230        |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -38.8      |\n",
      "|    reward             | -0.4616701 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 11.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 237        |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | 96.4       |\n",
      "|    reward             | 0.11014476 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.58       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 245       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -3.93     |\n",
      "|    reward             | 2.1390972 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 30.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | 76.4       |\n",
      "|    reward             | 0.16336557 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.35       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 259       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -85.2     |\n",
      "|    reward             | 1.0221922 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.59      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 266       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 225       |\n",
      "|    reward             | 1.1701288 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 38.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 273       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 33.2      |\n",
      "|    reward             | 2.4472284 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.27      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 281        |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 41.3       |\n",
      "|    reward             | -1.2081411 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.04       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 288       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | -0.481    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -5.13     |\n",
      "|    reward             | 1.3224076 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2         |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | 1.15        |\n",
      "|    reward             | -0.25540048 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.837       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 302       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0.000881  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -119      |\n",
      "|    reward             | 1.3826902 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 10.9      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 309       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -64       |\n",
      "|    reward             | 3.9822705 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.59      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 63.9       |\n",
      "|    reward             | 0.95108056 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 4.87       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 324        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | 86.2       |\n",
      "|    reward             | -2.1539907 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 331       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 102       |\n",
      "|    reward             | 4.8509326 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0.00948     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | -105        |\n",
      "|    reward             | -0.22313617 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 8.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 346         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | -104        |\n",
      "|    reward             | -0.99914765 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 7.87        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 353        |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -33.2      |\n",
      "|    reward             | 0.20132123 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.946      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 360        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | -7.57e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 46.2       |\n",
      "|    reward             | 0.26696855 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.03       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 367        |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | -83.4      |\n",
      "|    reward             | -1.8360271 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 374       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -359      |\n",
      "|    reward             | 3.2874866 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 92.2      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3161472.69\n",
      "total_reward: 2161472.69\n",
      "total_cost: 19221.41\n",
      "total_trades: 41334\n",
      "Sharpe: 0.663\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 382       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -7.54     |\n",
      "|    reward             | 0.2828299 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.173     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 389         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | 26.5        |\n",
      "|    reward             | -0.19252001 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.14        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 396       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -15       |\n",
      "|    reward             | 2.0577734 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.6       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 403         |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -46.9       |\n",
      "|    reward             | -0.06746031 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.12        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 411        |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0.00117    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | -37.6      |\n",
      "|    reward             | 0.18157594 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.34       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 418       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0.0166    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -31.3     |\n",
      "|    reward             | 0.6473793 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.72      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 425        |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | 7.13       |\n",
      "|    reward             | 0.22656512 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.251      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 432        |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | 59.9       |\n",
      "|    reward             | -0.8028962 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.88       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 439        |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | -10.2      |\n",
      "|    reward             | -1.7693416 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.89       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 446         |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 20.2        |\n",
      "|    reward             | -0.10761352 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 454      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 203      |\n",
      "|    reward             | 3.869458 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 34.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 461       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -0.0428   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 110       |\n",
      "|    reward             | 1.2343621 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.67      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 468       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    reward             | -2.028344 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.83      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 475        |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | -66.8      |\n",
      "|    reward             | 0.33169752 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.98       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 483      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | 0.00675  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -869     |\n",
      "|    reward             | -8.09732 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 536      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 490        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 28.9       |\n",
      "|    reward             | 0.56556416 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 13         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 497        |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -176       |\n",
      "|    reward             | -2.9329143 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 88.1       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 504        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 72.3       |\n",
      "|    reward             | 0.22214015 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 3.11       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 511        |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 105        |\n",
      "|    reward             | -0.6425189 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 12         |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 519         |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | -360        |\n",
      "|    reward             | -0.22756429 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 80.8        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 526         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | -430        |\n",
      "|    reward             | -0.44158605 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 131         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 533        |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | 404        |\n",
      "|    reward             | -5.8487034 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 111        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 540       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 1.07e+03  |\n",
      "|    reward             | -14.82644 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 832       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 548       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -141      |\n",
      "|    reward             | 1.4826734 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 555        |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | -0.0473    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | -184       |\n",
      "|    reward             | 0.34629944 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 25.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 562       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -42       |\n",
      "|    reward             | -2.415951 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 6         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 569       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 55.1      |\n",
      "|    reward             | 5.0485888 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 42.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 576        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | -207       |\n",
      "|    reward             | -3.2154734 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 56.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 584       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | 257       |\n",
      "|    reward             | 5.370093  |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 56.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 591        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -160       |\n",
      "|    reward             | 0.03019213 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 16.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 598        |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 118        |\n",
      "|    reward             | -1.1561224 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 12.6       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 605         |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -214        |\n",
      "|    reward             | -0.94865924 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 30.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 613       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -250      |\n",
      "|    reward             | 1.1797212 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 41.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 620        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 411        |\n",
      "|    reward             | -22.785406 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 144        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 627       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 72.4      |\n",
      "|    reward             | 3.2164123 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.27      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 634         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | 87          |\n",
      "|    reward             | -0.17441794 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 6.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 642         |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | 262         |\n",
      "|    reward             | -0.85795397 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 48.9        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 649        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | 72.7       |\n",
      "|    reward             | -2.2230675 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 22.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 656       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -49.2     |\n",
      "|    reward             | 2.6728501 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.66      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 663      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -238     |\n",
      "|    reward             | 8.656925 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 86.3     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 670         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0.000219    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | -187        |\n",
      "|    reward             | -0.62001467 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 27.3        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 678       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 55.6      |\n",
      "|    reward             | 1.1713017 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.79      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 685       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 139       |\n",
      "|    reward             | 1.3898315 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 14.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 692       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -52.5     |\n",
      "|    reward             | -6.044222 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.49      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 699       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 67.7      |\n",
      "|    reward             | 1.8213228 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 9.97      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 706      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 177      |\n",
      "|    reward             | 8.957433 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 58.6     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 714         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 14.2        |\n",
      "|    reward             | -0.26523116 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.559       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 721        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | -0.00926   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | 1.12       |\n",
      "|    reward             | -0.6623605 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.953      |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2YadjfnLwgt"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCDa78rqfO_a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "y5D5PFUhMzSV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Gt8eIQKYM4G3",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ppo/1_1\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 124       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 0.5073655 |\n",
      "----------------------------------\n",
      "day: 2892, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3946387.70\n",
      "total_reward: 2946387.70\n",
      "total_cost: 357438.48\n",
      "total_trades: 81024\n",
      "Sharpe: 0.793\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015788507 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.00723     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.41        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    reward               | 0.3435485   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012375185 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.7        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | -1.1157341  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 65.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016662188 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.00193    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 2.2809894   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017038994 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00886    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    reward               | 3.2505164   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 105        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01701039 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.4      |\n",
      "|    explained_variance   | 0.0063     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17         |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    reward               | 1.8685282  |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 32.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02486872 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.5      |\n",
      "|    explained_variance   | -0.0142    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.5       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    reward               | 0.39857626 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 46.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020911664 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | -0.0215     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | 1.3883617   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7870/2360990771.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_ppo = agent.train_model(model=model_ppo, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              total_timesteps=3000000)\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             )\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/zj/FinRL/finrl/finrl_meta/env_stock_trading/env_stocktrading.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    321\u001b[0m             )\n\u001b[1;32m    322\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_total_asset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_total_asset\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbegin_total_asset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/zj/FinRL/finrl/finrl_meta/env_stock_trading/env_stocktrading.py\u001b[0m in \u001b[0;36m_get_date\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2037\u001b[0m         \u001b[0mCategories\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'b'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2038\u001b[0m         \"\"\"\n\u001b[0;32m-> 2039\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0mhtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_hashtable_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_get_hashtable_algo\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mndtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_object_for_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0mhtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_hashtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mndtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_check_object_for_strings\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# including nulls because that is the only difference between\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# StringHashTable and ObjectHashtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0mndtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mndtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name=\"1\",\n",
    "                             total_timesteps=3000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JSAHhV4Xc-bh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent_con = DRLAgent(env = env_train_con)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo2 = agent_con.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "OSRxNYAxdKpU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load\n",
      "Logging to ppo/9_7\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 118        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 17         |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.40348062 |\n",
      "-----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014169915 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.0237     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.99        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    reward               | 0.70960116  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012743303 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.00503    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    reward               | -1.8170525  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 68.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014057685 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | 0.00318     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    reward               | 2.4765737   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013478018 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | 0.0169      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.44        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    reward               | 2.2553926   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018148262 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00826    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    reward               | 2.0096893   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017053649 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | 0.00236     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    reward               | 0.63455     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 147        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01934666 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.5      |\n",
      "|    explained_variance   | -0.0205    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.06       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0211    |\n",
      "|    reward               | 0.46009007 |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 18.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 166        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02170331 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.6      |\n",
      "|    explained_variance   | -0.0072    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.9       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0218    |\n",
      "|    reward               | 0.73683894 |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 43.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020332094 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | -0.00376    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 161         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    reward               | 1.388997    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 227         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017720772 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | -0.00331    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.5        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    reward               | 0.5552327   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01741166  |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | -0.0334     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    reward               | -0.12370278 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3262423.12\n",
      "total_reward: 2262423.12\n",
      "total_cost: 310798.82\n",
      "total_trades: 78026\n",
      "Sharpe: 0.625\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025459122 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | -0.0108     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    reward               | 0.039458103 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 92.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 256          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151849035 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.9        |\n",
      "|    explained_variance   | 0.0105       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.7         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    reward               | 2.1968157    |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015329551 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | -0.0172     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.5        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    reward               | 3.9157734   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 94.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 293         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021571234 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.000336    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.3        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    reward               | -0.07995539 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 311         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017339434 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | -0.00592    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.3        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | 1.1016418   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 330        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02268998 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.1      |\n",
      "|    explained_variance   | -0.00339   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 35.4       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    reward               | -0.4328649 |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 91.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03424495  |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | -0.0103     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -0.76890284 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 367         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029484611 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | -0.0022     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 0.17583422  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 387         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019497663 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | 0.000729    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.9        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | -8.22884    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 98.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 405         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025557566 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | 0.025       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    reward               | 4.424101    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 423         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021882009 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.000154    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.9        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | 0.23464254  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 81.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 441         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027822487 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | -0.00363    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 7.722479    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 224         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 460         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028668586 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.5       |\n",
      "|    explained_variance   | 0.00282     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 0.36210388  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 479        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03495821 |\n",
      "|    clip_fraction        | 0.361      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.6      |\n",
      "|    explained_variance   | -0.0023    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.9       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    reward               | 0.65205073 |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 24.9       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3208040.01\n",
      "total_reward: 2208040.01\n",
      "total_cost: 330824.29\n",
      "total_trades: 79010\n",
      "Sharpe: 0.658\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 498        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03705531 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | -0.00811   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 61.3       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    reward               | -1.5174596 |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 163        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 516         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035731405 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0113     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    reward               | -3.4086082  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 73.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030359047 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0781     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    reward               | -0.98007804 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 553        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02428497 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | 0.0016     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.1       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0182    |\n",
      "|    reward               | 1.11656    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 63.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 571         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029292993 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00427     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.7        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    reward               | 1.5496551   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 589         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028471969 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0208      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    reward               | -0.64046746 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 48.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 607          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.029158322  |\n",
      "|    clip_fraction        | 0.3          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.9        |\n",
      "|    explained_variance   | 0.00903      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33           |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.017       |\n",
      "|    reward               | 0.0051597157 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 92.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 626         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028463013 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.00982     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 1.5934055   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 78.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 644         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022382874 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.019       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.3        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 1.0252727   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 98.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 662         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027683523 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0084      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.98        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | -5.057246   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 680         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03039059  |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.00727     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    reward               | -0.51725465 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 70.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 699         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029393623 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0157      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | -10.531177  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 86.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 717         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041231856 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0175      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | -2.776342   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 735        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02577571 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | 0.00223    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.9       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0076    |\n",
      "|    reward               | -0.6796484 |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 55.9       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3665670.23\n",
      "total_reward: 2665670.23\n",
      "total_cost: 301341.44\n",
      "total_trades: 75343\n",
      "Sharpe: 0.671\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 754         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029148994 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.00622    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 0.6832749   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 80.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 774         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033209324 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.00132    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00681    |\n",
      "|    reward               | -0.47725743 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 78          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 792         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027383275 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0368      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.22        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 4.131234    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 810         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022773763 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.00196     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.1        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 0.112691306 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 84.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 828         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047176775 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.026       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.9        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | 0.00383     |\n",
      "|    reward               | -0.7914788  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 846         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022104714 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0203      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    reward               | -4.7904024  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 52.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 864         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030515429 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0277      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | 2.1738725   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 84.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 882         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014634268 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.00439     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.9        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    reward               | 16.618141   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 900         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022656364 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0506      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.8        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | 9.11e-05    |\n",
      "|    reward               | -1.8005838  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 50         |\n",
      "|    time_elapsed         | 918        |\n",
      "|    total_timesteps      | 102400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01880959 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.00808    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.1       |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | -0.0094    |\n",
      "|    reward               | -1.8692968 |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 40.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 936         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014584253 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.035       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.1        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | -0.7643113  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 954         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015190747 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0273      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    reward               | -1.1449255  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 95.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 973         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024396673 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.000469    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | -2.8572197  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 991         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027455334 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0262      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.2        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    reward               | 2.6394694   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 78.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1010        |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020180158 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0334      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.7        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 2.7134283   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 94.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4064441.78\n",
      "total_reward: 3064441.78\n",
      "total_cost: 286449.77\n",
      "total_trades: 74929\n",
      "Sharpe: 0.685\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1028        |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020594096 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.00992    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    reward               | 2.9247563   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 60          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 57         |\n",
      "|    time_elapsed         | 1046       |\n",
      "|    total_timesteps      | 116736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06246782 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.029      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.3       |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    reward               | -0.917867  |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 73.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 1065        |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027637474 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0293      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.6        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | 1.889407    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 1084       |\n",
      "|    total_timesteps      | 120832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01681196 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0352     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 49.3       |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.0127    |\n",
      "|    reward               | -2.497109  |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 115        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1103        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054993648 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | -0.068      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    reward               | 0.32335064  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1122        |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028081276 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0088      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.7        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | 0.66716427  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1140        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022945713 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0396      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88.4        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 6.096223    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 1160       |\n",
      "|    total_timesteps      | 129024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02294192 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.0851     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.6       |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.00652   |\n",
      "|    reward               | 2.3559108  |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 49.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 1178        |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025782846 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0388      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -0.24810508 |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 72.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 1197       |\n",
      "|    total_timesteps      | 133120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0342964  |\n",
      "|    clip_fraction        | 0.326      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.00239    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38         |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | -0.00582   |\n",
      "|    reward               | -1.3342444 |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 87.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1216        |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024056792 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.00189     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00109    |\n",
      "|    reward               | 4.2370152   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 1234        |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038579956 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | -0.0226     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | -0.42757517 |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 68         |\n",
      "|    time_elapsed         | 1253       |\n",
      "|    total_timesteps      | 139264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02004284 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.0613     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 61.9       |\n",
      "|    n_updates            | 670        |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    reward               | 0.36333928 |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 126        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1271        |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025226258 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0108      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.5        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | -3.2446966  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4003194.86\n",
      "total_reward: 3003194.86\n",
      "total_cost: 311208.58\n",
      "total_trades: 75206\n",
      "Sharpe: 0.659\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1290        |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027312249 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0167      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    reward               | 0.1626288   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1310        |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048830565 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0298      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    reward               | 0.6382035   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1328        |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018079579 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.000676    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.9        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00942    |\n",
      "|    reward               | -17.568949  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 1347         |\n",
      "|    total_timesteps      | 149504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0133040575 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.4        |\n",
      "|    explained_variance   | 0.07         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.6         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    reward               | -1.1141529   |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 74.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1367        |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044238493 |\n",
      "|    clip_fraction        | 0.417       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | -0.0127     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.6        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | 0.00678     |\n",
      "|    reward               | -0.7615396  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 75         |\n",
      "|    time_elapsed         | 1385       |\n",
      "|    total_timesteps      | 153600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03389915 |\n",
      "|    clip_fraction        | 0.34       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.04       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 56.6       |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | 0.00275    |\n",
      "|    reward               | 1.5871068  |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 119        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 1403       |\n",
      "|    total_timesteps      | 155648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05216954 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.035      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 72         |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | -0.00248   |\n",
      "|    reward               | -1.144459  |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 164        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 1421       |\n",
      "|    total_timesteps      | 157696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05246484 |\n",
      "|    clip_fraction        | 0.373      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.0504     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.9       |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | -0.00398   |\n",
      "|    reward               | 0.49103436 |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 65.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 78         |\n",
      "|    time_elapsed         | 1441       |\n",
      "|    total_timesteps      | 159744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02815647 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.0314     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 53.1       |\n",
      "|    n_updates            | 770        |\n",
      "|    policy_gradient_loss | -0.0118    |\n",
      "|    reward               | 3.1940503  |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 181        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 79         |\n",
      "|    time_elapsed         | 1459       |\n",
      "|    total_timesteps      | 161792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03371551 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.00846    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 63.4       |\n",
      "|    n_updates            | 780        |\n",
      "|    policy_gradient_loss | -0.00367   |\n",
      "|    reward               | -4.1727695 |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 150        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 1477       |\n",
      "|    total_timesteps      | 163840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04524828 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | -0.00934   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 50.4       |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | 0.00588    |\n",
      "|    reward               | 0.59163696 |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 88.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1496        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036302082 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.023       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.1        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    reward               | -0.53929454 |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1514        |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044670146 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0348      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.3        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    reward               | 0.025694795 |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 83         |\n",
      "|    time_elapsed         | 1532       |\n",
      "|    total_timesteps      | 169984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04048615 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.9      |\n",
      "|    explained_variance   | 0.0242     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 100        |\n",
      "|    n_updates            | 820        |\n",
      "|    policy_gradient_loss | -0.00415   |\n",
      "|    reward               | 0.14351042 |\n",
      "|    std                  | 1.14       |\n",
      "|    value_loss           | 220        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7490476.74\n",
      "total_reward: 6490476.74\n",
      "total_cost: 273290.72\n",
      "total_trades: 73632\n",
      "Sharpe: 0.974\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 84         |\n",
      "|    time_elapsed         | 1550       |\n",
      "|    total_timesteps      | 172032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04699745 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.9      |\n",
      "|    explained_variance   | 0.163      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.5       |\n",
      "|    n_updates            | 830        |\n",
      "|    policy_gradient_loss | -0.00506   |\n",
      "|    reward               | 0.47831354 |\n",
      "|    std                  | 1.14       |\n",
      "|    value_loss           | 25.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1568        |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038044743 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.052       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    reward               | 0.13994466  |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 86         |\n",
      "|    time_elapsed         | 1587       |\n",
      "|    total_timesteps      | 176128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03243041 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | 0.00334    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 211        |\n",
      "|    n_updates            | 850        |\n",
      "|    policy_gradient_loss | 0.00277    |\n",
      "|    reward               | 0.45864055 |\n",
      "|    std                  | 1.15       |\n",
      "|    value_loss           | 448        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 1605       |\n",
      "|    total_timesteps      | 178176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06472296 |\n",
      "|    clip_fraction        | 0.409      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.2      |\n",
      "|    explained_variance   | -0.134     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.3       |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | 0.00786    |\n",
      "|    reward               | 3.3354366  |\n",
      "|    std                  | 1.15       |\n",
      "|    value_loss           | 36.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1623        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032154284 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.0296      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.5        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    reward               | -2.691994   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 73.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1642        |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024528205 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0343      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 200         |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    reward               | -0.06025537 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 394         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1661        |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018544627 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | -0.000214   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 265         |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    reward               | 0.5526241   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 873         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 1679       |\n",
      "|    total_timesteps      | 186368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02808312 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.3      |\n",
      "|    explained_variance   | 0.0312     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.8       |\n",
      "|    n_updates            | 900        |\n",
      "|    policy_gradient_loss | -0.00573   |\n",
      "|    reward               | 0.36212358 |\n",
      "|    std                  | 1.15       |\n",
      "|    value_loss           | 35         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 1698        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02354655  |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | -0.00808    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 487         |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    reward               | -0.97534776 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 707         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 93         |\n",
      "|    time_elapsed         | 1717       |\n",
      "|    total_timesteps      | 190464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02298057 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.3      |\n",
      "|    explained_variance   | 0.00383    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 250        |\n",
      "|    n_updates            | 920        |\n",
      "|    policy_gradient_loss | -0.00652   |\n",
      "|    reward               | -1.9811898 |\n",
      "|    std                  | 1.16       |\n",
      "|    value_loss           | 481        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1736        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020931624 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0222      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    reward               | 1.9810807   |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 91          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1755        |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018545179 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.00283     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 448         |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | -1.414186   |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 558         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1774        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013934554 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0186      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    reward               | -4.5655026  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 522         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1792        |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017739594 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | -0.00275    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.1        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    reward               | 2.240207    |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 195         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4324780.23\n",
      "total_reward: 3324780.23\n",
      "total_cost: 328486.23\n",
      "total_trades: 75971\n",
      "Sharpe: 0.730\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 1811        |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017136944 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0376      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.1        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 0.18629819  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 373         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1829        |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038127188 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | -0.00551    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    reward               | -1.6079911  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 100        |\n",
      "|    time_elapsed         | 1848       |\n",
      "|    total_timesteps      | 204800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03517078 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.5      |\n",
      "|    explained_variance   | -0.00251   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 131        |\n",
      "|    n_updates            | 990        |\n",
      "|    policy_gradient_loss | -0.00382   |\n",
      "|    reward               | 0.72478974 |\n",
      "|    std                  | 1.17       |\n",
      "|    value_loss           | 320        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 1867        |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042739425 |\n",
      "|    clip_fraction        | 0.391       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.0114      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    reward               | -0.6181366  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 1886        |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029268403 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | -0.00988    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 86.6        |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    reward               | -1.3604256  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 1905        |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044877954 |\n",
      "|    clip_fraction        | 0.41        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | 0.04        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.4        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | 0.0044      |\n",
      "|    reward               | -1.694379   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 94.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 1924        |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052279893 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | 0.0667      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | 0.00141     |\n",
      "|    reward               | -0.5369126  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 105        |\n",
      "|    time_elapsed         | 1943       |\n",
      "|    total_timesteps      | 215040     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04227316 |\n",
      "|    clip_fraction        | 0.35       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.9      |\n",
      "|    explained_variance   | 0.0113     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.3       |\n",
      "|    n_updates            | 1040       |\n",
      "|    policy_gradient_loss | -0.00513   |\n",
      "|    reward               | -3.5365314 |\n",
      "|    std                  | 1.18       |\n",
      "|    value_loss           | 47.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 1962        |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029051539 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | -0.0176     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | -0.86997634 |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 1980         |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.051093414  |\n",
      "|    clip_fraction        | 0.365        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -46          |\n",
      "|    explained_variance   | 0.000376     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40           |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    reward               | -0.075252846 |\n",
      "|    std                  | 1.18         |\n",
      "|    value_loss           | 77.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 108        |\n",
      "|    time_elapsed         | 1999       |\n",
      "|    total_timesteps      | 221184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03882552 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46        |\n",
      "|    explained_variance   | -0.0457    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.77       |\n",
      "|    n_updates            | 1070       |\n",
      "|    policy_gradient_loss | -0.00964   |\n",
      "|    reward               | 0.5986325  |\n",
      "|    std                  | 1.18       |\n",
      "|    value_loss           | 19.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 2018        |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059144363 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | -0.0266     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    reward               | 0.49493793  |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 2036        |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02274843  |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.2       |\n",
      "|    explained_variance   | 0.0052      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.07508163 |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 2054        |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050292555 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.2       |\n",
      "|    explained_variance   | 0.0211      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    reward               | 4.211651    |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4254983.27\n",
      "total_reward: 3254983.27\n",
      "total_cost: 295521.85\n",
      "total_trades: 73256\n",
      "Sharpe: 0.745\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 2072        |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028734215 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.2       |\n",
      "|    explained_variance   | 0.0277      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    reward               | -0.6914373  |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 97.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 2091        |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043358296 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.3       |\n",
      "|    explained_variance   | 0.00445     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.7        |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | 0.000273    |\n",
      "|    reward               | -11.201429  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 114        |\n",
      "|    time_elapsed         | 2110       |\n",
      "|    total_timesteps      | 233472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02936332 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.3      |\n",
      "|    explained_variance   | 0.0146     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 161        |\n",
      "|    n_updates            | 1130       |\n",
      "|    policy_gradient_loss | -0.00444   |\n",
      "|    reward               | -3.00754   |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 173        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 2128        |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036954537 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.4       |\n",
      "|    explained_variance   | 0.0511      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    reward               | -2.0296     |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 2147        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035812985 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.4       |\n",
      "|    explained_variance   | 0.000222    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 193         |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | -1.5630921  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 231         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 2167        |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031621397 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.5       |\n",
      "|    explained_variance   | -0.0566     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    reward               | -0.25688913 |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 118        |\n",
      "|    time_elapsed         | 2185       |\n",
      "|    total_timesteps      | 241664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03121928 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.5      |\n",
      "|    explained_variance   | 0.0663     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.4       |\n",
      "|    n_updates            | 1170       |\n",
      "|    policy_gradient_loss | -0.00369   |\n",
      "|    reward               | 0.7100252  |\n",
      "|    std                  | 1.21       |\n",
      "|    value_loss           | 24.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 2203        |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049722847 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.6       |\n",
      "|    explained_variance   | -0.00673    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    reward               | 0.7115185   |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 67.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 2222        |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029935446 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.6       |\n",
      "|    explained_variance   | 0.0349      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    reward               | -5.2390537  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 67.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 121        |\n",
      "|    time_elapsed         | 2241       |\n",
      "|    total_timesteps      | 247808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05205429 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.7      |\n",
      "|    explained_variance   | 0.0076     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.3       |\n",
      "|    n_updates            | 1200       |\n",
      "|    policy_gradient_loss | -0.000409  |\n",
      "|    reward               | 0.47445703 |\n",
      "|    std                  | 1.21       |\n",
      "|    value_loss           | 57.4       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 2259        |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.04543548  |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | -0.0153     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.8        |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    reward               | -0.18316938 |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 2278        |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041414864 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | 0.0262      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.4        |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -6.32e-05   |\n",
      "|    reward               | 2.8573015   |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 72.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 2298        |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044519328 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.8       |\n",
      "|    explained_variance   | 0.00259     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.8        |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | 0.000362    |\n",
      "|    reward               | 0.33486995  |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 2317        |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035759754 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.8       |\n",
      "|    explained_variance   | -0.0645     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -6.68e-05   |\n",
      "|    reward               | 0.42599186  |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4821150.00\n",
      "total_reward: 3821150.00\n",
      "total_cost: 240404.35\n",
      "total_trades: 69752\n",
      "Sharpe: 0.788\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 2335        |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028104197 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.9       |\n",
      "|    explained_variance   | 0.0421      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.9        |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -0.5350415  |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 62.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 127        |\n",
      "|    time_elapsed         | 2353       |\n",
      "|    total_timesteps      | 260096     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03712703 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47        |\n",
      "|    explained_variance   | 0.0258     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 59.3       |\n",
      "|    n_updates            | 1260       |\n",
      "|    policy_gradient_loss | 0.0083     |\n",
      "|    reward               | -5.104442  |\n",
      "|    std                  | 1.22       |\n",
      "|    value_loss           | 120        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 128          |\n",
      "|    time_elapsed         | 2372         |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.040005416  |\n",
      "|    clip_fraction        | 0.347        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47          |\n",
      "|    explained_variance   | -0.0331      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.9         |\n",
      "|    n_updates            | 1270         |\n",
      "|    policy_gradient_loss | -0.00013     |\n",
      "|    reward               | -0.032218944 |\n",
      "|    std                  | 1.23         |\n",
      "|    value_loss           | 51.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 2391        |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024068644 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.0696      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | -0.8845985  |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 58.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 130        |\n",
      "|    time_elapsed         | 2410       |\n",
      "|    total_timesteps      | 266240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02491856 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.1      |\n",
      "|    explained_variance   | 0.00686    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 35.6       |\n",
      "|    n_updates            | 1290       |\n",
      "|    policy_gradient_loss | -0.00351   |\n",
      "|    reward               | 0.10365869 |\n",
      "|    std                  | 1.23       |\n",
      "|    value_loss           | 81         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 2429        |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025849765 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.0326      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.5        |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    reward               | 1.9974821   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 2447        |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044146698 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.00969     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    reward               | 2.5783622   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 133       |\n",
      "|    time_elapsed         | 2466      |\n",
      "|    total_timesteps      | 272384    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0276292 |\n",
      "|    clip_fraction        | 0.286     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -47.2     |\n",
      "|    explained_variance   | 0.00333   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 58.3      |\n",
      "|    n_updates            | 1320      |\n",
      "|    policy_gradient_loss | -0.00485  |\n",
      "|    reward               | 3.227999  |\n",
      "|    std                  | 1.24      |\n",
      "|    value_loss           | 141       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 2484        |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021323288 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.0189      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.2        |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -5.3e-05    |\n",
      "|    reward               | -4.971699   |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 2503        |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038044363 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | 0.00856     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00648    |\n",
      "|    reward               | -1.8785001  |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 57.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 2521        |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038501356 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | -0.000808   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.4        |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    reward               | 1.5546845   |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 137        |\n",
      "|    time_elapsed         | 2540       |\n",
      "|    total_timesteps      | 280576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02670377 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.4      |\n",
      "|    explained_variance   | 0.0125     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 215        |\n",
      "|    n_updates            | 1360       |\n",
      "|    policy_gradient_loss | -0.00569   |\n",
      "|    reward               | 1.7268038  |\n",
      "|    std                  | 1.24       |\n",
      "|    value_loss           | 342        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 2559        |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026266694 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | 0.018       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.00865    |\n",
      "|    reward               | 1.4609226   |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 2577        |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048165444 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | 0.0703      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    reward               | -1.0025368  |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4124731.47\n",
      "total_reward: 3124731.47\n",
      "total_cost: 312904.10\n",
      "total_trades: 73674\n",
      "Sharpe: 0.659\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 2596        |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040085934 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | -0.00514    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    reward               | 1.0715623   |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 382         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 2615        |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030705456 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.0062      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 194         |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.000807   |\n",
      "|    reward               | 18.832272   |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 404         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 2633        |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051289707 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | -0.138      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.2        |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | 0.00229     |\n",
      "|    reward               | -1.6205779  |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 92.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 2651        |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036354013 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | -0.00447    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 192         |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    reward               | 0.97311145  |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 653         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 2670        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027307838 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.00561     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 503         |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    reward               | 9.445848    |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 958         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 2687        |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035121463 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | 0.0243      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.6        |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | 0.000743    |\n",
      "|    reward               | -1.9188267  |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 232         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 2706       |\n",
      "|    total_timesteps      | 299008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01843504 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.7      |\n",
      "|    explained_variance   | 0.0183     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 350        |\n",
      "|    n_updates            | 1450       |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    reward               | 1.946793   |\n",
      "|    std                  | 1.26       |\n",
      "|    value_loss           | 521        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 147        |\n",
      "|    time_elapsed         | 2724       |\n",
      "|    total_timesteps      | 301056     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03546518 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.8      |\n",
      "|    explained_variance   | 0.0131     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 87         |\n",
      "|    n_updates            | 1460       |\n",
      "|    policy_gradient_loss | -0.0017    |\n",
      "|    reward               | -1.3442798 |\n",
      "|    std                  | 1.26       |\n",
      "|    value_loss           | 213        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 2742        |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023064978 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.9       |\n",
      "|    explained_variance   | 0.0188      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 302         |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | -0.000872   |\n",
      "|    reward               | 2.397882    |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 675         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 149        |\n",
      "|    time_elapsed         | 2761       |\n",
      "|    total_timesteps      | 305152     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03442894 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.9      |\n",
      "|    explained_variance   | 0.00204    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.5       |\n",
      "|    n_updates            | 1480       |\n",
      "|    policy_gradient_loss | -0.00271   |\n",
      "|    reward               | 0.69794035 |\n",
      "|    std                  | 1.27       |\n",
      "|    value_loss           | 50.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 2780        |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018661104 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | 0.0162      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 608         |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    reward               | 0.484712    |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 533         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 151          |\n",
      "|    time_elapsed         | 2798         |\n",
      "|    total_timesteps      | 309248       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120823365 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48          |\n",
      "|    explained_variance   | 0.0252       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 489          |\n",
      "|    n_updates            | 1500         |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | 1.1801353    |\n",
      "|    std                  | 1.27         |\n",
      "|    value_loss           | 673          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 152        |\n",
      "|    time_elapsed         | 2816       |\n",
      "|    total_timesteps      | 311296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02918168 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48        |\n",
      "|    explained_variance   | 0.00751    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 54.4       |\n",
      "|    n_updates            | 1510       |\n",
      "|    policy_gradient_loss | -0.00381   |\n",
      "|    reward               | -3.821835  |\n",
      "|    std                  | 1.27       |\n",
      "|    value_loss           | 152        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 2836        |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022106104 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | -0.00179    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.3        |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | -1.1636146  |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 393         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4380277.39\n",
      "total_reward: 3380277.39\n",
      "total_cost: 241700.80\n",
      "total_trades: 69004\n",
      "Sharpe: 0.684\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 2855        |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025677623 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 191         |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    reward               | -0.42176354 |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 408         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 2873        |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031894267 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.0134      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 446         |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | 0.3328854   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 444         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 2892        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053192757 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | -0.088      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | 0.0134      |\n",
      "|    reward               | -0.2907942  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 2911        |\n",
      "|    total_timesteps      | 321536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031658515 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | 0.0316      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 162         |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | 0.00351     |\n",
      "|    reward               | -2.3202424  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 621         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 2930        |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017545175 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | 0.067       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 175         |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    reward               | -16.79399   |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 623         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 2949        |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023000715 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | -0.128      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    reward               | 0.32856396  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 80.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 2968        |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037294596 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | 0.0984      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 178         |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | 0.00223     |\n",
      "|    reward               | 1.3174218   |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 320         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 2987        |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023496024 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.4       |\n",
      "|    explained_variance   | 0.0972      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 166         |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    reward               | 10.545273   |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 349         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 162        |\n",
      "|    time_elapsed         | 3006       |\n",
      "|    total_timesteps      | 331776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03932145 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.4      |\n",
      "|    explained_variance   | 0.072      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 75.4       |\n",
      "|    n_updates            | 1610       |\n",
      "|    policy_gradient_loss | 0.00388    |\n",
      "|    reward               | -1.1972967 |\n",
      "|    std                  | 1.29       |\n",
      "|    value_loss           | 424        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 163        |\n",
      "|    time_elapsed         | 3025       |\n",
      "|    total_timesteps      | 333824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05484241 |\n",
      "|    clip_fraction        | 0.379      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.4      |\n",
      "|    explained_variance   | 0.00507    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.2       |\n",
      "|    n_updates            | 1620       |\n",
      "|    policy_gradient_loss | -0.0013    |\n",
      "|    reward               | -1.6034193 |\n",
      "|    std                  | 1.29       |\n",
      "|    value_loss           | 51.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 3044        |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033441056 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.5       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 165         |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    reward               | 0.19784924  |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 324         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 3062        |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038186423 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.6       |\n",
      "|    explained_variance   | 0.0701      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | 0.00539     |\n",
      "|    reward               | 9.816934    |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 3081        |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035666447 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.6       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | 0.000171    |\n",
      "|    reward               | 0.91995776  |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 3100        |\n",
      "|    total_timesteps      | 342016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041685224 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.0497      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | 1.5469298   |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 168        |\n",
      "|    time_elapsed         | 3118       |\n",
      "|    total_timesteps      | 344064     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04009609 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.8      |\n",
      "|    explained_variance   | -0.00983   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 44.3       |\n",
      "|    n_updates            | 1670       |\n",
      "|    policy_gradient_loss | 0.00347    |\n",
      "|    reward               | 4.182146   |\n",
      "|    std                  | 1.3        |\n",
      "|    value_loss           | 136        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4467047.91\n",
      "total_reward: 3467047.91\n",
      "total_cost: 294943.50\n",
      "total_trades: 71603\n",
      "Sharpe: 0.729\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 3136        |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038643934 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.8       |\n",
      "|    explained_variance   | 0.013       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | 0.0121      |\n",
      "|    reward               | -2.8108046  |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 75.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 170        |\n",
      "|    time_elapsed         | 3155       |\n",
      "|    total_timesteps      | 348160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04163079 |\n",
      "|    clip_fraction        | 0.334      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.9      |\n",
      "|    explained_variance   | 0.0259     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 65.8       |\n",
      "|    n_updates            | 1690       |\n",
      "|    policy_gradient_loss | -0.00927   |\n",
      "|    reward               | -2.4823692 |\n",
      "|    std                  | 1.31       |\n",
      "|    value_loss           | 84.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 3173        |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045152504 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | 0.0393      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | 0.00546     |\n",
      "|    reward               | -1.4113001  |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 62.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 3192        |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026127225 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49         |\n",
      "|    explained_variance   | 0.0106      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | 1.3291919   |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 59.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 173        |\n",
      "|    time_elapsed         | 3210       |\n",
      "|    total_timesteps      | 354304     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0649821  |\n",
      "|    clip_fraction        | 0.455      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49        |\n",
      "|    explained_variance   | -0.0378    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.67       |\n",
      "|    n_updates            | 1720       |\n",
      "|    policy_gradient_loss | 0.00308    |\n",
      "|    reward               | -1.4441853 |\n",
      "|    std                  | 1.31       |\n",
      "|    value_loss           | 22.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 174        |\n",
      "|    time_elapsed         | 3229       |\n",
      "|    total_timesteps      | 356352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04933043 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.1      |\n",
      "|    explained_variance   | 0.00952    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.8       |\n",
      "|    n_updates            | 1730       |\n",
      "|    policy_gradient_loss | -0.00454   |\n",
      "|    reward               | 0.2339456  |\n",
      "|    std                  | 1.32       |\n",
      "|    value_loss           | 65.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 3247        |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028245138 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | 0.0158      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.2        |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | 0.0016      |\n",
      "|    reward               | 0.013383228 |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 3266        |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027932055 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | -0.0113     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | 0.00324     |\n",
      "|    reward               | 2.5314062   |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 235         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 177          |\n",
      "|    time_elapsed         | 3284         |\n",
      "|    total_timesteps      | 362496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012052505  |\n",
      "|    clip_fraction        | 0.0896       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.2        |\n",
      "|    explained_variance   | 0.00218      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 339          |\n",
      "|    n_updates            | 1760         |\n",
      "|    policy_gradient_loss | -0.00768     |\n",
      "|    reward               | -0.034184713 |\n",
      "|    std                  | 1.32         |\n",
      "|    value_loss           | 626          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 3302        |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011798252 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.074       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 212         |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    reward               | -1.1116471  |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 817         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 3320        |\n",
      "|    total_timesteps      | 366592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029077874 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.0177      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.3        |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | 0.52923256  |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 3339        |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030432355 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | -1.275505   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 46.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 3357        |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014612632 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.044       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 352         |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    reward               | 0.1821994   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 733         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 182        |\n",
      "|    time_elapsed         | 3376       |\n",
      "|    total_timesteps      | 372736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0401437  |\n",
      "|    clip_fraction        | 0.377      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.3      |\n",
      "|    explained_variance   | 0.0238     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 242        |\n",
      "|    n_updates            | 1810       |\n",
      "|    policy_gradient_loss | 0.000886   |\n",
      "|    reward               | -3.6382928 |\n",
      "|    std                  | 1.33       |\n",
      "|    value_loss           | 272        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4208489.38\n",
      "total_reward: 3208489.38\n",
      "total_cost: 228186.78\n",
      "total_trades: 66654\n",
      "Sharpe: 0.695\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 3395        |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042828526 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.0264      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | 0.0118      |\n",
      "|    reward               | -1.9532669  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 3414        |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029489439 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | -0.0412     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 253         |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | 0.00179     |\n",
      "|    reward               | -2.4222865  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 311         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 3432        |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011973991 |\n",
      "|    clip_fraction        | 0.0881      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | 0.0486      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 388         |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    reward               | 5.833486    |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 678         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 3451        |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031367686 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | 0.0872      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.1        |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | 0.00191     |\n",
      "|    reward               | -0.8272934  |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 83          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 3472        |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037179105 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | 0.00517     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.5        |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    reward               | 2.2903903   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 3490        |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019798856 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.051       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 322         |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | 1.3723443   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 431         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 3509        |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027100973 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.7       |\n",
      "|    explained_variance   | 0.00218     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 284         |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    reward               | -4.862699   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 680         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 3527        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042148102 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.7       |\n",
      "|    explained_variance   | -0.123      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | 0.00687     |\n",
      "|    reward               | 4.5065045   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 3545        |\n",
      "|    total_timesteps      | 391168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022744235 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.8       |\n",
      "|    explained_variance   | 0.0324      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.1        |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | 1.0945566   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 3564        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031762987 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.8       |\n",
      "|    explained_variance   | 0.0535      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.7        |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | 0.00161     |\n",
      "|    reward               | -3.223391   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 3583        |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021430548 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.8       |\n",
      "|    explained_variance   | 0.0517      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.000782   |\n",
      "|    reward               | -1.465621   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 54          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 3601        |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038360067 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | 0.0515      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.5        |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    reward               | 1.1555535   |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 3620        |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031914342 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | 0.0708      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | 0.000395    |\n",
      "|    reward               | 0.34016266  |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 196       |\n",
      "|    time_elapsed         | 3638      |\n",
      "|    total_timesteps      | 401408    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0426023 |\n",
      "|    clip_fraction        | 0.333     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -50       |\n",
      "|    explained_variance   | 0.053     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 121       |\n",
      "|    n_updates            | 1950      |\n",
      "|    policy_gradient_loss | -0.00412  |\n",
      "|    reward               | 2.4452698 |\n",
      "|    std                  | 1.36      |\n",
      "|    value_loss           | 186       |\n",
      "---------------------------------------\n",
      "day: 2892, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4051915.74\n",
      "total_reward: 3051915.74\n",
      "total_cost: 238279.67\n",
      "total_trades: 67880\n",
      "Sharpe: 0.755\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 3656        |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060394898 |\n",
      "|    clip_fraction        | 0.455       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.1       |\n",
      "|    explained_variance   | 0.0474      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 1960        |\n",
      "|    policy_gradient_loss | 0.00181     |\n",
      "|    reward               | 1.1887426   |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 3675        |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029193569 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.2       |\n",
      "|    explained_variance   | 0.0148      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.5        |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | 0.0016      |\n",
      "|    reward               | 0.48440954  |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 67.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 3693        |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024479996 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.2       |\n",
      "|    explained_variance   | 0.0809      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 1980        |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | 5.728036    |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 3712        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038084753 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.2       |\n",
      "|    explained_variance   | 0.0416      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.00024    |\n",
      "|    reward               | 1.9312627   |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 73.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 3731        |\n",
      "|    total_timesteps      | 411648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023953006 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.3       |\n",
      "|    explained_variance   | -0.0103     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.9        |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.00994    |\n",
      "|    reward               | -0.5819239  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 204         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 3749        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029617012 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.4       |\n",
      "|    explained_variance   | 0.0891      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.4        |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    reward               | -14.305208  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 3767        |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018755484 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.4       |\n",
      "|    explained_variance   | -0.00918    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 340         |\n",
      "|    n_updates            | 2020        |\n",
      "|    policy_gradient_loss | 0.00133     |\n",
      "|    reward               | -1.29524    |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 509         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 204        |\n",
      "|    time_elapsed         | 3787       |\n",
      "|    total_timesteps      | 417792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03488815 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.5      |\n",
      "|    explained_variance   | 0.0722     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.2       |\n",
      "|    n_updates            | 2030       |\n",
      "|    policy_gradient_loss | -0.000638  |\n",
      "|    reward               | 0.561074   |\n",
      "|    std                  | 1.38       |\n",
      "|    value_loss           | 37.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 3806        |\n",
      "|    total_timesteps      | 419840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021028236 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | 0.0481      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.6        |\n",
      "|    n_updates            | 2040        |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    reward               | 3.4746218   |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 3825        |\n",
      "|    total_timesteps      | 421888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029698033 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | 0.0647      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.6        |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | 0.0118      |\n",
      "|    reward               | -4.9372525  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 3844        |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025748353 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | 0.0385      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 2060        |\n",
      "|    policy_gradient_loss | 0.000784    |\n",
      "|    reward               | -1.7643788  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 55.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 3863        |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027406257 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.057       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.9        |\n",
      "|    n_updates            | 2070        |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | -4.4800754  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 90.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 3882        |\n",
      "|    total_timesteps      | 428032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013034955 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.0499      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.4        |\n",
      "|    n_updates            | 2080        |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | 5.1935954   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 3901        |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038149383 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.0286      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.9        |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | 0.00495     |\n",
      "|    reward               | -0.24564222 |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 80.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4601347.37\n",
      "total_reward: 3601347.37\n",
      "total_cost: 249525.97\n",
      "total_trades: 67278\n",
      "Sharpe: 0.782\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 3920        |\n",
      "|    total_timesteps      | 432128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035527274 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.8       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 2100        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 0.6197416   |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 3939        |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018837664 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.8       |\n",
      "|    explained_variance   | 0.0898      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.9        |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -0.22133984 |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 3957        |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015017835 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.8       |\n",
      "|    explained_variance   | 0.0632      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 249         |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | -1.9531817  |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 284         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 3976        |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047296382 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.9       |\n",
      "|    explained_variance   | -0.0379     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 2130        |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    reward               | -0.7982687  |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 215        |\n",
      "|    time_elapsed         | 3996       |\n",
      "|    total_timesteps      | 440320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02713729 |\n",
      "|    clip_fraction        | 0.258      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.9      |\n",
      "|    explained_variance   | 0.0953     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 51.6       |\n",
      "|    n_updates            | 2140       |\n",
      "|    policy_gradient_loss | -0.00842   |\n",
      "|    reward               | 1.0311764  |\n",
      "|    std                  | 1.4        |\n",
      "|    value_loss           | 101        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 4014        |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021320872 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.0898      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47          |\n",
      "|    n_updates            | 2150        |\n",
      "|    policy_gradient_loss | -0.00195    |\n",
      "|    reward               | 0.5105036   |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 4033        |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041889384 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.0143      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    reward               | -1.5542676  |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 4052        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022138728 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.0891      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | 0.041742682 |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 58.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 4070        |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025968466 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.5        |\n",
      "|    n_updates            | 2180        |\n",
      "|    policy_gradient_loss | 0.00192     |\n",
      "|    reward               | -0.57639825 |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 89.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 220         |\n",
      "|    time_elapsed         | 4088        |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028520733 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.0875      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.1        |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | 0.00147     |\n",
      "|    reward               | 1.7229679   |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 98.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 221        |\n",
      "|    time_elapsed         | 4107       |\n",
      "|    total_timesteps      | 452608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03880212 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.1      |\n",
      "|    explained_variance   | 0.144      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.3       |\n",
      "|    n_updates            | 2200       |\n",
      "|    policy_gradient_loss | -0.00236   |\n",
      "|    reward               | -1.4925205 |\n",
      "|    std                  | 1.41       |\n",
      "|    value_loss           | 30.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 4126        |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013230957 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.1       |\n",
      "|    explained_variance   | 0.0879      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.4        |\n",
      "|    n_updates            | 2210        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.4990961  |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 4145        |\n",
      "|    total_timesteps      | 456704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021413736 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.1       |\n",
      "|    explained_variance   | 0.0215      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.7        |\n",
      "|    n_updates            | 2220        |\n",
      "|    policy_gradient_loss | -0.00126    |\n",
      "|    reward               | 3.7953184   |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 361         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 4163        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050590113 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.1       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 2230        |\n",
      "|    policy_gradient_loss | 0.00354     |\n",
      "|    reward               | 2.378769    |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 75.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4615392.49\n",
      "total_reward: 3615392.49\n",
      "total_cost: 263065.92\n",
      "total_trades: 68428\n",
      "Sharpe: 0.768\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 225        |\n",
      "|    time_elapsed         | 4182       |\n",
      "|    total_timesteps      | 460800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02850909 |\n",
      "|    clip_fraction        | 0.233      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.2      |\n",
      "|    explained_variance   | 0.0667     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.6       |\n",
      "|    n_updates            | 2240       |\n",
      "|    policy_gradient_loss | -0.00736   |\n",
      "|    reward               | 1.9826882  |\n",
      "|    std                  | 1.42       |\n",
      "|    value_loss           | 202        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 4200        |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040230766 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.0622      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.000801   |\n",
      "|    reward               | 4.945061    |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 4218        |\n",
      "|    total_timesteps      | 464896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026707476 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.00956     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.5        |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | -0.32836598 |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 4238        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02309496  |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -0.23212464 |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 4257        |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011105514 |\n",
      "|    clip_fraction        | 0.0824      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    reward               | 0.84774077  |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 4275        |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030939866 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.0512      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.6        |\n",
      "|    n_updates            | 2290        |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    reward               | 1.5540175   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 340         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 4293        |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038913492 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38          |\n",
      "|    n_updates            | 2300        |\n",
      "|    policy_gradient_loss | -3.86e-06   |\n",
      "|    reward               | -2.6815245  |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 84.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 4311        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011757443 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.6       |\n",
      "|    explained_variance   | 0.0369      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 613         |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | -0.6497427  |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 457         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 4330        |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036700964 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.6       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | 0.0067      |\n",
      "|    reward               | 2.3361719   |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 4347        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021366246 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.6       |\n",
      "|    explained_variance   | 0.00309     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.6        |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    reward               | 0.891635    |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 235        |\n",
      "|    time_elapsed         | 4366       |\n",
      "|    total_timesteps      | 481280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03695299 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.7      |\n",
      "|    explained_variance   | -0.00212   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 53.7       |\n",
      "|    n_updates            | 2340       |\n",
      "|    policy_gradient_loss | -0.00406   |\n",
      "|    reward               | -4.001216  |\n",
      "|    std                  | 1.44       |\n",
      "|    value_loss           | 93.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 4385        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033863895 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.7       |\n",
      "|    explained_variance   | 0.0942      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.9        |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | 0.00123     |\n",
      "|    reward               | 2.1586256   |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 4404        |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040505588 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.7       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.2        |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | 0.00961     |\n",
      "|    reward               | 0.6648431   |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 4423        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023732964 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.8       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 2370        |\n",
      "|    policy_gradient_loss | -0.00517    |\n",
      "|    reward               | -1.1506057  |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 43          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3162848.16\n",
      "total_reward: 2162848.16\n",
      "total_cost: 247579.18\n",
      "total_trades: 68281\n",
      "Sharpe: 0.531\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 239        |\n",
      "|    time_elapsed         | 4442       |\n",
      "|    total_timesteps      | 489472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03547837 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.9      |\n",
      "|    explained_variance   | 0.135      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32         |\n",
      "|    n_updates            | 2380       |\n",
      "|    policy_gradient_loss | 0.00411    |\n",
      "|    reward               | 3.3325956  |\n",
      "|    std                  | 1.45       |\n",
      "|    value_loss           | 99         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 4460        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018109404 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52         |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.2        |\n",
      "|    n_updates            | 2390        |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    reward               | -3.979525   |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 241        |\n",
      "|    time_elapsed         | 4479       |\n",
      "|    total_timesteps      | 493568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01908117 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52        |\n",
      "|    explained_variance   | 0.0523     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38.6       |\n",
      "|    n_updates            | 2400       |\n",
      "|    policy_gradient_loss | -0.000562  |\n",
      "|    reward               | -1.652224  |\n",
      "|    std                  | 1.46       |\n",
      "|    value_loss           | 81.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 4498        |\n",
      "|    total_timesteps      | 495616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019954553 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52         |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 2410        |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    reward               | 1.5785365   |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 82.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 243        |\n",
      "|    time_elapsed         | 4517       |\n",
      "|    total_timesteps      | 497664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02105847 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.1      |\n",
      "|    explained_variance   | 0.136      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 48.9       |\n",
      "|    n_updates            | 2420       |\n",
      "|    policy_gradient_loss | -0.00433   |\n",
      "|    reward               | -0.1198037 |\n",
      "|    std                  | 1.46       |\n",
      "|    value_loss           | 121        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 4537        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017483197 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.1       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.2        |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    reward               | -0.10812385 |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 4556        |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025371158 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.2       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | 0.000663    |\n",
      "|    reward               | -1.8783741  |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 44.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 4575        |\n",
      "|    total_timesteps      | 503808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030598134 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.8        |\n",
      "|    n_updates            | 2450        |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    reward               | 2.1049185   |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 247         |\n",
      "|    time_elapsed         | 4594        |\n",
      "|    total_timesteps      | 505856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011481867 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.2        |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | 7.1501155   |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 4613        |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036115643 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.4        |\n",
      "|    n_updates            | 2470        |\n",
      "|    policy_gradient_loss | 0.00163     |\n",
      "|    reward               | -0.71232367 |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 78.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 249         |\n",
      "|    time_elapsed         | 4632        |\n",
      "|    total_timesteps      | 509952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023812393 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 2480        |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    reward               | 3.28864     |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 72          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 250         |\n",
      "|    time_elapsed         | 4651        |\n",
      "|    total_timesteps      | 512000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022226067 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.3        |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    reward               | -6.575529   |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 251        |\n",
      "|    time_elapsed         | 4670       |\n",
      "|    total_timesteps      | 514048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03623513 |\n",
      "|    clip_fraction        | 0.394      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.4      |\n",
      "|    explained_variance   | 0.0116     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 106        |\n",
      "|    n_updates            | 2500       |\n",
      "|    policy_gradient_loss | -0.000422  |\n",
      "|    reward               | 1.5460302  |\n",
      "|    std                  | 1.48       |\n",
      "|    value_loss           | 179        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 252         |\n",
      "|    time_elapsed         | 4689        |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041636243 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.5       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    reward               | -0.73380005 |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 50          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2902180.05\n",
      "total_reward: 1902180.05\n",
      "total_cost: 254746.03\n",
      "total_trades: 68856\n",
      "Sharpe: 0.498\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 4708        |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027754877 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.5       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.5        |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | 0.19347754  |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 254         |\n",
      "|    time_elapsed         | 4727        |\n",
      "|    total_timesteps      | 520192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012844643 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62          |\n",
      "|    n_updates            | 2530        |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    reward               | -3.231666   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 93.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 4747        |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019214742 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 2540        |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | 1.166544    |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 59.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 4765        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022401845 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63          |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | 0.000709    |\n",
      "|    reward               | 8.019451    |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 91.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 257         |\n",
      "|    time_elapsed         | 4784        |\n",
      "|    total_timesteps      | 526336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012825928 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.8        |\n",
      "|    n_updates            | 2560        |\n",
      "|    policy_gradient_loss | -0.0022     |\n",
      "|    reward               | -0.31971738 |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 4802        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020302514 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | 0.000743    |\n",
      "|    reward               | 1.0098661   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 96.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 4821        |\n",
      "|    total_timesteps      | 530432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032465838 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.00125    |\n",
      "|    reward               | 0.23134273  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 83.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 260         |\n",
      "|    time_elapsed         | 4840        |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026604427 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.2        |\n",
      "|    n_updates            | 2590        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | -0.86780673 |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 99.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 4859        |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047373507 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.8       |\n",
      "|    explained_variance   | 0.0688      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | 0.0028      |\n",
      "|    reward               | 1.4279759   |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 225         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 262         |\n",
      "|    time_elapsed         | 4878        |\n",
      "|    total_timesteps      | 536576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046588607 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.8       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 2610        |\n",
      "|    policy_gradient_loss | -0.000519   |\n",
      "|    reward               | 0.083274394 |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 263          |\n",
      "|    time_elapsed         | 4897         |\n",
      "|    total_timesteps      | 538624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015679087  |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -52.9        |\n",
      "|    explained_variance   | 0.147        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.4         |\n",
      "|    n_updates            | 2620         |\n",
      "|    policy_gradient_loss | -0.00845     |\n",
      "|    reward               | -0.085680455 |\n",
      "|    std                  | 1.5          |\n",
      "|    value_loss           | 122          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 264         |\n",
      "|    time_elapsed         | 4919        |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018714588 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.7        |\n",
      "|    n_updates            | 2630        |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    reward               | -2.2980816  |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 265        |\n",
      "|    time_elapsed         | 4937       |\n",
      "|    total_timesteps      | 542720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02935522 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.9      |\n",
      "|    explained_variance   | 0.0442     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.1       |\n",
      "|    n_updates            | 2640       |\n",
      "|    policy_gradient_loss | -0.000866  |\n",
      "|    reward               | 0.30477047 |\n",
      "|    std                  | 1.51       |\n",
      "|    value_loss           | 53.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 4957        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025812607 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53         |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    reward               | -2.3288708  |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3176474.50\n",
      "total_reward: 2176474.50\n",
      "total_cost: 251054.76\n",
      "total_trades: 69269\n",
      "Sharpe: 0.606\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 267        |\n",
      "|    time_elapsed         | 4975       |\n",
      "|    total_timesteps      | 546816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02696086 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53        |\n",
      "|    explained_variance   | 0.148      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23         |\n",
      "|    n_updates            | 2660       |\n",
      "|    policy_gradient_loss | -0.000982  |\n",
      "|    reward               | -1.2919749 |\n",
      "|    std                  | 1.51       |\n",
      "|    value_loss           | 58.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 268         |\n",
      "|    time_elapsed         | 4994        |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022985328 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53         |\n",
      "|    explained_variance   | 0.0753      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.9        |\n",
      "|    n_updates            | 2670        |\n",
      "|    policy_gradient_loss | 0.000293    |\n",
      "|    reward               | -0.51826453 |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 59.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 269         |\n",
      "|    time_elapsed         | 5013        |\n",
      "|    total_timesteps      | 550912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052588705 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | -0.00594    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.93        |\n",
      "|    n_updates            | 2680        |\n",
      "|    policy_gradient_loss | 0.003       |\n",
      "|    reward               | 0.6434632   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 5031        |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043213323 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.7        |\n",
      "|    n_updates            | 2690        |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    reward               | 2.5152085   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 271         |\n",
      "|    time_elapsed         | 5050        |\n",
      "|    total_timesteps      | 555008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024286028 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.2       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.4        |\n",
      "|    n_updates            | 2700        |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    reward               | 8.722736    |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 272          |\n",
      "|    time_elapsed         | 5069         |\n",
      "|    total_timesteps      | 557056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.021718038  |\n",
      "|    clip_fraction        | 0.211        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -53.2        |\n",
      "|    explained_variance   | 0.048        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.9         |\n",
      "|    n_updates            | 2710         |\n",
      "|    policy_gradient_loss | -0.00975     |\n",
      "|    reward               | -0.063082896 |\n",
      "|    std                  | 1.52         |\n",
      "|    value_loss           | 73.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 273         |\n",
      "|    time_elapsed         | 5088        |\n",
      "|    total_timesteps      | 559104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020913972 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.3       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.4        |\n",
      "|    n_updates            | 2720        |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    reward               | -0.4266848  |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 274         |\n",
      "|    time_elapsed         | 5107        |\n",
      "|    total_timesteps      | 561152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035894424 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.3       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.1        |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | 0.00464     |\n",
      "|    reward               | -12.104233  |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 5127        |\n",
      "|    total_timesteps      | 563200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022536509 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.4       |\n",
      "|    explained_variance   | 0.0194      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 2740        |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | -0.3096752  |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 72.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 5145        |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038277373 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.5       |\n",
      "|    explained_variance   | -0.0225     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    reward               | 1.1586242   |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 5164        |\n",
      "|    total_timesteps      | 567296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029609486 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.5       |\n",
      "|    explained_variance   | 0.029       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 203         |\n",
      "|    n_updates            | 2760        |\n",
      "|    policy_gradient_loss | 0.000678    |\n",
      "|    reward               | 0.15084499  |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 276         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 278         |\n",
      "|    time_elapsed         | 5182        |\n",
      "|    total_timesteps      | 569344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038755544 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.5       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 2770        |\n",
      "|    policy_gradient_loss | 0.00452     |\n",
      "|    reward               | 3.4645038   |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 84.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 279         |\n",
      "|    time_elapsed         | 5201        |\n",
      "|    total_timesteps      | 571392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02994398  |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 2780        |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    reward               | -0.30330116 |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 5220        |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020845447 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.5        |\n",
      "|    n_updates            | 2790        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 1.9607651   |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 66.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 5239        |\n",
      "|    total_timesteps      | 575488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026937991 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | 0.0751      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.1        |\n",
      "|    n_updates            | 2800        |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    reward               | 5.484944    |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 333         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4213003.06\n",
      "total_reward: 3213003.06\n",
      "total_cost: 259235.19\n",
      "total_trades: 69494\n",
      "Sharpe: 0.645\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 5258        |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027587326 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | 0.0596      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82          |\n",
      "|    n_updates            | 2810        |\n",
      "|    policy_gradient_loss | 0.00274     |\n",
      "|    reward               | -0.34151483 |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 283         |\n",
      "|    time_elapsed         | 5276        |\n",
      "|    total_timesteps      | 579584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017485652 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | 0.0333      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 2820        |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    reward               | 1.4473597   |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 344         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 284         |\n",
      "|    time_elapsed         | 5294        |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021833792 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.7       |\n",
      "|    explained_variance   | 0.0538      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.1        |\n",
      "|    n_updates            | 2830        |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    reward               | 1.7965947   |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 76.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 285        |\n",
      "|    time_elapsed         | 5312       |\n",
      "|    total_timesteps      | 583680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02193291 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.7      |\n",
      "|    explained_variance   | 0.0578     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.7       |\n",
      "|    n_updates            | 2840       |\n",
      "|    policy_gradient_loss | -0.00996   |\n",
      "|    reward               | 2.3700726  |\n",
      "|    std                  | 1.55       |\n",
      "|    value_loss           | 60.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 5331        |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041680045 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.8       |\n",
      "|    explained_variance   | 0.0904      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.88        |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | 0.000715    |\n",
      "|    reward               | -0.5577633  |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 5349        |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029278656 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.8       |\n",
      "|    explained_variance   | 0.0465      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | 0.00166     |\n",
      "|    reward               | 0.43123364  |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 86.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 5368        |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018133843 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.0959      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.9        |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 1.5661275   |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 86.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 289         |\n",
      "|    time_elapsed         | 5386        |\n",
      "|    total_timesteps      | 591872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029447274 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.0121      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 2880        |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    reward               | 5.574857    |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 77.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 5405        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041607015 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54         |\n",
      "|    explained_variance   | 0.0316      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    reward               | -0.43281043 |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 91.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 291         |\n",
      "|    time_elapsed         | 5423        |\n",
      "|    total_timesteps      | 595968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038627893 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54         |\n",
      "|    explained_variance   | 0.0775      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.7        |\n",
      "|    n_updates            | 2900        |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | 0.010650344 |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 84.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 5442        |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021341184 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.0251      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.1        |\n",
      "|    n_updates            | 2910        |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    reward               | -0.05550073 |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 86.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 293         |\n",
      "|    time_elapsed         | 5461        |\n",
      "|    total_timesteps      | 600064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061850194 |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.0245      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 2920        |\n",
      "|    policy_gradient_loss | 0.00404     |\n",
      "|    reward               | 0.7495285   |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 5479        |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021245858 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.0379      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 245         |\n",
      "|    n_updates            | 2930        |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    reward               | -0.0189144  |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 504         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 295        |\n",
      "|    time_elapsed         | 5498       |\n",
      "|    total_timesteps      | 604160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03872881 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.2      |\n",
      "|    explained_variance   | 0.0209     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 43.4       |\n",
      "|    n_updates            | 2940       |\n",
      "|    policy_gradient_loss | -0.00172   |\n",
      "|    reward               | -4.146906  |\n",
      "|    std                  | 1.57       |\n",
      "|    value_loss           | 116        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4137662.59\n",
      "total_reward: 3137662.59\n",
      "total_cost: 344944.10\n",
      "total_trades: 75674\n",
      "Sharpe: 0.724\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 5518        |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037239254 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.2       |\n",
      "|    explained_variance   | 0.0311      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    reward               | -1.736933   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 35.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 5536        |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028486956 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.0593      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.5        |\n",
      "|    n_updates            | 2960        |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    reward               | -2.295119   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 95.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 298         |\n",
      "|    time_elapsed         | 5555        |\n",
      "|    total_timesteps      | 610304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014016111 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.3        |\n",
      "|    n_updates            | 2970        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | -2.8075547  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 78.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 5574        |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030883804 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.0159      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 2980        |\n",
      "|    policy_gradient_loss | -0.00919    |\n",
      "|    reward               | -0.96850675 |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 73.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 5593        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034156524 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | 0.0207      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.4        |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    reward               | 0.5783243   |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 65.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 301        |\n",
      "|    time_elapsed         | 5612       |\n",
      "|    total_timesteps      | 616448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03754194 |\n",
      "|    clip_fraction        | 0.327      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.6      |\n",
      "|    explained_variance   | 0.0145     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 75.1       |\n",
      "|    n_updates            | 3000       |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    reward               | 1.2539412  |\n",
      "|    std                  | 1.6        |\n",
      "|    value_loss           | 189        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 5631        |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030579902 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.7       |\n",
      "|    explained_variance   | 0.099       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 3010        |\n",
      "|    policy_gradient_loss | 0.00641     |\n",
      "|    reward               | -11.020078  |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 77.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 303         |\n",
      "|    time_elapsed         | 5650        |\n",
      "|    total_timesteps      | 620544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039041363 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.7       |\n",
      "|    explained_variance   | -0.173      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 3020        |\n",
      "|    policy_gradient_loss | -0.00225    |\n",
      "|    reward               | -3.4915028  |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 5669        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023597747 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.7       |\n",
      "|    explained_variance   | 0.18        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 3030        |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | -2.1516178  |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 95.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 5689        |\n",
      "|    total_timesteps      | 624640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034558747 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.7       |\n",
      "|    explained_variance   | 0.0901      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.4        |\n",
      "|    n_updates            | 3040        |\n",
      "|    policy_gradient_loss | 0.00206     |\n",
      "|    reward               | -1.2153965  |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 72.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 5708        |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035850357 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.8       |\n",
      "|    explained_variance   | -0.0447     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 3050        |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    reward               | -4.043875   |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 307        |\n",
      "|    time_elapsed         | 5728       |\n",
      "|    total_timesteps      | 628736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02783813 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.9      |\n",
      "|    explained_variance   | 0.0118     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.4       |\n",
      "|    n_updates            | 3060       |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    reward               | 2.6682644  |\n",
      "|    std                  | 1.61       |\n",
      "|    value_loss           | 80.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 308         |\n",
      "|    time_elapsed         | 5748        |\n",
      "|    total_timesteps      | 630784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023921318 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.9       |\n",
      "|    explained_variance   | 0.00458     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.2        |\n",
      "|    n_updates            | 3070        |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    reward               | -0.10278759 |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 309          |\n",
      "|    time_elapsed         | 5766         |\n",
      "|    total_timesteps      | 632832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.03852182   |\n",
      "|    clip_fraction        | 0.299        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -55          |\n",
      "|    explained_variance   | 0.0229       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.1         |\n",
      "|    n_updates            | 3080         |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | 0.0005111556 |\n",
      "|    std                  | 1.62         |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3826025.06\n",
      "total_reward: 2826025.06\n",
      "total_cost: 338221.63\n",
      "total_trades: 75144\n",
      "Sharpe: 0.690\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 310        |\n",
      "|    time_elapsed         | 5785       |\n",
      "|    total_timesteps      | 634880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0306346  |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55        |\n",
      "|    explained_variance   | -0.00789   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.5       |\n",
      "|    n_updates            | 3090       |\n",
      "|    policy_gradient_loss | -0.00626   |\n",
      "|    reward               | -1.2695583 |\n",
      "|    std                  | 1.62       |\n",
      "|    value_loss           | 28.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 5805        |\n",
      "|    total_timesteps      | 636928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019929808 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.0498      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.7        |\n",
      "|    n_updates            | 3100        |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | 0.16598663  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 99.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 5824        |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024250746 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.069       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.4        |\n",
      "|    n_updates            | 3110        |\n",
      "|    policy_gradient_loss | 0.000592    |\n",
      "|    reward               | -1.1984365  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 73.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 313         |\n",
      "|    time_elapsed         | 5842        |\n",
      "|    total_timesteps      | 641024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025261464 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.0806      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    reward               | -12.223717  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 5861        |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022854531 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 3130        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -1.3605943  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 75.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 5879        |\n",
      "|    total_timesteps      | 645120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02933129  |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.0232      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 3140        |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    reward               | -0.43220907 |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 96          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 5897        |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029253699 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | -0.000506   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.8        |\n",
      "|    n_updates            | 3150        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    reward               | 2.4060893   |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 5916        |\n",
      "|    total_timesteps      | 649216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035295706 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.3       |\n",
      "|    explained_variance   | -0.0202     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 3160        |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    reward               | 0.07512692  |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 318         |\n",
      "|    time_elapsed         | 5934        |\n",
      "|    total_timesteps      | 651264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035011686 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.4       |\n",
      "|    explained_variance   | -0.0126     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 3170        |\n",
      "|    policy_gradient_loss | -0.00999    |\n",
      "|    reward               | 4.5739307   |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 85.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 319        |\n",
      "|    time_elapsed         | 5953       |\n",
      "|    total_timesteps      | 653312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03977324 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.4      |\n",
      "|    explained_variance   | 0.029      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 197        |\n",
      "|    n_updates            | 3180       |\n",
      "|    policy_gradient_loss | -0.00709   |\n",
      "|    reward               | -5.7543945 |\n",
      "|    std                  | 1.64       |\n",
      "|    value_loss           | 225        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 320         |\n",
      "|    time_elapsed         | 5972        |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033312332 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.5       |\n",
      "|    explained_variance   | -0.0528     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    reward               | 0.16334407  |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 321         |\n",
      "|    time_elapsed         | 5990        |\n",
      "|    total_timesteps      | 657408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026148323 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.6       |\n",
      "|    explained_variance   | 0.0415      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.3        |\n",
      "|    n_updates            | 3200        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -0.7138136  |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 322         |\n",
      "|    time_elapsed         | 6008        |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028386204 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.7       |\n",
      "|    explained_variance   | 0.00289     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.8        |\n",
      "|    n_updates            | 3210        |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    reward               | -0.37107944 |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 323        |\n",
      "|    time_elapsed         | 6026       |\n",
      "|    total_timesteps      | 661504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03178487 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.8      |\n",
      "|    explained_variance   | 0.0465     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 33.9       |\n",
      "|    n_updates            | 3220       |\n",
      "|    policy_gradient_loss | -0.00582   |\n",
      "|    reward               | -3.2335331 |\n",
      "|    std                  | 1.66       |\n",
      "|    value_loss           | 70.6       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7055107.20\n",
      "total_reward: 6055107.20\n",
      "total_cost: 329054.29\n",
      "total_trades: 74909\n",
      "Sharpe: 0.958\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 109       |\n",
      "|    iterations           | 324       |\n",
      "|    time_elapsed         | 6044      |\n",
      "|    total_timesteps      | 663552    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0306112 |\n",
      "|    clip_fraction        | 0.274     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -55.8     |\n",
      "|    explained_variance   | -0.00807  |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 32.1      |\n",
      "|    n_updates            | 3230      |\n",
      "|    policy_gradient_loss | -0.0183   |\n",
      "|    reward               | 1.1919409 |\n",
      "|    std                  | 1.66      |\n",
      "|    value_loss           | 128       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 6062        |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027080629 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.8       |\n",
      "|    explained_variance   | 0.032       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.4        |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 0.4438137   |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 6081        |\n",
      "|    total_timesteps      | 667648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025606945 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.9       |\n",
      "|    explained_variance   | 0.0171      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.2        |\n",
      "|    n_updates            | 3250        |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    reward               | 1.5880316   |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 238         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 6100        |\n",
      "|    total_timesteps      | 669696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032742035 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.9       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 3260        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 0.19429037  |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 328         |\n",
      "|    time_elapsed         | 6118        |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026580803 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56         |\n",
      "|    explained_variance   | 0.0496      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.8        |\n",
      "|    n_updates            | 3270        |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    reward               | -0.11332401 |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 329        |\n",
      "|    time_elapsed         | 6137       |\n",
      "|    total_timesteps      | 673792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01688072 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.1      |\n",
      "|    explained_variance   | 0.0663     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 87         |\n",
      "|    n_updates            | 3280       |\n",
      "|    policy_gradient_loss | -0.00855   |\n",
      "|    reward               | -6.2489614 |\n",
      "|    std                  | 1.68       |\n",
      "|    value_loss           | 206        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 330         |\n",
      "|    time_elapsed         | 6155        |\n",
      "|    total_timesteps      | 675840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018466618 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.1       |\n",
      "|    explained_variance   | 0.0345      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 3290        |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | -12.627981  |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 60.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 6173        |\n",
      "|    total_timesteps      | 677888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019042097 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.1       |\n",
      "|    explained_variance   | 0.0733      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 3300        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -0.3432334  |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 332         |\n",
      "|    time_elapsed         | 6192        |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017194726 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.0304      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.2        |\n",
      "|    n_updates            | 3310        |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    reward               | -0.49863845 |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 333         |\n",
      "|    time_elapsed         | 6210        |\n",
      "|    total_timesteps      | 681984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014985396 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.0392      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.2        |\n",
      "|    n_updates            | 3320        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 2.0532916   |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 6228        |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035779655 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 3330        |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    reward               | -0.40428016 |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 335         |\n",
      "|    time_elapsed         | 6247        |\n",
      "|    total_timesteps      | 686080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024627198 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.0361      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.3        |\n",
      "|    n_updates            | 3340        |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | -0.4552775  |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 6265        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016404614 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.0405      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45          |\n",
      "|    n_updates            | 3350        |\n",
      "|    policy_gradient_loss | 0.00303     |\n",
      "|    reward               | 4.631153    |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 337         |\n",
      "|    time_elapsed         | 6284        |\n",
      "|    total_timesteps      | 690176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020355463 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.0578      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    reward               | 2.0388856   |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 47.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5511245.11\n",
      "total_reward: 4511245.11\n",
      "total_cost: 286339.38\n",
      "total_trades: 71950\n",
      "Sharpe: 0.814\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 338        |\n",
      "|    time_elapsed         | 6303       |\n",
      "|    total_timesteps      | 692224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01738117 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.5      |\n",
      "|    explained_variance   | 0.0384     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 103        |\n",
      "|    n_updates            | 3370       |\n",
      "|    policy_gradient_loss | -0.00788   |\n",
      "|    reward               | -0.5219443 |\n",
      "|    std                  | 1.7        |\n",
      "|    value_loss           | 144        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 6321        |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014911152 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.5       |\n",
      "|    explained_variance   | 0.07        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.1        |\n",
      "|    n_updates            | 3380        |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | -2.8731356  |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 340         |\n",
      "|    time_elapsed         | 6340        |\n",
      "|    total_timesteps      | 696320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015519419 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.5       |\n",
      "|    explained_variance   | 0.0377      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.6        |\n",
      "|    n_updates            | 3390        |\n",
      "|    policy_gradient_loss | -0.00234    |\n",
      "|    reward               | 0.29979885  |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 341          |\n",
      "|    time_elapsed         | 6358         |\n",
      "|    total_timesteps      | 698368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146240555 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -56.5        |\n",
      "|    explained_variance   | 0.292        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 3400         |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | -1.5615758   |\n",
      "|    std                  | 1.71         |\n",
      "|    value_loss           | 28.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 342        |\n",
      "|    time_elapsed         | 6376       |\n",
      "|    total_timesteps      | 700416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02691967 |\n",
      "|    clip_fraction        | 0.195      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.6      |\n",
      "|    explained_variance   | 0.0107     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.9       |\n",
      "|    n_updates            | 3410       |\n",
      "|    policy_gradient_loss | -0.00709   |\n",
      "|    reward               | 0.70315796 |\n",
      "|    std                  | 1.71       |\n",
      "|    value_loss           | 87.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 6395        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029887045 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.00327     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | 0.00325     |\n",
      "|    reward               | 2.6391623   |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 6413        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024264762 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.0542      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 3430        |\n",
      "|    policy_gradient_loss | 0.0029      |\n",
      "|    reward               | 3.405408    |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 345        |\n",
      "|    time_elapsed         | 6432       |\n",
      "|    total_timesteps      | 706560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01711549 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.7      |\n",
      "|    explained_variance   | 0.00629    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 44.1       |\n",
      "|    n_updates            | 3440       |\n",
      "|    policy_gradient_loss | -0.00641   |\n",
      "|    reward               | 2.9278452  |\n",
      "|    std                  | 1.72       |\n",
      "|    value_loss           | 81.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 346        |\n",
      "|    time_elapsed         | 6450       |\n",
      "|    total_timesteps      | 708608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01999823 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.8      |\n",
      "|    explained_variance   | 0.0258     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 50         |\n",
      "|    n_updates            | 3450       |\n",
      "|    policy_gradient_loss | -0.00187   |\n",
      "|    reward               | 0.577639   |\n",
      "|    std                  | 1.72       |\n",
      "|    value_loss           | 152        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 347         |\n",
      "|    time_elapsed         | 6469        |\n",
      "|    total_timesteps      | 710656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0163467   |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.0951      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 3460        |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    reward               | -0.37572044 |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 80.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 348         |\n",
      "|    time_elapsed         | 6488        |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017975377 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.0726      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 3470        |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    reward               | -1.1983507  |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 72.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 6506        |\n",
      "|    total_timesteps      | 714752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020922842 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.0556      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 3480        |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    reward               | -0.17131923 |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 6525        |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011947783 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.0667      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 3490        |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    reward               | -1.1230786  |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 6543        |\n",
      "|    total_timesteps      | 718848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029008843 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.0301      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.57        |\n",
      "|    n_updates            | 3500        |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | 2.1157327   |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4870787.91\n",
      "total_reward: 3870787.91\n",
      "total_cost: 251820.76\n",
      "total_trades: 69889\n",
      "Sharpe: 0.764\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 352         |\n",
      "|    time_elapsed         | 6562        |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026848191 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.0727      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 3510        |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    reward               | -2.30402    |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 6580        |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015114615 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.029       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.3        |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    reward               | -0.8435203  |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 354        |\n",
      "|    time_elapsed         | 6599       |\n",
      "|    total_timesteps      | 724992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01909551 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57        |\n",
      "|    explained_variance   | -0.153     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.5       |\n",
      "|    n_updates            | 3530       |\n",
      "|    policy_gradient_loss | -0.00372   |\n",
      "|    reward               | -4.6981764 |\n",
      "|    std                  | 1.74       |\n",
      "|    value_loss           | 55.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 355         |\n",
      "|    time_elapsed         | 6618        |\n",
      "|    total_timesteps      | 727040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028463405 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.1       |\n",
      "|    explained_variance   | 0.0356      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 3540        |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    reward               | -0.6755511  |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 356         |\n",
      "|    time_elapsed         | 6637        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011304496 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.2       |\n",
      "|    explained_variance   | 0.0609      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.8        |\n",
      "|    n_updates            | 3550        |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    reward               | -0.6991684  |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 357         |\n",
      "|    time_elapsed         | 6656        |\n",
      "|    total_timesteps      | 731136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014456308 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.2       |\n",
      "|    explained_variance   | 0.0664      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 3560        |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    reward               | -1.5197786  |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 6675        |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029066306 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.3       |\n",
      "|    explained_variance   | 0.0774      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 3570        |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    reward               | -0.36405522 |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 359         |\n",
      "|    time_elapsed         | 6693        |\n",
      "|    total_timesteps      | 735232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025333982 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.3       |\n",
      "|    explained_variance   | 0.0294      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.7        |\n",
      "|    n_updates            | 3580        |\n",
      "|    policy_gradient_loss | 0.00259     |\n",
      "|    reward               | -1.6849848  |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 6712        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024741206 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.4       |\n",
      "|    explained_variance   | 0.00242     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98          |\n",
      "|    n_updates            | 3590        |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    reward               | 0.17257568  |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 6731        |\n",
      "|    total_timesteps      | 739328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022172958 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.5       |\n",
      "|    explained_variance   | -0.0973     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | -1.4372978  |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 43.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 362          |\n",
      "|    time_elapsed         | 6751         |\n",
      "|    total_timesteps      | 741376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0155246435 |\n",
      "|    clip_fraction        | 0.196        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -57.5        |\n",
      "|    explained_variance   | 0.0345       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 88.6         |\n",
      "|    n_updates            | 3610         |\n",
      "|    policy_gradient_loss | -0.00674     |\n",
      "|    reward               | 0.6802417    |\n",
      "|    std                  | 1.77         |\n",
      "|    value_loss           | 157          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 6771        |\n",
      "|    total_timesteps      | 743424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017403487 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.6       |\n",
      "|    explained_variance   | 0.0548      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -44.084244  |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 364        |\n",
      "|    time_elapsed         | 6796       |\n",
      "|    total_timesteps      | 745472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02326382 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.7      |\n",
      "|    explained_variance   | 0.0232     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 33.1       |\n",
      "|    n_updates            | 3630       |\n",
      "|    policy_gradient_loss | -0.0043    |\n",
      "|    reward               | 0.3764292  |\n",
      "|    std                  | 1.78       |\n",
      "|    value_loss           | 135        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 365        |\n",
      "|    time_elapsed         | 6814       |\n",
      "|    total_timesteps      | 747520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02928403 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.7      |\n",
      "|    explained_variance   | 0.0769     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.2       |\n",
      "|    n_updates            | 3640       |\n",
      "|    policy_gradient_loss | -0.00701   |\n",
      "|    reward               | 0.5949906  |\n",
      "|    std                  | 1.78       |\n",
      "|    value_loss           | 38.8       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5009455.62\n",
      "total_reward: 4009455.62\n",
      "total_cost: 233499.73\n",
      "total_trades: 68094\n",
      "Sharpe: 0.798\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 6832        |\n",
      "|    total_timesteps      | 749568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023417782 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.8       |\n",
      "|    explained_variance   | 0.0461      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.9        |\n",
      "|    n_updates            | 3650        |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    reward               | 1.4297111   |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 367         |\n",
      "|    time_elapsed         | 6852        |\n",
      "|    total_timesteps      | 751616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013075195 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.8       |\n",
      "|    explained_variance   | 0.0685      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 160         |\n",
      "|    n_updates            | 3660        |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    reward               | 4.349519    |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 6871        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037612826 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.8       |\n",
      "|    explained_variance   | -0.00118    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    reward               | 1.0470409   |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 6889        |\n",
      "|    total_timesteps      | 755712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017895583 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.9       |\n",
      "|    explained_variance   | 0.0119      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 149         |\n",
      "|    n_updates            | 3680        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -1.177042   |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 6908        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012872943 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.9       |\n",
      "|    explained_variance   | 0.0271      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68          |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    reward               | 3.803254    |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 371         |\n",
      "|    time_elapsed         | 6926        |\n",
      "|    total_timesteps      | 759808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023955334 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58         |\n",
      "|    explained_variance   | 0.0403      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.9        |\n",
      "|    n_updates            | 3700        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | -3.2889516  |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 55.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 372         |\n",
      "|    time_elapsed         | 6945        |\n",
      "|    total_timesteps      | 761856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019077253 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58         |\n",
      "|    explained_variance   | -0.0259     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.2        |\n",
      "|    n_updates            | 3710        |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | 2.3830185   |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 82.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 6963        |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020498006 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | 0.0435      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66          |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | 0.00534     |\n",
      "|    reward               | -1.1577276  |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 374         |\n",
      "|    time_elapsed         | 6981        |\n",
      "|    total_timesteps      | 765952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023284907 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | 0.0519      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.8        |\n",
      "|    n_updates            | 3730        |\n",
      "|    policy_gradient_loss | 0.00352     |\n",
      "|    reward               | 1.9091716   |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 6999        |\n",
      "|    total_timesteps      | 768000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027562698 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | -0.159      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 3740        |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | 0.16958399  |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 376         |\n",
      "|    time_elapsed         | 7017        |\n",
      "|    total_timesteps      | 770048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018085748 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | 0.0306      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.9        |\n",
      "|    n_updates            | 3750        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 0.91601336  |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 377          |\n",
      "|    time_elapsed         | 7035         |\n",
      "|    total_timesteps      | 772096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0129344985 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -58.2        |\n",
      "|    explained_variance   | 0.0422       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.3         |\n",
      "|    n_updates            | 3760         |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | -0.9536113   |\n",
      "|    std                  | 1.81         |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 7053        |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017001264 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.00413     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 3770        |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    reward               | 3.3318615   |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 379         |\n",
      "|    time_elapsed         | 7071        |\n",
      "|    total_timesteps      | 776192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040567055 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.0135      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.7        |\n",
      "|    n_updates            | 3780        |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    reward               | -1.6327337  |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6493586.88\n",
      "total_reward: 5493586.88\n",
      "total_cost: 359215.86\n",
      "total_trades: 75860\n",
      "Sharpe: 0.960\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 7090        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026042216 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | -0.0474     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.9        |\n",
      "|    n_updates            | 3790        |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    reward               | 0.398731    |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 381         |\n",
      "|    time_elapsed         | 7108        |\n",
      "|    total_timesteps      | 780288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030459452 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.0372      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.1        |\n",
      "|    n_updates            | 3800        |\n",
      "|    policy_gradient_loss | 0.0016      |\n",
      "|    reward               | 0.112643145 |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 382         |\n",
      "|    time_elapsed         | 7127        |\n",
      "|    total_timesteps      | 782336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033375252 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.0286      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 3810        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 0.09605558  |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 7146        |\n",
      "|    total_timesteps      | 784384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015648935 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.0101      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.2        |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 1.2293887   |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 384         |\n",
      "|    time_elapsed         | 7164        |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022922149 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | -0.00525    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.7        |\n",
      "|    n_updates            | 3830        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 6.591188    |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 220         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 7182        |\n",
      "|    total_timesteps      | 788480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035676263 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.0513      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 3840        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 0.6819808   |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 386         |\n",
      "|    time_elapsed         | 7202        |\n",
      "|    total_timesteps      | 790528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029788554 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | -0.00952    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    reward               | 1.0175376   |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 387         |\n",
      "|    time_elapsed         | 7220        |\n",
      "|    total_timesteps      | 792576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026160687 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | 0.0127      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.6        |\n",
      "|    n_updates            | 3860        |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    reward               | 9.529802    |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 308         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 7239        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024201535 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | -0.0142     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.4        |\n",
      "|    n_updates            | 3870        |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | 0.13341609  |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 389         |\n",
      "|    time_elapsed         | 7257        |\n",
      "|    total_timesteps      | 796672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023733646 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.8       |\n",
      "|    explained_variance   | 0.00707     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.8        |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 1.2515445   |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 7276        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017829161 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.8       |\n",
      "|    explained_variance   | -0.00193    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    reward               | 2.0452394   |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 290         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 391         |\n",
      "|    time_elapsed         | 7294        |\n",
      "|    total_timesteps      | 800768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023391306 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.9       |\n",
      "|    explained_variance   | 0.00312     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 1.0192093   |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 7312        |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035066184 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.093       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.21        |\n",
      "|    n_updates            | 3910        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -0.4016996  |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 7331        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024980724 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.0484      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.6        |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | 0.00293     |\n",
      "|    reward               | -0.77292264 |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 7349        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049727224 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.00111     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.8        |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | -0.000271   |\n",
      "|    reward               | -0.4956693  |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6516571.71\n",
      "total_reward: 5516571.71\n",
      "total_cost: 351746.90\n",
      "total_trades: 76112\n",
      "Sharpe: 0.932\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 7367        |\n",
      "|    total_timesteps      | 808960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028791336 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.4        |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | 2.6335242   |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 55.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 396         |\n",
      "|    time_elapsed         | 7385        |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038303196 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.2       |\n",
      "|    explained_variance   | 0.0808      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.3        |\n",
      "|    n_updates            | 3950        |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    reward               | 2.7506254   |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 7404        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025733206 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.2       |\n",
      "|    explained_variance   | 0.021       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 3960        |\n",
      "|    policy_gradient_loss | -0.00205    |\n",
      "|    reward               | -1.541795   |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 380         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 398         |\n",
      "|    time_elapsed         | 7422        |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030497337 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.2       |\n",
      "|    explained_variance   | 0.00348     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.00161    |\n",
      "|    reward               | -4.549274   |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 279         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 399        |\n",
      "|    time_elapsed         | 7440       |\n",
      "|    total_timesteps      | 817152     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04610943 |\n",
      "|    clip_fraction        | 0.344      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.3      |\n",
      "|    explained_variance   | -0.0844    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.9       |\n",
      "|    n_updates            | 3980       |\n",
      "|    policy_gradient_loss | -0.00122   |\n",
      "|    reward               | -5.716687  |\n",
      "|    std                  | 1.88       |\n",
      "|    value_loss           | 32.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 7459        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030834707 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.4       |\n",
      "|    explained_variance   | 0.0251      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 3990        |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    reward               | -0.7848359  |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 390         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 401        |\n",
      "|    time_elapsed         | 7477       |\n",
      "|    total_timesteps      | 821248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02187373 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.4      |\n",
      "|    explained_variance   | 0.0248     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 213        |\n",
      "|    n_updates            | 4000       |\n",
      "|    policy_gradient_loss | -0.0062    |\n",
      "|    reward               | -8.595881  |\n",
      "|    std                  | 1.89       |\n",
      "|    value_loss           | 287        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 109       |\n",
      "|    iterations           | 402       |\n",
      "|    time_elapsed         | 7496      |\n",
      "|    total_timesteps      | 823296    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0338644 |\n",
      "|    clip_fraction        | 0.313     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -59.5     |\n",
      "|    explained_variance   | -0.0913   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 66.3      |\n",
      "|    n_updates            | 4010      |\n",
      "|    policy_gradient_loss | -0.00425  |\n",
      "|    reward               | 2.3692203 |\n",
      "|    std                  | 1.89      |\n",
      "|    value_loss           | 108       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 403         |\n",
      "|    time_elapsed         | 7515        |\n",
      "|    total_timesteps      | 825344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018883422 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.5       |\n",
      "|    explained_variance   | 0.0323      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.3        |\n",
      "|    n_updates            | 4020        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -0.12045918 |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 322         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 7534        |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016023636 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.5       |\n",
      "|    explained_variance   | 0.0853      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 187         |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.00947    |\n",
      "|    reward               | 5.471146    |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 251         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 405         |\n",
      "|    time_elapsed         | 7552        |\n",
      "|    total_timesteps      | 829440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030030135 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.0445      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 186         |\n",
      "|    n_updates            | 4040        |\n",
      "|    policy_gradient_loss | -0.00958    |\n",
      "|    reward               | 2.396596    |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 335         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 406         |\n",
      "|    time_elapsed         | 7570        |\n",
      "|    total_timesteps      | 831488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045436334 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | -0.139      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 4050        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 2.2486484   |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 7589        |\n",
      "|    total_timesteps      | 833536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028210433 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | -0.0147     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 4060        |\n",
      "|    policy_gradient_loss | -0.00927    |\n",
      "|    reward               | 3.3708167   |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 324         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 408        |\n",
      "|    time_elapsed         | 7608       |\n",
      "|    total_timesteps      | 835584     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01608858 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.8      |\n",
      "|    explained_variance   | 0.00239    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 113        |\n",
      "|    n_updates            | 4070       |\n",
      "|    policy_gradient_loss | -0.00758   |\n",
      "|    reward               | 0.78123266 |\n",
      "|    std                  | 1.91       |\n",
      "|    value_loss           | 381        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6486098.24\n",
      "total_reward: 5486098.24\n",
      "total_cost: 349934.39\n",
      "total_trades: 74527\n",
      "Sharpe: 0.913\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 409         |\n",
      "|    time_elapsed         | 7626        |\n",
      "|    total_timesteps      | 837632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030649865 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | -0.0425     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 4080        |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    reward               | -5.2189994  |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 410        |\n",
      "|    time_elapsed         | 7644       |\n",
      "|    total_timesteps      | 839680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03125198 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.9      |\n",
      "|    explained_variance   | 0.022      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28         |\n",
      "|    n_updates            | 4090       |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    reward               | 1.5387326  |\n",
      "|    std                  | 1.92       |\n",
      "|    value_loss           | 293        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 411        |\n",
      "|    time_elapsed         | 7662       |\n",
      "|    total_timesteps      | 841728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03184823 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.9      |\n",
      "|    explained_variance   | 0.0221     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 84.6       |\n",
      "|    n_updates            | 4100       |\n",
      "|    policy_gradient_loss | -0.00476   |\n",
      "|    reward               | 1.035655   |\n",
      "|    std                  | 1.92       |\n",
      "|    value_loss           | 120        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 7681        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.05125035  |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60         |\n",
      "|    explained_variance   | 0.0437      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | 0.00251     |\n",
      "|    reward               | -0.23738308 |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 74.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 413        |\n",
      "|    time_elapsed         | 7699       |\n",
      "|    total_timesteps      | 845824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03132522 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.1      |\n",
      "|    explained_variance   | 0.0563     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 74.9       |\n",
      "|    n_updates            | 4120       |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    reward               | -2.1673155 |\n",
      "|    std                  | 1.93       |\n",
      "|    value_loss           | 112        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 7717        |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020887272 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.2       |\n",
      "|    explained_variance   | 0.0326      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 99.1        |\n",
      "|    n_updates            | 4130        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -1.0962958  |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 216         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 415        |\n",
      "|    time_elapsed         | 7736       |\n",
      "|    total_timesteps      | 849920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01650577 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.2      |\n",
      "|    explained_variance   | 0.00949    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 192        |\n",
      "|    n_updates            | 4140       |\n",
      "|    policy_gradient_loss | -0.00368   |\n",
      "|    reward               | 0.64297366 |\n",
      "|    std                  | 1.94       |\n",
      "|    value_loss           | 278        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 416         |\n",
      "|    time_elapsed         | 7755        |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032881618 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | -0.246      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 4150        |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    reward               | -1.8972979  |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 417         |\n",
      "|    time_elapsed         | 7774        |\n",
      "|    total_timesteps      | 854016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026721274 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | -0.00488    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.7        |\n",
      "|    n_updates            | 4160        |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | -0.06834891 |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 235         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 418         |\n",
      "|    time_elapsed         | 7792        |\n",
      "|    total_timesteps      | 856064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026408222 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.4       |\n",
      "|    explained_variance   | -0.00796    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.3        |\n",
      "|    n_updates            | 4170        |\n",
      "|    policy_gradient_loss | -0.00129    |\n",
      "|    reward               | 3.860231    |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 7811        |\n",
      "|    total_timesteps      | 858112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026789527 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.5       |\n",
      "|    explained_variance   | 0.0211      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.1        |\n",
      "|    n_updates            | 4180        |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | 0.40523228  |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 77.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 420         |\n",
      "|    time_elapsed         | 7829        |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022817347 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.6       |\n",
      "|    explained_variance   | 0.00922     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 4190        |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    reward               | 0.35989344  |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 7848        |\n",
      "|    total_timesteps      | 862208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02812358  |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.6       |\n",
      "|    explained_variance   | 0.0158      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.4        |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    reward               | -0.49991265 |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 109       |\n",
      "|    iterations           | 422       |\n",
      "|    time_elapsed         | 7867      |\n",
      "|    total_timesteps      | 864256    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0275123 |\n",
      "|    clip_fraction        | 0.273     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -60.6     |\n",
      "|    explained_variance   | 0.0362    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 127       |\n",
      "|    n_updates            | 4210      |\n",
      "|    policy_gradient_loss | -0.00412  |\n",
      "|    reward               | 2.6114764 |\n",
      "|    std                  | 1.97      |\n",
      "|    value_loss           | 154       |\n",
      "---------------------------------------\n",
      "day: 2892, episode: 300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6910395.19\n",
      "total_reward: 5910395.19\n",
      "total_cost: 350653.43\n",
      "total_trades: 73666\n",
      "Sharpe: 0.909\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 423         |\n",
      "|    time_elapsed         | 7886        |\n",
      "|    total_timesteps      | 866304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035747312 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | 0.0738      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 4220        |\n",
      "|    policy_gradient_loss | 0.00226     |\n",
      "|    reward               | 1.9545944   |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 424         |\n",
      "|    time_elapsed         | 7905        |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023020022 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | -0.00401    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 364         |\n",
      "|    n_updates            | 4230        |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    reward               | -2.0472045  |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 453         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 425         |\n",
      "|    time_elapsed         | 7924        |\n",
      "|    total_timesteps      | 870400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021094866 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | -0.00682    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    reward               | -15.818213  |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 419         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 7942        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024388334 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | 0.0546      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 4250        |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    reward               | 1.566789    |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 81.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 7961        |\n",
      "|    total_timesteps      | 874496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018012974 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.8       |\n",
      "|    explained_variance   | -0.00948    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 169         |\n",
      "|    n_updates            | 4260        |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    reward               | -0.55097705 |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 348         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 428         |\n",
      "|    time_elapsed         | 7979        |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021495158 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.8       |\n",
      "|    explained_variance   | 0.0106      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 4270        |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | -6.503838   |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 429        |\n",
      "|    time_elapsed         | 7998       |\n",
      "|    total_timesteps      | 878592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01960213 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.8      |\n",
      "|    explained_variance   | 0.0658     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 35.1       |\n",
      "|    n_updates            | 4280       |\n",
      "|    policy_gradient_loss | -0.00474   |\n",
      "|    reward               | -1.2216604 |\n",
      "|    std                  | 1.98       |\n",
      "|    value_loss           | 152        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 430         |\n",
      "|    time_elapsed         | 8017        |\n",
      "|    total_timesteps      | 880640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046542365 |\n",
      "|    clip_fraction        | 0.406       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.0875      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.32        |\n",
      "|    n_updates            | 4290        |\n",
      "|    policy_gradient_loss | 0.00559     |\n",
      "|    reward               | 1.7667086   |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 431        |\n",
      "|    time_elapsed         | 8036       |\n",
      "|    total_timesteps      | 882688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02194455 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.9      |\n",
      "|    explained_variance   | 0.00163    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 59.2       |\n",
      "|    n_updates            | 4300       |\n",
      "|    policy_gradient_loss | -0.00239   |\n",
      "|    reward               | -1.2522199 |\n",
      "|    std                  | 1.99       |\n",
      "|    value_loss           | 121        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 8054        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028527074 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.0289      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.6        |\n",
      "|    n_updates            | 4310        |\n",
      "|    policy_gradient_loss | -0.00873    |\n",
      "|    reward               | -1.458972   |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 72.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 433         |\n",
      "|    time_elapsed         | 8073        |\n",
      "|    total_timesteps      | 886784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034129232 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.0506      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.95        |\n",
      "|    n_updates            | 4320        |\n",
      "|    policy_gradient_loss | 0.000875    |\n",
      "|    reward               | -3.1324742  |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 434         |\n",
      "|    time_elapsed         | 8092        |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023394827 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 4330        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 1.6787863   |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 435         |\n",
      "|    time_elapsed         | 8111        |\n",
      "|    total_timesteps      | 890880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018377896 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 4340        |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | 1.6692709   |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 8129        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027088687 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | -0.000466   |\n",
      "|    reward               | 2.629139    |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3441281.81\n",
      "total_reward: 2441281.81\n",
      "total_cost: 177779.77\n",
      "total_trades: 62402\n",
      "Sharpe: 0.745\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 8148        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031796232 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    reward               | -0.2908806  |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 8166        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019177217 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    reward               | 1.1102374   |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 8184        |\n",
      "|    total_timesteps      | 899072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028961668 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 4380        |\n",
      "|    policy_gradient_loss | 0.00769     |\n",
      "|    reward               | 1.5743996   |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 440         |\n",
      "|    time_elapsed         | 8202        |\n",
      "|    total_timesteps      | 901120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026266377 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.0467      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.94        |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    reward               | -0.6170085  |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 441         |\n",
      "|    time_elapsed         | 8221        |\n",
      "|    total_timesteps      | 903168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022300437 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 4400        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -1.378987   |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 442         |\n",
      "|    time_elapsed         | 8240        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030423932 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    reward               | 2.4466934   |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 443         |\n",
      "|    time_elapsed         | 8258        |\n",
      "|    total_timesteps      | 907264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033835027 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.4       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 4420        |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    reward               | 2.6870892   |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 8277        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025197208 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.5       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | -0.5062102  |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 445        |\n",
      "|    time_elapsed         | 8296       |\n",
      "|    total_timesteps      | 911360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02388071 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.5      |\n",
      "|    explained_variance   | 0.137      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.7       |\n",
      "|    n_updates            | 4440       |\n",
      "|    policy_gradient_loss | -0.00216   |\n",
      "|    reward               | -1.2919021 |\n",
      "|    std                  | 2.03       |\n",
      "|    value_loss           | 37.1       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 109       |\n",
      "|    iterations           | 446       |\n",
      "|    time_elapsed         | 8315      |\n",
      "|    total_timesteps      | 913408    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.020776  |\n",
      "|    clip_fraction        | 0.202     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -61.6     |\n",
      "|    explained_variance   | 0.132     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 16.7      |\n",
      "|    n_updates            | 4450      |\n",
      "|    policy_gradient_loss | -0.00676  |\n",
      "|    reward               | 1.8293736 |\n",
      "|    std                  | 2.03      |\n",
      "|    value_loss           | 41.6      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 447         |\n",
      "|    time_elapsed         | 8332        |\n",
      "|    total_timesteps      | 915456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038690902 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.6       |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.47        |\n",
      "|    n_updates            | 4460        |\n",
      "|    policy_gradient_loss | -0.00298    |\n",
      "|    reward               | -1.0665642  |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 8351        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017812546 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.7       |\n",
      "|    explained_variance   | 0.0426      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 4470        |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | 0.7516668   |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 59.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 449        |\n",
      "|    time_elapsed         | 8369       |\n",
      "|    total_timesteps      | 919552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03220795 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.7      |\n",
      "|    explained_variance   | -0.0117    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.3       |\n",
      "|    n_updates            | 4480       |\n",
      "|    policy_gradient_loss | 0.00193    |\n",
      "|    reward               | 11.943112  |\n",
      "|    std                  | 2.04       |\n",
      "|    value_loss           | 80.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 450        |\n",
      "|    time_elapsed         | 8388       |\n",
      "|    total_timesteps      | 921600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0242665  |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.8      |\n",
      "|    explained_variance   | -0.087     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.6       |\n",
      "|    n_updates            | 4490       |\n",
      "|    policy_gradient_loss | -0.000336  |\n",
      "|    reward               | -1.1592332 |\n",
      "|    std                  | 2.05       |\n",
      "|    value_loss           | 33.5       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4228386.16\n",
      "total_reward: 3228386.16\n",
      "total_cost: 341739.94\n",
      "total_trades: 72993\n",
      "Sharpe: 0.772\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 8407        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028050516 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.8       |\n",
      "|    explained_variance   | 0.0294      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | 0.6951903   |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 83.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 8425        |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018384207 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.8       |\n",
      "|    explained_variance   | 0.0478      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 4510        |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | -7.7646437  |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 62.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 453         |\n",
      "|    time_elapsed         | 8445        |\n",
      "|    total_timesteps      | 927744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031950988 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.9       |\n",
      "|    explained_variance   | 0.00239     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.1        |\n",
      "|    n_updates            | 4520        |\n",
      "|    policy_gradient_loss | 0.00249     |\n",
      "|    reward               | -5.5126567  |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 454         |\n",
      "|    time_elapsed         | 8464        |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038443103 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.9       |\n",
      "|    explained_variance   | 0.0191      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 4530        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.9203034   |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 455         |\n",
      "|    time_elapsed         | 8482        |\n",
      "|    total_timesteps      | 931840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019209126 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62         |\n",
      "|    explained_variance   | 0.0345      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.2        |\n",
      "|    n_updates            | 4540        |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    reward               | 1.719321    |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 84.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 8501        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023518018 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62         |\n",
      "|    explained_variance   | 0.00184     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.7        |\n",
      "|    n_updates            | 4550        |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    reward               | -3.207838   |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 8520        |\n",
      "|    total_timesteps      | 935936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024060104 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.1       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    reward               | -3.285359   |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 8540        |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021134118 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.1       |\n",
      "|    explained_variance   | 0.0378      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 4570        |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    reward               | -6.336621   |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 459         |\n",
      "|    time_elapsed         | 8559        |\n",
      "|    total_timesteps      | 940032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022665223 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.0414      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.3        |\n",
      "|    n_updates            | 4580        |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | -2.6307485  |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 460         |\n",
      "|    time_elapsed         | 8579        |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036555264 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.0738      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.2        |\n",
      "|    n_updates            | 4590        |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    reward               | -2.9463599  |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 89.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 8597        |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020560116 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.0258      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 162         |\n",
      "|    n_updates            | 4600        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | -0.73688424 |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 462        |\n",
      "|    time_elapsed         | 8616       |\n",
      "|    total_timesteps      | 946176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01857669 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.2      |\n",
      "|    explained_variance   | 0.0918     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 45.4       |\n",
      "|    n_updates            | 4610       |\n",
      "|    policy_gradient_loss | -0.0124    |\n",
      "|    reward               | -1.0300581 |\n",
      "|    std                  | 2.08       |\n",
      "|    value_loss           | 113        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 463        |\n",
      "|    time_elapsed         | 8634       |\n",
      "|    total_timesteps      | 948224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01929373 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.3      |\n",
      "|    explained_variance   | 0.0605     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 60.2       |\n",
      "|    n_updates            | 4620       |\n",
      "|    policy_gradient_loss | -0.00922   |\n",
      "|    reward               | 3.3275852  |\n",
      "|    std                  | 2.08       |\n",
      "|    value_loss           | 110        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 464         |\n",
      "|    time_elapsed         | 8652        |\n",
      "|    total_timesteps      | 950272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041388214 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | -0.0266     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 4630        |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    reward               | -1.2084863  |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5442333.93\n",
      "total_reward: 4442333.93\n",
      "total_cost: 307276.53\n",
      "total_trades: 71592\n",
      "Sharpe: 0.934\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 8670        |\n",
      "|    total_timesteps      | 952320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024562668 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | 0.049       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 4640        |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    reward               | 0.29602274  |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 74.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 466         |\n",
      "|    time_elapsed         | 8688        |\n",
      "|    total_timesteps      | 954368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019942217 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.4       |\n",
      "|    explained_variance   | 0.0672      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.6        |\n",
      "|    n_updates            | 4650        |\n",
      "|    policy_gradient_loss | -0.00912    |\n",
      "|    reward               | -7.0792766  |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 96.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 467         |\n",
      "|    time_elapsed         | 8706        |\n",
      "|    total_timesteps      | 956416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022287678 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | -0.0128     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 4660        |\n",
      "|    policy_gradient_loss | 0.000496    |\n",
      "|    reward               | 1.2761207   |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 468         |\n",
      "|    time_elapsed         | 8724        |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020806337 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.6       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 4670        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -2.3160446  |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 50.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 469         |\n",
      "|    time_elapsed         | 8743        |\n",
      "|    total_timesteps      | 960512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016952915 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.6       |\n",
      "|    explained_variance   | 0.0476      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.4        |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -0.7843109  |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 89.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 470          |\n",
      "|    time_elapsed         | 8762         |\n",
      "|    total_timesteps      | 962560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0142153315 |\n",
      "|    clip_fraction        | 0.163        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -62.6        |\n",
      "|    explained_variance   | 0.101        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.6         |\n",
      "|    n_updates            | 4690         |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | -1.4414389   |\n",
      "|    std                  | 2.11         |\n",
      "|    value_loss           | 73.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 8780        |\n",
      "|    total_timesteps      | 964608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017596576 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.7       |\n",
      "|    explained_variance   | 0.0625      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 4700        |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    reward               | 0.22111325  |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 472        |\n",
      "|    time_elapsed         | 8799       |\n",
      "|    total_timesteps      | 966656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02673003 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.7      |\n",
      "|    explained_variance   | 0.0766     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38.6       |\n",
      "|    n_updates            | 4710       |\n",
      "|    policy_gradient_loss | 0.000284   |\n",
      "|    reward               | -1.0169135 |\n",
      "|    std                  | 2.11       |\n",
      "|    value_loss           | 71.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 473         |\n",
      "|    time_elapsed         | 8818        |\n",
      "|    total_timesteps      | 968704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008575068 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.7       |\n",
      "|    explained_variance   | 0.0397      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 4720        |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    reward               | -0.6897542  |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 97.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 474         |\n",
      "|    time_elapsed         | 8836        |\n",
      "|    total_timesteps      | 970752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021905469 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.7       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 4730        |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    reward               | 2.2177076   |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 475        |\n",
      "|    time_elapsed         | 8855       |\n",
      "|    total_timesteps      | 972800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01993842 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.8      |\n",
      "|    explained_variance   | 0.0862     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.6       |\n",
      "|    n_updates            | 4740       |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    reward               | -0.1262035 |\n",
      "|    std                  | 2.12       |\n",
      "|    value_loss           | 51.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 8874        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014897192 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.8       |\n",
      "|    explained_variance   | 0.0629      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 4750        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -4.4055333  |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 60.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 477         |\n",
      "|    time_elapsed         | 8892        |\n",
      "|    total_timesteps      | 976896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019320872 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | -0.0336     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 4760        |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    reward               | -2.9565945  |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 8911        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026139665 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 0.0286      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.74        |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 2.5171874   |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5974658.08\n",
      "total_reward: 4974658.08\n",
      "total_cost: 311191.08\n",
      "total_trades: 71866\n",
      "Sharpe: 0.953\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 479         |\n",
      "|    time_elapsed         | 8930        |\n",
      "|    total_timesteps      | 980992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022238385 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 0.0447      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.6        |\n",
      "|    n_updates            | 4780        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    reward               | -3.3282833  |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 96.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 8948        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030004445 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.0365      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.1        |\n",
      "|    n_updates            | 4790        |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    reward               | -0.8665981  |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 481        |\n",
      "|    time_elapsed         | 8966       |\n",
      "|    total_timesteps      | 985088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02524501 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.1      |\n",
      "|    explained_variance   | 0.11       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.7        |\n",
      "|    n_updates            | 4800       |\n",
      "|    policy_gradient_loss | -0.00735   |\n",
      "|    reward               | 0.58087415 |\n",
      "|    std                  | 2.14       |\n",
      "|    value_loss           | 23.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 8984        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020683909 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.0575      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.3        |\n",
      "|    n_updates            | 4810        |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    reward               | -0.31297436 |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 483        |\n",
      "|    time_elapsed         | 9002       |\n",
      "|    total_timesteps      | 989184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01993948 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.2      |\n",
      "|    explained_variance   | 0.0483     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.5       |\n",
      "|    n_updates            | 4820       |\n",
      "|    policy_gradient_loss | -0.00312   |\n",
      "|    reward               | -9.181052  |\n",
      "|    std                  | 2.15       |\n",
      "|    value_loss           | 62.5       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 484          |\n",
      "|    time_elapsed         | 9020         |\n",
      "|    total_timesteps      | 991232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0156166395 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -63.2        |\n",
      "|    explained_variance   | 0.0114       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 4830         |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 1.9735012    |\n",
      "|    std                  | 2.15         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 9044        |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017345442 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.2       |\n",
      "|    explained_variance   | 0.0385      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 4840        |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    reward               | -0.48016047 |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 49.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 486         |\n",
      "|    time_elapsed         | 9062        |\n",
      "|    total_timesteps      | 995328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017134083 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.2       |\n",
      "|    explained_variance   | 0.0888      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 4850        |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | 1.6484131   |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 9080        |\n",
      "|    total_timesteps      | 997376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017145317 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.2       |\n",
      "|    explained_variance   | 0.0598      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 4860        |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    reward               | 0.10408305  |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 53.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 9097        |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032775268 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.0476      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.87        |\n",
      "|    n_updates            | 4870        |\n",
      "|    policy_gradient_loss | 0.00115     |\n",
      "|    reward               | 0.19121358  |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 489         |\n",
      "|    time_elapsed         | 9115        |\n",
      "|    total_timesteps      | 1001472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023837801 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.0266      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 4880        |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | -0.81190693 |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 81.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 490         |\n",
      "|    time_elapsed         | 9133        |\n",
      "|    total_timesteps      | 1003520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014833728 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.0246      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.7        |\n",
      "|    n_updates            | 4890        |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    reward               | -2.072282   |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 85.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 491         |\n",
      "|    time_elapsed         | 9151        |\n",
      "|    total_timesteps      | 1005568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019380169 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.0963      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 4900        |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    reward               | 4.9626856   |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 9170        |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016998824 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.0923      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 4910        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | 3.1125953   |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4394947.14\n",
      "total_reward: 3394947.14\n",
      "total_cost: 248236.32\n",
      "total_trades: 64906\n",
      "Sharpe: 0.818\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 493          |\n",
      "|    time_elapsed         | 9189         |\n",
      "|    total_timesteps      | 1009664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.018510967  |\n",
      "|    clip_fraction        | 0.192        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -63.5        |\n",
      "|    explained_variance   | 0.0614       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 4920         |\n",
      "|    policy_gradient_loss | 0.00179      |\n",
      "|    reward               | -0.055507258 |\n",
      "|    std                  | 2.18         |\n",
      "|    value_loss           | 57.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 494         |\n",
      "|    time_elapsed         | 9208        |\n",
      "|    total_timesteps      | 1011712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016912572 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.0303      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 4930        |\n",
      "|    policy_gradient_loss | -0.00088    |\n",
      "|    reward               | -2.1314213  |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 9226        |\n",
      "|    total_timesteps      | 1013760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031172559 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.0784      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.42        |\n",
      "|    n_updates            | 4940        |\n",
      "|    policy_gradient_loss | 0.000364    |\n",
      "|    reward               | -2.4175942  |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 496        |\n",
      "|    time_elapsed         | 9245       |\n",
      "|    total_timesteps      | 1015808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02620606 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.6      |\n",
      "|    explained_variance   | 0.0753     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.6       |\n",
      "|    n_updates            | 4950       |\n",
      "|    policy_gradient_loss | -0.00316   |\n",
      "|    reward               | 0.19561955 |\n",
      "|    std                  | 2.18       |\n",
      "|    value_loss           | 54.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 497        |\n",
      "|    time_elapsed         | 9263       |\n",
      "|    total_timesteps      | 1017856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02109517 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.7      |\n",
      "|    explained_variance   | 0.0343     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 37.1       |\n",
      "|    n_updates            | 4960       |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    reward               | 0.3409089  |\n",
      "|    std                  | 2.18       |\n",
      "|    value_loss           | 97.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 498         |\n",
      "|    time_elapsed         | 9282        |\n",
      "|    total_timesteps      | 1019904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020679422 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 4970        |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    reward               | 1.5924964   |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 499         |\n",
      "|    time_elapsed         | 9300        |\n",
      "|    total_timesteps      | 1021952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025753982 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.0512      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.5        |\n",
      "|    n_updates            | 4980        |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    reward               | -0.8915084  |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 77.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 500         |\n",
      "|    time_elapsed         | 9319        |\n",
      "|    total_timesteps      | 1024000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018810451 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.0995      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.4        |\n",
      "|    n_updates            | 4990        |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    reward               | -2.6896818  |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 74          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 501         |\n",
      "|    time_elapsed         | 9337        |\n",
      "|    total_timesteps      | 1026048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021814836 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 5000        |\n",
      "|    policy_gradient_loss | -0.00257    |\n",
      "|    reward               | -0.35563242 |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 502         |\n",
      "|    time_elapsed         | 9356        |\n",
      "|    total_timesteps      | 1028096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025881823 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | 0.0678      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 5010        |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    reward               | 0.8988556   |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 54          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 503         |\n",
      "|    time_elapsed         | 9374        |\n",
      "|    total_timesteps      | 1030144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018397462 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.054       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.6        |\n",
      "|    n_updates            | 5020        |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    reward               | 0.6790079   |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 96.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 504          |\n",
      "|    time_elapsed         | 9391         |\n",
      "|    total_timesteps      | 1032192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0155435335 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.1        |\n",
      "|    explained_variance   | 0.047        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29           |\n",
      "|    n_updates            | 5030         |\n",
      "|    policy_gradient_loss | -0.00767     |\n",
      "|    reward               | -4.766809    |\n",
      "|    std                  | 2.22         |\n",
      "|    value_loss           | 83.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 505         |\n",
      "|    time_elapsed         | 9409        |\n",
      "|    total_timesteps      | 1034240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026036583 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.1       |\n",
      "|    explained_variance   | -0.00299    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 5040        |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | -1.5726299  |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 506         |\n",
      "|    time_elapsed         | 9428        |\n",
      "|    total_timesteps      | 1036288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022436818 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.2       |\n",
      "|    explained_variance   | 0.0541      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 5050        |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    reward               | 0.4995283   |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 55.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 507         |\n",
      "|    time_elapsed         | 9445        |\n",
      "|    total_timesteps      | 1038336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018995963 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.2       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 5060        |\n",
      "|    policy_gradient_loss | -0.00909    |\n",
      "|    reward               | 3.0725868   |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 64.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4442542.88\n",
      "total_reward: 3442542.88\n",
      "total_cost: 152109.23\n",
      "total_trades: 59384\n",
      "Sharpe: 0.808\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 508         |\n",
      "|    time_elapsed         | 9464        |\n",
      "|    total_timesteps      | 1040384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013886888 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | -0.000486   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 5070        |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    reward               | 1.610325    |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 46.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 509         |\n",
      "|    time_elapsed         | 9482        |\n",
      "|    total_timesteps      | 1042432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022815313 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.11        |\n",
      "|    n_updates            | 5080        |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    reward               | -0.21853596 |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 9501        |\n",
      "|    total_timesteps      | 1044480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011738694 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 5090        |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    reward               | -0.3734339  |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 511         |\n",
      "|    time_elapsed         | 9520        |\n",
      "|    total_timesteps      | 1046528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015292465 |\n",
      "|    clip_fraction        | 0.0977      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 5100        |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | 0.2687033   |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 67.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 512         |\n",
      "|    time_elapsed         | 9538        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018351315 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.59        |\n",
      "|    n_updates            | 5110        |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    reward               | -0.9978524  |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 513         |\n",
      "|    time_elapsed         | 9556        |\n",
      "|    total_timesteps      | 1050624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016748842 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42          |\n",
      "|    n_updates            | 5120        |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    reward               | 1.1839219   |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 514         |\n",
      "|    time_elapsed         | 9576        |\n",
      "|    total_timesteps      | 1052672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023627546 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 5130        |\n",
      "|    policy_gradient_loss | 0.0064      |\n",
      "|    reward               | 3.8950245   |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 53.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 515        |\n",
      "|    time_elapsed         | 9594       |\n",
      "|    total_timesteps      | 1054720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0237429  |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.5      |\n",
      "|    explained_variance   | 0.063      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.9       |\n",
      "|    n_updates            | 5140       |\n",
      "|    policy_gradient_loss | -0.00606   |\n",
      "|    reward               | -1.9121634 |\n",
      "|    std                  | 2.25       |\n",
      "|    value_loss           | 41.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 516          |\n",
      "|    time_elapsed         | 9613         |\n",
      "|    total_timesteps      | 1056768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0129145505 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.5        |\n",
      "|    explained_variance   | 0.183        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.94         |\n",
      "|    n_updates            | 5150         |\n",
      "|    policy_gradient_loss | 0.000321     |\n",
      "|    reward               | -2.6226447   |\n",
      "|    std                  | 2.25         |\n",
      "|    value_loss           | 28           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 517         |\n",
      "|    time_elapsed         | 9631        |\n",
      "|    total_timesteps      | 1058816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017071964 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 5160        |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    reward               | 0.38859636  |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 518         |\n",
      "|    time_elapsed         | 9649        |\n",
      "|    total_timesteps      | 1060864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016397614 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.0493      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 5170        |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    reward               | -0.55098695 |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 52.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 519         |\n",
      "|    time_elapsed         | 9668        |\n",
      "|    total_timesteps      | 1062912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018042816 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.69        |\n",
      "|    n_updates            | 5180        |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    reward               | -0.18760996 |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 520         |\n",
      "|    time_elapsed         | 9686        |\n",
      "|    total_timesteps      | 1064960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022023976 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.0934      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 5190        |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    reward               | -0.3599692  |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 521         |\n",
      "|    time_elapsed         | 9705        |\n",
      "|    total_timesteps      | 1067008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018816743 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 5200        |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    reward               | 0.8370893   |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3847651.10\n",
      "total_reward: 2847651.10\n",
      "total_cost: 231975.72\n",
      "total_trades: 65062\n",
      "Sharpe: 0.756\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 522          |\n",
      "|    time_elapsed         | 9723         |\n",
      "|    total_timesteps      | 1069056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.02569748   |\n",
      "|    clip_fraction        | 0.282        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.8        |\n",
      "|    explained_variance   | 0.0236       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 5210         |\n",
      "|    policy_gradient_loss | -0.0068      |\n",
      "|    reward               | -0.052680492 |\n",
      "|    std                  | 2.28         |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 523         |\n",
      "|    time_elapsed         | 9741        |\n",
      "|    total_timesteps      | 1071104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015426525 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 5220        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 2.4237814   |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 524         |\n",
      "|    time_elapsed         | 9759        |\n",
      "|    total_timesteps      | 1073152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021974994 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65         |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 5230        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -0.6149415  |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 525         |\n",
      "|    time_elapsed         | 9778        |\n",
      "|    total_timesteps      | 1075200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009864409 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65         |\n",
      "|    explained_variance   | 0.0194      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 5240        |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    reward               | 0.29539993  |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 526         |\n",
      "|    time_elapsed         | 9796        |\n",
      "|    total_timesteps      | 1077248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028774895 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65         |\n",
      "|    explained_variance   | 0.18        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 5250        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    reward               | 0.22832188  |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 527        |\n",
      "|    time_elapsed         | 9814       |\n",
      "|    total_timesteps      | 1079296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01529819 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.1      |\n",
      "|    explained_variance   | 0.0166     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.1       |\n",
      "|    n_updates            | 5260       |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    reward               | -3.0910769 |\n",
      "|    std                  | 2.29       |\n",
      "|    value_loss           | 44.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 528         |\n",
      "|    time_elapsed         | 9832        |\n",
      "|    total_timesteps      | 1081344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012172134 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 5270        |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    reward               | 0.6591229   |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 44.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 529          |\n",
      "|    time_elapsed         | 9851         |\n",
      "|    total_timesteps      | 1083392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.023800649  |\n",
      "|    clip_fraction        | 0.226        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -65.1        |\n",
      "|    explained_variance   | -0.0973      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 5280         |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    reward               | -0.041169748 |\n",
      "|    std                  | 2.3          |\n",
      "|    value_loss           | 20.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 530         |\n",
      "|    time_elapsed         | 9869        |\n",
      "|    total_timesteps      | 1085440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01642243  |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 5290        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -0.61300933 |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 9887        |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021866973 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.0949      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 5300        |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    reward               | 1.7988797   |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 9906        |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015037527 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 5310        |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    reward               | -0.23477457 |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 533         |\n",
      "|    time_elapsed         | 9925        |\n",
      "|    total_timesteps      | 1091584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029014315 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 5320        |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    reward               | -1.9887174  |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 534         |\n",
      "|    time_elapsed         | 9944        |\n",
      "|    total_timesteps      | 1093632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018301044 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 5330        |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    reward               | -0.47210437 |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 535         |\n",
      "|    time_elapsed         | 9962        |\n",
      "|    total_timesteps      | 1095680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017705124 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.0745      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 5340        |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    reward               | 0.96268106  |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4580356.98\n",
      "total_reward: 3580356.98\n",
      "total_cost: 292426.26\n",
      "total_trades: 69887\n",
      "Sharpe: 0.849\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 536         |\n",
      "|    time_elapsed         | 9980        |\n",
      "|    total_timesteps      | 1097728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022124639 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 5350        |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    reward               | 0.5253636   |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 537         |\n",
      "|    time_elapsed         | 9998        |\n",
      "|    total_timesteps      | 1099776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013914009 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 5360        |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    reward               | -0.45114133 |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 52.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 538         |\n",
      "|    time_elapsed         | 10016       |\n",
      "|    total_timesteps      | 1101824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023791946 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | 0.0124      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.1        |\n",
      "|    n_updates            | 5370        |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | -2.8398411  |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 82.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 539         |\n",
      "|    time_elapsed         | 10034       |\n",
      "|    total_timesteps      | 1103872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021538004 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | 0.0029      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.6         |\n",
      "|    n_updates            | 5380        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.2737805  |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 540         |\n",
      "|    time_elapsed         | 10053       |\n",
      "|    total_timesteps      | 1105920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017973293 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 5390        |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | 0.8369111   |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 541         |\n",
      "|    time_elapsed         | 10071       |\n",
      "|    total_timesteps      | 1107968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015139477 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 5400        |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    reward               | -8.23053    |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 52.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 542         |\n",
      "|    time_elapsed         | 10090       |\n",
      "|    total_timesteps      | 1110016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009677164 |\n",
      "|    clip_fraction        | 0.0816      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.8       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 5410        |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    reward               | 4.648191    |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 51.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 10108       |\n",
      "|    total_timesteps      | 1112064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017627925 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.8       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 5420        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 3.0565517   |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 544         |\n",
      "|    time_elapsed         | 10126       |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016457876 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.8       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 5430        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -0.86452883 |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 47.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 545        |\n",
      "|    time_elapsed         | 10145      |\n",
      "|    total_timesteps      | 1116160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01885535 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.9      |\n",
      "|    explained_variance   | 0.0957     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.1       |\n",
      "|    n_updates            | 5440       |\n",
      "|    policy_gradient_loss | -0.00786   |\n",
      "|    reward               | 0.9494527  |\n",
      "|    std                  | 2.36       |\n",
      "|    value_loss           | 47.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 546        |\n",
      "|    time_elapsed         | 10163      |\n",
      "|    total_timesteps      | 1118208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01964145 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.9      |\n",
      "|    explained_variance   | -0.0567    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.8       |\n",
      "|    n_updates            | 5450       |\n",
      "|    policy_gradient_loss | -0.00182   |\n",
      "|    reward               | -0.5290535 |\n",
      "|    std                  | 2.36       |\n",
      "|    value_loss           | 22.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 547         |\n",
      "|    time_elapsed         | 10181       |\n",
      "|    total_timesteps      | 1120256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027394757 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | 0.0331      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 5460        |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    reward               | 5.5753493   |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 56.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 548         |\n",
      "|    time_elapsed         | 10199       |\n",
      "|    total_timesteps      | 1122304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013288457 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | 0.061       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 5470        |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    reward               | -0.4059572  |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 58.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 10218       |\n",
      "|    total_timesteps      | 1124352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021755315 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.0276      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.8        |\n",
      "|    n_updates            | 5480        |\n",
      "|    policy_gradient_loss | -0.00877    |\n",
      "|    reward               | 1.9546888   |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 61.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4739633.88\n",
      "total_reward: 3739633.88\n",
      "total_cost: 317444.10\n",
      "total_trades: 71187\n",
      "Sharpe: 0.820\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 550         |\n",
      "|    time_elapsed         | 10236       |\n",
      "|    total_timesteps      | 1126400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021644924 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.00513     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.9        |\n",
      "|    n_updates            | 5490        |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    reward               | 0.094643295 |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 89          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 551         |\n",
      "|    time_elapsed         | 10255       |\n",
      "|    total_timesteps      | 1128448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018569166 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.049       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.3        |\n",
      "|    n_updates            | 5500        |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    reward               | 0.23643266  |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 61.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 552         |\n",
      "|    time_elapsed         | 10273       |\n",
      "|    total_timesteps      | 1130496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024927936 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.0511      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 5510        |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    reward               | 2.2201343   |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 71.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 10292       |\n",
      "|    total_timesteps      | 1132544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01984095  |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.1         |\n",
      "|    n_updates            | 5520        |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    reward               | -0.17246552 |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 554         |\n",
      "|    time_elapsed         | 10311       |\n",
      "|    total_timesteps      | 1134592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025050972 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.0499      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 5530        |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    reward               | 0.1555381   |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 57.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 555         |\n",
      "|    time_elapsed         | 10330       |\n",
      "|    total_timesteps      | 1136640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024257177 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | 0.0424      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 5540        |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    reward               | 3.9460158   |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 58.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 556         |\n",
      "|    time_elapsed         | 10349       |\n",
      "|    total_timesteps      | 1138688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016083876 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | 0.053       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 5550        |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | -2.0757933  |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 557         |\n",
      "|    time_elapsed         | 10368       |\n",
      "|    total_timesteps      | 1140736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02348252  |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | 0.0537      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 5560        |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    reward               | -0.77355963 |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 50          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 558         |\n",
      "|    time_elapsed         | 10386       |\n",
      "|    total_timesteps      | 1142784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024399392 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.3       |\n",
      "|    explained_variance   | 0.077       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.8        |\n",
      "|    n_updates            | 5570        |\n",
      "|    policy_gradient_loss | -0.000688   |\n",
      "|    reward               | -0.23216248 |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 68.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 10405       |\n",
      "|    total_timesteps      | 1144832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022075037 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.4       |\n",
      "|    explained_variance   | 0.0859      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 5580        |\n",
      "|    policy_gradient_loss | 0.00175     |\n",
      "|    reward               | 0.035387557 |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 65.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 560        |\n",
      "|    time_elapsed         | 10423      |\n",
      "|    total_timesteps      | 1146880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01713446 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.5      |\n",
      "|    explained_variance   | 0.107      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.33       |\n",
      "|    n_updates            | 5590       |\n",
      "|    policy_gradient_loss | -0.00998   |\n",
      "|    reward               | 1.4599884  |\n",
      "|    std                  | 2.41       |\n",
      "|    value_loss           | 15.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 561        |\n",
      "|    time_elapsed         | 10440      |\n",
      "|    total_timesteps      | 1148928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01843888 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.6      |\n",
      "|    explained_variance   | 0.035      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.1       |\n",
      "|    n_updates            | 5600       |\n",
      "|    policy_gradient_loss | -0.00573   |\n",
      "|    reward               | 0.5563185  |\n",
      "|    std                  | 2.42       |\n",
      "|    value_loss           | 58.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 562         |\n",
      "|    time_elapsed         | 10458       |\n",
      "|    total_timesteps      | 1150976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020798447 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.9        |\n",
      "|    n_updates            | 5610        |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    reward               | -1.8380488  |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 49.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 563         |\n",
      "|    time_elapsed         | 10476       |\n",
      "|    total_timesteps      | 1153024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017180745 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.8       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 5620        |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    reward               | -0.38932174 |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4283188.36\n",
      "total_reward: 3283188.36\n",
      "total_cost: 271779.23\n",
      "total_trades: 69200\n",
      "Sharpe: 0.796\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 564        |\n",
      "|    time_elapsed         | 10495      |\n",
      "|    total_timesteps      | 1155072    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02189275 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.8      |\n",
      "|    explained_variance   | 0.215      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.9       |\n",
      "|    n_updates            | 5630       |\n",
      "|    policy_gradient_loss | -0.00609   |\n",
      "|    reward               | 1.3248059  |\n",
      "|    std                  | 2.43       |\n",
      "|    value_loss           | 33         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 565         |\n",
      "|    time_elapsed         | 10513       |\n",
      "|    total_timesteps      | 1157120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013361601 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.8       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 5640        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | -2.0715783  |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 566        |\n",
      "|    time_elapsed         | 10531      |\n",
      "|    total_timesteps      | 1159168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02222487 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.8      |\n",
      "|    explained_variance   | 0.131      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.2       |\n",
      "|    n_updates            | 5650       |\n",
      "|    policy_gradient_loss | 0.000743   |\n",
      "|    reward               | 1.2920489  |\n",
      "|    std                  | 2.43       |\n",
      "|    value_loss           | 39         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 567        |\n",
      "|    time_elapsed         | 10549      |\n",
      "|    total_timesteps      | 1161216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01807663 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.9      |\n",
      "|    explained_variance   | 0.198      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.79       |\n",
      "|    n_updates            | 5660       |\n",
      "|    policy_gradient_loss | -0.0223    |\n",
      "|    reward               | -5.03255   |\n",
      "|    std                  | 2.44       |\n",
      "|    value_loss           | 23         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 568         |\n",
      "|    time_elapsed         | 10567       |\n",
      "|    total_timesteps      | 1163264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02026555  |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 5670        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -0.07438978 |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 569         |\n",
      "|    time_elapsed         | 10585       |\n",
      "|    total_timesteps      | 1165312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017321263 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 5680        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -11.988398  |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 59.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 570         |\n",
      "|    time_elapsed         | 10603       |\n",
      "|    total_timesteps      | 1167360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016314037 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 5690        |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    reward               | 1.397583    |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 571         |\n",
      "|    time_elapsed         | 10621       |\n",
      "|    total_timesteps      | 1169408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016437765 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.1       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 5700        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 0.77676886  |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 572        |\n",
      "|    time_elapsed         | 10639      |\n",
      "|    total_timesteps      | 1171456    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01619628 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.1      |\n",
      "|    explained_variance   | 0.182      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.1       |\n",
      "|    n_updates            | 5710       |\n",
      "|    policy_gradient_loss | -0.00417   |\n",
      "|    reward               | -0.0899415 |\n",
      "|    std                  | 2.46       |\n",
      "|    value_loss           | 58.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 573        |\n",
      "|    time_elapsed         | 10657      |\n",
      "|    total_timesteps      | 1173504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01562522 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.2      |\n",
      "|    explained_variance   | 0.0627     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.4       |\n",
      "|    n_updates            | 5720       |\n",
      "|    policy_gradient_loss | -0.0106    |\n",
      "|    reward               | 0.41216904 |\n",
      "|    std                  | 2.47       |\n",
      "|    value_loss           | 36.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 574         |\n",
      "|    time_elapsed         | 10674       |\n",
      "|    total_timesteps      | 1175552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025509913 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 5730        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | -1.0544955  |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 575         |\n",
      "|    time_elapsed         | 10692       |\n",
      "|    total_timesteps      | 1177600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021668028 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.3       |\n",
      "|    explained_variance   | 0.0245      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.5        |\n",
      "|    n_updates            | 5740        |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    reward               | -0.7765369  |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 89.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 576         |\n",
      "|    time_elapsed         | 10711       |\n",
      "|    total_timesteps      | 1179648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017371584 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.0953      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 5750        |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    reward               | 0.8683942   |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 67.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 577         |\n",
      "|    time_elapsed         | 10729       |\n",
      "|    total_timesteps      | 1181696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023921434 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.15        |\n",
      "|    n_updates            | 5760        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.131342   |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4227728.48\n",
      "total_reward: 3227728.48\n",
      "total_cost: 306083.94\n",
      "total_trades: 69964\n",
      "Sharpe: 0.826\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 578         |\n",
      "|    time_elapsed         | 10747       |\n",
      "|    total_timesteps      | 1183744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023396587 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.0633      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 5770        |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | -0.37024185 |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 579         |\n",
      "|    time_elapsed         | 10765       |\n",
      "|    total_timesteps      | 1185792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019046199 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.5       |\n",
      "|    explained_variance   | 0.0933      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 5780        |\n",
      "|    policy_gradient_loss | 0.000294    |\n",
      "|    reward               | 1.7834828   |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 56.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 580         |\n",
      "|    time_elapsed         | 10783       |\n",
      "|    total_timesteps      | 1187840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015941747 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.5       |\n",
      "|    explained_variance   | -0.119      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 5790        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 0.04821679  |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 581         |\n",
      "|    time_elapsed         | 10802       |\n",
      "|    total_timesteps      | 1189888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019728512 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.5       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 5800        |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | 1.465997    |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 582         |\n",
      "|    time_elapsed         | 10821       |\n",
      "|    total_timesteps      | 1191936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022462822 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.0437      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 5810        |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    reward               | -0.09743509 |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 583         |\n",
      "|    time_elapsed         | 10840       |\n",
      "|    total_timesteps      | 1193984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011594921 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.0738      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 5820        |\n",
      "|    policy_gradient_loss | -0.00025    |\n",
      "|    reward               | 1.187158    |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 70.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 584         |\n",
      "|    time_elapsed         | 10858       |\n",
      "|    total_timesteps      | 1196032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019788815 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.56        |\n",
      "|    n_updates            | 5830        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 0.25919214  |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 585         |\n",
      "|    time_elapsed         | 10876       |\n",
      "|    total_timesteps      | 1198080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012959469 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 5840        |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    reward               | 0.8869775   |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 586          |\n",
      "|    time_elapsed         | 10894        |\n",
      "|    total_timesteps      | 1200128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134625845 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -67.7        |\n",
      "|    explained_variance   | 0.13         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 5850         |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    reward               | 0.57017463   |\n",
      "|    std                  | 2.51         |\n",
      "|    value_loss           | 29           |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 587        |\n",
      "|    time_elapsed         | 10912      |\n",
      "|    total_timesteps      | 1202176    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01900323 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.7      |\n",
      "|    explained_variance   | 0.0274     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.3       |\n",
      "|    n_updates            | 5860       |\n",
      "|    policy_gradient_loss | -0.00394   |\n",
      "|    reward               | 0.69040716 |\n",
      "|    std                  | 2.51       |\n",
      "|    value_loss           | 24.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 588         |\n",
      "|    time_elapsed         | 10930       |\n",
      "|    total_timesteps      | 1204224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023006178 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.07        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 5870        |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    reward               | -0.37360868 |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 57.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 589         |\n",
      "|    time_elapsed         | 10949       |\n",
      "|    total_timesteps      | 1206272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012907833 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.0289      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 5880        |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    reward               | -4.744668   |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 60.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 590         |\n",
      "|    time_elapsed         | 10967       |\n",
      "|    total_timesteps      | 1208320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021849692 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | -0.0186     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 5890        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 2.4293869   |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 591          |\n",
      "|    time_elapsed         | 10986        |\n",
      "|    total_timesteps      | 1210368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.020095278  |\n",
      "|    clip_fraction        | 0.203        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68          |\n",
      "|    explained_variance   | 0.117        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 5900         |\n",
      "|    policy_gradient_loss | -0.00904     |\n",
      "|    reward               | -0.021230271 |\n",
      "|    std                  | 2.54         |\n",
      "|    value_loss           | 26.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4053287.94\n",
      "total_reward: 3053287.94\n",
      "total_cost: 281817.91\n",
      "total_trades: 69221\n",
      "Sharpe: 0.771\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 592         |\n",
      "|    time_elapsed         | 11004       |\n",
      "|    total_timesteps      | 1212416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017584767 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.077       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 5910        |\n",
      "|    policy_gradient_loss | -0.00681    |\n",
      "|    reward               | -0.11497906 |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 54.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 593         |\n",
      "|    time_elapsed         | 11023       |\n",
      "|    total_timesteps      | 1214464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010700702 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.0411      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.5        |\n",
      "|    n_updates            | 5920        |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    reward               | 3.6239367   |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 72.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 594         |\n",
      "|    time_elapsed         | 11041       |\n",
      "|    total_timesteps      | 1216512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027891014 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.00633     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 5930        |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | -2.6366765  |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 595        |\n",
      "|    time_elapsed         | 11060      |\n",
      "|    total_timesteps      | 1218560    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01679694 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.2      |\n",
      "|    explained_variance   | 0.13       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.8       |\n",
      "|    n_updates            | 5940       |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    reward               | -3.1973288 |\n",
      "|    std                  | 2.56       |\n",
      "|    value_loss           | 37.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 596         |\n",
      "|    time_elapsed         | 11079       |\n",
      "|    total_timesteps      | 1220608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012706192 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 5950        |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    reward               | -1.3483926  |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 11098       |\n",
      "|    total_timesteps      | 1222656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02755473  |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | -0.0732     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 5960        |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    reward               | 0.064667135 |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 598           |\n",
      "|    time_elapsed         | 11116         |\n",
      "|    total_timesteps      | 1224704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.017912816   |\n",
      "|    clip_fraction        | 0.193         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -68.4         |\n",
      "|    explained_variance   | 0.18          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.22          |\n",
      "|    n_updates            | 5970          |\n",
      "|    policy_gradient_loss | -0.0134       |\n",
      "|    reward               | -0.0019563006 |\n",
      "|    std                  | 2.57          |\n",
      "|    value_loss           | 24.9          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 599         |\n",
      "|    time_elapsed         | 11135       |\n",
      "|    total_timesteps      | 1226752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012360111 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 5980        |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    reward               | 1.420122    |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 600         |\n",
      "|    time_elapsed         | 11153       |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020760655 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.0406      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 5990        |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    reward               | 1.3636097   |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 601         |\n",
      "|    time_elapsed         | 11172       |\n",
      "|    total_timesteps      | 1230848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017986894 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | -0.00562    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.93        |\n",
      "|    n_updates            | 6000        |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    reward               | 0.41791326  |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 602         |\n",
      "|    time_elapsed         | 11190       |\n",
      "|    total_timesteps      | 1232896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018418562 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 6010        |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    reward               | 1.2478938   |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 11209       |\n",
      "|    total_timesteps      | 1234944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014682377 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 6020        |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    reward               | 0.022280246 |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 604         |\n",
      "|    time_elapsed         | 11227       |\n",
      "|    total_timesteps      | 1236992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020438109 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | 0.0198      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 6030        |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    reward               | 5.298462    |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 605         |\n",
      "|    time_elapsed         | 11244       |\n",
      "|    total_timesteps      | 1239040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015008149 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.06        |\n",
      "|    n_updates            | 6040        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -0.06794726 |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 606         |\n",
      "|    time_elapsed         | 11262       |\n",
      "|    total_timesteps      | 1241088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014182794 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.7       |\n",
      "|    explained_variance   | 0.0144      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.4        |\n",
      "|    n_updates            | 6050        |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    reward               | -3.1537924  |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 72.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3646875.46\n",
      "total_reward: 2646875.46\n",
      "total_cost: 160796.19\n",
      "total_trades: 60992\n",
      "Sharpe: 0.739\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 11280       |\n",
      "|    total_timesteps      | 1243136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016689945 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.7       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 6060        |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    reward               | -0.759525   |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 608         |\n",
      "|    time_elapsed         | 11298       |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021076215 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.67        |\n",
      "|    n_updates            | 6070        |\n",
      "|    policy_gradient_loss | -0.00896    |\n",
      "|    reward               | 0.87816447  |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 609         |\n",
      "|    time_elapsed         | 11316       |\n",
      "|    total_timesteps      | 1247232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017898671 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.06        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 6080        |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    reward               | -0.8008172  |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 80.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 610        |\n",
      "|    time_elapsed         | 11334      |\n",
      "|    total_timesteps      | 1249280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01542154 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.8      |\n",
      "|    explained_variance   | 0.0386     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 45.3       |\n",
      "|    n_updates            | 6090       |\n",
      "|    policy_gradient_loss | -0.00452   |\n",
      "|    reward               | 5.909574   |\n",
      "|    std                  | 2.61       |\n",
      "|    value_loss           | 100        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 611        |\n",
      "|    time_elapsed         | 11352      |\n",
      "|    total_timesteps      | 1251328    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02189915 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.9      |\n",
      "|    explained_variance   | 0.0347     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.3       |\n",
      "|    n_updates            | 6100       |\n",
      "|    policy_gradient_loss | 0.00079    |\n",
      "|    reward               | 0.90857023 |\n",
      "|    std                  | 2.62       |\n",
      "|    value_loss           | 28.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 612        |\n",
      "|    time_elapsed         | 11370      |\n",
      "|    total_timesteps      | 1253376    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02486248 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.9      |\n",
      "|    explained_variance   | 0.138      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 36.3       |\n",
      "|    n_updates            | 6110       |\n",
      "|    policy_gradient_loss | -0.00237   |\n",
      "|    reward               | 2.225817   |\n",
      "|    std                  | 2.62       |\n",
      "|    value_loss           | 64.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 613         |\n",
      "|    time_elapsed         | 11388       |\n",
      "|    total_timesteps      | 1255424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017517317 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 6120        |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    reward               | 8.733605    |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 84.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 614         |\n",
      "|    time_elapsed         | 11408       |\n",
      "|    total_timesteps      | 1257472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017950285 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.0305      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 6130        |\n",
      "|    policy_gradient_loss | -0.00162    |\n",
      "|    reward               | 0.57124305  |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 11428       |\n",
      "|    total_timesteps      | 1259520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018830772 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.1       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 6140        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 0.6719994   |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 616        |\n",
      "|    time_elapsed         | 11448      |\n",
      "|    total_timesteps      | 1261568    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01473112 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.1      |\n",
      "|    explained_variance   | 0.0725     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 51.8       |\n",
      "|    n_updates            | 6150       |\n",
      "|    policy_gradient_loss | -0.00748   |\n",
      "|    reward               | 1.2346146  |\n",
      "|    std                  | 2.64       |\n",
      "|    value_loss           | 96.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 11466       |\n",
      "|    total_timesteps      | 1263616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019131603 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.2       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 6160        |\n",
      "|    policy_gradient_loss | 0.0055      |\n",
      "|    reward               | 3.222917    |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 61.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 618          |\n",
      "|    time_elapsed         | 11484        |\n",
      "|    total_timesteps      | 1265664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.025400255  |\n",
      "|    clip_fraction        | 0.276        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.2        |\n",
      "|    explained_variance   | 0.14         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.98         |\n",
      "|    n_updates            | 6170         |\n",
      "|    policy_gradient_loss | -0.00768     |\n",
      "|    reward               | 0.0036924365 |\n",
      "|    std                  | 2.64         |\n",
      "|    value_loss           | 20.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 619         |\n",
      "|    time_elapsed         | 11502       |\n",
      "|    total_timesteps      | 1267712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013174653 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.2       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 6180        |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | 0.47395748  |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 620         |\n",
      "|    time_elapsed         | 11520       |\n",
      "|    total_timesteps      | 1269760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013752397 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 6190        |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    reward               | 3.4500332   |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4205510.30\n",
      "total_reward: 3205510.30\n",
      "total_cost: 198347.82\n",
      "total_trades: 64265\n",
      "Sharpe: 0.781\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 621         |\n",
      "|    time_elapsed         | 11538       |\n",
      "|    total_timesteps      | 1271808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016750548 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.0328      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 6200        |\n",
      "|    policy_gradient_loss | -0.00161    |\n",
      "|    reward               | 0.9222795   |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 622         |\n",
      "|    time_elapsed         | 11556       |\n",
      "|    total_timesteps      | 1273856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013840266 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.4       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 6210        |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    reward               | 0.5122682   |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 623         |\n",
      "|    time_elapsed         | 11575       |\n",
      "|    total_timesteps      | 1275904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014420699 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.4       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 6220        |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    reward               | 0.85975933  |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 39.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 624        |\n",
      "|    time_elapsed         | 11593      |\n",
      "|    total_timesteps      | 1277952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01210575 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.4      |\n",
      "|    explained_variance   | 0.173      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.4       |\n",
      "|    n_updates            | 6230       |\n",
      "|    policy_gradient_loss | -0.00294   |\n",
      "|    reward               | -0.8159381 |\n",
      "|    std                  | 2.66       |\n",
      "|    value_loss           | 48.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 625         |\n",
      "|    time_elapsed         | 11611       |\n",
      "|    total_timesteps      | 1280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016068585 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.0271      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 6240        |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    reward               | -0.52868277 |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 626         |\n",
      "|    time_elapsed         | 11629       |\n",
      "|    total_timesteps      | 1282048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019045886 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 6250        |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    reward               | -0.36696845 |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 627         |\n",
      "|    time_elapsed         | 11647       |\n",
      "|    total_timesteps      | 1284096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013286894 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 6260        |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    reward               | 3.550858    |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 628         |\n",
      "|    time_elapsed         | 11665       |\n",
      "|    total_timesteps      | 1286144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011176191 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.0771      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.5         |\n",
      "|    n_updates            | 6270        |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    reward               | 1.3984361   |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 629         |\n",
      "|    time_elapsed         | 11683       |\n",
      "|    total_timesteps      | 1288192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015929434 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.82        |\n",
      "|    n_updates            | 6280        |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    reward               | -0.3566821  |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 630         |\n",
      "|    time_elapsed         | 11702       |\n",
      "|    total_timesteps      | 1290240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012145969 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 6290        |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    reward               | -2.36007    |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 30.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 11719       |\n",
      "|    total_timesteps      | 1292288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019849094 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.0688      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 6300        |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    reward               | 0.63563764  |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 44.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 632        |\n",
      "|    time_elapsed         | 11737      |\n",
      "|    total_timesteps      | 1294336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01642604 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.7      |\n",
      "|    explained_variance   | 0.199      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.34       |\n",
      "|    n_updates            | 6310       |\n",
      "|    policy_gradient_loss | -0.00962   |\n",
      "|    reward               | -0.1772247 |\n",
      "|    std                  | 2.7        |\n",
      "|    value_loss           | 14.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 633         |\n",
      "|    time_elapsed         | 11755       |\n",
      "|    total_timesteps      | 1296384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01677709  |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 6320        |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    reward               | -0.13795322 |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 634         |\n",
      "|    time_elapsed         | 11780       |\n",
      "|    total_timesteps      | 1298432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013941474 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 6330        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -4.003911   |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3213358.49\n",
      "total_reward: 2213358.49\n",
      "total_cost: 130199.21\n",
      "total_trades: 58500\n",
      "Sharpe: 0.660\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 635         |\n",
      "|    time_elapsed         | 11798       |\n",
      "|    total_timesteps      | 1300480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011117822 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.2         |\n",
      "|    n_updates            | 6340        |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    reward               | 4.341339    |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 23.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 636         |\n",
      "|    time_elapsed         | 11816       |\n",
      "|    total_timesteps      | 1302528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018769737 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.19        |\n",
      "|    n_updates            | 6350        |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    reward               | 1.026418    |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 637         |\n",
      "|    time_elapsed         | 11834       |\n",
      "|    total_timesteps      | 1304576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015689274 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 6360        |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    reward               | -2.4792795  |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 638         |\n",
      "|    time_elapsed         | 11852       |\n",
      "|    total_timesteps      | 1306624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017932814 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 6370        |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    reward               | 1.7649194   |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 639         |\n",
      "|    time_elapsed         | 11870       |\n",
      "|    total_timesteps      | 1308672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017777717 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 6380        |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | -0.68006986 |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 640         |\n",
      "|    time_elapsed         | 11889       |\n",
      "|    total_timesteps      | 1310720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016384352 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 6390        |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    reward               | 1.6178759   |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 641         |\n",
      "|    time_elapsed         | 11907       |\n",
      "|    total_timesteps      | 1312768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010810906 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.0747      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 6400        |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    reward               | -0.44615003 |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 59.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 642         |\n",
      "|    time_elapsed         | 11926       |\n",
      "|    total_timesteps      | 1314816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019556865 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | -0.0205     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.81        |\n",
      "|    n_updates            | 6410        |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | 1.962206    |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 643         |\n",
      "|    time_elapsed         | 11944       |\n",
      "|    total_timesteps      | 1316864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013248166 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 6420        |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    reward               | 0.44961235  |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 644         |\n",
      "|    time_elapsed         | 11962       |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018609408 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 6430        |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    reward               | 3.7975304   |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 645         |\n",
      "|    time_elapsed         | 11981       |\n",
      "|    total_timesteps      | 1320960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020913815 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.0542      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 6440        |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    reward               | -3.9865391  |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 646        |\n",
      "|    time_elapsed         | 12000      |\n",
      "|    total_timesteps      | 1323008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01684914 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.2      |\n",
      "|    explained_variance   | 0.194      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12         |\n",
      "|    n_updates            | 6450       |\n",
      "|    policy_gradient_loss | -0.00631   |\n",
      "|    reward               | 0.8158044  |\n",
      "|    std                  | 2.73       |\n",
      "|    value_loss           | 25.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 647        |\n",
      "|    time_elapsed         | 12017      |\n",
      "|    total_timesteps      | 1325056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01679405 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.2      |\n",
      "|    explained_variance   | 0.132      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.9       |\n",
      "|    n_updates            | 6460       |\n",
      "|    policy_gradient_loss | -0.00347   |\n",
      "|    reward               | 1.3151377  |\n",
      "|    std                  | 2.73       |\n",
      "|    value_loss           | 42.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 648         |\n",
      "|    time_elapsed         | 12036       |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015540353 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.2       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 6470        |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    reward               | -0.69785345 |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3578626.07\n",
      "total_reward: 2578626.07\n",
      "total_cost: 107647.51\n",
      "total_trades: 58059\n",
      "Sharpe: 0.687\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 649         |\n",
      "|    time_elapsed         | 12054       |\n",
      "|    total_timesteps      | 1329152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014676964 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.2       |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.35        |\n",
      "|    n_updates            | 6480        |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    reward               | -0.7056901  |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 650         |\n",
      "|    time_elapsed         | 12071       |\n",
      "|    total_timesteps      | 1331200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013671821 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.2       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 6490        |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    reward               | 1.0593592   |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 651         |\n",
      "|    time_elapsed         | 12089       |\n",
      "|    total_timesteps      | 1333248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018172093 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 6500        |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    reward               | 0.21474941  |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 652        |\n",
      "|    time_elapsed         | 12107      |\n",
      "|    total_timesteps      | 1335296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02263413 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.3      |\n",
      "|    explained_variance   | -0.00686   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.2       |\n",
      "|    n_updates            | 6510       |\n",
      "|    policy_gradient_loss | -0.0106    |\n",
      "|    reward               | 1.4079984  |\n",
      "|    std                  | 2.75       |\n",
      "|    value_loss           | 31.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 12125       |\n",
      "|    total_timesteps      | 1337344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020052252 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 6520        |\n",
      "|    policy_gradient_loss | -0.00992    |\n",
      "|    reward               | 2.2313442   |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 12143       |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018357804 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 6530        |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    reward               | 2.430017    |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 655         |\n",
      "|    time_elapsed         | 12162       |\n",
      "|    total_timesteps      | 1341440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012006232 |\n",
      "|    clip_fraction        | 0.0969      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 6540        |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | -1.7760618  |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 656         |\n",
      "|    time_elapsed         | 12179       |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014716726 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.6       |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.68        |\n",
      "|    n_updates            | 6550        |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | 1.0387391   |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 657        |\n",
      "|    time_elapsed         | 12198      |\n",
      "|    total_timesteps      | 1345536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01825171 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.6      |\n",
      "|    explained_variance   | 0.267      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.3       |\n",
      "|    n_updates            | 6560       |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    reward               | 0.20131612 |\n",
      "|    std                  | 2.78       |\n",
      "|    value_loss           | 35.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 658         |\n",
      "|    time_elapsed         | 12215       |\n",
      "|    total_timesteps      | 1347584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016228963 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.7       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 6570        |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    reward               | 0.7082879   |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 12234       |\n",
      "|    total_timesteps      | 1349632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013339539 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.7       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.57        |\n",
      "|    n_updates            | 6580        |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    reward               | -1.1173954  |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 660         |\n",
      "|    time_elapsed         | 12253       |\n",
      "|    total_timesteps      | 1351680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015605553 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.71        |\n",
      "|    n_updates            | 6590        |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    reward               | -0.69319427 |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 661          |\n",
      "|    time_elapsed         | 12271        |\n",
      "|    total_timesteps      | 1353728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097809285 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.8        |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 6600         |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    reward               | 0.28760493   |\n",
      "|    std                  | 2.79         |\n",
      "|    value_loss           | 32.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 662        |\n",
      "|    time_elapsed         | 12290      |\n",
      "|    total_timesteps      | 1355776    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01885606 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.8      |\n",
      "|    explained_variance   | 0.137      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.9       |\n",
      "|    n_updates            | 6610       |\n",
      "|    policy_gradient_loss | 0.00214    |\n",
      "|    reward               | 0.7729454  |\n",
      "|    std                  | 2.8        |\n",
      "|    value_loss           | 30.4       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4171310.57\n",
      "total_reward: 3171310.57\n",
      "total_cost: 198848.87\n",
      "total_trades: 63146\n",
      "Sharpe: 0.800\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 663        |\n",
      "|    time_elapsed         | 12308      |\n",
      "|    total_timesteps      | 1357824    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02691476 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.9      |\n",
      "|    explained_variance   | 0.298      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.3        |\n",
      "|    n_updates            | 6620       |\n",
      "|    policy_gradient_loss | -0.00586   |\n",
      "|    reward               | -0.5749987 |\n",
      "|    std                  | 2.81       |\n",
      "|    value_loss           | 19.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 664         |\n",
      "|    time_elapsed         | 12326       |\n",
      "|    total_timesteps      | 1359872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015206007 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 6630        |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    reward               | 0.529461    |\n",
      "|    std                  | 2.82        |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 665          |\n",
      "|    time_elapsed         | 12344        |\n",
      "|    total_timesteps      | 1361920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013471693  |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.1        |\n",
      "|    explained_variance   | 0.271        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 6640         |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    reward               | -0.094624706 |\n",
      "|    std                  | 2.82         |\n",
      "|    value_loss           | 37.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 12362       |\n",
      "|    total_timesteps      | 1363968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020569181 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.0528      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.55        |\n",
      "|    n_updates            | 6650        |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    reward               | 0.14194538  |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 667         |\n",
      "|    time_elapsed         | 12380       |\n",
      "|    total_timesteps      | 1366016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012966774 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 6660        |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | -0.04461537 |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 668          |\n",
      "|    time_elapsed         | 12399        |\n",
      "|    total_timesteps      | 1368064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122246165 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.3        |\n",
      "|    explained_variance   | 0.138        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 6670         |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | 0.51398295   |\n",
      "|    std                  | 2.84         |\n",
      "|    value_loss           | 49.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 669         |\n",
      "|    time_elapsed         | 12417       |\n",
      "|    total_timesteps      | 1370112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018275738 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.3       |\n",
      "|    explained_variance   | 0.0876      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 6680        |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | 0.32272077  |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 54.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 670          |\n",
      "|    time_elapsed         | 12434        |\n",
      "|    total_timesteps      | 1372160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081531275 |\n",
      "|    clip_fraction        | 0.0549       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.3        |\n",
      "|    explained_variance   | 0.116        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.59         |\n",
      "|    n_updates            | 6690         |\n",
      "|    policy_gradient_loss | -0.00782     |\n",
      "|    reward               | 0.62404925   |\n",
      "|    std                  | 2.84         |\n",
      "|    value_loss           | 36.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 671          |\n",
      "|    time_elapsed         | 12452        |\n",
      "|    total_timesteps      | 1374208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096195545 |\n",
      "|    clip_fraction        | 0.0976       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.4        |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 6700         |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | -0.33111626  |\n",
      "|    std                  | 2.85         |\n",
      "|    value_loss           | 31           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 672         |\n",
      "|    time_elapsed         | 12470       |\n",
      "|    total_timesteps      | 1376256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015058391 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 6710        |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    reward               | 0.33707294  |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 12488       |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021885676 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 6720        |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    reward               | -0.08394534 |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 16.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 674         |\n",
      "|    time_elapsed         | 12506       |\n",
      "|    total_timesteps      | 1380352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008389669 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 6730        |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    reward               | 0.7453365   |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 675         |\n",
      "|    time_elapsed         | 12524       |\n",
      "|    total_timesteps      | 1382400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015018225 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.5       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 6740        |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    reward               | -0.6458695  |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 57.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 676         |\n",
      "|    time_elapsed         | 12543       |\n",
      "|    total_timesteps      | 1384448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010087926 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.5       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 6750        |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    reward               | -2.3369918  |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3004233.68\n",
      "total_reward: 2004233.68\n",
      "total_cost: 123907.17\n",
      "total_trades: 58576\n",
      "Sharpe: 0.601\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 677         |\n",
      "|    time_elapsed         | 12561       |\n",
      "|    total_timesteps      | 1386496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013972791 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.5       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.87        |\n",
      "|    n_updates            | 6760        |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | -0.74458236 |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 678       |\n",
      "|    time_elapsed         | 12579     |\n",
      "|    total_timesteps      | 1388544   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0171944 |\n",
      "|    clip_fraction        | 0.138     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -71.6     |\n",
      "|    explained_variance   | 0.217     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 12.8      |\n",
      "|    n_updates            | 6770      |\n",
      "|    policy_gradient_loss | -0.00281  |\n",
      "|    reward               | 4.984734  |\n",
      "|    std                  | 2.87      |\n",
      "|    value_loss           | 33.4      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 679         |\n",
      "|    time_elapsed         | 12597       |\n",
      "|    total_timesteps      | 1390592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014557863 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.6       |\n",
      "|    explained_variance   | 0.0969      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 6780        |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    reward               | -0.1317268  |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 42.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 680         |\n",
      "|    time_elapsed         | 12615       |\n",
      "|    total_timesteps      | 1392640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018219708 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 6790        |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | -2.134086   |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 681          |\n",
      "|    time_elapsed         | 12633        |\n",
      "|    total_timesteps      | 1394688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120111145 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.7        |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 6800         |\n",
      "|    policy_gradient_loss | -0.00771     |\n",
      "|    reward               | 1.7856463    |\n",
      "|    std                  | 2.88         |\n",
      "|    value_loss           | 47.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 682        |\n",
      "|    time_elapsed         | 12652      |\n",
      "|    total_timesteps      | 1396736    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01487489 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.7      |\n",
      "|    explained_variance   | 0.225      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.4       |\n",
      "|    n_updates            | 6810       |\n",
      "|    policy_gradient_loss | -0.00502   |\n",
      "|    reward               | 2.0113118  |\n",
      "|    std                  | 2.88       |\n",
      "|    value_loss           | 48.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 683         |\n",
      "|    time_elapsed         | 12670       |\n",
      "|    total_timesteps      | 1398784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025296763 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.8       |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 6820        |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | -0.4112388  |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 684         |\n",
      "|    time_elapsed         | 12687       |\n",
      "|    total_timesteps      | 1400832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010611378 |\n",
      "|    clip_fraction        | 0.0823      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.9       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.58        |\n",
      "|    n_updates            | 6830        |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    reward               | 0.5590805   |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 685         |\n",
      "|    time_elapsed         | 12705       |\n",
      "|    total_timesteps      | 1402880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012860585 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.9       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 6840        |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    reward               | -3.290309   |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 53          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 686         |\n",
      "|    time_elapsed         | 12724       |\n",
      "|    total_timesteps      | 1404928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017471656 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.9       |\n",
      "|    explained_variance   | 0.0031      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 6850        |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    reward               | 1.5811961   |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 687         |\n",
      "|    time_elapsed         | 12742       |\n",
      "|    total_timesteps      | 1406976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013002049 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.65        |\n",
      "|    n_updates            | 6860        |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    reward               | 0.04875792  |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 688          |\n",
      "|    time_elapsed         | 12759        |\n",
      "|    total_timesteps      | 1409024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0133727165 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72          |\n",
      "|    explained_variance   | 0.177        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.6         |\n",
      "|    n_updates            | 6870         |\n",
      "|    policy_gradient_loss | -0.00759     |\n",
      "|    reward               | 2.7227085    |\n",
      "|    std                  | 2.91         |\n",
      "|    value_loss           | 42.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 689          |\n",
      "|    time_elapsed         | 12778        |\n",
      "|    total_timesteps      | 1411072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0137606375 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72          |\n",
      "|    explained_variance   | 0.145        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 6880         |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    reward               | -1.0909672   |\n",
      "|    std                  | 2.91         |\n",
      "|    value_loss           | 40.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 690         |\n",
      "|    time_elapsed         | 12796       |\n",
      "|    total_timesteps      | 1413120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015891718 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.0405      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.1         |\n",
      "|    n_updates            | 6890        |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    reward               | 0.07318033  |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3709063.44\n",
      "total_reward: 2709063.44\n",
      "total_cost: 131194.92\n",
      "total_trades: 58548\n",
      "Sharpe: 0.713\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 691          |\n",
      "|    time_elapsed         | 12813        |\n",
      "|    total_timesteps      | 1415168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.020498535  |\n",
      "|    clip_fraction        | 0.172        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.1        |\n",
      "|    explained_variance   | 0.165        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 6900         |\n",
      "|    policy_gradient_loss | -0.0082      |\n",
      "|    reward               | -0.018907247 |\n",
      "|    std                  | 2.92         |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 692         |\n",
      "|    time_elapsed         | 12832       |\n",
      "|    total_timesteps      | 1417216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011432057 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 6910        |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    reward               | 2.3996508   |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 12850       |\n",
      "|    total_timesteps      | 1419264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005768626 |\n",
      "|    clip_fraction        | 0.0216      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 6920        |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | 0.16876772  |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 694         |\n",
      "|    time_elapsed         | 12867       |\n",
      "|    total_timesteps      | 1421312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016893309 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 6930        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.27397737 |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 695         |\n",
      "|    time_elapsed         | 12886       |\n",
      "|    total_timesteps      | 1423360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018091412 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 6940        |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    reward               | -0.03219213 |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 696         |\n",
      "|    time_elapsed         | 12904       |\n",
      "|    total_timesteps      | 1425408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013870213 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 6950        |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    reward               | -2.294705   |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 42.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 697         |\n",
      "|    time_elapsed         | 12922       |\n",
      "|    total_timesteps      | 1427456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021149602 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.0231      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.02        |\n",
      "|    n_updates            | 6960        |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    reward               | -0.23821022 |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 12940       |\n",
      "|    total_timesteps      | 1429504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017587986 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 6970        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.5275987   |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 699         |\n",
      "|    time_elapsed         | 12958       |\n",
      "|    total_timesteps      | 1431552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006348061 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 6980        |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    reward               | 0.97823876  |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 48.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 700         |\n",
      "|    time_elapsed         | 12976       |\n",
      "|    total_timesteps      | 1433600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010984577 |\n",
      "|    clip_fraction        | 0.0471      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.071       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.17        |\n",
      "|    n_updates            | 6990        |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    reward               | -0.7739822  |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 36.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 701         |\n",
      "|    time_elapsed         | 12995       |\n",
      "|    total_timesteps      | 1435648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017074678 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 7000        |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    reward               | -4.5063076  |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 702         |\n",
      "|    time_elapsed         | 13013       |\n",
      "|    total_timesteps      | 1437696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009478716 |\n",
      "|    clip_fraction        | 0.0691      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 7010        |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    reward               | 0.32357237  |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 703        |\n",
      "|    time_elapsed         | 13031      |\n",
      "|    total_timesteps      | 1439744    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01371828 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.4      |\n",
      "|    explained_variance   | 0.219      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.4       |\n",
      "|    n_updates            | 7020       |\n",
      "|    policy_gradient_loss | -0.00732   |\n",
      "|    reward               | -2.1579263 |\n",
      "|    std                  | 2.95       |\n",
      "|    value_loss           | 47.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 704        |\n",
      "|    time_elapsed         | 13049      |\n",
      "|    total_timesteps      | 1441792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01472277 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.5      |\n",
      "|    explained_variance   | 0.201      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.2       |\n",
      "|    n_updates            | 7030       |\n",
      "|    policy_gradient_loss | -0.00383   |\n",
      "|    reward               | -0.9506855 |\n",
      "|    std                  | 2.96       |\n",
      "|    value_loss           | 26.2       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3224836.73\n",
      "total_reward: 2224836.73\n",
      "total_cost: 96212.44\n",
      "total_trades: 56358\n",
      "Sharpe: 0.633\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 705         |\n",
      "|    time_elapsed         | 13066       |\n",
      "|    total_timesteps      | 1443840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013145476 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 7040        |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    reward               | 0.45509663  |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 706         |\n",
      "|    time_elapsed         | 13084       |\n",
      "|    total_timesteps      | 1445888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012818085 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.6       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 7050        |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    reward               | 2.1277928   |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 42.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 707         |\n",
      "|    time_elapsed         | 13102       |\n",
      "|    total_timesteps      | 1447936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01767942  |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.6       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.32        |\n",
      "|    n_updates            | 7060        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | -0.20359498 |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 708         |\n",
      "|    time_elapsed         | 13119       |\n",
      "|    total_timesteps      | 1449984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018593306 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 7070        |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    reward               | 0.22384265  |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 709         |\n",
      "|    time_elapsed         | 13137       |\n",
      "|    total_timesteps      | 1452032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020976445 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 7080        |\n",
      "|    policy_gradient_loss | -0.00281    |\n",
      "|    reward               | 1.1362371   |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 43.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 13155       |\n",
      "|    total_timesteps      | 1454080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014792135 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 7090        |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    reward               | 1.3691981   |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 711          |\n",
      "|    time_elapsed         | 13174        |\n",
      "|    total_timesteps      | 1456128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014456816  |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.8        |\n",
      "|    explained_variance   | 0.364        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 7100         |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    reward               | -0.058810737 |\n",
      "|    std                  | 2.99         |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 712         |\n",
      "|    time_elapsed         | 13192       |\n",
      "|    total_timesteps      | 1458176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015751936 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 7110        |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    reward               | -0.26880935 |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 713         |\n",
      "|    time_elapsed         | 13210       |\n",
      "|    total_timesteps      | 1460224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014550905 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 7120        |\n",
      "|    policy_gradient_loss | -0.00999    |\n",
      "|    reward               | 0.3154817   |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 60.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 13229       |\n",
      "|    total_timesteps      | 1462272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024194572 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.45        |\n",
      "|    n_updates            | 7130        |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    reward               | -1.6857564  |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 715        |\n",
      "|    time_elapsed         | 13247      |\n",
      "|    total_timesteps      | 1464320    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01200255 |\n",
      "|    clip_fraction        | 0.0774     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.8      |\n",
      "|    explained_variance   | 0.256      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.7       |\n",
      "|    n_updates            | 7140       |\n",
      "|    policy_gradient_loss | -0.00638   |\n",
      "|    reward               | 0.9409501  |\n",
      "|    std                  | 2.99       |\n",
      "|    value_loss           | 33.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 716         |\n",
      "|    time_elapsed         | 13266       |\n",
      "|    total_timesteps      | 1466368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016080698 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 7150        |\n",
      "|    policy_gradient_loss | 0.000171    |\n",
      "|    reward               | -0.49609286 |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 47.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 717         |\n",
      "|    time_elapsed         | 13284       |\n",
      "|    total_timesteps      | 1468416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014374847 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 7160        |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | 0.7206944   |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 44.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 718         |\n",
      "|    time_elapsed         | 13302       |\n",
      "|    total_timesteps      | 1470464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022002181 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.69        |\n",
      "|    n_updates            | 7170        |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    reward               | -1.2802708  |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 719         |\n",
      "|    time_elapsed         | 13320       |\n",
      "|    total_timesteps      | 1472512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013170974 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 7180        |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | -4.1305923  |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3474478.32\n",
      "total_reward: 2474478.32\n",
      "total_cost: 70533.23\n",
      "total_trades: 54090\n",
      "Sharpe: 0.670\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 720         |\n",
      "|    time_elapsed         | 13338       |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011175994 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.4        |\n",
      "|    n_updates            | 7190        |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    reward               | 3.5728326   |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 51.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 721         |\n",
      "|    time_elapsed         | 13357       |\n",
      "|    total_timesteps      | 1476608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017731925 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.62        |\n",
      "|    n_updates            | 7200        |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | 2.412074    |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 722        |\n",
      "|    time_elapsed         | 13375      |\n",
      "|    total_timesteps      | 1478656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01565765 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.9      |\n",
      "|    explained_variance   | 0.261      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.1       |\n",
      "|    n_updates            | 7210       |\n",
      "|    policy_gradient_loss | -0.00661   |\n",
      "|    reward               | -1.37243   |\n",
      "|    std                  | 3          |\n",
      "|    value_loss           | 42.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 723         |\n",
      "|    time_elapsed         | 13393       |\n",
      "|    total_timesteps      | 1480704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009614168 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.4        |\n",
      "|    n_updates            | 7220        |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | 1.6153444   |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 50.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 724         |\n",
      "|    time_elapsed         | 13411       |\n",
      "|    total_timesteps      | 1482752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013010629 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 7230        |\n",
      "|    policy_gradient_loss | -0.000303   |\n",
      "|    reward               | 3.1204343   |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 725         |\n",
      "|    time_elapsed         | 13428       |\n",
      "|    total_timesteps      | 1484800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012261679 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.19        |\n",
      "|    n_updates            | 7240        |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    reward               | 1.2230912   |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 23.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 726         |\n",
      "|    time_elapsed         | 13446       |\n",
      "|    total_timesteps      | 1486848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013150839 |\n",
      "|    clip_fraction        | 0.0823      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 7250        |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    reward               | -1.0960622  |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 36.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 727         |\n",
      "|    time_elapsed         | 13464       |\n",
      "|    total_timesteps      | 1488896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013301689 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.1       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 7260        |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | 0.886277    |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 728         |\n",
      "|    time_elapsed         | 13483       |\n",
      "|    total_timesteps      | 1490944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014658807 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.1       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.85        |\n",
      "|    n_updates            | 7270        |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    reward               | -0.5034244  |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 729         |\n",
      "|    time_elapsed         | 13501       |\n",
      "|    total_timesteps      | 1492992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016371075 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.1       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 7280        |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    reward               | -0.8401795  |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 35.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 730         |\n",
      "|    time_elapsed         | 13519       |\n",
      "|    total_timesteps      | 1495040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014841849 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.2       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 7290        |\n",
      "|    policy_gradient_loss | -0.00077    |\n",
      "|    reward               | -0.59294033 |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 47          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 731         |\n",
      "|    time_elapsed         | 13537       |\n",
      "|    total_timesteps      | 1497088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013287641 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.2       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 7300        |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    reward               | 3.66601     |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 732         |\n",
      "|    time_elapsed         | 13555       |\n",
      "|    total_timesteps      | 1499136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02682022  |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.2       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.03        |\n",
      "|    n_updates            | 7310        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.50194067 |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 733        |\n",
      "|    time_elapsed         | 13573      |\n",
      "|    total_timesteps      | 1501184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0148254  |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.3      |\n",
      "|    explained_variance   | 0.261      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.3       |\n",
      "|    n_updates            | 7320       |\n",
      "|    policy_gradient_loss | -0.00357   |\n",
      "|    reward               | -1.4332312 |\n",
      "|    std                  | 3.05       |\n",
      "|    value_loss           | 55.6       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3651395.80\n",
      "total_reward: 2651395.80\n",
      "total_cost: 122620.74\n",
      "total_trades: 56934\n",
      "Sharpe: 0.694\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 734         |\n",
      "|    time_elapsed         | 13591       |\n",
      "|    total_timesteps      | 1503232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015537751 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 7330        |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | 3.474099    |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 46.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 735        |\n",
      "|    time_elapsed         | 13609      |\n",
      "|    total_timesteps      | 1505280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01393344 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.4      |\n",
      "|    explained_variance   | 0.331      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.3       |\n",
      "|    n_updates            | 7340       |\n",
      "|    policy_gradient_loss | -0.00775   |\n",
      "|    reward               | 0.782765   |\n",
      "|    std                  | 3.06       |\n",
      "|    value_loss           | 29.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 736         |\n",
      "|    time_elapsed         | 13628       |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015275501 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 7350        |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    reward               | -0.4277943  |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 737        |\n",
      "|    time_elapsed         | 13646      |\n",
      "|    total_timesteps      | 1509376    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02080457 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.5      |\n",
      "|    explained_variance   | 0.0604     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.7       |\n",
      "|    n_updates            | 7360       |\n",
      "|    policy_gradient_loss | -0.00287   |\n",
      "|    reward               | 1.3048186  |\n",
      "|    std                  | 3.07       |\n",
      "|    value_loss           | 45.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 738         |\n",
      "|    time_elapsed         | 13664       |\n",
      "|    total_timesteps      | 1511424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014537651 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.5       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.46        |\n",
      "|    n_updates            | 7370        |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | -0.3419485  |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 739         |\n",
      "|    time_elapsed         | 13682       |\n",
      "|    total_timesteps      | 1513472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015400991 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 7380        |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | -0.24942149 |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 40.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 740          |\n",
      "|    time_elapsed         | 13700        |\n",
      "|    total_timesteps      | 1515520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099105295 |\n",
      "|    clip_fraction        | 0.0897       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.7        |\n",
      "|    explained_variance   | 0.276        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 7390         |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    reward               | 1.697951     |\n",
      "|    std                  | 3.08         |\n",
      "|    value_loss           | 51           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 741         |\n",
      "|    time_elapsed         | 13718       |\n",
      "|    total_timesteps      | 1517568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019181162 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 7400        |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    reward               | 1.64352     |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 40.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 742         |\n",
      "|    time_elapsed         | 13737       |\n",
      "|    total_timesteps      | 1519616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005097256 |\n",
      "|    clip_fraction        | 0.0221      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.57        |\n",
      "|    n_updates            | 7410        |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | 0.5717386   |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 743         |\n",
      "|    time_elapsed         | 13754       |\n",
      "|    total_timesteps      | 1521664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015459243 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 7420        |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | -1.0776285  |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 744         |\n",
      "|    time_elapsed         | 13773       |\n",
      "|    total_timesteps      | 1523712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009932404 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 7430        |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    reward               | 0.5885718   |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 745          |\n",
      "|    time_elapsed         | 13791        |\n",
      "|    total_timesteps      | 1525760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008047205  |\n",
      "|    clip_fraction        | 0.0535       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.7        |\n",
      "|    explained_variance   | 0.429        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 7440         |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | -0.076936945 |\n",
      "|    std                  | 3.09         |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 746         |\n",
      "|    time_elapsed         | 13810       |\n",
      "|    total_timesteps      | 1527808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022179946 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.8       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 7450        |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    reward               | -0.71103215 |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 747         |\n",
      "|    time_elapsed         | 13829       |\n",
      "|    total_timesteps      | 1529856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012576449 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.8       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 7460        |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    reward               | 0.6704504   |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3491671.72\n",
      "total_reward: 2491671.72\n",
      "total_cost: 120124.01\n",
      "total_trades: 57380\n",
      "Sharpe: 0.673\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 748         |\n",
      "|    time_elapsed         | 13848       |\n",
      "|    total_timesteps      | 1531904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016732924 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 7470        |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    reward               | -0.7021326  |\n",
      "|    std                  | 3.11        |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 749         |\n",
      "|    time_elapsed         | 13866       |\n",
      "|    total_timesteps      | 1533952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018250145 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 7480        |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | -3.1382852  |\n",
      "|    std                  | 3.12        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 750         |\n",
      "|    time_elapsed         | 13885       |\n",
      "|    total_timesteps      | 1536000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020606203 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 7490        |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    reward               | 4.1625733   |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 751         |\n",
      "|    time_elapsed         | 13903       |\n",
      "|    total_timesteps      | 1538048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013390396 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 7500        |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    reward               | -0.75790334 |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 47.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 752         |\n",
      "|    time_elapsed         | 13922       |\n",
      "|    total_timesteps      | 1540096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017807305 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 7510        |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    reward               | -0.41585466 |\n",
      "|    std                  | 3.14        |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 753          |\n",
      "|    time_elapsed         | 13941        |\n",
      "|    total_timesteps      | 1542144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0129491165 |\n",
      "|    clip_fraction        | 0.163        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.2        |\n",
      "|    explained_variance   | 0.198        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 7520         |\n",
      "|    policy_gradient_loss | -0.00681     |\n",
      "|    reward               | 0.95619595   |\n",
      "|    std                  | 3.14         |\n",
      "|    value_loss           | 41.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 754          |\n",
      "|    time_elapsed         | 13959        |\n",
      "|    total_timesteps      | 1544192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0132339895 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.2        |\n",
      "|    explained_variance   | 0.269        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.6         |\n",
      "|    n_updates            | 7530         |\n",
      "|    policy_gradient_loss | -0.00767     |\n",
      "|    reward               | 1.0417085    |\n",
      "|    std                  | 3.14         |\n",
      "|    value_loss           | 45.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 755          |\n",
      "|    time_elapsed         | 13976        |\n",
      "|    total_timesteps      | 1546240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151304165 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.3        |\n",
      "|    explained_variance   | 0.399        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 7540         |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | -0.8581479   |\n",
      "|    std                  | 3.15         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 756         |\n",
      "|    time_elapsed         | 13994       |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017726848 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 7550        |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    reward               | -1.2579033  |\n",
      "|    std                  | 3.15        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 757          |\n",
      "|    time_elapsed         | 14012        |\n",
      "|    total_timesteps      | 1550336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074575227 |\n",
      "|    clip_fraction        | 0.046        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.3        |\n",
      "|    explained_variance   | 0.236        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 7560         |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | 2.08606      |\n",
      "|    std                  | 3.15         |\n",
      "|    value_loss           | 39.3         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 758        |\n",
      "|    time_elapsed         | 14030      |\n",
      "|    total_timesteps      | 1552384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01716493 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.3      |\n",
      "|    explained_variance   | 0.247      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.9       |\n",
      "|    n_updates            | 7570       |\n",
      "|    policy_gradient_loss | -0.0061    |\n",
      "|    reward               | -1.0511405 |\n",
      "|    std                  | 3.16       |\n",
      "|    value_loss           | 44.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 759        |\n",
      "|    time_elapsed         | 14048      |\n",
      "|    total_timesteps      | 1554432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01955337 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.4      |\n",
      "|    explained_variance   | 0.351      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.2       |\n",
      "|    n_updates            | 7580       |\n",
      "|    policy_gradient_loss | -0.00378   |\n",
      "|    reward               | 0.24133855 |\n",
      "|    std                  | 3.16       |\n",
      "|    value_loss           | 28.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 760         |\n",
      "|    time_elapsed         | 14065       |\n",
      "|    total_timesteps      | 1556480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015431123 |\n",
      "|    clip_fraction        | 0.0632      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 7590        |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    reward               | 0.4498367   |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 53.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 761         |\n",
      "|    time_elapsed         | 14083       |\n",
      "|    total_timesteps      | 1558528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013039019 |\n",
      "|    clip_fraction        | 0.0723      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 7600        |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    reward               | -0.7484     |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3431397.02\n",
      "total_reward: 2431397.02\n",
      "total_cost: 81547.68\n",
      "total_trades: 53336\n",
      "Sharpe: 0.665\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 762         |\n",
      "|    time_elapsed         | 14101       |\n",
      "|    total_timesteps      | 1560576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008749325 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.34        |\n",
      "|    n_updates            | 7610        |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    reward               | 2.2090251   |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 763          |\n",
      "|    time_elapsed         | 14119        |\n",
      "|    total_timesteps      | 1562624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120741185 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.5        |\n",
      "|    explained_variance   | 0.259        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.4         |\n",
      "|    n_updates            | 7620         |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    reward               | -3.0192833   |\n",
      "|    std                  | 3.17         |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 764         |\n",
      "|    time_elapsed         | 14139       |\n",
      "|    total_timesteps      | 1564672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016940434 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 7630        |\n",
      "|    policy_gradient_loss | -0.00019    |\n",
      "|    reward               | -0.689805   |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 60          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 765          |\n",
      "|    time_elapsed         | 14158        |\n",
      "|    total_timesteps      | 1566720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146067375 |\n",
      "|    clip_fraction        | 0.0907       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.5        |\n",
      "|    explained_variance   | 0.251        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 7640         |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    reward               | -0.6122005   |\n",
      "|    std                  | 3.18         |\n",
      "|    value_loss           | 39           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 766         |\n",
      "|    time_elapsed         | 14177       |\n",
      "|    total_timesteps      | 1568768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014816221 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.6       |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.55        |\n",
      "|    n_updates            | 7650        |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    reward               | 0.8338934   |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 767         |\n",
      "|    time_elapsed         | 14195       |\n",
      "|    total_timesteps      | 1570816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012708742 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.6       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 7660        |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    reward               | 11.893457   |\n",
      "|    std                  | 3.19        |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 768         |\n",
      "|    time_elapsed         | 14212       |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008309215 |\n",
      "|    clip_fraction        | 0.0309      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 7670        |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | -1.1798933  |\n",
      "|    std                  | 3.19        |\n",
      "|    value_loss           | 53.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 769         |\n",
      "|    time_elapsed         | 14231       |\n",
      "|    total_timesteps      | 1574912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009308955 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 7680        |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    reward               | 0.34516647  |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 770         |\n",
      "|    time_elapsed         | 14250       |\n",
      "|    total_timesteps      | 1576960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013566439 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 7690        |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    reward               | 0.69768184  |\n",
      "|    std                  | 3.19        |\n",
      "|    value_loss           | 46          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 771         |\n",
      "|    time_elapsed         | 14267       |\n",
      "|    total_timesteps      | 1579008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013792913 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 7700        |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    reward               | -3.9747777  |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 50.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 772         |\n",
      "|    time_elapsed         | 14285       |\n",
      "|    total_timesteps      | 1581056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012146566 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 7710        |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    reward               | 0.044405814 |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 773         |\n",
      "|    time_elapsed         | 14303       |\n",
      "|    total_timesteps      | 1583104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013146201 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 7720        |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    reward               | -0.944649   |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 774         |\n",
      "|    time_elapsed         | 14320       |\n",
      "|    total_timesteps      | 1585152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009672948 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 7730        |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    reward               | 0.83224714  |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 775         |\n",
      "|    time_elapsed         | 14338       |\n",
      "|    total_timesteps      | 1587200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008697029 |\n",
      "|    clip_fraction        | 0.0333      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 7740        |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    reward               | -1.3803227  |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3102016.96\n",
      "total_reward: 2102016.96\n",
      "total_cost: 59030.80\n",
      "total_trades: 51379\n",
      "Sharpe: 0.616\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 776         |\n",
      "|    time_elapsed         | 14357       |\n",
      "|    total_timesteps      | 1589248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020006884 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.43        |\n",
      "|    n_updates            | 7750        |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    reward               | -0.09520925 |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 777         |\n",
      "|    time_elapsed         | 14375       |\n",
      "|    total_timesteps      | 1591296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011458417 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.79        |\n",
      "|    n_updates            | 7760        |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    reward               | 1.2083125   |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 778         |\n",
      "|    time_elapsed         | 14394       |\n",
      "|    total_timesteps      | 1593344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010893682 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 7770        |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    reward               | 1.1299584   |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 779         |\n",
      "|    time_elapsed         | 14413       |\n",
      "|    total_timesteps      | 1595392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013475802 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.45        |\n",
      "|    n_updates            | 7780        |\n",
      "|    policy_gradient_loss | -0.00136    |\n",
      "|    reward               | -0.98415583 |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 780         |\n",
      "|    time_elapsed         | 14430       |\n",
      "|    total_timesteps      | 1597440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024732191 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75         |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 7790        |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    reward               | 1.2814764   |\n",
      "|    std                  | 3.23        |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 781         |\n",
      "|    time_elapsed         | 14449       |\n",
      "|    total_timesteps      | 1599488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015473265 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75         |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 7800        |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    reward               | -1.1732622  |\n",
      "|    std                  | 3.23        |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 782         |\n",
      "|    time_elapsed         | 14468       |\n",
      "|    total_timesteps      | 1601536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014480891 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75         |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 7810        |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    reward               | -18.276304  |\n",
      "|    std                  | 3.23        |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 783         |\n",
      "|    time_elapsed         | 14487       |\n",
      "|    total_timesteps      | 1603584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017609516 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 7820        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.9709834  |\n",
      "|    std                  | 3.24        |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 784         |\n",
      "|    time_elapsed         | 14505       |\n",
      "|    total_timesteps      | 1605632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011575334 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 7830        |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | 0.7135325   |\n",
      "|    std                  | 3.24        |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 785         |\n",
      "|    time_elapsed         | 14524       |\n",
      "|    total_timesteps      | 1607680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017296698 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 7840        |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    reward               | -1.4245765  |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 49.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 786         |\n",
      "|    time_elapsed         | 14542       |\n",
      "|    total_timesteps      | 1609728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013170171 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.06        |\n",
      "|    n_updates            | 7850        |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | 1.8099382   |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 787         |\n",
      "|    time_elapsed         | 14561       |\n",
      "|    total_timesteps      | 1611776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016624834 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.3       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.97        |\n",
      "|    n_updates            | 7860        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -1.7810613  |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 788         |\n",
      "|    time_elapsed         | 14579       |\n",
      "|    total_timesteps      | 1613824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008385728 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.3       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 7870        |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | -2.1294994  |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 789         |\n",
      "|    time_elapsed         | 14598       |\n",
      "|    total_timesteps      | 1615872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015655708 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.3       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 7880        |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    reward               | -0.96903795 |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3599776.96\n",
      "total_reward: 2599776.96\n",
      "total_cost: 75663.54\n",
      "total_trades: 54000\n",
      "Sharpe: 0.700\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 790         |\n",
      "|    time_elapsed         | 14616       |\n",
      "|    total_timesteps      | 1617920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019053906 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.4       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 7890        |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    reward               | 0.86471444  |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 791        |\n",
      "|    time_elapsed         | 14634      |\n",
      "|    total_timesteps      | 1619968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00878882 |\n",
      "|    clip_fraction        | 0.0964     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.4      |\n",
      "|    explained_variance   | 0.309      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.6       |\n",
      "|    n_updates            | 7900       |\n",
      "|    policy_gradient_loss | -0.00678   |\n",
      "|    reward               | 1.2259221  |\n",
      "|    std                  | 3.28       |\n",
      "|    value_loss           | 46.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 792         |\n",
      "|    time_elapsed         | 14652       |\n",
      "|    total_timesteps      | 1622016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012641251 |\n",
      "|    clip_fraction        | 0.0741      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.4       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.04        |\n",
      "|    n_updates            | 7910        |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    reward               | 3.9285572   |\n",
      "|    std                  | 3.28        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 793         |\n",
      "|    time_elapsed         | 14670       |\n",
      "|    total_timesteps      | 1624064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012213988 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 7920        |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | -1.0777888  |\n",
      "|    std                  | 3.28        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 794          |\n",
      "|    time_elapsed         | 14688        |\n",
      "|    total_timesteps      | 1626112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.020381946  |\n",
      "|    clip_fraction        | 0.235        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.5        |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 7930         |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    reward               | -0.020567836 |\n",
      "|    std                  | 3.28         |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 795          |\n",
      "|    time_elapsed         | 14707        |\n",
      "|    total_timesteps      | 1628160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095214285 |\n",
      "|    clip_fraction        | 0.0747       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.5        |\n",
      "|    explained_variance   | 0.203        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 7940         |\n",
      "|    policy_gradient_loss | -0.00785     |\n",
      "|    reward               | 3.593815     |\n",
      "|    std                  | 3.28         |\n",
      "|    value_loss           | 48.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 796         |\n",
      "|    time_elapsed         | 14726       |\n",
      "|    total_timesteps      | 1630208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013818111 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.83        |\n",
      "|    n_updates            | 7950        |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | -0.07887144 |\n",
      "|    std                  | 3.29        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 797          |\n",
      "|    time_elapsed         | 14744        |\n",
      "|    total_timesteps      | 1632256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013739634  |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.5        |\n",
      "|    explained_variance   | 0.466        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.47         |\n",
      "|    n_updates            | 7960         |\n",
      "|    policy_gradient_loss | -0.00767     |\n",
      "|    reward               | -0.018605111 |\n",
      "|    std                  | 3.29         |\n",
      "|    value_loss           | 23.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 798         |\n",
      "|    time_elapsed         | 14763       |\n",
      "|    total_timesteps      | 1634304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008904386 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 7970        |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    reward               | 0.338303    |\n",
      "|    std                  | 3.29        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 799         |\n",
      "|    time_elapsed         | 14783       |\n",
      "|    total_timesteps      | 1636352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014908564 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 7980        |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    reward               | -0.00456863 |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 800         |\n",
      "|    time_elapsed         | 14800       |\n",
      "|    total_timesteps      | 1638400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015658922 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.4         |\n",
      "|    n_updates            | 7990        |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    reward               | 0.90275     |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 801         |\n",
      "|    time_elapsed         | 14820       |\n",
      "|    total_timesteps      | 1640448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014103707 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 8000        |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    reward               | -2.73787    |\n",
      "|    std                  | 3.31        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 802         |\n",
      "|    time_elapsed         | 14838       |\n",
      "|    total_timesteps      | 1642496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009302855 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 8010        |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    reward               | 1.3450876   |\n",
      "|    std                  | 3.31        |\n",
      "|    value_loss           | 44.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 803         |\n",
      "|    time_elapsed         | 14858       |\n",
      "|    total_timesteps      | 1644544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019659374 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.31        |\n",
      "|    n_updates            | 8020        |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | 0.7372922   |\n",
      "|    std                  | 3.32        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3429403.32\n",
      "total_reward: 2429403.32\n",
      "total_cost: 75785.22\n",
      "total_trades: 53727\n",
      "Sharpe: 0.663\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 804         |\n",
      "|    time_elapsed         | 14876       |\n",
      "|    total_timesteps      | 1646592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018132538 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.5        |\n",
      "|    n_updates            | 8030        |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    reward               | 0.8283871   |\n",
      "|    std                  | 3.32        |\n",
      "|    value_loss           | 36.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 805        |\n",
      "|    time_elapsed         | 14894      |\n",
      "|    total_timesteps      | 1648640    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00821513 |\n",
      "|    clip_fraction        | 0.0628     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.8      |\n",
      "|    explained_variance   | 0.491      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.2       |\n",
      "|    n_updates            | 8040       |\n",
      "|    policy_gradient_loss | -0.00444   |\n",
      "|    reward               | -0.2996182 |\n",
      "|    std                  | 3.32       |\n",
      "|    value_loss           | 40.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 806         |\n",
      "|    time_elapsed         | 14913       |\n",
      "|    total_timesteps      | 1650688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010335285 |\n",
      "|    clip_fraction        | 0.0751      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 8050        |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | 1.3920105   |\n",
      "|    std                  | 3.32        |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 807         |\n",
      "|    time_elapsed         | 14932       |\n",
      "|    total_timesteps      | 1652736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011638865 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.22        |\n",
      "|    n_updates            | 8060        |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | -3.5576656  |\n",
      "|    std                  | 3.32        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 808         |\n",
      "|    time_elapsed         | 14951       |\n",
      "|    total_timesteps      | 1654784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016296394 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 8070        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 0.95193684  |\n",
      "|    std                  | 3.33        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 809         |\n",
      "|    time_elapsed         | 14969       |\n",
      "|    total_timesteps      | 1656832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014213879 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 8080        |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    reward               | -0.52124685 |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 48.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 810         |\n",
      "|    time_elapsed         | 14988       |\n",
      "|    total_timesteps      | 1658880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012836784 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.06        |\n",
      "|    n_updates            | 8090        |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    reward               | -0.5490668  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 811         |\n",
      "|    time_elapsed         | 15006       |\n",
      "|    total_timesteps      | 1660928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016170189 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76         |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 8100        |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    reward               | -1.0063773  |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 812        |\n",
      "|    time_elapsed         | 15026      |\n",
      "|    total_timesteps      | 1662976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01300177 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76        |\n",
      "|    explained_variance   | 0.372      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.3       |\n",
      "|    n_updates            | 8110       |\n",
      "|    policy_gradient_loss | -0.00601   |\n",
      "|    reward               | 4.0395136  |\n",
      "|    std                  | 3.35       |\n",
      "|    value_loss           | 39.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 813         |\n",
      "|    time_elapsed         | 15044       |\n",
      "|    total_timesteps      | 1665024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014191435 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 8120        |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    reward               | 0.09308878  |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 814         |\n",
      "|    time_elapsed         | 15061       |\n",
      "|    total_timesteps      | 1667072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015315921 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.94        |\n",
      "|    n_updates            | 8130        |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    reward               | 1.8934996   |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 815        |\n",
      "|    time_elapsed         | 15079      |\n",
      "|    total_timesteps      | 1669120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01572007 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.1      |\n",
      "|    explained_variance   | 0.447      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.2       |\n",
      "|    n_updates            | 8140       |\n",
      "|    policy_gradient_loss | 5.48e-05   |\n",
      "|    reward               | -1.3297492 |\n",
      "|    std                  | 3.36       |\n",
      "|    value_loss           | 41.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 816         |\n",
      "|    time_elapsed         | 15097       |\n",
      "|    total_timesteps      | 1671168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009679006 |\n",
      "|    clip_fraction        | 0.0845      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 8150        |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    reward               | 2.0265503   |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 817        |\n",
      "|    time_elapsed         | 15115      |\n",
      "|    total_timesteps      | 1673216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01912117 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.1      |\n",
      "|    explained_variance   | 0.454      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.7       |\n",
      "|    n_updates            | 8160       |\n",
      "|    policy_gradient_loss | -0.00721   |\n",
      "|    reward               | 0.97829986 |\n",
      "|    std                  | 3.36       |\n",
      "|    value_loss           | 24.9       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3754812.77\n",
      "total_reward: 2754812.77\n",
      "total_cost: 96222.42\n",
      "total_trades: 54916\n",
      "Sharpe: 0.721\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 818         |\n",
      "|    time_elapsed         | 15133       |\n",
      "|    total_timesteps      | 1675264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021151684 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 8170        |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    reward               | 0.6950859   |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 819        |\n",
      "|    time_elapsed         | 15151      |\n",
      "|    total_timesteps      | 1677312    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01530768 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.2      |\n",
      "|    explained_variance   | 0.0916     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.8       |\n",
      "|    n_updates            | 8180       |\n",
      "|    policy_gradient_loss | -0.00329   |\n",
      "|    reward               | -0.4182073 |\n",
      "|    std                  | 3.37       |\n",
      "|    value_loss           | 49.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 820        |\n",
      "|    time_elapsed         | 15169      |\n",
      "|    total_timesteps      | 1679360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0178263  |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.3      |\n",
      "|    explained_variance   | 0.42       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.6       |\n",
      "|    n_updates            | 8190       |\n",
      "|    policy_gradient_loss | -0.00553   |\n",
      "|    reward               | -0.0681435 |\n",
      "|    std                  | 3.38       |\n",
      "|    value_loss           | 22.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 821        |\n",
      "|    time_elapsed         | 15188      |\n",
      "|    total_timesteps      | 1681408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01897968 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.3      |\n",
      "|    explained_variance   | 0.148      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.6       |\n",
      "|    n_updates            | 8200       |\n",
      "|    policy_gradient_loss | -0.00662   |\n",
      "|    reward               | -0.5692157 |\n",
      "|    std                  | 3.38       |\n",
      "|    value_loss           | 41.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 822         |\n",
      "|    time_elapsed         | 15206       |\n",
      "|    total_timesteps      | 1683456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013814562 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 8210        |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    reward               | 1.9035032   |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 823         |\n",
      "|    time_elapsed         | 15224       |\n",
      "|    total_timesteps      | 1685504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014104579 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 8220        |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    reward               | -0.28656486 |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 824         |\n",
      "|    time_elapsed         | 15252       |\n",
      "|    total_timesteps      | 1687552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017326571 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.58        |\n",
      "|    n_updates            | 8230        |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    reward               | -0.59140396 |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 825         |\n",
      "|    time_elapsed         | 15270       |\n",
      "|    total_timesteps      | 1689600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016828628 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 8240        |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    reward               | -2.6451108  |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 826         |\n",
      "|    time_elapsed         | 15288       |\n",
      "|    total_timesteps      | 1691648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010810174 |\n",
      "|    clip_fraction        | 0.052       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 8250        |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | 1.3838136   |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 827        |\n",
      "|    time_elapsed         | 15307      |\n",
      "|    total_timesteps      | 1693696    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01930407 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.6      |\n",
      "|    explained_variance   | 0.375      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.51       |\n",
      "|    n_updates            | 8260       |\n",
      "|    policy_gradient_loss | -0.00962   |\n",
      "|    reward               | -2.812233  |\n",
      "|    std                  | 3.42       |\n",
      "|    value_loss           | 18         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 828         |\n",
      "|    time_elapsed         | 15325       |\n",
      "|    total_timesteps      | 1695744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013756311 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 8270        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 0.4100583   |\n",
      "|    std                  | 3.43        |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 829        |\n",
      "|    time_elapsed         | 15343      |\n",
      "|    total_timesteps      | 1697792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01538075 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.7      |\n",
      "|    explained_variance   | 0.444      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.6       |\n",
      "|    n_updates            | 8280       |\n",
      "|    policy_gradient_loss | -0.00586   |\n",
      "|    reward               | 6.5022893  |\n",
      "|    std                  | 3.43       |\n",
      "|    value_loss           | 42.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 830         |\n",
      "|    time_elapsed         | 15361       |\n",
      "|    total_timesteps      | 1699840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016619239 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 8290        |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    reward               | -1.4052808  |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 831         |\n",
      "|    time_elapsed         | 15380       |\n",
      "|    total_timesteps      | 1701888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015573395 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.03        |\n",
      "|    n_updates            | 8300        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    reward               | 2.81352     |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 832         |\n",
      "|    time_elapsed         | 15398       |\n",
      "|    total_timesteps      | 1703936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014206909 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 8310        |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    reward               | 2.0125284   |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3210184.26\n",
      "total_reward: 2210184.26\n",
      "total_cost: 147538.07\n",
      "total_trades: 57785\n",
      "Sharpe: 0.615\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 833        |\n",
      "|    time_elapsed         | 15417      |\n",
      "|    total_timesteps      | 1705984    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01078509 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.9      |\n",
      "|    explained_variance   | 0.326      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.3       |\n",
      "|    n_updates            | 8320       |\n",
      "|    policy_gradient_loss | -0.00569   |\n",
      "|    reward               | -1.7646198 |\n",
      "|    std                  | 3.45       |\n",
      "|    value_loss           | 38.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 834         |\n",
      "|    time_elapsed         | 15436       |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015377671 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.24        |\n",
      "|    n_updates            | 8330        |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | -5.5484004  |\n",
      "|    std                  | 3.46        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 835        |\n",
      "|    time_elapsed         | 15454      |\n",
      "|    total_timesteps      | 1710080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01648774 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77        |\n",
      "|    explained_variance   | 0.204      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.6       |\n",
      "|    n_updates            | 8340       |\n",
      "|    policy_gradient_loss | -0.00744   |\n",
      "|    reward               | 0.15785448 |\n",
      "|    std                  | 3.46       |\n",
      "|    value_loss           | 42.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 836        |\n",
      "|    time_elapsed         | 15471      |\n",
      "|    total_timesteps      | 1712128    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01869763 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77        |\n",
      "|    explained_variance   | 0.287      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.5       |\n",
      "|    n_updates            | 8350       |\n",
      "|    policy_gradient_loss | -0.00328   |\n",
      "|    reward               | -1.287281  |\n",
      "|    std                  | 3.46       |\n",
      "|    value_loss           | 41.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 837         |\n",
      "|    time_elapsed         | 15490       |\n",
      "|    total_timesteps      | 1714176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018507073 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.0865      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 8360        |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    reward               | 0.57498467  |\n",
      "|    std                  | 3.46        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 838         |\n",
      "|    time_elapsed         | 15510       |\n",
      "|    total_timesteps      | 1716224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026661891 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 8370        |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    reward               | 3.497431    |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 839         |\n",
      "|    time_elapsed         | 15528       |\n",
      "|    total_timesteps      | 1718272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024503613 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 8380        |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    reward               | 0.9374134   |\n",
      "|    std                  | 3.48        |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 840         |\n",
      "|    time_elapsed         | 15546       |\n",
      "|    total_timesteps      | 1720320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013320844 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 8390        |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    reward               | 0.3929514   |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 841        |\n",
      "|    time_elapsed         | 15565      |\n",
      "|    total_timesteps      | 1722368    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02172879 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.2      |\n",
      "|    explained_variance   | 0.0193     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.22       |\n",
      "|    n_updates            | 8400       |\n",
      "|    policy_gradient_loss | -0.00736   |\n",
      "|    reward               | 0.05349299 |\n",
      "|    std                  | 3.49       |\n",
      "|    value_loss           | 26.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 842         |\n",
      "|    time_elapsed         | 15583       |\n",
      "|    total_timesteps      | 1724416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014793338 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 8410        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -2.388953   |\n",
      "|    std                  | 3.5         |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 843        |\n",
      "|    time_elapsed         | 15601      |\n",
      "|    total_timesteps      | 1726464    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01029087 |\n",
      "|    clip_fraction        | 0.0663     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.3      |\n",
      "|    explained_variance   | 0.38       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.3       |\n",
      "|    n_updates            | 8420       |\n",
      "|    policy_gradient_loss | -0.00562   |\n",
      "|    reward               | -4.3113446 |\n",
      "|    std                  | 3.5        |\n",
      "|    value_loss           | 39.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 844         |\n",
      "|    time_elapsed         | 15620       |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020913307 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.4       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.21        |\n",
      "|    n_updates            | 8430        |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | 3.384224    |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 845        |\n",
      "|    time_elapsed         | 15639      |\n",
      "|    total_timesteps      | 1730560    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01617488 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.4      |\n",
      "|    explained_variance   | 0.438      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.6       |\n",
      "|    n_updates            | 8440       |\n",
      "|    policy_gradient_loss | -0.00475   |\n",
      "|    reward               | -1.1201042 |\n",
      "|    std                  | 3.51       |\n",
      "|    value_loss           | 28.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 846         |\n",
      "|    time_elapsed         | 15656       |\n",
      "|    total_timesteps      | 1732608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012768171 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.4       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 8450        |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    reward               | 0.04543159  |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3832314.78\n",
      "total_reward: 2832314.78\n",
      "total_cost: 170234.44\n",
      "total_trades: 59167\n",
      "Sharpe: 0.710\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 847        |\n",
      "|    time_elapsed         | 15675      |\n",
      "|    total_timesteps      | 1734656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01682515 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.5      |\n",
      "|    explained_variance   | 0.228      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.9       |\n",
      "|    n_updates            | 8460       |\n",
      "|    policy_gradient_loss | -0.0094    |\n",
      "|    reward               | 1.539304   |\n",
      "|    std                  | 3.53       |\n",
      "|    value_loss           | 33.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 848         |\n",
      "|    time_elapsed         | 15694       |\n",
      "|    total_timesteps      | 1736704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016243774 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.6       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 8470        |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    reward               | 2.2173615   |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 849         |\n",
      "|    time_elapsed         | 15712       |\n",
      "|    total_timesteps      | 1738752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013891375 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.6       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 8480        |\n",
      "|    policy_gradient_loss | -0.0093     |\n",
      "|    reward               | -1.0227389  |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 850         |\n",
      "|    time_elapsed         | 15730       |\n",
      "|    total_timesteps      | 1740800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013887146 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 8490        |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | -7.247234   |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 851         |\n",
      "|    time_elapsed         | 15749       |\n",
      "|    total_timesteps      | 1742848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019692464 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | 0.0599      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.55        |\n",
      "|    n_updates            | 8500        |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | 0.2345128   |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 852         |\n",
      "|    time_elapsed         | 15767       |\n",
      "|    total_timesteps      | 1744896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011781612 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.8       |\n",
      "|    explained_variance   | 0.0321      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 8510        |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | -1.7703782  |\n",
      "|    std                  | 3.57        |\n",
      "|    value_loss           | 71.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 853         |\n",
      "|    time_elapsed         | 15786       |\n",
      "|    total_timesteps      | 1746944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016774902 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.6        |\n",
      "|    n_updates            | 8520        |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    reward               | 3.1772358   |\n",
      "|    std                  | 3.57        |\n",
      "|    value_loss           | 63.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 854         |\n",
      "|    time_elapsed         | 15805       |\n",
      "|    total_timesteps      | 1748992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017884986 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.05        |\n",
      "|    n_updates            | 8530        |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | 0.24675572  |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 855         |\n",
      "|    time_elapsed         | 15824       |\n",
      "|    total_timesteps      | 1751040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013816794 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 8540        |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    reward               | 0.4486733   |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 44.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 856         |\n",
      "|    time_elapsed         | 15841       |\n",
      "|    total_timesteps      | 1753088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008266766 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 8550        |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    reward               | -7.631097   |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 857         |\n",
      "|    time_elapsed         | 15859       |\n",
      "|    total_timesteps      | 1755136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016350437 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 8560        |\n",
      "|    policy_gradient_loss | -0.00894    |\n",
      "|    reward               | 6.373283    |\n",
      "|    std                  | 3.59        |\n",
      "|    value_loss           | 64.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 858         |\n",
      "|    time_elapsed         | 15878       |\n",
      "|    total_timesteps      | 1757184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013993763 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.85        |\n",
      "|    n_updates            | 8570        |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    reward               | 2.4187782   |\n",
      "|    std                  | 3.6         |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 859          |\n",
      "|    time_elapsed         | 15897        |\n",
      "|    total_timesteps      | 1759232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093572    |\n",
      "|    clip_fraction        | 0.0543       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -78.1        |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 8580         |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    reward               | -0.097956195 |\n",
      "|    std                  | 3.6          |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 860          |\n",
      "|    time_elapsed         | 15915        |\n",
      "|    total_timesteps      | 1761280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073343185 |\n",
      "|    clip_fraction        | 0.0471       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -78.1        |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 8590         |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    reward               | 1.702955     |\n",
      "|    std                  | 3.6          |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3049648.74\n",
      "total_reward: 2049648.74\n",
      "total_cost: 154056.29\n",
      "total_trades: 57087\n",
      "Sharpe: 0.606\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 15933       |\n",
      "|    total_timesteps      | 1763328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015726814 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 8600        |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    reward               | -0.4977491  |\n",
      "|    std                  | 3.6         |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 862         |\n",
      "|    time_elapsed         | 15951       |\n",
      "|    total_timesteps      | 1765376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015736163 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.45        |\n",
      "|    n_updates            | 8610        |\n",
      "|    policy_gradient_loss | -0.00762    |\n",
      "|    reward               | -1.7385191  |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 863         |\n",
      "|    time_elapsed         | 15970       |\n",
      "|    total_timesteps      | 1767424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015958784 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 8620        |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    reward               | 1.13405     |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 47          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 864          |\n",
      "|    time_elapsed         | 15988        |\n",
      "|    total_timesteps      | 1769472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082220975 |\n",
      "|    clip_fraction        | 0.0841       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -78.3        |\n",
      "|    explained_variance   | 0.311        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 8630         |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | 0.27766      |\n",
      "|    std                  | 3.62         |\n",
      "|    value_loss           | 26.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 865         |\n",
      "|    time_elapsed         | 16006       |\n",
      "|    total_timesteps      | 1771520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023035668 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 8640        |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    reward               | -1.4492654  |\n",
      "|    std                  | 3.63        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 866         |\n",
      "|    time_elapsed         | 16023       |\n",
      "|    total_timesteps      | 1773568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004755645 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 8650        |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    reward               | 0.78684926  |\n",
      "|    std                  | 3.63        |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 867        |\n",
      "|    time_elapsed         | 16042      |\n",
      "|    total_timesteps      | 1775616    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00843287 |\n",
      "|    clip_fraction        | 0.0687     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.4      |\n",
      "|    explained_variance   | 0.173      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.5       |\n",
      "|    n_updates            | 8660       |\n",
      "|    policy_gradient_loss | -0.00866   |\n",
      "|    reward               | 3.8282928  |\n",
      "|    std                  | 3.64       |\n",
      "|    value_loss           | 42.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 868        |\n",
      "|    time_elapsed         | 16060      |\n",
      "|    total_timesteps      | 1777664    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01988922 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.5      |\n",
      "|    explained_variance   | 0.273      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.08       |\n",
      "|    n_updates            | 8670       |\n",
      "|    policy_gradient_loss | -0.00872   |\n",
      "|    reward               | -0.085138  |\n",
      "|    std                  | 3.65       |\n",
      "|    value_loss           | 14         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 869        |\n",
      "|    time_elapsed         | 16078      |\n",
      "|    total_timesteps      | 1779712    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01451442 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.5      |\n",
      "|    explained_variance   | 0.455      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.2       |\n",
      "|    n_updates            | 8680       |\n",
      "|    policy_gradient_loss | -0.00217   |\n",
      "|    reward               | 0.40456182 |\n",
      "|    std                  | 3.65       |\n",
      "|    value_loss           | 34.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 870         |\n",
      "|    time_elapsed         | 16097       |\n",
      "|    total_timesteps      | 1781760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010986877 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.6       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 8690        |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    reward               | 0.35529408  |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 871         |\n",
      "|    time_elapsed         | 16116       |\n",
      "|    total_timesteps      | 1783808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012524201 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.6       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 8700        |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    reward               | 2.4232125   |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 872         |\n",
      "|    time_elapsed         | 16135       |\n",
      "|    total_timesteps      | 1785856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014185468 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.6       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 8710        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 0.65912306  |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 873         |\n",
      "|    time_elapsed         | 16153       |\n",
      "|    total_timesteps      | 1787904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013362479 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.6       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 8720        |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    reward               | -1.4985378  |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 874         |\n",
      "|    time_elapsed         | 16172       |\n",
      "|    total_timesteps      | 1789952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007824186 |\n",
      "|    clip_fraction        | 0.0499      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 8730        |\n",
      "|    policy_gradient_loss | -0.0066     |\n",
      "|    reward               | -1.988586   |\n",
      "|    std                  | 3.67        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3616536.80\n",
      "total_reward: 2616536.80\n",
      "total_cost: 201612.49\n",
      "total_trades: 61555\n",
      "Sharpe: 0.709\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 875         |\n",
      "|    time_elapsed         | 16191       |\n",
      "|    total_timesteps      | 1792000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018450696 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.74        |\n",
      "|    n_updates            | 8740        |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | 0.49817508  |\n",
      "|    std                  | 3.67        |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 876         |\n",
      "|    time_elapsed         | 16209       |\n",
      "|    total_timesteps      | 1794048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011135114 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.57        |\n",
      "|    n_updates            | 8750        |\n",
      "|    policy_gradient_loss | -0.000423   |\n",
      "|    reward               | 0.67480934  |\n",
      "|    std                  | 3.67        |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 877        |\n",
      "|    time_elapsed         | 16228      |\n",
      "|    total_timesteps      | 1796096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01698329 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.7      |\n",
      "|    explained_variance   | 0.236      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18         |\n",
      "|    n_updates            | 8760       |\n",
      "|    policy_gradient_loss | -0.00348   |\n",
      "|    reward               | -0.5011943 |\n",
      "|    std                  | 3.68       |\n",
      "|    value_loss           | 80.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 878         |\n",
      "|    time_elapsed         | 16246       |\n",
      "|    total_timesteps      | 1798144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014210925 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 8770        |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    reward               | 0.008685929 |\n",
      "|    std                  | 3.68        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 879         |\n",
      "|    time_elapsed         | 16264       |\n",
      "|    total_timesteps      | 1800192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018360833 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 8780        |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    reward               | 0.48337904  |\n",
      "|    std                  | 3.68        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 880         |\n",
      "|    time_elapsed         | 16283       |\n",
      "|    total_timesteps      | 1802240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013447506 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.4        |\n",
      "|    n_updates            | 8790        |\n",
      "|    policy_gradient_loss | -0.00895    |\n",
      "|    reward               | -3.879522   |\n",
      "|    std                  | 3.69        |\n",
      "|    value_loss           | 50.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 881         |\n",
      "|    time_elapsed         | 16301       |\n",
      "|    total_timesteps      | 1804288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009180188 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 8800        |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | -3.2306926  |\n",
      "|    std                  | 3.69        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 882         |\n",
      "|    time_elapsed         | 16319       |\n",
      "|    total_timesteps      | 1806336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019669835 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.9       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 8810        |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    reward               | -1.3564962  |\n",
      "|    std                  | 3.7         |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 883         |\n",
      "|    time_elapsed         | 16338       |\n",
      "|    total_timesteps      | 1808384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014518859 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 8820        |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    reward               | 0.9282796   |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 884         |\n",
      "|    time_elapsed         | 16357       |\n",
      "|    total_timesteps      | 1810432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009960173 |\n",
      "|    clip_fraction        | 0.0845      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 8830        |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    reward               | 3.3630939   |\n",
      "|    std                  | 3.72        |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 16376       |\n",
      "|    total_timesteps      | 1812480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015449699 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.1       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.88        |\n",
      "|    n_updates            | 8840        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 1.1949916   |\n",
      "|    std                  | 3.72        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 886         |\n",
      "|    time_elapsed         | 16394       |\n",
      "|    total_timesteps      | 1814528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011526493 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.1       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 8850        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -1.6891314  |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 887         |\n",
      "|    time_elapsed         | 16413       |\n",
      "|    total_timesteps      | 1816576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009555982 |\n",
      "|    clip_fraction        | 0.0687      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.1       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 8860        |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    reward               | 3.9613986   |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 53.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 888          |\n",
      "|    time_elapsed         | 16432        |\n",
      "|    total_timesteps      | 1818624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015735004  |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.2        |\n",
      "|    explained_variance   | 0.342        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 8870         |\n",
      "|    policy_gradient_loss | -0.00793     |\n",
      "|    reward               | -0.014447713 |\n",
      "|    std                  | 3.73         |\n",
      "|    value_loss           | 26.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3954362.03\n",
      "total_reward: 2954362.03\n",
      "total_cost: 171319.51\n",
      "total_trades: 59529\n",
      "Sharpe: 0.770\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 889         |\n",
      "|    time_elapsed         | 16451       |\n",
      "|    total_timesteps      | 1820672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022177378 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.2       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.02        |\n",
      "|    n_updates            | 8880        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | -2.9609401  |\n",
      "|    std                  | 3.74        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 890         |\n",
      "|    time_elapsed         | 16471       |\n",
      "|    total_timesteps      | 1822720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012603592 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 8890        |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    reward               | -0.4911331  |\n",
      "|    std                  | 3.75        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 891         |\n",
      "|    time_elapsed         | 16490       |\n",
      "|    total_timesteps      | 1824768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016448801 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 8900        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | -1.3114303  |\n",
      "|    std                  | 3.75        |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 892         |\n",
      "|    time_elapsed         | 16507       |\n",
      "|    total_timesteps      | 1826816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015769523 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | 0.0133      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.11        |\n",
      "|    n_updates            | 8910        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 0.5255107   |\n",
      "|    std                  | 3.76        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 893         |\n",
      "|    time_elapsed         | 16526       |\n",
      "|    total_timesteps      | 1828864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018296968 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.0918      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 8920        |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    reward               | 0.20614952  |\n",
      "|    std                  | 3.76        |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 894         |\n",
      "|    time_elapsed         | 16545       |\n",
      "|    total_timesteps      | 1830912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010627318 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 8930        |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    reward               | 1.567409    |\n",
      "|    std                  | 3.77        |\n",
      "|    value_loss           | 41.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 895         |\n",
      "|    time_elapsed         | 16563       |\n",
      "|    total_timesteps      | 1832960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014793657 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.5       |\n",
      "|    explained_variance   | 0.0909      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 8940        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -1.3228066  |\n",
      "|    std                  | 3.78        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 896         |\n",
      "|    time_elapsed         | 16582       |\n",
      "|    total_timesteps      | 1835008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018675594 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.079       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 8950        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -4.478564   |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 897         |\n",
      "|    time_elapsed         | 16600       |\n",
      "|    total_timesteps      | 1837056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016369652 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.033       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 8960        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -10.135383  |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 66.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 898         |\n",
      "|    time_elapsed         | 16619       |\n",
      "|    total_timesteps      | 1839104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014336275 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.0134      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 8970        |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    reward               | 0.16051005  |\n",
      "|    std                  | 3.8         |\n",
      "|    value_loss           | 96.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 899        |\n",
      "|    time_elapsed         | 16638      |\n",
      "|    total_timesteps      | 1841152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01863546 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -79.7      |\n",
      "|    explained_variance   | 0.188      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.21       |\n",
      "|    n_updates            | 8980       |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    reward               | -1.3517531 |\n",
      "|    std                  | 3.81       |\n",
      "|    value_loss           | 23.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 900         |\n",
      "|    time_elapsed         | 16656       |\n",
      "|    total_timesteps      | 1843200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012352992 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65          |\n",
      "|    n_updates            | 8990        |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    reward               | 1.3203124   |\n",
      "|    std                  | 3.81        |\n",
      "|    value_loss           | 89.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 901         |\n",
      "|    time_elapsed         | 16675       |\n",
      "|    total_timesteps      | 1845248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014261559 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | 0.0931      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60          |\n",
      "|    n_updates            | 9000        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 0.8615641   |\n",
      "|    std                  | 3.82        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 902         |\n",
      "|    time_elapsed         | 16694       |\n",
      "|    total_timesteps      | 1847296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015874283 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | 0.0422      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 9010        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -1.3513489  |\n",
      "|    std                  | 3.82        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3841592.47\n",
      "total_reward: 2841592.47\n",
      "total_cost: 312229.58\n",
      "total_trades: 68357\n",
      "Sharpe: 0.694\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 903         |\n",
      "|    time_elapsed         | 16712       |\n",
      "|    total_timesteps      | 1849344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014370373 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 9020        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -0.5609714  |\n",
      "|    std                  | 3.83        |\n",
      "|    value_loss           | 59.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 904         |\n",
      "|    time_elapsed         | 16732       |\n",
      "|    total_timesteps      | 1851392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013838471 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | 0.068       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 9030        |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    reward               | 0.065266915 |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 905         |\n",
      "|    time_elapsed         | 16751       |\n",
      "|    total_timesteps      | 1853440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013527047 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 9040        |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    reward               | -0.15653825 |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 906         |\n",
      "|    time_elapsed         | 16770       |\n",
      "|    total_timesteps      | 1855488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010687411 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 9050        |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    reward               | 0.7146724   |\n",
      "|    std                  | 3.85        |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 907         |\n",
      "|    time_elapsed         | 16788       |\n",
      "|    total_timesteps      | 1857536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013801163 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 9060        |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    reward               | 1.1474987   |\n",
      "|    std                  | 3.85        |\n",
      "|    value_loss           | 59.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 908         |\n",
      "|    time_elapsed         | 16806       |\n",
      "|    total_timesteps      | 1859584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011674371 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 9070        |\n",
      "|    policy_gradient_loss | -0.00291    |\n",
      "|    reward               | 4.0373774   |\n",
      "|    std                  | 3.85        |\n",
      "|    value_loss           | 60.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 909        |\n",
      "|    time_elapsed         | 16825      |\n",
      "|    total_timesteps      | 1861632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02185933 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.1      |\n",
      "|    explained_variance   | 0.0108     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19         |\n",
      "|    n_updates            | 9080       |\n",
      "|    policy_gradient_loss | -0.00281   |\n",
      "|    reward               | -1.1612173 |\n",
      "|    std                  | 3.87       |\n",
      "|    value_loss           | 35.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 910         |\n",
      "|    time_elapsed         | 16843       |\n",
      "|    total_timesteps      | 1863680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014326716 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.2       |\n",
      "|    explained_variance   | -0.00669    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 9090        |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    reward               | -1.4961607  |\n",
      "|    std                  | 3.88        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 911         |\n",
      "|    time_elapsed         | 16861       |\n",
      "|    total_timesteps      | 1865728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010746476 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.3       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 9100        |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    reward               | -1.6537708  |\n",
      "|    std                  | 3.89        |\n",
      "|    value_loss           | 84.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 912         |\n",
      "|    time_elapsed         | 16880       |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018406954 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 9110        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 2.0904071   |\n",
      "|    std                  | 3.9         |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 913         |\n",
      "|    time_elapsed         | 16899       |\n",
      "|    total_timesteps      | 1869824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015448073 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.5       |\n",
      "|    explained_variance   | 0.0385      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.1        |\n",
      "|    n_updates            | 9120        |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    reward               | 0.35191804  |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 71.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 914         |\n",
      "|    time_elapsed         | 16919       |\n",
      "|    total_timesteps      | 1871872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013246339 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 9130        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.44110194  |\n",
      "|    std                  | 3.92        |\n",
      "|    value_loss           | 55          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 915          |\n",
      "|    time_elapsed         | 16938        |\n",
      "|    total_timesteps      | 1873920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104016885 |\n",
      "|    clip_fraction        | 0.0944       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80.6        |\n",
      "|    explained_variance   | 0.322        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.5         |\n",
      "|    n_updates            | 9140         |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    reward               | 1.6191251    |\n",
      "|    std                  | 3.92         |\n",
      "|    value_loss           | 66.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 916         |\n",
      "|    time_elapsed         | 16956       |\n",
      "|    total_timesteps      | 1875968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013823371 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 9150        |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    reward               | -0.8814361  |\n",
      "|    std                  | 3.93        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4313728.41\n",
      "total_reward: 3313728.41\n",
      "total_cost: 352911.74\n",
      "total_trades: 70699\n",
      "Sharpe: 0.790\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 917          |\n",
      "|    time_elapsed         | 16974        |\n",
      "|    total_timesteps      | 1878016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011713138  |\n",
      "|    clip_fraction        | 0.078        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80.6        |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.6         |\n",
      "|    n_updates            | 9160         |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    reward               | -0.024878828 |\n",
      "|    std                  | 3.93         |\n",
      "|    value_loss           | 60.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 918         |\n",
      "|    time_elapsed         | 16994       |\n",
      "|    total_timesteps      | 1880064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014416587 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.7       |\n",
      "|    explained_variance   | 0.0679      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.2        |\n",
      "|    n_updates            | 9170        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 1.0624565   |\n",
      "|    std                  | 3.94        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 919         |\n",
      "|    time_elapsed         | 17013       |\n",
      "|    total_timesteps      | 1882112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015430687 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.7       |\n",
      "|    explained_variance   | -0.00617    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 9180        |\n",
      "|    policy_gradient_loss | -0.00991    |\n",
      "|    reward               | -5.3601465  |\n",
      "|    std                  | 3.94        |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 920         |\n",
      "|    time_elapsed         | 17031       |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019114925 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.8       |\n",
      "|    explained_variance   | 0.0448      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 9190        |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    reward               | 0.39957297  |\n",
      "|    std                  | 3.95        |\n",
      "|    value_loss           | 68.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 921        |\n",
      "|    time_elapsed         | 17049      |\n",
      "|    total_timesteps      | 1886208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01937642 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.9      |\n",
      "|    explained_variance   | 0.138      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.5       |\n",
      "|    n_updates            | 9200       |\n",
      "|    policy_gradient_loss | -0.00671   |\n",
      "|    reward               | 0.52658594 |\n",
      "|    std                  | 3.97       |\n",
      "|    value_loss           | 83.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 922         |\n",
      "|    time_elapsed         | 17067       |\n",
      "|    total_timesteps      | 1888256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019460639 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.6        |\n",
      "|    n_updates            | 9210        |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | 0.7701069   |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 63.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 923        |\n",
      "|    time_elapsed         | 17085      |\n",
      "|    total_timesteps      | 1890304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01607963 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81        |\n",
      "|    explained_variance   | 0.123      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.4       |\n",
      "|    n_updates            | 9220       |\n",
      "|    policy_gradient_loss | -0.00362   |\n",
      "|    reward               | 1.1384126  |\n",
      "|    std                  | 3.98       |\n",
      "|    value_loss           | 28.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 924         |\n",
      "|    time_elapsed         | 17103       |\n",
      "|    total_timesteps      | 1892352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010276419 |\n",
      "|    clip_fraction        | 0.0871      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | 0.0763      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.7        |\n",
      "|    n_updates            | 9230        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -2.4060092  |\n",
      "|    std                  | 3.98        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 925        |\n",
      "|    time_elapsed         | 17121      |\n",
      "|    total_timesteps      | 1894400    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01722166 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.1      |\n",
      "|    explained_variance   | 0.0813     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 43.2       |\n",
      "|    n_updates            | 9240       |\n",
      "|    policy_gradient_loss | -0.00882   |\n",
      "|    reward               | 0.24927601 |\n",
      "|    std                  | 3.99       |\n",
      "|    value_loss           | 93.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 926         |\n",
      "|    time_elapsed         | 17139       |\n",
      "|    total_timesteps      | 1896448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016648274 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.1       |\n",
      "|    explained_variance   | -0.041      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 9250        |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    reward               | 2.6628382   |\n",
      "|    std                  | 4           |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 927         |\n",
      "|    time_elapsed         | 17158       |\n",
      "|    total_timesteps      | 1898496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013222454 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.1       |\n",
      "|    explained_variance   | 0.0362      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.4        |\n",
      "|    n_updates            | 9260        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 3.7650983   |\n",
      "|    std                  | 4           |\n",
      "|    value_loss           | 88.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 928         |\n",
      "|    time_elapsed         | 17176       |\n",
      "|    total_timesteps      | 1900544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018514227 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.0102      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.2        |\n",
      "|    n_updates            | 9270        |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | -3.303768   |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 929         |\n",
      "|    time_elapsed         | 17195       |\n",
      "|    total_timesteps      | 1902592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011397365 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.0382      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.6        |\n",
      "|    n_updates            | 9280        |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    reward               | 6.5443635   |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 80.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 930        |\n",
      "|    time_elapsed         | 17214      |\n",
      "|    total_timesteps      | 1904640    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00902891 |\n",
      "|    clip_fraction        | 0.0726     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.2      |\n",
      "|    explained_variance   | 0.045      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 106        |\n",
      "|    n_updates            | 9290       |\n",
      "|    policy_gradient_loss | -0.0079    |\n",
      "|    reward               | 0.5753522  |\n",
      "|    std                  | 4.01       |\n",
      "|    value_loss           | 141        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5351771.02\n",
      "total_reward: 4351771.02\n",
      "total_cost: 330967.30\n",
      "total_trades: 69332\n",
      "Sharpe: 0.826\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 931          |\n",
      "|    time_elapsed         | 17232        |\n",
      "|    total_timesteps      | 1906688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061512617 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.3        |\n",
      "|    explained_variance   | 0.14         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.2         |\n",
      "|    n_updates            | 9300         |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    reward               | 0.07589625   |\n",
      "|    std                  | 4.02         |\n",
      "|    value_loss           | 153          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 932        |\n",
      "|    time_elapsed         | 17251      |\n",
      "|    total_timesteps      | 1908736    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01868761 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.3      |\n",
      "|    explained_variance   | 0.0141     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 95.7       |\n",
      "|    n_updates            | 9310       |\n",
      "|    policy_gradient_loss | -0.00501   |\n",
      "|    reward               | 0.23335506 |\n",
      "|    std                  | 4.02       |\n",
      "|    value_loss           | 206        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 933         |\n",
      "|    time_elapsed         | 17269       |\n",
      "|    total_timesteps      | 1910784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01274471  |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.0909      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 9320        |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    reward               | -0.34831604 |\n",
      "|    std                  | 4.02        |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 934          |\n",
      "|    time_elapsed         | 17288        |\n",
      "|    total_timesteps      | 1912832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069750007 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.3        |\n",
      "|    explained_variance   | 0.103        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.1         |\n",
      "|    n_updates            | 9330         |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | 1.1811664    |\n",
      "|    std                  | 4.03         |\n",
      "|    value_loss           | 197          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 935         |\n",
      "|    time_elapsed         | 17307       |\n",
      "|    total_timesteps      | 1914880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008093197 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 9340        |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    reward               | 4.067432    |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 936         |\n",
      "|    time_elapsed         | 17326       |\n",
      "|    total_timesteps      | 1916928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015896432 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.0534      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 9350        |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    reward               | -4.2885003  |\n",
      "|    std                  | 4.04        |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 937         |\n",
      "|    time_elapsed         | 17345       |\n",
      "|    total_timesteps      | 1918976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016255364 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 9360        |\n",
      "|    policy_gradient_loss | -0.0085     |\n",
      "|    reward               | -0.13878973 |\n",
      "|    std                  | 4.05        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 938         |\n",
      "|    time_elapsed         | 17363       |\n",
      "|    total_timesteps      | 1921024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01488609  |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | -0.0115     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 9370        |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | -0.17317103 |\n",
      "|    std                  | 4.05        |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 939         |\n",
      "|    time_elapsed         | 17381       |\n",
      "|    total_timesteps      | 1923072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017925952 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.00163     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85          |\n",
      "|    n_updates            | 9380        |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    reward               | -2.1524403  |\n",
      "|    std                  | 4.06        |\n",
      "|    value_loss           | 231         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 940         |\n",
      "|    time_elapsed         | 17399       |\n",
      "|    total_timesteps      | 1925120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009156171 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.0992      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 9390        |\n",
      "|    policy_gradient_loss | -0.00552    |\n",
      "|    reward               | -0.9983881  |\n",
      "|    std                  | 4.06        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 941         |\n",
      "|    time_elapsed         | 17418       |\n",
      "|    total_timesteps      | 1927168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009311635 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.0184      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.3        |\n",
      "|    n_updates            | 9400        |\n",
      "|    policy_gradient_loss | -0.00762    |\n",
      "|    reward               | -0.22572893 |\n",
      "|    std                  | 4.06        |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 942         |\n",
      "|    time_elapsed         | 17437       |\n",
      "|    total_timesteps      | 1929216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012242935 |\n",
      "|    clip_fraction        | 0.0733      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.0165      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88.1        |\n",
      "|    n_updates            | 9410        |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    reward               | 1.9320637   |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 943         |\n",
      "|    time_elapsed         | 17455       |\n",
      "|    total_timesteps      | 1931264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011194324 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 9420        |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | 1.7686665   |\n",
      "|    std                  | 4.06        |\n",
      "|    value_loss           | 50          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 944         |\n",
      "|    time_elapsed         | 17474       |\n",
      "|    total_timesteps      | 1933312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014062213 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.0775      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 9430        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 1.247489    |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 945         |\n",
      "|    time_elapsed         | 17492       |\n",
      "|    total_timesteps      | 1935360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007476408 |\n",
      "|    clip_fraction        | 0.0381      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.2        |\n",
      "|    n_updates            | 9440        |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | 10.803474   |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6345365.43\n",
      "total_reward: 5345365.43\n",
      "total_cost: 334764.46\n",
      "total_trades: 69317\n",
      "Sharpe: 0.903\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 946          |\n",
      "|    time_elapsed         | 17511        |\n",
      "|    total_timesteps      | 1937408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011466531  |\n",
      "|    clip_fraction        | 0.0978       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.7        |\n",
      "|    explained_variance   | 0.0782       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 121          |\n",
      "|    n_updates            | 9450         |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | 0.0063166614 |\n",
      "|    std                  | 4.07         |\n",
      "|    value_loss           | 225          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 947         |\n",
      "|    time_elapsed         | 17530       |\n",
      "|    total_timesteps      | 1939456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012035907 |\n",
      "|    clip_fraction        | 0.0815      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | -0.016      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.09        |\n",
      "|    n_updates            | 9460        |\n",
      "|    policy_gradient_loss | -0.00768    |\n",
      "|    reward               | 0.19120564  |\n",
      "|    std                  | 4.08        |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 948          |\n",
      "|    time_elapsed         | 17549        |\n",
      "|    total_timesteps      | 1941504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098558925 |\n",
      "|    clip_fraction        | 0.0736       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.7        |\n",
      "|    explained_variance   | 0.0566       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 86.4         |\n",
      "|    n_updates            | 9470         |\n",
      "|    policy_gradient_loss | -0.00736     |\n",
      "|    reward               | 0.538256     |\n",
      "|    std                  | 4.09         |\n",
      "|    value_loss           | 180          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 949         |\n",
      "|    time_elapsed         | 17567       |\n",
      "|    total_timesteps      | 1943552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013467709 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.8       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.9        |\n",
      "|    n_updates            | 9480        |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    reward               | 0.27607194  |\n",
      "|    std                  | 4.09        |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 950         |\n",
      "|    time_elapsed         | 17585       |\n",
      "|    total_timesteps      | 1945600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015742352 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.8       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 9490        |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    reward               | 1.6858017   |\n",
      "|    std                  | 4.09        |\n",
      "|    value_loss           | 46.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 951         |\n",
      "|    time_elapsed         | 17604       |\n",
      "|    total_timesteps      | 1947648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011580734 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 9500        |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | 2.234529    |\n",
      "|    std                  | 4.1         |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 952         |\n",
      "|    time_elapsed         | 17623       |\n",
      "|    total_timesteps      | 1949696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010736778 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.0732      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.8        |\n",
      "|    n_updates            | 9510        |\n",
      "|    policy_gradient_loss | -0.00743    |\n",
      "|    reward               | 7.1256633   |\n",
      "|    std                  | 4.1         |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 953         |\n",
      "|    time_elapsed         | 17641       |\n",
      "|    total_timesteps      | 1951744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007214782 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 9520        |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    reward               | -1.3786683  |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 61.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 17659       |\n",
      "|    total_timesteps      | 1953792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011162414 |\n",
      "|    clip_fraction        | 0.098       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.1        |\n",
      "|    n_updates            | 9530        |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    reward               | 0.6823577   |\n",
      "|    std                  | 4.12        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 955         |\n",
      "|    time_elapsed         | 17677       |\n",
      "|    total_timesteps      | 1955840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012027561 |\n",
      "|    clip_fraction        | 0.0858      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82         |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.9        |\n",
      "|    n_updates            | 9540        |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    reward               | 1.206005    |\n",
      "|    std                  | 4.12        |\n",
      "|    value_loss           | 186         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 956         |\n",
      "|    time_elapsed         | 17697       |\n",
      "|    total_timesteps      | 1957888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010637524 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82         |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 9550        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.19306572 |\n",
      "|    std                  | 4.12        |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 957         |\n",
      "|    time_elapsed         | 17715       |\n",
      "|    total_timesteps      | 1959936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011743169 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82         |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 9560        |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    reward               | 0.556934    |\n",
      "|    std                  | 4.13        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 958         |\n",
      "|    time_elapsed         | 17734       |\n",
      "|    total_timesteps      | 1961984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013055582 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82         |\n",
      "|    explained_variance   | 0.0312      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.8        |\n",
      "|    n_updates            | 9570        |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | -0.33765292 |\n",
      "|    std                  | 4.13        |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 959         |\n",
      "|    time_elapsed         | 17753       |\n",
      "|    total_timesteps      | 1964032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012439653 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.0511      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.8        |\n",
      "|    n_updates            | 9580        |\n",
      "|    policy_gradient_loss | -0.00912    |\n",
      "|    reward               | -1.226808   |\n",
      "|    std                  | 4.14        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5113808.49\n",
      "total_reward: 4113808.49\n",
      "total_cost: 278832.79\n",
      "total_trades: 64636\n",
      "Sharpe: 0.768\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 960         |\n",
      "|    time_elapsed         | 17771       |\n",
      "|    total_timesteps      | 1966080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013537287 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.0157      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 9590        |\n",
      "|    policy_gradient_loss | -0.00972    |\n",
      "|    reward               | 2.2015646   |\n",
      "|    std                  | 4.14        |\n",
      "|    value_loss           | 81.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 961         |\n",
      "|    time_elapsed         | 17791       |\n",
      "|    total_timesteps      | 1968128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009973997 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.0221      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 9600        |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    reward               | -0.6467889  |\n",
      "|    std                  | 4.15        |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 962         |\n",
      "|    time_elapsed         | 17809       |\n",
      "|    total_timesteps      | 1970176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008374285 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 9610        |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    reward               | -0.298462   |\n",
      "|    std                  | 4.16        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 963         |\n",
      "|    time_elapsed         | 17827       |\n",
      "|    total_timesteps      | 1972224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014594335 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.0753      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.5        |\n",
      "|    n_updates            | 9620        |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    reward               | 0.5045875   |\n",
      "|    std                  | 4.16        |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 964         |\n",
      "|    time_elapsed         | 17846       |\n",
      "|    total_timesteps      | 1974272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018120334 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.0497      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 9630        |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | 0.23445979  |\n",
      "|    std                  | 4.17        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 965         |\n",
      "|    time_elapsed         | 17864       |\n",
      "|    total_timesteps      | 1976320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011856688 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.0364      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.4        |\n",
      "|    n_updates            | 9640        |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    reward               | -1.0822757  |\n",
      "|    std                  | 4.17        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 966         |\n",
      "|    time_elapsed         | 17883       |\n",
      "|    total_timesteps      | 1978368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011868573 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 9650        |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    reward               | 0.37951487  |\n",
      "|    std                  | 4.17        |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 967         |\n",
      "|    time_elapsed         | 17902       |\n",
      "|    total_timesteps      | 1980416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017206423 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.0661      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 9660        |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    reward               | -1.873204   |\n",
      "|    std                  | 4.17        |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 968         |\n",
      "|    time_elapsed         | 17920       |\n",
      "|    total_timesteps      | 1982464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011680479 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.4       |\n",
      "|    explained_variance   | -0.000648   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.4        |\n",
      "|    n_updates            | 9670        |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    reward               | -0.46166825 |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 166         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 969         |\n",
      "|    time_elapsed         | 17939       |\n",
      "|    total_timesteps      | 1984512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009294119 |\n",
      "|    clip_fraction        | 0.0579      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.4       |\n",
      "|    explained_variance   | 0.0935      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 9680        |\n",
      "|    policy_gradient_loss | -0.00614    |\n",
      "|    reward               | 4.559375    |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 970          |\n",
      "|    time_elapsed         | 17957        |\n",
      "|    total_timesteps      | 1986560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062742857 |\n",
      "|    clip_fraction        | 0.0428       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.5        |\n",
      "|    explained_variance   | -0.0132      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.6         |\n",
      "|    n_updates            | 9690         |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | -0.13584894  |\n",
      "|    std                  | 4.19         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 971         |\n",
      "|    time_elapsed         | 17976       |\n",
      "|    total_timesteps      | 1988608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010983052 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.0237      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 9700        |\n",
      "|    policy_gradient_loss | -0.00865    |\n",
      "|    reward               | -1.538113   |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 84.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 972         |\n",
      "|    time_elapsed         | 17995       |\n",
      "|    total_timesteps      | 1990656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011222519 |\n",
      "|    clip_fraction        | 0.0731      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.0254      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.1        |\n",
      "|    n_updates            | 9710        |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    reward               | 1.3547119   |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 973         |\n",
      "|    time_elapsed         | 18014       |\n",
      "|    total_timesteps      | 1992704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014808334 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.0768      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.2        |\n",
      "|    n_updates            | 9720        |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    reward               | -14.4768505 |\n",
      "|    std                  | 4.2         |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4477952.83\n",
      "total_reward: 3477952.83\n",
      "total_cost: 261618.83\n",
      "total_trades: 63427\n",
      "Sharpe: 0.707\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 974         |\n",
      "|    time_elapsed         | 18033       |\n",
      "|    total_timesteps      | 1994752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009711973 |\n",
      "|    clip_fraction        | 0.0493      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 9730        |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | -0.00965017 |\n",
      "|    std                  | 4.2         |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 975         |\n",
      "|    time_elapsed         | 18051       |\n",
      "|    total_timesteps      | 1996800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012709382 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.6       |\n",
      "|    explained_variance   | 0.00731     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.1        |\n",
      "|    n_updates            | 9740        |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    reward               | -0.9000536  |\n",
      "|    std                  | 4.21        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 976         |\n",
      "|    time_elapsed         | 18070       |\n",
      "|    total_timesteps      | 1998848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010419015 |\n",
      "|    clip_fraction        | 0.0735      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.6       |\n",
      "|    explained_variance   | 0.0895      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.5        |\n",
      "|    n_updates            | 9750        |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    reward               | -19.293116  |\n",
      "|    std                  | 4.21        |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 977         |\n",
      "|    time_elapsed         | 18088       |\n",
      "|    total_timesteps      | 2000896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012548124 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58          |\n",
      "|    n_updates            | 9760        |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    reward               | -0.44659233 |\n",
      "|    std                  | 4.22        |\n",
      "|    value_loss           | 84.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 978        |\n",
      "|    time_elapsed         | 18106      |\n",
      "|    total_timesteps      | 2002944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01189982 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.7      |\n",
      "|    explained_variance   | 0.0939     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 80.3       |\n",
      "|    n_updates            | 9770       |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    reward               | 1.7237307  |\n",
      "|    std                  | 4.23       |\n",
      "|    value_loss           | 130        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 979         |\n",
      "|    time_elapsed         | 18124       |\n",
      "|    total_timesteps      | 2004992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011479025 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.8       |\n",
      "|    explained_variance   | 0.0239      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.5        |\n",
      "|    n_updates            | 9780        |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    reward               | -0.6970232  |\n",
      "|    std                  | 4.24        |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 980         |\n",
      "|    time_elapsed         | 18142       |\n",
      "|    total_timesteps      | 2007040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016579233 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.0497      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 9790        |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    reward               | 3.6293223   |\n",
      "|    std                  | 4.25        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 981         |\n",
      "|    time_elapsed         | 18161       |\n",
      "|    total_timesteps      | 2009088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01313033  |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 9800        |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    reward               | -0.25242326 |\n",
      "|    std                  | 4.25        |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 982         |\n",
      "|    time_elapsed         | 18180       |\n",
      "|    total_timesteps      | 2011136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012749264 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.6        |\n",
      "|    n_updates            | 9810        |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    reward               | -0.16015378 |\n",
      "|    std                  | 4.26        |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 983         |\n",
      "|    time_elapsed         | 18199       |\n",
      "|    total_timesteps      | 2013184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013576178 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83         |\n",
      "|    explained_variance   | 0.0997      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98.6        |\n",
      "|    n_updates            | 9820        |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    reward               | 8.705954    |\n",
      "|    std                  | 4.27        |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 984          |\n",
      "|    time_elapsed         | 18217        |\n",
      "|    total_timesteps      | 2015232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062464094 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83          |\n",
      "|    explained_variance   | 0.0753       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.2         |\n",
      "|    n_updates            | 9830         |\n",
      "|    policy_gradient_loss | 0.00101      |\n",
      "|    reward               | 1.0933789    |\n",
      "|    std                  | 4.27         |\n",
      "|    value_loss           | 94.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 985         |\n",
      "|    time_elapsed         | 18235       |\n",
      "|    total_timesteps      | 2017280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011693871 |\n",
      "|    clip_fraction        | 0.0746      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83         |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.2        |\n",
      "|    n_updates            | 9840        |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | -2.1016018  |\n",
      "|    std                  | 4.28        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 986         |\n",
      "|    time_elapsed         | 18254       |\n",
      "|    total_timesteps      | 2019328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008104312 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.1       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.7        |\n",
      "|    n_updates            | 9850        |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    reward               | 0.05582819  |\n",
      "|    std                  | 4.28        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 987         |\n",
      "|    time_elapsed         | 18272       |\n",
      "|    total_timesteps      | 2021376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013466904 |\n",
      "|    clip_fraction        | 0.0982      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.1       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 9860        |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    reward               | -2.1707296  |\n",
      "|    std                  | 4.29        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4122156.33\n",
      "total_reward: 3122156.33\n",
      "total_cost: 263583.99\n",
      "total_trades: 62404\n",
      "Sharpe: 0.664\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 988         |\n",
      "|    time_elapsed         | 18291       |\n",
      "|    total_timesteps      | 2023424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013535177 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 9870        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 0.6823108   |\n",
      "|    std                  | 4.3         |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 989         |\n",
      "|    time_elapsed         | 18309       |\n",
      "|    total_timesteps      | 2025472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013193801 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.6        |\n",
      "|    n_updates            | 9880        |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    reward               | 2.00998     |\n",
      "|    std                  | 4.3         |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 990         |\n",
      "|    time_elapsed         | 18328       |\n",
      "|    total_timesteps      | 2027520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010257097 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 9890        |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    reward               | 2.073584    |\n",
      "|    std                  | 4.3         |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 991         |\n",
      "|    time_elapsed         | 18347       |\n",
      "|    total_timesteps      | 2029568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014533002 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 9900        |\n",
      "|    policy_gradient_loss | -0.00345    |\n",
      "|    reward               | -0.33346522 |\n",
      "|    std                  | 4.3         |\n",
      "|    value_loss           | 49.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 992         |\n",
      "|    time_elapsed         | 18364       |\n",
      "|    total_timesteps      | 2031616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011142526 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.9        |\n",
      "|    n_updates            | 9910        |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    reward               | -4.6411676  |\n",
      "|    std                  | 4.3         |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 993         |\n",
      "|    time_elapsed         | 18382       |\n",
      "|    total_timesteps      | 2033664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013461476 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91          |\n",
      "|    n_updates            | 9920        |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    reward               | 4.1433992   |\n",
      "|    std                  | 4.31        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 994         |\n",
      "|    time_elapsed         | 18400       |\n",
      "|    total_timesteps      | 2035712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015852615 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 9930        |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    reward               | -1.7437582  |\n",
      "|    std                  | 4.32        |\n",
      "|    value_loss           | 69.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 995         |\n",
      "|    time_elapsed         | 18418       |\n",
      "|    total_timesteps      | 2037760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014477712 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.0753      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 9940        |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | -2.4248314  |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 996         |\n",
      "|    time_elapsed         | 18437       |\n",
      "|    total_timesteps      | 2039808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011870787 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 9950        |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    reward               | -0.07046915 |\n",
      "|    std                  | 4.34        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 997         |\n",
      "|    time_elapsed         | 18455       |\n",
      "|    total_timesteps      | 2041856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011862554 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.5       |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.8        |\n",
      "|    n_updates            | 9960        |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    reward               | -16.460125  |\n",
      "|    std                  | 4.34        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 998       |\n",
      "|    time_elapsed         | 18475     |\n",
      "|    total_timesteps      | 2043904   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0150024 |\n",
      "|    clip_fraction        | 0.201     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -83.6     |\n",
      "|    explained_variance   | -0.0146   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 17.4      |\n",
      "|    n_updates            | 9970      |\n",
      "|    policy_gradient_loss | -0.00972  |\n",
      "|    reward               | -3.628518 |\n",
      "|    std                  | 4.36      |\n",
      "|    value_loss           | 42.3      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 999         |\n",
      "|    time_elapsed         | 18495       |\n",
      "|    total_timesteps      | 2045952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008330703 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.3        |\n",
      "|    n_updates            | 9980        |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    reward               | -2.1488695  |\n",
      "|    std                  | 4.37        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1000         |\n",
      "|    time_elapsed         | 18514        |\n",
      "|    total_timesteps      | 2048000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082856435 |\n",
      "|    clip_fraction        | 0.0734       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.7        |\n",
      "|    explained_variance   | 0.296        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.8         |\n",
      "|    n_updates            | 9990         |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    reward               | -5.1270475   |\n",
      "|    std                  | 4.37         |\n",
      "|    value_loss           | 211          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1001        |\n",
      "|    time_elapsed         | 18532       |\n",
      "|    total_timesteps      | 2050048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007007109 |\n",
      "|    clip_fraction        | 0.0322      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 10000       |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    reward               | 0.58660597  |\n",
      "|    std                  | 4.37        |\n",
      "|    value_loss           | 66.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4338604.52\n",
      "total_reward: 3338604.52\n",
      "total_cost: 264797.93\n",
      "total_trades: 63559\n",
      "Sharpe: 0.693\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1002       |\n",
      "|    time_elapsed         | 18551      |\n",
      "|    total_timesteps      | 2052096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01593594 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.7      |\n",
      "|    explained_variance   | 0.308      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 43.5       |\n",
      "|    n_updates            | 10010      |\n",
      "|    policy_gradient_loss | -0.00946   |\n",
      "|    reward               | 0.285445   |\n",
      "|    std                  | 4.38       |\n",
      "|    value_loss           | 116        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1003        |\n",
      "|    time_elapsed         | 18571       |\n",
      "|    total_timesteps      | 2054144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009967474 |\n",
      "|    clip_fraction        | 0.0706      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.3        |\n",
      "|    n_updates            | 10020       |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    reward               | -1.16116    |\n",
      "|    std                  | 4.38        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1004        |\n",
      "|    time_elapsed         | 18589       |\n",
      "|    total_timesteps      | 2056192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010286441 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49          |\n",
      "|    n_updates            | 10030       |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    reward               | 2.3653822   |\n",
      "|    std                  | 4.39        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 1005      |\n",
      "|    time_elapsed         | 18608     |\n",
      "|    total_timesteps      | 2058240   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0144662 |\n",
      "|    clip_fraction        | 0.156     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -83.8     |\n",
      "|    explained_variance   | -0.00825  |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 19.7      |\n",
      "|    n_updates            | 10040     |\n",
      "|    policy_gradient_loss | -0.0125   |\n",
      "|    reward               | 1.1096939 |\n",
      "|    std                  | 4.4       |\n",
      "|    value_loss           | 40.3      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1006        |\n",
      "|    time_elapsed         | 18627       |\n",
      "|    total_timesteps      | 2060288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008417634 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.6        |\n",
      "|    n_updates            | 10050       |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    reward               | -0.19405343 |\n",
      "|    std                  | 4.4         |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1007         |\n",
      "|    time_elapsed         | 18645        |\n",
      "|    total_timesteps      | 2062336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058601806 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.9        |\n",
      "|    explained_variance   | 0.156        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.2         |\n",
      "|    n_updates            | 10060        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | -0.58354294  |\n",
      "|    std                  | 4.4          |\n",
      "|    value_loss           | 170          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1008         |\n",
      "|    time_elapsed         | 18664        |\n",
      "|    total_timesteps      | 2064384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059826146 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.9        |\n",
      "|    explained_variance   | 0.369        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.4         |\n",
      "|    n_updates            | 10070        |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    reward               | -1.5287035   |\n",
      "|    std                  | 4.4          |\n",
      "|    value_loss           | 68.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1009        |\n",
      "|    time_elapsed         | 18682       |\n",
      "|    total_timesteps      | 2066432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005337533 |\n",
      "|    clip_fraction        | 0.0331      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.2        |\n",
      "|    n_updates            | 10080       |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    reward               | -1.5820332  |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1010        |\n",
      "|    time_elapsed         | 18701       |\n",
      "|    total_timesteps      | 2068480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013531124 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72          |\n",
      "|    n_updates            | 10090       |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    reward               | -14.9356575 |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 88.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1011        |\n",
      "|    time_elapsed         | 18721       |\n",
      "|    total_timesteps      | 2070528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007275698 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.2        |\n",
      "|    n_updates            | 10100       |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    reward               | -2.821085   |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1012        |\n",
      "|    time_elapsed         | 18740       |\n",
      "|    total_timesteps      | 2072576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010109236 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 10110       |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | -3.6199846  |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1013        |\n",
      "|    time_elapsed         | 18758       |\n",
      "|    total_timesteps      | 2074624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007067926 |\n",
      "|    clip_fraction        | 0.0314      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.1        |\n",
      "|    n_updates            | 10120       |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    reward               | -2.1106796  |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1014         |\n",
      "|    time_elapsed         | 18777        |\n",
      "|    total_timesteps      | 2076672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075590536 |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84          |\n",
      "|    explained_variance   | 0.381        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.3         |\n",
      "|    n_updates            | 10130        |\n",
      "|    policy_gradient_loss | -0.00637     |\n",
      "|    reward               | -1.8174137   |\n",
      "|    std                  | 4.41         |\n",
      "|    value_loss           | 197          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1015        |\n",
      "|    time_elapsed         | 18796       |\n",
      "|    total_timesteps      | 2078720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014304237 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 10140       |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    reward               | 0.64697206  |\n",
      "|    std                  | 4.42        |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4468828.48\n",
      "total_reward: 3468828.48\n",
      "total_cost: 227143.79\n",
      "total_trades: 61293\n",
      "Sharpe: 0.701\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1016        |\n",
      "|    time_elapsed         | 18815       |\n",
      "|    total_timesteps      | 2080768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009954708 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.2        |\n",
      "|    n_updates            | 10150       |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    reward               | -2.2783527  |\n",
      "|    std                  | 4.43        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1017         |\n",
      "|    time_elapsed         | 18834        |\n",
      "|    total_timesteps      | 2082816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075428756 |\n",
      "|    clip_fraction        | 0.0705       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84          |\n",
      "|    explained_variance   | 0.413        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.9         |\n",
      "|    n_updates            | 10160        |\n",
      "|    policy_gradient_loss | -0.00532     |\n",
      "|    reward               | 6.473881     |\n",
      "|    std                  | 4.43         |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1018        |\n",
      "|    time_elapsed         | 18853       |\n",
      "|    total_timesteps      | 2084864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007863706 |\n",
      "|    clip_fraction        | 0.0503      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 10170       |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    reward               | -1.4314046  |\n",
      "|    std                  | 4.43        |\n",
      "|    value_loss           | 84.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1019        |\n",
      "|    time_elapsed         | 18871       |\n",
      "|    total_timesteps      | 2086912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013692742 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40          |\n",
      "|    n_updates            | 10180       |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    reward               | 0.8981695   |\n",
      "|    std                  | 4.43        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1020        |\n",
      "|    time_elapsed         | 18889       |\n",
      "|    total_timesteps      | 2088960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011017982 |\n",
      "|    clip_fraction        | 0.0512      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.3        |\n",
      "|    n_updates            | 10190       |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    reward               | 0.022762917 |\n",
      "|    std                  | 4.44        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1021        |\n",
      "|    time_elapsed         | 18908       |\n",
      "|    total_timesteps      | 2091008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012742002 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.2       |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.3        |\n",
      "|    n_updates            | 10200       |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    reward               | 0.6629978   |\n",
      "|    std                  | 4.45        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1022        |\n",
      "|    time_elapsed         | 18925       |\n",
      "|    total_timesteps      | 2093056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016823983 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.2       |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 10210       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 2.3440871   |\n",
      "|    std                  | 4.46        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1023        |\n",
      "|    time_elapsed         | 18944       |\n",
      "|    total_timesteps      | 2095104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0124533   |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.3        |\n",
      "|    n_updates            | 10220       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | -0.22619846 |\n",
      "|    std                  | 4.47        |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1024       |\n",
      "|    time_elapsed         | 18963      |\n",
      "|    total_timesteps      | 2097152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00926153 |\n",
      "|    clip_fraction        | 0.0735     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.3      |\n",
      "|    explained_variance   | 0.0253     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 93.4       |\n",
      "|    n_updates            | 10230      |\n",
      "|    policy_gradient_loss | -0.00562   |\n",
      "|    reward               | 5.2182508  |\n",
      "|    std                  | 4.46       |\n",
      "|    value_loss           | 259        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1025        |\n",
      "|    time_elapsed         | 18982       |\n",
      "|    total_timesteps      | 2099200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009658879 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 10240       |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | 4.403638    |\n",
      "|    std                  | 4.47        |\n",
      "|    value_loss           | 83.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1026         |\n",
      "|    time_elapsed         | 19000        |\n",
      "|    total_timesteps      | 2101248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0119945025 |\n",
      "|    clip_fraction        | 0.0736       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.3        |\n",
      "|    explained_variance   | 0.382        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.1         |\n",
      "|    n_updates            | 10250        |\n",
      "|    policy_gradient_loss | -0.00549     |\n",
      "|    reward               | 1.4631722    |\n",
      "|    std                  | 4.47         |\n",
      "|    value_loss           | 138          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1027         |\n",
      "|    time_elapsed         | 19018        |\n",
      "|    total_timesteps      | 2103296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092397705 |\n",
      "|    clip_fraction        | 0.0722       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.3        |\n",
      "|    explained_variance   | 0.413        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.1         |\n",
      "|    n_updates            | 10260        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | 1.2432654    |\n",
      "|    std                  | 4.47         |\n",
      "|    value_loss           | 160          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1028        |\n",
      "|    time_elapsed         | 19037       |\n",
      "|    total_timesteps      | 2105344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012686328 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 10270       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.40210757 |\n",
      "|    std                  | 4.48        |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1029        |\n",
      "|    time_elapsed         | 19056       |\n",
      "|    total_timesteps      | 2107392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012229079 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 10280       |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | 0.29015055  |\n",
      "|    std                  | 4.48        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4386232.94\n",
      "total_reward: 3386232.94\n",
      "total_cost: 175706.68\n",
      "total_trades: 58039\n",
      "Sharpe: 0.683\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1030        |\n",
      "|    time_elapsed         | 19074       |\n",
      "|    total_timesteps      | 2109440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009504525 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.1        |\n",
      "|    n_updates            | 10290       |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    reward               | 0.8773282   |\n",
      "|    std                  | 4.49        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1031        |\n",
      "|    time_elapsed         | 19094       |\n",
      "|    total_timesteps      | 2111488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010276113 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.3        |\n",
      "|    n_updates            | 10300       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | -3.2677598  |\n",
      "|    std                  | 4.49        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1032       |\n",
      "|    time_elapsed         | 19112      |\n",
      "|    total_timesteps      | 2113536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01445958 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.5      |\n",
      "|    explained_variance   | 0.0568     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27         |\n",
      "|    n_updates            | 10310      |\n",
      "|    policy_gradient_loss | -0.00556   |\n",
      "|    reward               | 1.7094002  |\n",
      "|    std                  | 4.51       |\n",
      "|    value_loss           | 67.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1033        |\n",
      "|    time_elapsed         | 19130       |\n",
      "|    total_timesteps      | 2115584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008755241 |\n",
      "|    clip_fraction        | 0.0937      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.0869      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96.1        |\n",
      "|    n_updates            | 10320       |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    reward               | 3.757218    |\n",
      "|    std                  | 4.51        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1034        |\n",
      "|    time_elapsed         | 19149       |\n",
      "|    total_timesteps      | 2117632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008631704 |\n",
      "|    clip_fraction        | 0.0472      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 10330       |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    reward               | 10.142542   |\n",
      "|    std                  | 4.52        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1035        |\n",
      "|    time_elapsed         | 19168       |\n",
      "|    total_timesteps      | 2119680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010895856 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.6        |\n",
      "|    n_updates            | 10340       |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    reward               | -0.6080093  |\n",
      "|    std                  | 4.52        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1036         |\n",
      "|    time_elapsed         | 19186        |\n",
      "|    total_timesteps      | 2121728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011398617  |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.7        |\n",
      "|    explained_variance   | 0.299        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 10350        |\n",
      "|    policy_gradient_loss | -0.0084      |\n",
      "|    reward               | -0.043015998 |\n",
      "|    std                  | 4.53         |\n",
      "|    value_loss           | 38.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1037        |\n",
      "|    time_elapsed         | 19205       |\n",
      "|    total_timesteps      | 2123776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014051481 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.4        |\n",
      "|    n_updates            | 10360       |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    reward               | 0.6450611   |\n",
      "|    std                  | 4.53        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1038       |\n",
      "|    time_elapsed         | 19224      |\n",
      "|    total_timesteps      | 2125824    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01049093 |\n",
      "|    clip_fraction        | 0.0739     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.7      |\n",
      "|    explained_variance   | 0.438      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 53.1       |\n",
      "|    n_updates            | 10370      |\n",
      "|    policy_gradient_loss | -0.00599   |\n",
      "|    reward               | 1.8930357  |\n",
      "|    std                  | 4.53       |\n",
      "|    value_loss           | 153        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1039        |\n",
      "|    time_elapsed         | 19242       |\n",
      "|    total_timesteps      | 2127872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011429599 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.3        |\n",
      "|    n_updates            | 10380       |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    reward               | 1.4127742   |\n",
      "|    std                  | 4.54        |\n",
      "|    value_loss           | 77.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1040        |\n",
      "|    time_elapsed         | 19261       |\n",
      "|    total_timesteps      | 2129920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010456514 |\n",
      "|    clip_fraction        | 0.0747      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.1        |\n",
      "|    n_updates            | 10390       |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    reward               | -3.4898021  |\n",
      "|    std                  | 4.55        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1041        |\n",
      "|    time_elapsed         | 19279       |\n",
      "|    total_timesteps      | 2131968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010616371 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.9        |\n",
      "|    n_updates            | 10400       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | 2.471954    |\n",
      "|    std                  | 4.55        |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1042        |\n",
      "|    time_elapsed         | 19297       |\n",
      "|    total_timesteps      | 2134016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015204022 |\n",
      "|    clip_fraction        | 0.0948      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.6        |\n",
      "|    n_updates            | 10410       |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    reward               | -0.19062111 |\n",
      "|    std                  | 4.56        |\n",
      "|    value_loss           | 94.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1043        |\n",
      "|    time_elapsed         | 19315       |\n",
      "|    total_timesteps      | 2136064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010838561 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.9       |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 10420       |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    reward               | -0.1808017  |\n",
      "|    std                  | 4.56        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4390101.74\n",
      "total_reward: 3390101.74\n",
      "total_cost: 194640.62\n",
      "total_trades: 57668\n",
      "Sharpe: 0.689\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1044        |\n",
      "|    time_elapsed         | 19335       |\n",
      "|    total_timesteps      | 2138112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005837375 |\n",
      "|    clip_fraction        | 0.0168      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.9       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.1        |\n",
      "|    n_updates            | 10430       |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    reward               | 0.0444176   |\n",
      "|    std                  | 4.57        |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1045        |\n",
      "|    time_elapsed         | 19353       |\n",
      "|    total_timesteps      | 2140160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010188028 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.4        |\n",
      "|    n_updates            | 10440       |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | 0.6931361   |\n",
      "|    std                  | 4.57        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1046        |\n",
      "|    time_elapsed         | 19372       |\n",
      "|    total_timesteps      | 2142208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022578489 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 10450       |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    reward               | -1.1728239  |\n",
      "|    std                  | 4.57        |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1047        |\n",
      "|    time_elapsed         | 19391       |\n",
      "|    total_timesteps      | 2144256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009694706 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.2        |\n",
      "|    n_updates            | 10460       |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    reward               | -3.2128463  |\n",
      "|    std                  | 4.58        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1048        |\n",
      "|    time_elapsed         | 19409       |\n",
      "|    total_timesteps      | 2146304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005048803 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.1       |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 10470       |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    reward               | -1.774284   |\n",
      "|    std                  | 4.58        |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1049        |\n",
      "|    time_elapsed         | 19428       |\n",
      "|    total_timesteps      | 2148352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015690615 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.1       |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 10480       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -2.1015828  |\n",
      "|    std                  | 4.6         |\n",
      "|    value_loss           | 70.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1050        |\n",
      "|    time_elapsed         | 19447       |\n",
      "|    total_timesteps      | 2150400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012629677 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 10490       |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    reward               | -0.90810275 |\n",
      "|    std                  | 4.6         |\n",
      "|    value_loss           | 96.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1051         |\n",
      "|    time_elapsed         | 19466        |\n",
      "|    total_timesteps      | 2152448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076301685 |\n",
      "|    clip_fraction        | 0.051        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.2        |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.2         |\n",
      "|    n_updates            | 10500        |\n",
      "|    policy_gradient_loss | -0.00861     |\n",
      "|    reward               | 0.6878901    |\n",
      "|    std                  | 4.6          |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1052        |\n",
      "|    time_elapsed         | 19485       |\n",
      "|    total_timesteps      | 2154496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012683668 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.7        |\n",
      "|    n_updates            | 10510       |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | -1.134349   |\n",
      "|    std                  | 4.61        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1053        |\n",
      "|    time_elapsed         | 19504       |\n",
      "|    total_timesteps      | 2156544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011690572 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | -0.0146     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 10520       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 0.9196026   |\n",
      "|    std                  | 4.62        |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1054        |\n",
      "|    time_elapsed         | 19523       |\n",
      "|    total_timesteps      | 2158592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00834607  |\n",
      "|    clip_fraction        | 0.0572      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.1        |\n",
      "|    n_updates            | 10530       |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    reward               | -0.34424677 |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1055        |\n",
      "|    time_elapsed         | 19542       |\n",
      "|    total_timesteps      | 2160640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009921169 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.6        |\n",
      "|    n_updates            | 10540       |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    reward               | 3.9554617   |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1056        |\n",
      "|    time_elapsed         | 19575       |\n",
      "|    total_timesteps      | 2162688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011997676 |\n",
      "|    clip_fraction        | 0.0943      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 10550       |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    reward               | -1.8028951  |\n",
      "|    std                  | 4.64        |\n",
      "|    value_loss           | 75.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1057         |\n",
      "|    time_elapsed         | 19594        |\n",
      "|    total_timesteps      | 2164736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071915914 |\n",
      "|    clip_fraction        | 0.0282       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.4        |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.6         |\n",
      "|    n_updates            | 10560        |\n",
      "|    policy_gradient_loss | -0.00711     |\n",
      "|    reward               | -0.09586012  |\n",
      "|    std                  | 4.64         |\n",
      "|    value_loss           | 139          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1058         |\n",
      "|    time_elapsed         | 19612        |\n",
      "|    total_timesteps      | 2166784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070460513 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.4        |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 154          |\n",
      "|    n_updates            | 10570        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | -41.998993   |\n",
      "|    std                  | 4.64         |\n",
      "|    value_loss           | 190          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4663257.33\n",
      "total_reward: 3663257.33\n",
      "total_cost: 190189.76\n",
      "total_trades: 58849\n",
      "Sharpe: 0.713\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1059        |\n",
      "|    time_elapsed         | 19631       |\n",
      "|    total_timesteps      | 2168832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012904443 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 10580       |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | -0.7646415  |\n",
      "|    std                  | 4.65        |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1060        |\n",
      "|    time_elapsed         | 19649       |\n",
      "|    total_timesteps      | 2170880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010044701 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.5       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 10590       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 1.3015534   |\n",
      "|    std                  | 4.66        |\n",
      "|    value_loss           | 46.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1061        |\n",
      "|    time_elapsed         | 19667       |\n",
      "|    total_timesteps      | 2172928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007365114 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.5       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.6        |\n",
      "|    n_updates            | 10600       |\n",
      "|    policy_gradient_loss | -0.00554    |\n",
      "|    reward               | 0.45525768  |\n",
      "|    std                  | 4.66        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1062        |\n",
      "|    time_elapsed         | 19686       |\n",
      "|    total_timesteps      | 2174976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008354163 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.4        |\n",
      "|    n_updates            | 10610       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | -4.515908   |\n",
      "|    std                  | 4.67        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1063        |\n",
      "|    time_elapsed         | 19704       |\n",
      "|    total_timesteps      | 2177024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011641206 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 10620       |\n",
      "|    policy_gradient_loss | -0.00719    |\n",
      "|    reward               | -3.8046439  |\n",
      "|    std                  | 4.67        |\n",
      "|    value_loss           | 40.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1064        |\n",
      "|    time_elapsed         | 19723       |\n",
      "|    total_timesteps      | 2179072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008883974 |\n",
      "|    clip_fraction        | 0.0416      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.2        |\n",
      "|    n_updates            | 10630       |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    reward               | -2.9116237  |\n",
      "|    std                  | 4.67        |\n",
      "|    value_loss           | 98.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1065        |\n",
      "|    time_elapsed         | 19741       |\n",
      "|    total_timesteps      | 2181120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008838014 |\n",
      "|    clip_fraction        | 0.0576      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.8        |\n",
      "|    n_updates            | 10640       |\n",
      "|    policy_gradient_loss | -0.00834    |\n",
      "|    reward               | -7.936912   |\n",
      "|    std                  | 4.68        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1066        |\n",
      "|    time_elapsed         | 19760       |\n",
      "|    total_timesteps      | 2183168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011185473 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 10650       |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    reward               | -4.6152563  |\n",
      "|    std                  | 4.68        |\n",
      "|    value_loss           | 79.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1067        |\n",
      "|    time_elapsed         | 19777       |\n",
      "|    total_timesteps      | 2185216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013740056 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.2        |\n",
      "|    n_updates            | 10660       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -1.2777026  |\n",
      "|    std                  | 4.69        |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1068        |\n",
      "|    time_elapsed         | 19796       |\n",
      "|    total_timesteps      | 2187264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004644992 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.7        |\n",
      "|    n_updates            | 10670       |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    reward               | -2.1276138  |\n",
      "|    std                  | 4.7         |\n",
      "|    value_loss           | 200         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1069        |\n",
      "|    time_elapsed         | 19815       |\n",
      "|    total_timesteps      | 2189312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00168598  |\n",
      "|    clip_fraction        | 0.0228      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.3        |\n",
      "|    n_updates            | 10680       |\n",
      "|    policy_gradient_loss | -0.000382   |\n",
      "|    reward               | -0.33601558 |\n",
      "|    std                  | 4.7         |\n",
      "|    value_loss           | 190         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1070        |\n",
      "|    time_elapsed         | 19834       |\n",
      "|    total_timesteps      | 2191360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012010895 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.0557      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 10690       |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    reward               | 0.92085737  |\n",
      "|    std                  | 4.7         |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1071         |\n",
      "|    time_elapsed         | 19853        |\n",
      "|    total_timesteps      | 2193408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018022319 |\n",
      "|    clip_fraction        | 0.004        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.8        |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.7         |\n",
      "|    n_updates            | 10700        |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    reward               | 0.3547239    |\n",
      "|    std                  | 4.7          |\n",
      "|    value_loss           | 195          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1072        |\n",
      "|    time_elapsed         | 19871       |\n",
      "|    total_timesteps      | 2195456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003097904 |\n",
      "|    clip_fraction        | 0.0064      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.2        |\n",
      "|    n_updates            | 10710       |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    reward               | 5.6199956   |\n",
      "|    std                  | 4.71        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5182052.20\n",
      "total_reward: 4182052.20\n",
      "total_cost: 178468.16\n",
      "total_trades: 58851\n",
      "Sharpe: 0.767\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1073        |\n",
      "|    time_elapsed         | 19890       |\n",
      "|    total_timesteps      | 2197504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010897715 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 10720       |\n",
      "|    policy_gradient_loss | -0.00919    |\n",
      "|    reward               | 2.976589    |\n",
      "|    std                  | 4.71        |\n",
      "|    value_loss           | 87.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1074        |\n",
      "|    time_elapsed         | 19909       |\n",
      "|    total_timesteps      | 2199552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010782698 |\n",
      "|    clip_fraction        | 0.0697      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.9       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.7        |\n",
      "|    n_updates            | 10730       |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    reward               | 2.4007106   |\n",
      "|    std                  | 4.72        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1075         |\n",
      "|    time_elapsed         | 19928        |\n",
      "|    total_timesteps      | 2201600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009629035 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.9        |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77           |\n",
      "|    n_updates            | 10740        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | 0.16705889   |\n",
      "|    std                  | 4.72         |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1076         |\n",
      "|    time_elapsed         | 19947        |\n",
      "|    total_timesteps      | 2203648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034305793 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.9        |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.4         |\n",
      "|    n_updates            | 10750        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | -1.5576708   |\n",
      "|    std                  | 4.72         |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1077        |\n",
      "|    time_elapsed         | 19966       |\n",
      "|    total_timesteps      | 2205696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009797616 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86         |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 10760       |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    reward               | -1.8528779  |\n",
      "|    std                  | 4.73        |\n",
      "|    value_loss           | 35.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1078         |\n",
      "|    time_elapsed         | 19985        |\n",
      "|    total_timesteps      | 2207744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033696624 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86          |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59           |\n",
      "|    n_updates            | 10770        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 0.030151268  |\n",
      "|    std                  | 4.73         |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1079         |\n",
      "|    time_elapsed         | 20003        |\n",
      "|    total_timesteps      | 2209792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034356567 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86          |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65           |\n",
      "|    n_updates            | 10780        |\n",
      "|    policy_gradient_loss | -0.00479     |\n",
      "|    reward               | -1.1423484   |\n",
      "|    std                  | 4.73         |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1080        |\n",
      "|    time_elapsed         | 20022       |\n",
      "|    total_timesteps      | 2211840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009948045 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86         |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 10790       |\n",
      "|    policy_gradient_loss | -0.00253    |\n",
      "|    reward               | 0.10907375  |\n",
      "|    std                  | 4.74        |\n",
      "|    value_loss           | 43          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1081         |\n",
      "|    time_elapsed         | 20040        |\n",
      "|    total_timesteps      | 2213888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036929543 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86          |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.4         |\n",
      "|    n_updates            | 10800        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    reward               | -2.20855     |\n",
      "|    std                  | 4.74         |\n",
      "|    value_loss           | 96.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1082        |\n",
      "|    time_elapsed         | 20058       |\n",
      "|    total_timesteps      | 2215936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004067159 |\n",
      "|    clip_fraction        | 0.00679     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.1       |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.4        |\n",
      "|    n_updates            | 10810       |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    reward               | 4.3314257   |\n",
      "|    std                  | 4.75        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1083         |\n",
      "|    time_elapsed         | 20076        |\n",
      "|    total_timesteps      | 2217984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059725903 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.1        |\n",
      "|    explained_variance   | 0.805        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.2         |\n",
      "|    n_updates            | 10820        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | -0.19880147  |\n",
      "|    std                  | 4.75         |\n",
      "|    value_loss           | 92.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1084        |\n",
      "|    time_elapsed         | 20094       |\n",
      "|    total_timesteps      | 2220032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014947588 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.1       |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 10830       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 0.15635577  |\n",
      "|    std                  | 4.76        |\n",
      "|    value_loss           | 81.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1085       |\n",
      "|    time_elapsed         | 20113      |\n",
      "|    total_timesteps      | 2222080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0072183  |\n",
      "|    clip_fraction        | 0.0342     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.2      |\n",
      "|    explained_variance   | 0.608      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 53.8       |\n",
      "|    n_updates            | 10840      |\n",
      "|    policy_gradient_loss | -0.00477   |\n",
      "|    reward               | 0.67661035 |\n",
      "|    std                  | 4.77       |\n",
      "|    value_loss           | 124        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1086        |\n",
      "|    time_elapsed         | 20131       |\n",
      "|    total_timesteps      | 2224128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003673246 |\n",
      "|    clip_fraction        | 0.00967     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.2       |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.2        |\n",
      "|    n_updates            | 10850       |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    reward               | -7.6496396  |\n",
      "|    std                  | 4.77        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4146778.41\n",
      "total_reward: 3146778.41\n",
      "total_cost: 194910.38\n",
      "total_trades: 59667\n",
      "Sharpe: 0.664\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1087        |\n",
      "|    time_elapsed         | 20149       |\n",
      "|    total_timesteps      | 2226176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017469406 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.2       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 10860       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -0.60930276 |\n",
      "|    std                  | 4.78        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1088         |\n",
      "|    time_elapsed         | 20168        |\n",
      "|    total_timesteps      | 2228224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051436685 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.3        |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.1         |\n",
      "|    n_updates            | 10870        |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    reward               | -2.8510785   |\n",
      "|    std                  | 4.79         |\n",
      "|    value_loss           | 95.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1089        |\n",
      "|    time_elapsed         | 20186       |\n",
      "|    total_timesteps      | 2230272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007675159 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.4       |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.3        |\n",
      "|    n_updates            | 10880       |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    reward               | -9.763377   |\n",
      "|    std                  | 4.8         |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1090        |\n",
      "|    time_elapsed         | 20205       |\n",
      "|    total_timesteps      | 2232320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012870676 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.4       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.5        |\n",
      "|    n_updates            | 10890       |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    reward               | -2.0814908  |\n",
      "|    std                  | 4.81        |\n",
      "|    value_loss           | 77.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1091        |\n",
      "|    time_elapsed         | 20225       |\n",
      "|    total_timesteps      | 2234368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011229462 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.5       |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 10900       |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    reward               | 1.0883726   |\n",
      "|    std                  | 4.82        |\n",
      "|    value_loss           | 84          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1092        |\n",
      "|    time_elapsed         | 20243       |\n",
      "|    total_timesteps      | 2236416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008179918 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.5       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 10910       |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    reward               | -0.71323216 |\n",
      "|    std                  | 4.82        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1093         |\n",
      "|    time_elapsed         | 20262        |\n",
      "|    total_timesteps      | 2238464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072458605 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.5        |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.4         |\n",
      "|    n_updates            | 10920        |\n",
      "|    policy_gradient_loss | -0.00469     |\n",
      "|    reward               | -1.2798842   |\n",
      "|    std                  | 4.82         |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1094       |\n",
      "|    time_elapsed         | 20282      |\n",
      "|    total_timesteps      | 2240512    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01377433 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.5      |\n",
      "|    explained_variance   | -0.337     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.6       |\n",
      "|    n_updates            | 10930      |\n",
      "|    policy_gradient_loss | -0.00692   |\n",
      "|    reward               | 2.8640232  |\n",
      "|    std                  | 4.83       |\n",
      "|    value_loss           | 30.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1095        |\n",
      "|    time_elapsed         | 20301       |\n",
      "|    total_timesteps      | 2242560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009568581 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.6       |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.3        |\n",
      "|    n_updates            | 10940       |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    reward               | -0.0533465  |\n",
      "|    std                  | 4.84        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1096        |\n",
      "|    time_elapsed         | 20320       |\n",
      "|    total_timesteps      | 2244608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007394962 |\n",
      "|    clip_fraction        | 0.0369      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.4        |\n",
      "|    n_updates            | 10950       |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    reward               | -2.3377235  |\n",
      "|    std                  | 4.85        |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1097        |\n",
      "|    time_elapsed         | 20338       |\n",
      "|    total_timesteps      | 2246656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009082946 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 10960       |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    reward               | -2.150331   |\n",
      "|    std                  | 4.85        |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1098        |\n",
      "|    time_elapsed         | 20356       |\n",
      "|    total_timesteps      | 2248704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010036384 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 10970       |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    reward               | -0.94356257 |\n",
      "|    std                  | 4.86        |\n",
      "|    value_loss           | 87.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1099        |\n",
      "|    time_elapsed         | 20374       |\n",
      "|    total_timesteps      | 2250752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010473974 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.8       |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.8        |\n",
      "|    n_updates            | 10980       |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | 12.426871   |\n",
      "|    std                  | 4.87        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1100        |\n",
      "|    time_elapsed         | 20392       |\n",
      "|    total_timesteps      | 2252800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007189735 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.8       |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.1        |\n",
      "|    n_updates            | 10990       |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    reward               | 1.2253456   |\n",
      "|    std                  | 4.87        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4335332.99\n",
      "total_reward: 3335332.99\n",
      "total_cost: 216762.56\n",
      "total_trades: 60737\n",
      "Sharpe: 0.679\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1101       |\n",
      "|    time_elapsed         | 20411      |\n",
      "|    total_timesteps      | 2254848    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02008747 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.9      |\n",
      "|    explained_variance   | 0.033      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.3       |\n",
      "|    n_updates            | 11000      |\n",
      "|    policy_gradient_loss | -0.00915   |\n",
      "|    reward               | 6.993344   |\n",
      "|    std                  | 4.89       |\n",
      "|    value_loss           | 41.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1102        |\n",
      "|    time_elapsed         | 20429       |\n",
      "|    total_timesteps      | 2256896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015262694 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.9        |\n",
      "|    n_updates            | 11010       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | 0.57148445  |\n",
      "|    std                  | 4.89        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1103        |\n",
      "|    time_elapsed         | 20448       |\n",
      "|    total_timesteps      | 2258944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009357974 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87         |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.8        |\n",
      "|    n_updates            | 11020       |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    reward               | 2.3927372   |\n",
      "|    std                  | 4.9         |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1104        |\n",
      "|    time_elapsed         | 20467       |\n",
      "|    total_timesteps      | 2260992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011683404 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87         |\n",
      "|    explained_variance   | 0.0533      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 11030       |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    reward               | 3.4074516   |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1105        |\n",
      "|    time_elapsed         | 20485       |\n",
      "|    total_timesteps      | 2263040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012211682 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.5        |\n",
      "|    n_updates            | 11040       |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    reward               | -4.4024115  |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1106         |\n",
      "|    time_elapsed         | 20504        |\n",
      "|    total_timesteps      | 2265088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021756715 |\n",
      "|    clip_fraction        | 0.00688      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.1        |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.3         |\n",
      "|    n_updates            | 11050        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    reward               | 0.06220006   |\n",
      "|    std                  | 4.92         |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1107        |\n",
      "|    time_elapsed         | 20522       |\n",
      "|    total_timesteps      | 2267136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007730373 |\n",
      "|    clip_fraction        | 0.0689      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.5        |\n",
      "|    n_updates            | 11060       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    reward               | 2.1047494   |\n",
      "|    std                  | 4.92        |\n",
      "|    value_loss           | 76.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1108       |\n",
      "|    time_elapsed         | 20540      |\n",
      "|    total_timesteps      | 2269184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01183605 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.1      |\n",
      "|    explained_variance   | 0.613      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.2       |\n",
      "|    n_updates            | 11070      |\n",
      "|    policy_gradient_loss | -0.00843   |\n",
      "|    reward               | 1.3268853  |\n",
      "|    std                  | 4.93       |\n",
      "|    value_loss           | 57.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1109         |\n",
      "|    time_elapsed         | 20559        |\n",
      "|    total_timesteps      | 2271232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079438845 |\n",
      "|    clip_fraction        | 0.0639       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.2        |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.4         |\n",
      "|    n_updates            | 11080        |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    reward               | 0.61762923   |\n",
      "|    std                  | 4.94         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1110          |\n",
      "|    time_elapsed         | 20577         |\n",
      "|    total_timesteps      | 2273280       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039251865 |\n",
      "|    clip_fraction        | 0.000977      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -87.2         |\n",
      "|    explained_variance   | 0.68          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 111           |\n",
      "|    n_updates            | 11090         |\n",
      "|    policy_gradient_loss | -0.00153      |\n",
      "|    reward               | 1.7680532     |\n",
      "|    std                  | 4.94          |\n",
      "|    value_loss           | 186           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1111        |\n",
      "|    time_elapsed         | 20596       |\n",
      "|    total_timesteps      | 2275328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015113102 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.2       |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 11100       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -2.3894877  |\n",
      "|    std                  | 4.94        |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1112        |\n",
      "|    time_elapsed         | 20614       |\n",
      "|    total_timesteps      | 2277376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008570657 |\n",
      "|    clip_fraction        | 0.0583      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.3       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 11110       |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    reward               | 1.1557183   |\n",
      "|    std                  | 4.94        |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1113        |\n",
      "|    time_elapsed         | 20633       |\n",
      "|    total_timesteps      | 2279424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009424593 |\n",
      "|    clip_fraction        | 0.0478      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.3       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 11120       |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    reward               | 3.0337732   |\n",
      "|    std                  | 4.94        |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1114        |\n",
      "|    time_elapsed         | 20651       |\n",
      "|    total_timesteps      | 2281472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009648262 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.3       |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 11130       |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    reward               | -0.51148885 |\n",
      "|    std                  | 4.95        |\n",
      "|    value_loss           | 88.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5502833.12\n",
      "total_reward: 4502833.12\n",
      "total_cost: 187232.97\n",
      "total_trades: 59206\n",
      "Sharpe: 0.782\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1115        |\n",
      "|    time_elapsed         | 20670       |\n",
      "|    total_timesteps      | 2283520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010363482 |\n",
      "|    clip_fraction        | 0.0937      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.3       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39          |\n",
      "|    n_updates            | 11140       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -1.6151047  |\n",
      "|    std                  | 4.96        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1116         |\n",
      "|    time_elapsed         | 20688        |\n",
      "|    total_timesteps      | 2285568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068950136 |\n",
      "|    clip_fraction        | 0.037        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.4        |\n",
      "|    explained_variance   | 0.274        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 196          |\n",
      "|    n_updates            | 11150        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | 1.6614658    |\n",
      "|    std                  | 4.97         |\n",
      "|    value_loss           | 216          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1117        |\n",
      "|    time_elapsed         | 20706       |\n",
      "|    total_timesteps      | 2287616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004295646 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.4       |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 163         |\n",
      "|    n_updates            | 11160       |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    reward               | 1.6138034   |\n",
      "|    std                  | 4.96        |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1118        |\n",
      "|    time_elapsed         | 20724       |\n",
      "|    total_timesteps      | 2289664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015758567 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.5       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 11170       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 0.23072109  |\n",
      "|    std                  | 4.99        |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1119        |\n",
      "|    time_elapsed         | 20742       |\n",
      "|    total_timesteps      | 2291712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003087031 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.8        |\n",
      "|    n_updates            | 11180       |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    reward               | 1.1067797   |\n",
      "|    std                  | 5           |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1120        |\n",
      "|    time_elapsed         | 20760       |\n",
      "|    total_timesteps      | 2293760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005292961 |\n",
      "|    clip_fraction        | 0.025       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.2        |\n",
      "|    n_updates            | 11190       |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    reward               | 1.8400881   |\n",
      "|    std                  | 5           |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1121        |\n",
      "|    time_elapsed         | 20778       |\n",
      "|    total_timesteps      | 2295808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010063635 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.5        |\n",
      "|    n_updates            | 11200       |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    reward               | 0.12811525  |\n",
      "|    std                  | 5.01        |\n",
      "|    value_loss           | 73.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1122        |\n",
      "|    time_elapsed         | 20797       |\n",
      "|    total_timesteps      | 2297856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011492923 |\n",
      "|    clip_fraction        | 0.0698      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.5        |\n",
      "|    n_updates            | 11210       |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    reward               | -1.4072073  |\n",
      "|    std                  | 5.01        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1123         |\n",
      "|    time_elapsed         | 20815        |\n",
      "|    total_timesteps      | 2299904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027647829 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.7        |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.4         |\n",
      "|    n_updates            | 11220        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | 36.07087     |\n",
      "|    std                  | 5.01         |\n",
      "|    value_loss           | 155          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1124        |\n",
      "|    time_elapsed         | 20833       |\n",
      "|    total_timesteps      | 2301952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005804111 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.7       |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.2        |\n",
      "|    n_updates            | 11230       |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | 5.3298664   |\n",
      "|    std                  | 5.02        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1125       |\n",
      "|    time_elapsed         | 20852      |\n",
      "|    total_timesteps      | 2304000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01762776 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.7      |\n",
      "|    explained_variance   | 0.381      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21         |\n",
      "|    n_updates            | 11240      |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    reward               | 1.6265904  |\n",
      "|    std                  | 5.03       |\n",
      "|    value_loss           | 39.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1126        |\n",
      "|    time_elapsed         | 20870       |\n",
      "|    total_timesteps      | 2306048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005766266 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.8       |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.8        |\n",
      "|    n_updates            | 11250       |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | 1.3484683   |\n",
      "|    std                  | 5.03        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1127          |\n",
      "|    time_elapsed         | 20888         |\n",
      "|    total_timesteps      | 2308096       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008071117   |\n",
      "|    clip_fraction        | 0.0566        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -87.8         |\n",
      "|    explained_variance   | 0.711         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 65.8          |\n",
      "|    n_updates            | 11260         |\n",
      "|    policy_gradient_loss | -0.00535      |\n",
      "|    reward               | -0.0030587662 |\n",
      "|    std                  | 5.03          |\n",
      "|    value_loss           | 155           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1128        |\n",
      "|    time_elapsed         | 20905       |\n",
      "|    total_timesteps      | 2310144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012155065 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.8       |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 11270       |\n",
      "|    policy_gradient_loss | -0.00818    |\n",
      "|    reward               | 5.294559    |\n",
      "|    std                  | 5.05        |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4580681.88\n",
      "total_reward: 3580681.88\n",
      "total_cost: 176051.60\n",
      "total_trades: 59166\n",
      "Sharpe: 0.699\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1129         |\n",
      "|    time_elapsed         | 20923        |\n",
      "|    total_timesteps      | 2312192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031771206 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.9        |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.7         |\n",
      "|    n_updates            | 11280        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | -4.8878713   |\n",
      "|    std                  | 5.05         |\n",
      "|    value_loss           | 137          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1130         |\n",
      "|    time_elapsed         | 20941        |\n",
      "|    total_timesteps      | 2314240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010285714 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.9        |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 11290        |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    reward               | -1.0554519   |\n",
      "|    std                  | 5.05         |\n",
      "|    value_loss           | 207          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1131        |\n",
      "|    time_elapsed         | 20960       |\n",
      "|    total_timesteps      | 2316288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010132353 |\n",
      "|    clip_fraction        | 0.0782      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.9       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 11300       |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    reward               | -4.2027617  |\n",
      "|    std                  | 5.06        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1132        |\n",
      "|    time_elapsed         | 20978       |\n",
      "|    total_timesteps      | 2318336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011115677 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.9       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 11310       |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    reward               | 0.6083187   |\n",
      "|    std                  | 5.06        |\n",
      "|    value_loss           | 81.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1133         |\n",
      "|    time_elapsed         | 20997        |\n",
      "|    total_timesteps      | 2320384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068991575 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88          |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76           |\n",
      "|    n_updates            | 11320        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 0.5651302    |\n",
      "|    std                  | 5.06         |\n",
      "|    value_loss           | 138          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1134         |\n",
      "|    time_elapsed         | 21016        |\n",
      "|    total_timesteps      | 2322432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036619299 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88          |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.6         |\n",
      "|    n_updates            | 11330        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    reward               | -2.2232692   |\n",
      "|    std                  | 5.06         |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1135        |\n",
      "|    time_elapsed         | 21034       |\n",
      "|    total_timesteps      | 2324480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015369261 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 11340       |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    reward               | -3.6534922  |\n",
      "|    std                  | 5.08        |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1136        |\n",
      "|    time_elapsed         | 21052       |\n",
      "|    total_timesteps      | 2326528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005702353 |\n",
      "|    clip_fraction        | 0.0471      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.2        |\n",
      "|    n_updates            | 11350       |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    reward               | 2.1549792   |\n",
      "|    std                  | 5.08        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1137         |\n",
      "|    time_elapsed         | 21070        |\n",
      "|    total_timesteps      | 2328576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006294612  |\n",
      "|    clip_fraction        | 0.0321       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.1        |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 118          |\n",
      "|    n_updates            | 11360        |\n",
      "|    policy_gradient_loss | -0.00709     |\n",
      "|    reward               | 0.0070979944 |\n",
      "|    std                  | 5.08         |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1138        |\n",
      "|    time_elapsed         | 21089       |\n",
      "|    total_timesteps      | 2330624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008262137 |\n",
      "|    clip_fraction        | 0.0555      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.6        |\n",
      "|    n_updates            | 11370       |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | 3.1785986   |\n",
      "|    std                  | 5.09        |\n",
      "|    value_loss           | 71.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1139        |\n",
      "|    time_elapsed         | 21107       |\n",
      "|    total_timesteps      | 2332672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012816248 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 11380       |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | 2.0295434   |\n",
      "|    std                  | 5.1         |\n",
      "|    value_loss           | 93.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1140        |\n",
      "|    time_elapsed         | 21125       |\n",
      "|    total_timesteps      | 2334720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009073034 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.1        |\n",
      "|    n_updates            | 11390       |\n",
      "|    policy_gradient_loss | -0.00958    |\n",
      "|    reward               | -0.9044494  |\n",
      "|    std                  | 5.1         |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1141        |\n",
      "|    time_elapsed         | 21143       |\n",
      "|    total_timesteps      | 2336768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011436518 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.8        |\n",
      "|    n_updates            | 11400       |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    reward               | 1.4535915   |\n",
      "|    std                  | 5.11        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1142        |\n",
      "|    time_elapsed         | 21161       |\n",
      "|    total_timesteps      | 2338816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012946361 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.3       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 11410       |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    reward               | -3.5585618  |\n",
      "|    std                  | 5.13        |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5055716.44\n",
      "total_reward: 4055716.44\n",
      "total_cost: 202179.86\n",
      "total_trades: 59858\n",
      "Sharpe: 0.739\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1143         |\n",
      "|    time_elapsed         | 21179        |\n",
      "|    total_timesteps      | 2340864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060309153 |\n",
      "|    clip_fraction        | 0.0464       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.3        |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.4         |\n",
      "|    n_updates            | 11420        |\n",
      "|    policy_gradient_loss | -0.00503     |\n",
      "|    reward               | -0.6983183   |\n",
      "|    std                  | 5.13         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1144        |\n",
      "|    time_elapsed         | 21198       |\n",
      "|    total_timesteps      | 2342912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007728703 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.4       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.3        |\n",
      "|    n_updates            | 11430       |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    reward               | 6.73719     |\n",
      "|    std                  | 5.14        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1145        |\n",
      "|    time_elapsed         | 21217       |\n",
      "|    total_timesteps      | 2344960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010430837 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.4       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 11440       |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    reward               | -2.208775   |\n",
      "|    std                  | 5.15        |\n",
      "|    value_loss           | 61.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1146        |\n",
      "|    time_elapsed         | 21237       |\n",
      "|    total_timesteps      | 2347008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014430344 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 11450       |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    reward               | 0.007991828 |\n",
      "|    std                  | 5.16        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1147        |\n",
      "|    time_elapsed         | 21255       |\n",
      "|    total_timesteps      | 2349056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004573481 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 11460       |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | 28.807865   |\n",
      "|    std                  | 5.16        |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1148        |\n",
      "|    time_elapsed         | 21273       |\n",
      "|    total_timesteps      | 2351104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007826671 |\n",
      "|    clip_fraction        | 0.0336      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93          |\n",
      "|    n_updates            | 11470       |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | 3.344436    |\n",
      "|    std                  | 5.17        |\n",
      "|    value_loss           | 227         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1149        |\n",
      "|    time_elapsed         | 21292       |\n",
      "|    total_timesteps      | 2353152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014055077 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.6       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 11480       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 1.1997424   |\n",
      "|    std                  | 5.19        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1150        |\n",
      "|    time_elapsed         | 21311       |\n",
      "|    total_timesteps      | 2355200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012908827 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.7       |\n",
      "|    explained_variance   | 0.0642      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.8        |\n",
      "|    n_updates            | 11490       |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    reward               | 0.7202918   |\n",
      "|    std                  | 5.19        |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1151         |\n",
      "|    time_elapsed         | 21329        |\n",
      "|    total_timesteps      | 2357248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103543345 |\n",
      "|    clip_fraction        | 0.076        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.7        |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.4         |\n",
      "|    n_updates            | 11500        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    reward               | -6.4834137   |\n",
      "|    std                  | 5.2          |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1152        |\n",
      "|    time_elapsed         | 21348       |\n",
      "|    total_timesteps      | 2359296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015493672 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.7       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 11510       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 9.656091    |\n",
      "|    std                  | 5.21        |\n",
      "|    value_loss           | 57.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1153        |\n",
      "|    time_elapsed         | 21366       |\n",
      "|    total_timesteps      | 2361344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009370692 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 11520       |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    reward               | -9.243664   |\n",
      "|    std                  | 5.21        |\n",
      "|    value_loss           | 220         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1154        |\n",
      "|    time_elapsed         | 21384       |\n",
      "|    total_timesteps      | 2363392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008195465 |\n",
      "|    clip_fraction        | 0.0407      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 11530       |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | -16.010286  |\n",
      "|    std                  | 5.21        |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1155         |\n",
      "|    time_elapsed         | 21402        |\n",
      "|    total_timesteps      | 2365440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089075565 |\n",
      "|    clip_fraction        | 0.0376       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.8        |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.9         |\n",
      "|    n_updates            | 11540        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    reward               | -0.7368937   |\n",
      "|    std                  | 5.22         |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1156        |\n",
      "|    time_elapsed         | 21421       |\n",
      "|    total_timesteps      | 2367488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009876224 |\n",
      "|    clip_fraction        | 0.07        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.9       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38          |\n",
      "|    n_updates            | 11550       |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    reward               | 0.18166368  |\n",
      "|    std                  | 5.23        |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5583977.20\n",
      "total_reward: 4583977.20\n",
      "total_cost: 174542.92\n",
      "total_trades: 57413\n",
      "Sharpe: 0.789\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1157        |\n",
      "|    time_elapsed         | 21440       |\n",
      "|    total_timesteps      | 2369536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005128133 |\n",
      "|    clip_fraction        | 0.0302      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.9       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 11560       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | 1.21625     |\n",
      "|    std                  | 5.23        |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1158         |\n",
      "|    time_elapsed         | 21459        |\n",
      "|    total_timesteps      | 2371584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034832503 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.9        |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.5         |\n",
      "|    n_updates            | 11570        |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    reward               | 1.3452071    |\n",
      "|    std                  | 5.24         |\n",
      "|    value_loss           | 211          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1159        |\n",
      "|    time_elapsed         | 21477       |\n",
      "|    total_timesteps      | 2373632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018906862 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89         |\n",
      "|    explained_variance   | -0.162      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 11580       |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    reward               | 1.0704997   |\n",
      "|    std                  | 5.25        |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1160         |\n",
      "|    time_elapsed         | 21496        |\n",
      "|    total_timesteps      | 2375680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041288203 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89          |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.9         |\n",
      "|    n_updates            | 11590        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | 0.13195935   |\n",
      "|    std                  | 5.25         |\n",
      "|    value_loss           | 173          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1161         |\n",
      "|    time_elapsed         | 21516        |\n",
      "|    total_timesteps      | 2377728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029277215 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89          |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.2         |\n",
      "|    n_updates            | 11600        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | 4.2751713    |\n",
      "|    std                  | 5.25         |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1162        |\n",
      "|    time_elapsed         | 21534       |\n",
      "|    total_timesteps      | 2379776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011203855 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.7        |\n",
      "|    n_updates            | 11610       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 5.9521885   |\n",
      "|    std                  | 5.27        |\n",
      "|    value_loss           | 78.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1163        |\n",
      "|    time_elapsed         | 21552       |\n",
      "|    total_timesteps      | 2381824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009047916 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.4        |\n",
      "|    n_updates            | 11620       |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    reward               | 0.9297874   |\n",
      "|    std                  | 5.28        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1164         |\n",
      "|    time_elapsed         | 21571        |\n",
      "|    total_timesteps      | 2383872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004196697  |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.2        |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 122          |\n",
      "|    n_updates            | 11630        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | -0.099798165 |\n",
      "|    std                  | 5.29         |\n",
      "|    value_loss           | 169          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1165        |\n",
      "|    time_elapsed         | 21590       |\n",
      "|    total_timesteps      | 2385920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002753971 |\n",
      "|    clip_fraction        | 0.00225     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 11640       |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    reward               | 3.4084883   |\n",
      "|    std                  | 5.29        |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1166        |\n",
      "|    time_elapsed         | 21609       |\n",
      "|    total_timesteps      | 2387968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014003697 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.3       |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 11650       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -0.24778096 |\n",
      "|    std                  | 5.3         |\n",
      "|    value_loss           | 31.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1167        |\n",
      "|    time_elapsed         | 21628       |\n",
      "|    total_timesteps      | 2390016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008248058 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.3       |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39          |\n",
      "|    n_updates            | 11660       |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    reward               | -0.62830454 |\n",
      "|    std                  | 5.31        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1168        |\n",
      "|    time_elapsed         | 21646       |\n",
      "|    total_timesteps      | 2392064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007275111 |\n",
      "|    clip_fraction        | 0.0492      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98.1        |\n",
      "|    n_updates            | 11670       |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    reward               | 3.1006422   |\n",
      "|    std                  | 5.32        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1169        |\n",
      "|    time_elapsed         | 21665       |\n",
      "|    total_timesteps      | 2394112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017144041 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 11680       |\n",
      "|    policy_gradient_loss | -0.00648    |\n",
      "|    reward               | 6.6786313   |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 61.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1170         |\n",
      "|    time_elapsed         | 21684        |\n",
      "|    total_timesteps      | 2396160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0125868535 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.5        |\n",
      "|    explained_variance   | 0.197        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.7         |\n",
      "|    n_updates            | 11690        |\n",
      "|    policy_gradient_loss | -0.00761     |\n",
      "|    reward               | 3.6596553    |\n",
      "|    std                  | 5.35         |\n",
      "|    value_loss           | 169          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1171        |\n",
      "|    time_elapsed         | 21703       |\n",
      "|    total_timesteps      | 2398208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008575849 |\n",
      "|    clip_fraction        | 0.0417      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.8        |\n",
      "|    n_updates            | 11700       |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | -27.505417  |\n",
      "|    std                  | 5.36        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6424166.53\n",
      "total_reward: 5424166.53\n",
      "total_cost: 161423.85\n",
      "total_trades: 56668\n",
      "Sharpe: 0.852\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1172        |\n",
      "|    time_elapsed         | 21722       |\n",
      "|    total_timesteps      | 2400256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004119858 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.8        |\n",
      "|    n_updates            | 11710       |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    reward               | 1.9100486   |\n",
      "|    std                  | 5.36        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1173        |\n",
      "|    time_elapsed         | 21740       |\n",
      "|    total_timesteps      | 2402304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009211639 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 11720       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 3.7049255   |\n",
      "|    std                  | 5.36        |\n",
      "|    value_loss           | 65.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1174         |\n",
      "|    time_elapsed         | 21758        |\n",
      "|    total_timesteps      | 2404352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029507454 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.6        |\n",
      "|    explained_variance   | 0.399        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.5         |\n",
      "|    n_updates            | 11730        |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    reward               | -1.2835393   |\n",
      "|    std                  | 5.36         |\n",
      "|    value_loss           | 244          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1175         |\n",
      "|    time_elapsed         | 21776        |\n",
      "|    total_timesteps      | 2406400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047540097 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.6        |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 97.4         |\n",
      "|    n_updates            | 11740        |\n",
      "|    policy_gradient_loss | -0.00709     |\n",
      "|    reward               | -6.571088    |\n",
      "|    std                  | 5.36         |\n",
      "|    value_loss           | 165          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1176        |\n",
      "|    time_elapsed         | 21794       |\n",
      "|    total_timesteps      | 2408448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012621466 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.7       |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 11750       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 0.1675112   |\n",
      "|    std                  | 5.38        |\n",
      "|    value_loss           | 47.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1177         |\n",
      "|    time_elapsed         | 21813        |\n",
      "|    total_timesteps      | 2410496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055811275 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.7        |\n",
      "|    explained_variance   | 0.302        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.4         |\n",
      "|    n_updates            | 11760        |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    reward               | 1.2153141    |\n",
      "|    std                  | 5.39         |\n",
      "|    value_loss           | 159          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1178         |\n",
      "|    time_elapsed         | 21830        |\n",
      "|    total_timesteps      | 2412544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021190753 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.8        |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 11770        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | -6.0459533   |\n",
      "|    std                  | 5.39         |\n",
      "|    value_loss           | 183          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1179        |\n",
      "|    time_elapsed         | 21849       |\n",
      "|    total_timesteps      | 2414592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011097979 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.8       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.8        |\n",
      "|    n_updates            | 11780       |\n",
      "|    policy_gradient_loss | -0.00554    |\n",
      "|    reward               | 3.6333644   |\n",
      "|    std                  | 5.4         |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1180        |\n",
      "|    time_elapsed         | 21867       |\n",
      "|    total_timesteps      | 2416640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012238046 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.9       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 11790       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.21715583 |\n",
      "|    std                  | 5.41        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1181         |\n",
      "|    time_elapsed         | 21886        |\n",
      "|    total_timesteps      | 2418688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024488044 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.9        |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.5         |\n",
      "|    n_updates            | 11800        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | 0.111829326  |\n",
      "|    std                  | 5.42         |\n",
      "|    value_loss           | 173          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1182        |\n",
      "|    time_elapsed         | 21904       |\n",
      "|    total_timesteps      | 2420736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007274544 |\n",
      "|    clip_fraction        | 0.0342      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.9       |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.8        |\n",
      "|    n_updates            | 11810       |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    reward               | -1.1710533  |\n",
      "|    std                  | 5.42        |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1183        |\n",
      "|    time_elapsed         | 21923       |\n",
      "|    total_timesteps      | 2422784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010486878 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90         |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 11820       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -3.274753   |\n",
      "|    std                  | 5.45        |\n",
      "|    value_loss           | 31.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1184         |\n",
      "|    time_elapsed         | 21942        |\n",
      "|    total_timesteps      | 2424832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069654128 |\n",
      "|    clip_fraction        | 0.0554       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.1        |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 98.3         |\n",
      "|    n_updates            | 11830        |\n",
      "|    policy_gradient_loss | -0.00694     |\n",
      "|    reward               | -0.5979318   |\n",
      "|    std                  | 5.45         |\n",
      "|    value_loss           | 149          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1185        |\n",
      "|    time_elapsed         | 21961       |\n",
      "|    total_timesteps      | 2426880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003250868 |\n",
      "|    clip_fraction        | 0.00737     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.1       |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 11840       |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    reward               | -2.6720693  |\n",
      "|    std                  | 5.46        |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6059837.22\n",
      "total_reward: 5059837.22\n",
      "total_cost: 154962.65\n",
      "total_trades: 56828\n",
      "Sharpe: 0.830\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1186        |\n",
      "|    time_elapsed         | 21979       |\n",
      "|    total_timesteps      | 2428928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015556743 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 11850       |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    reward               | -0.356138   |\n",
      "|    std                  | 5.46        |\n",
      "|    value_loss           | 79.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1187        |\n",
      "|    time_elapsed         | 21998       |\n",
      "|    total_timesteps      | 2430976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011853614 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.4        |\n",
      "|    n_updates            | 11860       |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    reward               | -1.7744272  |\n",
      "|    std                  | 5.48        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1188        |\n",
      "|    time_elapsed         | 22016       |\n",
      "|    total_timesteps      | 2433024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005985208 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.3       |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.6        |\n",
      "|    n_updates            | 11870       |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | -1.0064564  |\n",
      "|    std                  | 5.49        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1189        |\n",
      "|    time_elapsed         | 22035       |\n",
      "|    total_timesteps      | 2435072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011120843 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.3       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.8        |\n",
      "|    n_updates            | 11880       |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    reward               | -1.2742614  |\n",
      "|    std                  | 5.49        |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1190        |\n",
      "|    time_elapsed         | 22053       |\n",
      "|    total_timesteps      | 2437120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013314804 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 11890       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -0.1957837  |\n",
      "|    std                  | 5.53        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1191         |\n",
      "|    time_elapsed         | 22071        |\n",
      "|    total_timesteps      | 2439168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073111146 |\n",
      "|    clip_fraction        | 0.0538       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.5        |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.1         |\n",
      "|    n_updates            | 11900        |\n",
      "|    policy_gradient_loss | -0.00721     |\n",
      "|    reward               | -2.50371     |\n",
      "|    std                  | 5.53         |\n",
      "|    value_loss           | 199          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1192        |\n",
      "|    time_elapsed         | 22089       |\n",
      "|    total_timesteps      | 2441216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008004971 |\n",
      "|    clip_fraction        | 0.0544      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.5       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.8        |\n",
      "|    n_updates            | 11910       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | -2.9308064  |\n",
      "|    std                  | 5.54        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1193       |\n",
      "|    time_elapsed         | 22108      |\n",
      "|    total_timesteps      | 2443264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01144223 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -90.6      |\n",
      "|    explained_variance   | 0.262      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.6       |\n",
      "|    n_updates            | 11920      |\n",
      "|    policy_gradient_loss | -0.00739   |\n",
      "|    reward               | 1.060628   |\n",
      "|    std                  | 5.54       |\n",
      "|    value_loss           | 46.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1194         |\n",
      "|    time_elapsed         | 22126        |\n",
      "|    total_timesteps      | 2445312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009138269  |\n",
      "|    clip_fraction        | 0.0667       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.6        |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62           |\n",
      "|    n_updates            | 11930        |\n",
      "|    policy_gradient_loss | -0.00792     |\n",
      "|    reward               | -0.013744677 |\n",
      "|    std                  | 5.55         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1195         |\n",
      "|    time_elapsed         | 22145        |\n",
      "|    total_timesteps      | 2447360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048634894 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.6        |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.2         |\n",
      "|    n_updates            | 11940        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | 10.759699    |\n",
      "|    std                  | 5.55         |\n",
      "|    value_loss           | 160          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1196         |\n",
      "|    time_elapsed         | 22164        |\n",
      "|    total_timesteps      | 2449408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076140095 |\n",
      "|    clip_fraction        | 0.06         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.7        |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59           |\n",
      "|    n_updates            | 11950        |\n",
      "|    policy_gradient_loss | -0.00863     |\n",
      "|    reward               | -1.4910406   |\n",
      "|    std                  | 5.57         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1197        |\n",
      "|    time_elapsed         | 22182       |\n",
      "|    total_timesteps      | 2451456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012919012 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.7       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 11960       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -1.3361653  |\n",
      "|    std                  | 5.58        |\n",
      "|    value_loss           | 81.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1198         |\n",
      "|    time_elapsed         | 22200        |\n",
      "|    total_timesteps      | 2453504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076886765 |\n",
      "|    clip_fraction        | 0.0581       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.8        |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.9         |\n",
      "|    n_updates            | 11970        |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    reward               | -0.51556754  |\n",
      "|    std                  | 5.58         |\n",
      "|    value_loss           | 166          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1199        |\n",
      "|    time_elapsed         | 22218       |\n",
      "|    total_timesteps      | 2455552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003898506 |\n",
      "|    clip_fraction        | 0.0063      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.8       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.8        |\n",
      "|    n_updates            | 11980       |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    reward               | -21.872854  |\n",
      "|    std                  | 5.58        |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6117109.08\n",
      "total_reward: 5117109.08\n",
      "total_cost: 151159.24\n",
      "total_trades: 56380\n",
      "Sharpe: 0.828\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1200        |\n",
      "|    time_elapsed         | 22236       |\n",
      "|    total_timesteps      | 2457600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010419487 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.8       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 11990       |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    reward               | 3.6880457   |\n",
      "|    std                  | 5.59        |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1201         |\n",
      "|    time_elapsed         | 22255        |\n",
      "|    total_timesteps      | 2459648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075262776 |\n",
      "|    clip_fraction        | 0.0529       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.8        |\n",
      "|    explained_variance   | 0.164        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 91.1         |\n",
      "|    n_updates            | 12000        |\n",
      "|    policy_gradient_loss | -0.0069      |\n",
      "|    reward               | 2.7783775    |\n",
      "|    std                  | 5.59         |\n",
      "|    value_loss           | 196          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1202         |\n",
      "|    time_elapsed         | 22274        |\n",
      "|    total_timesteps      | 2461696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033953905 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.8        |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 106          |\n",
      "|    n_updates            | 12010        |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    reward               | -2.2264664   |\n",
      "|    std                  | 5.6          |\n",
      "|    value_loss           | 229          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1203         |\n",
      "|    time_elapsed         | 22292        |\n",
      "|    total_timesteps      | 2463744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076416144 |\n",
      "|    clip_fraction        | 0.0735       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.9        |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.3         |\n",
      "|    n_updates            | 12020        |\n",
      "|    policy_gradient_loss | -0.00758     |\n",
      "|    reward               | 14.256674    |\n",
      "|    std                  | 5.61         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1204        |\n",
      "|    time_elapsed         | 22311       |\n",
      "|    total_timesteps      | 2465792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010675817 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 12030       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 0.8650675   |\n",
      "|    std                  | 5.62        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1205        |\n",
      "|    time_elapsed         | 22330       |\n",
      "|    total_timesteps      | 2467840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010461052 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.2        |\n",
      "|    n_updates            | 12040       |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    reward               | -0.12773988 |\n",
      "|    std                  | 5.62        |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1206        |\n",
      "|    time_elapsed         | 22348       |\n",
      "|    total_timesteps      | 2469888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008283911 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 12050       |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    reward               | 2.702939    |\n",
      "|    std                  | 5.63        |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1207       |\n",
      "|    time_elapsed         | 22366      |\n",
      "|    total_timesteps      | 2471936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01210105 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91        |\n",
      "|    explained_variance   | 0.239      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.9       |\n",
      "|    n_updates            | 12060      |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    reward               | 1.483633   |\n",
      "|    std                  | 5.63       |\n",
      "|    value_loss           | 30.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1208         |\n",
      "|    time_elapsed         | 22385        |\n",
      "|    total_timesteps      | 2473984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045918333 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91          |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.9         |\n",
      "|    n_updates            | 12070        |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    reward               | -1.3790404   |\n",
      "|    std                  | 5.64         |\n",
      "|    value_loss           | 167          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1209        |\n",
      "|    time_elapsed         | 22404       |\n",
      "|    total_timesteps      | 2476032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010938282 |\n",
      "|    clip_fraction        | 0.0478      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.5        |\n",
      "|    n_updates            | 12080       |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    reward               | -10.068167  |\n",
      "|    std                  | 5.64        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1210        |\n",
      "|    time_elapsed         | 22422       |\n",
      "|    total_timesteps      | 2478080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009133026 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 12090       |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    reward               | -3.9231613  |\n",
      "|    std                  | 5.65        |\n",
      "|    value_loss           | 63.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1211        |\n",
      "|    time_elapsed         | 22440       |\n",
      "|    total_timesteps      | 2480128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008325059 |\n",
      "|    clip_fraction        | 0.056       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.6        |\n",
      "|    n_updates            | 12100       |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    reward               | -0.6306089  |\n",
      "|    std                  | 5.65        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1212        |\n",
      "|    time_elapsed         | 22458       |\n",
      "|    total_timesteps      | 2482176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003387951 |\n",
      "|    clip_fraction        | 0.00825     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75          |\n",
      "|    n_updates            | 12110       |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    reward               | 20.221224   |\n",
      "|    std                  | 5.65        |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1213        |\n",
      "|    time_elapsed         | 22476       |\n",
      "|    total_timesteps      | 2484224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007738827 |\n",
      "|    clip_fraction        | 0.0645      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.2       |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.2        |\n",
      "|    n_updates            | 12120       |\n",
      "|    policy_gradient_loss | 0.000677    |\n",
      "|    reward               | 0.28719255  |\n",
      "|    std                  | 5.66        |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5695778.16\n",
      "total_reward: 4695778.16\n",
      "total_cost: 156783.37\n",
      "total_trades: 57274\n",
      "Sharpe: 0.787\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1214        |\n",
      "|    time_elapsed         | 22495       |\n",
      "|    total_timesteps      | 2486272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013519171 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.2       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 12130       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 3.5398767   |\n",
      "|    std                  | 5.69        |\n",
      "|    value_loss           | 43          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1215         |\n",
      "|    time_elapsed         | 22513        |\n",
      "|    total_timesteps      | 2488320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076756002 |\n",
      "|    clip_fraction        | 0.0597       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.3        |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 91.1         |\n",
      "|    n_updates            | 12140        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    reward               | -0.63961816  |\n",
      "|    std                  | 5.69         |\n",
      "|    value_loss           | 228          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1216        |\n",
      "|    time_elapsed         | 22531       |\n",
      "|    total_timesteps      | 2490368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006094449 |\n",
      "|    clip_fraction        | 0.0244      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.8        |\n",
      "|    n_updates            | 12150       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | 0.27879605  |\n",
      "|    std                  | 5.69        |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1217        |\n",
      "|    time_elapsed         | 22549       |\n",
      "|    total_timesteps      | 2492416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013453037 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 12160       |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | 2.231749    |\n",
      "|    std                  | 5.7         |\n",
      "|    value_loss           | 59.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1218        |\n",
      "|    time_elapsed         | 22567       |\n",
      "|    total_timesteps      | 2494464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008817287 |\n",
      "|    clip_fraction        | 0.0432      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.6        |\n",
      "|    n_updates            | 12170       |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    reward               | 5.512704    |\n",
      "|    std                  | 5.7         |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1219        |\n",
      "|    time_elapsed         | 22585       |\n",
      "|    total_timesteps      | 2496512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005074422 |\n",
      "|    clip_fraction        | 0.02        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 159         |\n",
      "|    n_updates            | 12180       |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    reward               | -3.1302755  |\n",
      "|    std                  | 5.71        |\n",
      "|    value_loss           | 217         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1220        |\n",
      "|    time_elapsed         | 22604       |\n",
      "|    total_timesteps      | 2498560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012570121 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.0813      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 12190       |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    reward               | -10.311417  |\n",
      "|    std                  | 5.7         |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1221        |\n",
      "|    time_elapsed         | 22623       |\n",
      "|    total_timesteps      | 2500608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01141994  |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | -0.0319     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 172         |\n",
      "|    n_updates            | 12200       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -0.69499165 |\n",
      "|    std                  | 5.71        |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1222        |\n",
      "|    time_elapsed         | 22642       |\n",
      "|    total_timesteps      | 2502656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00841059  |\n",
      "|    clip_fraction        | 0.0886      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.0263      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 225         |\n",
      "|    n_updates            | 12210       |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    reward               | 0.014650405 |\n",
      "|    std                  | 5.73        |\n",
      "|    value_loss           | 310         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1223         |\n",
      "|    time_elapsed         | 22660        |\n",
      "|    total_timesteps      | 2504704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063596508 |\n",
      "|    clip_fraction        | 0.0455       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.6        |\n",
      "|    explained_variance   | 0.166        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.6         |\n",
      "|    n_updates            | 12220        |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    reward               | -3.000395    |\n",
      "|    std                  | 5.74         |\n",
      "|    value_loss           | 204          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1224        |\n",
      "|    time_elapsed         | 22679       |\n",
      "|    total_timesteps      | 2506752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016230881 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.6       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 12230       |\n",
      "|    policy_gradient_loss | -0.00981    |\n",
      "|    reward               | -0.4011817  |\n",
      "|    std                  | 5.74        |\n",
      "|    value_loss           | 39.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1225        |\n",
      "|    time_elapsed         | 22698       |\n",
      "|    total_timesteps      | 2508800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006671541 |\n",
      "|    clip_fraction        | 0.0226      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.6       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.9        |\n",
      "|    n_updates            | 12240       |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    reward               | 0.15752223  |\n",
      "|    std                  | 5.75        |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1226       |\n",
      "|    time_elapsed         | 22717      |\n",
      "|    total_timesteps      | 2510848    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00462305 |\n",
      "|    clip_fraction        | 0.0203     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.6      |\n",
      "|    explained_variance   | 0.205      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 65.9       |\n",
      "|    n_updates            | 12250      |\n",
      "|    policy_gradient_loss | -0.00282   |\n",
      "|    reward               | -3.389224  |\n",
      "|    std                  | 5.75       |\n",
      "|    value_loss           | 214        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1227        |\n",
      "|    time_elapsed         | 22735       |\n",
      "|    total_timesteps      | 2512896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010396483 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.7       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.7        |\n",
      "|    n_updates            | 12260       |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    reward               | 0.113736674 |\n",
      "|    std                  | 5.76        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5826103.02\n",
      "total_reward: 4826103.02\n",
      "total_cost: 142733.11\n",
      "total_trades: 56454\n",
      "Sharpe: 0.801\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1228        |\n",
      "|    time_elapsed         | 22753       |\n",
      "|    total_timesteps      | 2514944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008046936 |\n",
      "|    clip_fraction        | 0.0526      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.7       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 12270       |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    reward               | 4.5808196   |\n",
      "|    std                  | 5.76        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1229         |\n",
      "|    time_elapsed         | 22771        |\n",
      "|    total_timesteps      | 2516992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042978213 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.7        |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 12280        |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    reward               | 0.12728813   |\n",
      "|    std                  | 5.77         |\n",
      "|    value_loss           | 259          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1230         |\n",
      "|    time_elapsed         | 22790        |\n",
      "|    total_timesteps      | 2519040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052812183 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.7        |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 137          |\n",
      "|    n_updates            | 12290        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | -3.5531402   |\n",
      "|    std                  | 5.77         |\n",
      "|    value_loss           | 227          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1231        |\n",
      "|    time_elapsed         | 22809       |\n",
      "|    total_timesteps      | 2521088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017413951 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.8       |\n",
      "|    explained_variance   | 0.0644      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 12300       |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    reward               | 3.8851075   |\n",
      "|    std                  | 5.78        |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1232         |\n",
      "|    time_elapsed         | 22827        |\n",
      "|    total_timesteps      | 2523136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040156725 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.8        |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 186          |\n",
      "|    n_updates            | 12310        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    reward               | 0.7642439    |\n",
      "|    std                  | 5.79         |\n",
      "|    value_loss           | 218          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1233        |\n",
      "|    time_elapsed         | 22846       |\n",
      "|    total_timesteps      | 2525184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006498484 |\n",
      "|    clip_fraction        | 0.0241      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.8       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 12320       |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | -5.373612   |\n",
      "|    std                  | 5.79        |\n",
      "|    value_loss           | 251         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1234        |\n",
      "|    time_elapsed         | 22865       |\n",
      "|    total_timesteps      | 2527232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011011936 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.9       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64          |\n",
      "|    n_updates            | 12330       |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    reward               | -0.490211   |\n",
      "|    std                  | 5.81        |\n",
      "|    value_loss           | 97.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1235        |\n",
      "|    time_elapsed         | 22884       |\n",
      "|    total_timesteps      | 2529280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009044463 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 12340       |\n",
      "|    policy_gradient_loss | -0.00759    |\n",
      "|    reward               | -1.991669   |\n",
      "|    std                  | 5.82        |\n",
      "|    value_loss           | 223         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1236        |\n",
      "|    time_elapsed         | 22903       |\n",
      "|    total_timesteps      | 2531328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009634172 |\n",
      "|    clip_fraction        | 0.0662      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 192         |\n",
      "|    n_updates            | 12350       |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    reward               | 3.3229291   |\n",
      "|    std                  | 5.83        |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1237         |\n",
      "|    time_elapsed         | 22921        |\n",
      "|    total_timesteps      | 2533376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104162395 |\n",
      "|    clip_fraction        | 0.0769       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.1        |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93.8         |\n",
      "|    n_updates            | 12360        |\n",
      "|    policy_gradient_loss | -0.00692     |\n",
      "|    reward               | 1.9001675    |\n",
      "|    std                  | 5.85         |\n",
      "|    value_loss           | 173          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1238        |\n",
      "|    time_elapsed         | 22940       |\n",
      "|    total_timesteps      | 2535424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017755698 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.1       |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 12370       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -1.3310803  |\n",
      "|    std                  | 5.86        |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1239        |\n",
      "|    time_elapsed         | 22959       |\n",
      "|    total_timesteps      | 2537472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003871673 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 12380       |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    reward               | -0.10431981 |\n",
      "|    std                  | 5.86        |\n",
      "|    value_loss           | 236         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1240         |\n",
      "|    time_elapsed         | 22978        |\n",
      "|    total_timesteps      | 2539520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070826523 |\n",
      "|    clip_fraction        | 0.0438       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.2        |\n",
      "|    explained_variance   | 0.757        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.6         |\n",
      "|    n_updates            | 12390        |\n",
      "|    policy_gradient_loss | -0.00771     |\n",
      "|    reward               | 0.65945023   |\n",
      "|    std                  | 5.87         |\n",
      "|    value_loss           | 157          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1241        |\n",
      "|    time_elapsed         | 22996       |\n",
      "|    total_timesteps      | 2541568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013488909 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | 0.0441      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 12400       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | 5.391565    |\n",
      "|    std                  | 5.9         |\n",
      "|    value_loss           | 50.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4862027.95\n",
      "total_reward: 3862027.95\n",
      "total_cost: 176249.42\n",
      "total_trades: 58845\n",
      "Sharpe: 0.730\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1242        |\n",
      "|    time_elapsed         | 23014       |\n",
      "|    total_timesteps      | 2543616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009756513 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.2        |\n",
      "|    n_updates            | 12410       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 4.4399495   |\n",
      "|    std                  | 5.9         |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1243         |\n",
      "|    time_elapsed         | 23033        |\n",
      "|    total_timesteps      | 2545664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072096935 |\n",
      "|    clip_fraction        | 0.0316       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.4        |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 12420        |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    reward               | -6.3388195   |\n",
      "|    std                  | 5.9          |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1244        |\n",
      "|    time_elapsed         | 23051       |\n",
      "|    total_timesteps      | 2547712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011592906 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 12430       |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    reward               | -1.6749889  |\n",
      "|    std                  | 5.91        |\n",
      "|    value_loss           | 96.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1245        |\n",
      "|    time_elapsed         | 23069       |\n",
      "|    total_timesteps      | 2549760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012560075 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 12440       |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | 2.7217882   |\n",
      "|    std                  | 5.92        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1246        |\n",
      "|    time_elapsed         | 23088       |\n",
      "|    total_timesteps      | 2551808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008396248 |\n",
      "|    clip_fraction        | 0.0408      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 192         |\n",
      "|    n_updates            | 12450       |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    reward               | -1.6942652  |\n",
      "|    std                  | 5.92        |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1247        |\n",
      "|    time_elapsed         | 23106       |\n",
      "|    total_timesteps      | 2553856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008457064 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.1        |\n",
      "|    n_updates            | 12460       |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    reward               | -4.3850646  |\n",
      "|    std                  | 5.93        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1248        |\n",
      "|    time_elapsed         | 23124       |\n",
      "|    total_timesteps      | 2555904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013782162 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | -0.115      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 12470       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -1.5203142  |\n",
      "|    std                  | 5.93        |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1249        |\n",
      "|    time_elapsed         | 23142       |\n",
      "|    total_timesteps      | 2557952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007699239 |\n",
      "|    clip_fraction        | 0.0369      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.6        |\n",
      "|    n_updates            | 12480       |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    reward               | 1.4330703   |\n",
      "|    std                  | 5.93        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1250         |\n",
      "|    time_elapsed         | 23161        |\n",
      "|    total_timesteps      | 2560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034272766 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.5        |\n",
      "|    explained_variance   | 0.762        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63           |\n",
      "|    n_updates            | 12490        |\n",
      "|    policy_gradient_loss | -0.00472     |\n",
      "|    reward               | 2.7645164    |\n",
      "|    std                  | 5.94         |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1251       |\n",
      "|    time_elapsed         | 23180      |\n",
      "|    total_timesteps      | 2562048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00977608 |\n",
      "|    clip_fraction        | 0.0471     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.6      |\n",
      "|    explained_variance   | 0.521      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.4       |\n",
      "|    n_updates            | 12500      |\n",
      "|    policy_gradient_loss | -0.00623   |\n",
      "|    reward               | 6.411481   |\n",
      "|    std                  | 5.94       |\n",
      "|    value_loss           | 71.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1252        |\n",
      "|    time_elapsed         | 23199       |\n",
      "|    total_timesteps      | 2564096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009300466 |\n",
      "|    clip_fraction        | 0.0482      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.6       |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 12510       |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | 2.3681757   |\n",
      "|    std                  | 5.95        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1253       |\n",
      "|    time_elapsed         | 23218      |\n",
      "|    total_timesteps      | 2566144    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00271679 |\n",
      "|    clip_fraction        | 0.00195    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.6      |\n",
      "|    explained_variance   | 0.763      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 84         |\n",
      "|    n_updates            | 12520      |\n",
      "|    policy_gradient_loss | -0.00207   |\n",
      "|    reward               | -1.0161752 |\n",
      "|    std                  | 5.96       |\n",
      "|    value_loss           | 139        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1254        |\n",
      "|    time_elapsed         | 23237       |\n",
      "|    total_timesteps      | 2568192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007432339 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.1        |\n",
      "|    n_updates            | 12530       |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    reward               | 1.601758    |\n",
      "|    std                  | 5.96        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1255        |\n",
      "|    time_elapsed         | 23256       |\n",
      "|    total_timesteps      | 2570240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009035747 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.0721      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 12540       |\n",
      "|    policy_gradient_loss | -0.00865    |\n",
      "|    reward               | -0.643102   |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5734733.81\n",
      "total_reward: 4734733.81\n",
      "total_cost: 186350.88\n",
      "total_trades: 59045\n",
      "Sharpe: 0.801\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1256         |\n",
      "|    time_elapsed         | 23274        |\n",
      "|    total_timesteps      | 2572288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041266847 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.7        |\n",
      "|    explained_variance   | 0.752        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.8         |\n",
      "|    n_updates            | 12550        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | 1.1890182    |\n",
      "|    std                  | 5.97         |\n",
      "|    value_loss           | 156          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1257        |\n",
      "|    time_elapsed         | 23292       |\n",
      "|    total_timesteps      | 2574336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004949459 |\n",
      "|    clip_fraction        | 0.0144      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.8        |\n",
      "|    n_updates            | 12560       |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | -10.918155  |\n",
      "|    std                  | 5.98        |\n",
      "|    value_loss           | 209         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1258        |\n",
      "|    time_elapsed         | 23310       |\n",
      "|    total_timesteps      | 2576384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010004457 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 12570       |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    reward               | 1.4119794   |\n",
      "|    std                  | 5.99        |\n",
      "|    value_loss           | 52.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1259        |\n",
      "|    time_elapsed         | 23328       |\n",
      "|    total_timesteps      | 2578432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005149822 |\n",
      "|    clip_fraction        | 0.0188      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.8       |\n",
      "|    explained_variance   | 0.0392      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.7        |\n",
      "|    n_updates            | 12580       |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    reward               | 0.78706086  |\n",
      "|    std                  | 5.99        |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1260         |\n",
      "|    time_elapsed         | 23346        |\n",
      "|    total_timesteps      | 2580480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057861805 |\n",
      "|    clip_fraction        | 0.0412       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.8        |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.4         |\n",
      "|    n_updates            | 12590        |\n",
      "|    policy_gradient_loss | -0.00703     |\n",
      "|    reward               | 46.19971     |\n",
      "|    std                  | 5.99         |\n",
      "|    value_loss           | 173          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1261        |\n",
      "|    time_elapsed         | 23364       |\n",
      "|    total_timesteps      | 2582528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009809731 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.8       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.7        |\n",
      "|    n_updates            | 12600       |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | -2.5276544  |\n",
      "|    std                  | 6           |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1262        |\n",
      "|    time_elapsed         | 23383       |\n",
      "|    total_timesteps      | 2584576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012224663 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.8       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 12610       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 4.768643    |\n",
      "|    std                  | 6           |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1263        |\n",
      "|    time_elapsed         | 23402       |\n",
      "|    total_timesteps      | 2586624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011320488 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | 0.0348      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 12620       |\n",
      "|    policy_gradient_loss | -0.00779    |\n",
      "|    reward               | 0.8534688   |\n",
      "|    std                  | 6.01        |\n",
      "|    value_loss           | 247         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1264         |\n",
      "|    time_elapsed         | 23420        |\n",
      "|    total_timesteps      | 2588672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075678835 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.9        |\n",
      "|    explained_variance   | 0.387        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 134          |\n",
      "|    n_updates            | 12630        |\n",
      "|    policy_gradient_loss | -0.00681     |\n",
      "|    reward               | -11.307801   |\n",
      "|    std                  | 6.01         |\n",
      "|    value_loss           | 191          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1265        |\n",
      "|    time_elapsed         | 23438       |\n",
      "|    total_timesteps      | 2590720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011292549 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 12640       |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    reward               | 0.14359364  |\n",
      "|    std                  | 6.01        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1266        |\n",
      "|    time_elapsed         | 23457       |\n",
      "|    total_timesteps      | 2592768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007767647 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.4        |\n",
      "|    n_updates            | 12650       |\n",
      "|    policy_gradient_loss | -0.0071     |\n",
      "|    reward               | 2.6896093   |\n",
      "|    std                  | 6.02        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1267         |\n",
      "|    time_elapsed         | 23475        |\n",
      "|    total_timesteps      | 2594816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037589164 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.9        |\n",
      "|    explained_variance   | 0.0752       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.8         |\n",
      "|    n_updates            | 12660        |\n",
      "|    policy_gradient_loss | -0.00477     |\n",
      "|    reward               | -3.1226354   |\n",
      "|    std                  | 6.02         |\n",
      "|    value_loss           | 217          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1268        |\n",
      "|    time_elapsed         | 23493       |\n",
      "|    total_timesteps      | 2596864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007978579 |\n",
      "|    clip_fraction        | 0.0482      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.5        |\n",
      "|    n_updates            | 12670       |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    reward               | -1.5762297  |\n",
      "|    std                  | 6.02        |\n",
      "|    value_loss           | 92.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1269        |\n",
      "|    time_elapsed         | 23511       |\n",
      "|    total_timesteps      | 2598912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013918081 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 12680       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | -1.0071199  |\n",
      "|    std                  | 6.04        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5663585.67\n",
      "total_reward: 4663585.67\n",
      "total_cost: 209739.41\n",
      "total_trades: 59649\n",
      "Sharpe: 0.830\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1270       |\n",
      "|    time_elapsed         | 23530      |\n",
      "|    total_timesteps      | 2600960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00470783 |\n",
      "|    clip_fraction        | 0.0181     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93        |\n",
      "|    explained_variance   | 0.579      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 161        |\n",
      "|    n_updates            | 12690      |\n",
      "|    policy_gradient_loss | -0.00546   |\n",
      "|    reward               | 1.289929   |\n",
      "|    std                  | 6.04       |\n",
      "|    value_loss           | 211        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1271         |\n",
      "|    time_elapsed         | 23548        |\n",
      "|    total_timesteps      | 2603008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026008845 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93          |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 101          |\n",
      "|    n_updates            | 12700        |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    reward               | 2.5307696    |\n",
      "|    std                  | 6.04         |\n",
      "|    value_loss           | 202          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1272        |\n",
      "|    time_elapsed         | 23567       |\n",
      "|    total_timesteps      | 2605056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012846582 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | -0.303      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 12710       |\n",
      "|    policy_gradient_loss | -0.00893    |\n",
      "|    reward               | 1.2495096   |\n",
      "|    std                  | 6.05        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1273        |\n",
      "|    time_elapsed         | 23586       |\n",
      "|    total_timesteps      | 2607104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007860443 |\n",
      "|    clip_fraction        | 0.0329      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.9        |\n",
      "|    n_updates            | 12720       |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    reward               | 1.8448473   |\n",
      "|    std                  | 6.05        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1274        |\n",
      "|    time_elapsed         | 23604       |\n",
      "|    total_timesteps      | 2609152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003163036 |\n",
      "|    clip_fraction        | 0.00811     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 12730       |\n",
      "|    policy_gradient_loss | -0.000355   |\n",
      "|    reward               | -1.8600825  |\n",
      "|    std                  | 6.05        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1275        |\n",
      "|    time_elapsed         | 23622       |\n",
      "|    total_timesteps      | 2611200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009513837 |\n",
      "|    clip_fraction        | 0.0757      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 12740       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | 2.7169092   |\n",
      "|    std                  | 6.07        |\n",
      "|    value_loss           | 60.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1276         |\n",
      "|    time_elapsed         | 23641        |\n",
      "|    total_timesteps      | 2613248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074962573 |\n",
      "|    clip_fraction        | 0.0485       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.2        |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40           |\n",
      "|    n_updates            | 12750        |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    reward               | 0.95998436   |\n",
      "|    std                  | 6.07         |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1277         |\n",
      "|    time_elapsed         | 23660        |\n",
      "|    total_timesteps      | 2615296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030066534 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.2        |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.4         |\n",
      "|    n_updates            | 12760        |\n",
      "|    policy_gradient_loss | -0.00469     |\n",
      "|    reward               | 0.9039926    |\n",
      "|    std                  | 6.08         |\n",
      "|    value_loss           | 145          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1278       |\n",
      "|    time_elapsed         | 23678      |\n",
      "|    total_timesteps      | 2617344    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00698441 |\n",
      "|    clip_fraction        | 0.0342     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.2      |\n",
      "|    explained_variance   | 0.385      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.1       |\n",
      "|    n_updates            | 12770      |\n",
      "|    policy_gradient_loss | -0.00482   |\n",
      "|    reward               | 3.3401656  |\n",
      "|    std                  | 6.08       |\n",
      "|    value_loss           | 158        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1279        |\n",
      "|    time_elapsed         | 23697       |\n",
      "|    total_timesteps      | 2619392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012852807 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.2       |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 12780       |\n",
      "|    policy_gradient_loss | -0.00908    |\n",
      "|    reward               | -0.129506   |\n",
      "|    std                  | 6.09        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1280        |\n",
      "|    time_elapsed         | 23715       |\n",
      "|    total_timesteps      | 2621440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004230655 |\n",
      "|    clip_fraction        | 0.0082      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.3       |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.9        |\n",
      "|    n_updates            | 12790       |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    reward               | -0.26227808 |\n",
      "|    std                  | 6.09        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1281         |\n",
      "|    time_elapsed         | 23733        |\n",
      "|    total_timesteps      | 2623488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035614197 |\n",
      "|    clip_fraction        | 0.00459      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.3        |\n",
      "|    explained_variance   | 0.752        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71           |\n",
      "|    n_updates            | 12800        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | 2.3576655    |\n",
      "|    std                  | 6.1          |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1282        |\n",
      "|    time_elapsed         | 23751       |\n",
      "|    total_timesteps      | 2625536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019277982 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.4       |\n",
      "|    explained_variance   | 0.0308      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 12810       |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    reward               | 3.1477478   |\n",
      "|    std                  | 6.13        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1283       |\n",
      "|    time_elapsed         | 23770      |\n",
      "|    total_timesteps      | 2627584    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00715105 |\n",
      "|    clip_fraction        | 0.0292     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.5      |\n",
      "|    explained_variance   | 0.741      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 92.9       |\n",
      "|    n_updates            | 12820      |\n",
      "|    policy_gradient_loss | -0.00424   |\n",
      "|    reward               | -2.7500916 |\n",
      "|    std                  | 6.14       |\n",
      "|    value_loss           | 115        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1284         |\n",
      "|    time_elapsed         | 23788        |\n",
      "|    total_timesteps      | 2629632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010368583 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.5        |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 12830        |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    reward               | -23.914446   |\n",
      "|    std                  | 6.14         |\n",
      "|    value_loss           | 222          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6247677.74\n",
      "total_reward: 5247677.74\n",
      "total_cost: 215301.39\n",
      "total_trades: 59640\n",
      "Sharpe: 0.863\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1285         |\n",
      "|    time_elapsed         | 23807        |\n",
      "|    total_timesteps      | 2631680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018475456 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.5        |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45           |\n",
      "|    n_updates            | 12840        |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    reward               | 2.5357614    |\n",
      "|    std                  | 6.14         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1286         |\n",
      "|    time_elapsed         | 23825        |\n",
      "|    total_timesteps      | 2633728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061537935 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.5        |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.1         |\n",
      "|    n_updates            | 12850        |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    reward               | 0.3865255    |\n",
      "|    std                  | 6.15         |\n",
      "|    value_loss           | 91.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1287         |\n",
      "|    time_elapsed         | 23844        |\n",
      "|    total_timesteps      | 2635776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017636252 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.6        |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 131          |\n",
      "|    n_updates            | 12860        |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    reward               | 0.10021603   |\n",
      "|    std                  | 6.16         |\n",
      "|    value_loss           | 180          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1288         |\n",
      "|    time_elapsed         | 23863        |\n",
      "|    total_timesteps      | 2637824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058428347 |\n",
      "|    clip_fraction        | 0.0301       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.6        |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 92.1         |\n",
      "|    n_updates            | 12870        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | 5.9976587    |\n",
      "|    std                  | 6.16         |\n",
      "|    value_loss           | 190          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1289        |\n",
      "|    time_elapsed         | 23882       |\n",
      "|    total_timesteps      | 2639872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010174673 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 12880       |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    reward               | -3.5657902  |\n",
      "|    std                  | 6.16        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1290         |\n",
      "|    time_elapsed         | 23900        |\n",
      "|    total_timesteps      | 2641920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072227074 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.6        |\n",
      "|    explained_variance   | 0.477        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.5         |\n",
      "|    n_updates            | 12890        |\n",
      "|    policy_gradient_loss | -0.0079      |\n",
      "|    reward               | -0.8758318   |\n",
      "|    std                  | 6.16         |\n",
      "|    value_loss           | 153          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1291         |\n",
      "|    time_elapsed         | 23918        |\n",
      "|    total_timesteps      | 2643968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045513725 |\n",
      "|    clip_fraction        | 0.00786      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.6        |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.3         |\n",
      "|    n_updates            | 12900        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | 3.1765046    |\n",
      "|    std                  | 6.17         |\n",
      "|    value_loss           | 188          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1292         |\n",
      "|    time_elapsed         | 23937        |\n",
      "|    total_timesteps      | 2646016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024391848 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.6        |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.6         |\n",
      "|    n_updates            | 12910        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | 3.8845863    |\n",
      "|    std                  | 6.17         |\n",
      "|    value_loss           | 99.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1293        |\n",
      "|    time_elapsed         | 23955       |\n",
      "|    total_timesteps      | 2648064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008939028 |\n",
      "|    clip_fraction        | 0.0562      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.7       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.7        |\n",
      "|    n_updates            | 12920       |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    reward               | -5.447286   |\n",
      "|    std                  | 6.18        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1294       |\n",
      "|    time_elapsed         | 23973      |\n",
      "|    total_timesteps      | 2650112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00809026 |\n",
      "|    clip_fraction        | 0.056      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.7      |\n",
      "|    explained_variance   | 0.0217     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 72.5       |\n",
      "|    n_updates            | 12930      |\n",
      "|    policy_gradient_loss | -0.00865   |\n",
      "|    reward               | 0.2759018  |\n",
      "|    std                  | 6.18       |\n",
      "|    value_loss           | 254        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1295         |\n",
      "|    time_elapsed         | 23992        |\n",
      "|    total_timesteps      | 2652160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076255035 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.7        |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 134          |\n",
      "|    n_updates            | 12940        |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    reward               | -2.4786289   |\n",
      "|    std                  | 6.19         |\n",
      "|    value_loss           | 190          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1296        |\n",
      "|    time_elapsed         | 24011       |\n",
      "|    total_timesteps      | 2654208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010889624 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 12950       |\n",
      "|    policy_gradient_loss | -0.00943    |\n",
      "|    reward               | -3.0736241  |\n",
      "|    std                  | 6.2         |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1297        |\n",
      "|    time_elapsed         | 24030       |\n",
      "|    total_timesteps      | 2656256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005914634 |\n",
      "|    clip_fraction        | 0.0226      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.1        |\n",
      "|    n_updates            | 12960       |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    reward               | 3.2477896   |\n",
      "|    std                  | 6.21        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1298        |\n",
      "|    time_elapsed         | 24049       |\n",
      "|    total_timesteps      | 2658304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008006221 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 12970       |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    reward               | 2.7624302   |\n",
      "|    std                  | 6.21        |\n",
      "|    value_loss           | 238         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5173601.41\n",
      "total_reward: 4173601.41\n",
      "total_cost: 200805.96\n",
      "total_trades: 58916\n",
      "Sharpe: 0.762\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1299         |\n",
      "|    time_elapsed         | 24068        |\n",
      "|    total_timesteps      | 2660352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101126125 |\n",
      "|    clip_fraction        | 0.0897       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.9        |\n",
      "|    explained_variance   | 0.198        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.2         |\n",
      "|    n_updates            | 12980        |\n",
      "|    policy_gradient_loss | -0.00925     |\n",
      "|    reward               | -0.89970064  |\n",
      "|    std                  | 6.22         |\n",
      "|    value_loss           | 58.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1300        |\n",
      "|    time_elapsed         | 24086       |\n",
      "|    total_timesteps      | 2662400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011493436 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.9       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 12990       |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | -0.97319126 |\n",
      "|    std                  | 6.23        |\n",
      "|    value_loss           | 81.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1301        |\n",
      "|    time_elapsed         | 24105       |\n",
      "|    total_timesteps      | 2664448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004330094 |\n",
      "|    clip_fraction        | 0.0132      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.9       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.7        |\n",
      "|    n_updates            | 13000       |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    reward               | -23.824549  |\n",
      "|    std                  | 6.24        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1302         |\n",
      "|    time_elapsed         | 24123        |\n",
      "|    total_timesteps      | 2666496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061909063 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.9        |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.3         |\n",
      "|    n_updates            | 13010        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    reward               | 0.61650914   |\n",
      "|    std                  | 6.24         |\n",
      "|    value_loss           | 157          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1303         |\n",
      "|    time_elapsed         | 24141        |\n",
      "|    total_timesteps      | 2668544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0106455255 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94          |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 13020        |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    reward               | 1.3463651    |\n",
      "|    std                  | 6.26         |\n",
      "|    value_loss           | 31.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1304         |\n",
      "|    time_elapsed         | 24160        |\n",
      "|    total_timesteps      | 2670592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037306095 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94          |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.3         |\n",
      "|    n_updates            | 13030        |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    reward               | -1.5171984   |\n",
      "|    std                  | 6.26         |\n",
      "|    value_loss           | 152          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1305        |\n",
      "|    time_elapsed         | 24178       |\n",
      "|    total_timesteps      | 2672640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001965613 |\n",
      "|    clip_fraction        | 0.000586    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.4        |\n",
      "|    n_updates            | 13040       |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    reward               | 1.6532192   |\n",
      "|    std                  | 6.26        |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1306        |\n",
      "|    time_elapsed         | 24196       |\n",
      "|    total_timesteps      | 2674688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009470064 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 13050       |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    reward               | -1.9346399  |\n",
      "|    std                  | 6.27        |\n",
      "|    value_loss           | 53.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1307       |\n",
      "|    time_elapsed         | 24215      |\n",
      "|    total_timesteps      | 2676736    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00735801 |\n",
      "|    clip_fraction        | 0.0286     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.1      |\n",
      "|    explained_variance   | 0.729      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 42.7       |\n",
      "|    n_updates            | 13060      |\n",
      "|    policy_gradient_loss | -0.00767   |\n",
      "|    reward               | 6.381917   |\n",
      "|    std                  | 6.27       |\n",
      "|    value_loss           | 148        |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1308          |\n",
      "|    time_elapsed         | 24233         |\n",
      "|    total_timesteps      | 2678784       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00056366867 |\n",
      "|    clip_fraction        | 0.00361       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -94.1         |\n",
      "|    explained_variance   | 0.747         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 159           |\n",
      "|    n_updates            | 13070         |\n",
      "|    policy_gradient_loss | -0.000881     |\n",
      "|    reward               | -6.6693125    |\n",
      "|    std                  | 6.27          |\n",
      "|    value_loss           | 372           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1309        |\n",
      "|    time_elapsed         | 24252       |\n",
      "|    total_timesteps      | 2680832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006134866 |\n",
      "|    clip_fraction        | 0.0393      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.4        |\n",
      "|    n_updates            | 13080       |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | -0.91696614 |\n",
      "|    std                  | 6.28        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1310         |\n",
      "|    time_elapsed         | 24272        |\n",
      "|    total_timesteps      | 2682880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110808965 |\n",
      "|    clip_fraction        | 0.0632       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.1        |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.4         |\n",
      "|    n_updates            | 13090        |\n",
      "|    policy_gradient_loss | -0.00735     |\n",
      "|    reward               | 1.0928377    |\n",
      "|    std                  | 6.29         |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1311        |\n",
      "|    time_elapsed         | 24290       |\n",
      "|    total_timesteps      | 2684928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008475654 |\n",
      "|    clip_fraction        | 0.0339      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.2       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.8        |\n",
      "|    n_updates            | 13100       |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    reward               | -0.5028553  |\n",
      "|    std                  | 6.28        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1312         |\n",
      "|    time_elapsed         | 24310        |\n",
      "|    total_timesteps      | 2686976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066018375 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.2        |\n",
      "|    explained_variance   | 0.147        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 227          |\n",
      "|    n_updates            | 13110        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | 2.8566856    |\n",
      "|    std                  | 6.29         |\n",
      "|    value_loss           | 235          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6138778.25\n",
      "total_reward: 5138778.25\n",
      "total_cost: 162326.50\n",
      "total_trades: 57050\n",
      "Sharpe: 0.838\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1313        |\n",
      "|    time_elapsed         | 24328       |\n",
      "|    total_timesteps      | 2689024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010466976 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.2       |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 13120       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | -1.6328539  |\n",
      "|    std                  | 6.3         |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1314         |\n",
      "|    time_elapsed         | 24348        |\n",
      "|    total_timesteps      | 2691072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062018028 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.3        |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 114          |\n",
      "|    n_updates            | 13130        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    reward               | 2.838769     |\n",
      "|    std                  | 6.31         |\n",
      "|    value_loss           | 184          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1315         |\n",
      "|    time_elapsed         | 24366        |\n",
      "|    total_timesteps      | 2693120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050237197 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.3        |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 13140        |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    reward               | -0.6839334   |\n",
      "|    std                  | 6.31         |\n",
      "|    value_loss           | 231          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1316         |\n",
      "|    time_elapsed         | 24385        |\n",
      "|    total_timesteps      | 2695168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034106073 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.3        |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.5         |\n",
      "|    n_updates            | 13150        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    reward               | -1.9123391   |\n",
      "|    std                  | 6.32         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1317        |\n",
      "|    time_elapsed         | 24404       |\n",
      "|    total_timesteps      | 2697216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007508152 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.7        |\n",
      "|    n_updates            | 13160       |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    reward               | -3.0893264  |\n",
      "|    std                  | 6.33        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1318        |\n",
      "|    time_elapsed         | 24423       |\n",
      "|    total_timesteps      | 2699264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004117595 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.4       |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76          |\n",
      "|    n_updates            | 13170       |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    reward               | -0.94540423 |\n",
      "|    std                  | 6.34        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1319         |\n",
      "|    time_elapsed         | 24442        |\n",
      "|    total_timesteps      | 2701312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031923675 |\n",
      "|    clip_fraction        | 0.00825      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.4        |\n",
      "|    explained_variance   | 0.366        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.2         |\n",
      "|    n_updates            | 13180        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    reward               | 1.9052078    |\n",
      "|    std                  | 6.34         |\n",
      "|    value_loss           | 210          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1320        |\n",
      "|    time_elapsed         | 24460       |\n",
      "|    total_timesteps      | 2703360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012459308 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 13190       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -2.3105419  |\n",
      "|    std                  | 6.37        |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1321        |\n",
      "|    time_elapsed         | 24478       |\n",
      "|    total_timesteps      | 2705408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007873157 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 13200       |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    reward               | 2.4863305   |\n",
      "|    std                  | 6.37        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1322        |\n",
      "|    time_elapsed         | 24496       |\n",
      "|    total_timesteps      | 2707456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003461034 |\n",
      "|    clip_fraction        | 0.00654     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.6       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.2        |\n",
      "|    n_updates            | 13210       |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    reward               | -1.827621   |\n",
      "|    std                  | 6.37        |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1323        |\n",
      "|    time_elapsed         | 24515       |\n",
      "|    total_timesteps      | 2709504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010114618 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.6       |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 13220       |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    reward               | -2.3855965  |\n",
      "|    std                  | 6.39        |\n",
      "|    value_loss           | 71.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1324        |\n",
      "|    time_elapsed         | 24533       |\n",
      "|    total_timesteps      | 2711552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009609044 |\n",
      "|    clip_fraction        | 0.0666      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.6       |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.2        |\n",
      "|    n_updates            | 13230       |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    reward               | -0.40344337 |\n",
      "|    std                  | 6.4         |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1325         |\n",
      "|    time_elapsed         | 24551        |\n",
      "|    total_timesteps      | 2713600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065729883 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.7        |\n",
      "|    explained_variance   | 0.343        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.1         |\n",
      "|    n_updates            | 13240        |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    reward               | -16.21981    |\n",
      "|    std                  | 6.4          |\n",
      "|    value_loss           | 210          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1326       |\n",
      "|    time_elapsed         | 24569      |\n",
      "|    total_timesteps      | 2715648    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00817541 |\n",
      "|    clip_fraction        | 0.0403     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.7      |\n",
      "|    explained_variance   | 0.786      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 72.2       |\n",
      "|    n_updates            | 13250      |\n",
      "|    policy_gradient_loss | -0.00962   |\n",
      "|    reward               | 1.3007483  |\n",
      "|    std                  | 6.41       |\n",
      "|    value_loss           | 167        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6315062.37\n",
      "total_reward: 5315062.37\n",
      "total_cost: 197269.68\n",
      "total_trades: 58614\n",
      "Sharpe: 0.846\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1327        |\n",
      "|    time_elapsed         | 24587       |\n",
      "|    total_timesteps      | 2717696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014415214 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 13260       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -0.6381098  |\n",
      "|    std                  | 6.43        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1328         |\n",
      "|    time_elapsed         | 24606        |\n",
      "|    total_timesteps      | 2719744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076252413 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.8        |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.2         |\n",
      "|    n_updates            | 13270        |\n",
      "|    policy_gradient_loss | -0.00863     |\n",
      "|    reward               | 0.32076135   |\n",
      "|    std                  | 6.44         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1329        |\n",
      "|    time_elapsed         | 24625       |\n",
      "|    total_timesteps      | 2721792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001702142 |\n",
      "|    clip_fraction        | 0.00327     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 13280       |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    reward               | 3.2331252   |\n",
      "|    std                  | 6.44        |\n",
      "|    value_loss           | 278         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1330        |\n",
      "|    time_elapsed         | 24644       |\n",
      "|    total_timesteps      | 2723840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009089855 |\n",
      "|    clip_fraction        | 0.0882      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.9       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 13290       |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    reward               | -1.0294709  |\n",
      "|    std                  | 6.45        |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1331        |\n",
      "|    time_elapsed         | 24663       |\n",
      "|    total_timesteps      | 2725888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008269958 |\n",
      "|    clip_fraction        | 0.0485      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.9       |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 13300       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | 1.2049702   |\n",
      "|    std                  | 6.47        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1332        |\n",
      "|    time_elapsed         | 24680       |\n",
      "|    total_timesteps      | 2727936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006116883 |\n",
      "|    clip_fraction        | 0.0295      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95         |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.3        |\n",
      "|    n_updates            | 13310       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.41188723  |\n",
      "|    std                  | 6.47        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1333        |\n",
      "|    time_elapsed         | 24699       |\n",
      "|    total_timesteps      | 2729984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006563641 |\n",
      "|    clip_fraction        | 0.028       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95         |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.2        |\n",
      "|    n_updates            | 13320       |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    reward               | 1.5105467   |\n",
      "|    std                  | 6.48        |\n",
      "|    value_loss           | 84.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1334        |\n",
      "|    time_elapsed         | 24717       |\n",
      "|    total_timesteps      | 2732032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012452227 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95         |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 13330       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.4169344  |\n",
      "|    std                  | 6.49        |\n",
      "|    value_loss           | 73.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1335        |\n",
      "|    time_elapsed         | 24735       |\n",
      "|    total_timesteps      | 2734080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005568874 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.1       |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.6        |\n",
      "|    n_updates            | 13340       |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    reward               | 0.3059843   |\n",
      "|    std                  | 6.49        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1336         |\n",
      "|    time_elapsed         | 24754        |\n",
      "|    total_timesteps      | 2736128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016695608 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.1        |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.3         |\n",
      "|    n_updates            | 13350        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | -0.3845855   |\n",
      "|    std                  | 6.49         |\n",
      "|    value_loss           | 187          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1337        |\n",
      "|    time_elapsed         | 24773       |\n",
      "|    total_timesteps      | 2738176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013082039 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.1       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 13360       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -1.5028569  |\n",
      "|    std                  | 6.52        |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1338         |\n",
      "|    time_elapsed         | 24792        |\n",
      "|    total_timesteps      | 2740224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074221836 |\n",
      "|    clip_fraction        | 0.0417       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.2        |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 142          |\n",
      "|    n_updates            | 13370        |\n",
      "|    policy_gradient_loss | -0.00893     |\n",
      "|    reward               | -2.0112333   |\n",
      "|    std                  | 6.53         |\n",
      "|    value_loss           | 257          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1339        |\n",
      "|    time_elapsed         | 24810       |\n",
      "|    total_timesteps      | 2742272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007846571 |\n",
      "|    clip_fraction        | 0.0388      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.6        |\n",
      "|    n_updates            | 13380       |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    reward               | -4.1360598  |\n",
      "|    std                  | 6.54        |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1340        |\n",
      "|    time_elapsed         | 24829       |\n",
      "|    total_timesteps      | 2744320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009703031 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.7        |\n",
      "|    n_updates            | 13390       |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | 2.6414084   |\n",
      "|    std                  | 6.54        |\n",
      "|    value_loss           | 85.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5961198.91\n",
      "total_reward: 4961198.91\n",
      "total_cost: 147427.44\n",
      "total_trades: 56729\n",
      "Sharpe: 0.822\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1341        |\n",
      "|    time_elapsed         | 24847       |\n",
      "|    total_timesteps      | 2746368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010196733 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 13400       |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    reward               | -0.6009494  |\n",
      "|    std                  | 6.56        |\n",
      "|    value_loss           | 82.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1342        |\n",
      "|    time_elapsed         | 24865       |\n",
      "|    total_timesteps      | 2748416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007234079 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.6        |\n",
      "|    n_updates            | 13410       |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    reward               | 0.3561483   |\n",
      "|    std                  | 6.55        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1343        |\n",
      "|    time_elapsed         | 24883       |\n",
      "|    total_timesteps      | 2750464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002764271 |\n",
      "|    clip_fraction        | 0.00127     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.8        |\n",
      "|    n_updates            | 13420       |\n",
      "|    policy_gradient_loss | -0.00192    |\n",
      "|    reward               | -1.527925   |\n",
      "|    std                  | 6.56        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1344        |\n",
      "|    time_elapsed         | 24901       |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015594922 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 13430       |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    reward               | -0.8625575  |\n",
      "|    std                  | 6.56        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1345          |\n",
      "|    time_elapsed         | 24919         |\n",
      "|    total_timesteps      | 2754560       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007404262   |\n",
      "|    clip_fraction        | 0.0326        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -95.4         |\n",
      "|    explained_variance   | 0.707         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 106           |\n",
      "|    n_updates            | 13440         |\n",
      "|    policy_gradient_loss | -0.00582      |\n",
      "|    reward               | -0.0009307298 |\n",
      "|    std                  | 6.56          |\n",
      "|    value_loss           | 154           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1346         |\n",
      "|    time_elapsed         | 24954        |\n",
      "|    total_timesteps      | 2756608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023182018 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.4        |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 13450        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | -5.510791    |\n",
      "|    std                  | 6.56         |\n",
      "|    value_loss           | 182          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1347         |\n",
      "|    time_elapsed         | 24973        |\n",
      "|    total_timesteps      | 2758656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078616645 |\n",
      "|    clip_fraction        | 0.0487       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.4        |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 13460        |\n",
      "|    policy_gradient_loss | -0.00771     |\n",
      "|    reward               | 0.2993051    |\n",
      "|    std                  | 6.58         |\n",
      "|    value_loss           | 73.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1348        |\n",
      "|    time_elapsed         | 24991       |\n",
      "|    total_timesteps      | 2760704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013094088 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.5       |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.8        |\n",
      "|    n_updates            | 13470       |\n",
      "|    policy_gradient_loss | -0.00851    |\n",
      "|    reward               | 0.86630213  |\n",
      "|    std                  | 6.59        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1349         |\n",
      "|    time_elapsed         | 25009        |\n",
      "|    total_timesteps      | 2762752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053331847 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.5        |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.7         |\n",
      "|    n_updates            | 13480        |\n",
      "|    policy_gradient_loss | -0.00724     |\n",
      "|    reward               | -18.60812    |\n",
      "|    std                  | 6.59         |\n",
      "|    value_loss           | 158          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1350        |\n",
      "|    time_elapsed         | 25027       |\n",
      "|    total_timesteps      | 2764800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008481029 |\n",
      "|    clip_fraction        | 0.0466      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.5       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.7        |\n",
      "|    n_updates            | 13490       |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    reward               | -2.3987703  |\n",
      "|    std                  | 6.6         |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1351       |\n",
      "|    time_elapsed         | 25046      |\n",
      "|    total_timesteps      | 2766848    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01009721 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.6      |\n",
      "|    explained_variance   | 0.388      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.8       |\n",
      "|    n_updates            | 13500      |\n",
      "|    policy_gradient_loss | -0.00916   |\n",
      "|    reward               | -1.4887904 |\n",
      "|    std                  | 6.63       |\n",
      "|    value_loss           | 36.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1352        |\n",
      "|    time_elapsed         | 25065       |\n",
      "|    total_timesteps      | 2768896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003085735 |\n",
      "|    clip_fraction        | 0.00967     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.7       |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 193         |\n",
      "|    n_updates            | 13510       |\n",
      "|    policy_gradient_loss | -5.04e-05   |\n",
      "|    reward               | -0.3183108  |\n",
      "|    std                  | 6.64        |\n",
      "|    value_loss           | 290         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1353        |\n",
      "|    time_elapsed         | 25084       |\n",
      "|    total_timesteps      | 2770944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008351679 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.7       |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.8        |\n",
      "|    n_updates            | 13520       |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    reward               | -0.19558072 |\n",
      "|    std                  | 6.64        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1354        |\n",
      "|    time_elapsed         | 25103       |\n",
      "|    total_timesteps      | 2772992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013168147 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.8       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 13530       |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    reward               | -0.7009187  |\n",
      "|    std                  | 6.66        |\n",
      "|    value_loss           | 43          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5893519.10\n",
      "total_reward: 4893519.10\n",
      "total_cost: 184494.69\n",
      "total_trades: 58859\n",
      "Sharpe: 0.811\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1355         |\n",
      "|    time_elapsed         | 25122        |\n",
      "|    total_timesteps      | 2775040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041296445 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.8        |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.5         |\n",
      "|    n_updates            | 13540        |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    reward               | -1.3343105   |\n",
      "|    std                  | 6.67         |\n",
      "|    value_loss           | 146          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1356        |\n",
      "|    time_elapsed         | 25141       |\n",
      "|    total_timesteps      | 2777088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004240661 |\n",
      "|    clip_fraction        | 0.00723     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.8        |\n",
      "|    n_updates            | 13550       |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    reward               | -0.23141687 |\n",
      "|    std                  | 6.67        |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1357        |\n",
      "|    time_elapsed         | 25159       |\n",
      "|    total_timesteps      | 2779136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006271178 |\n",
      "|    clip_fraction        | 0.0472      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.6        |\n",
      "|    n_updates            | 13560       |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    reward               | -2.032801   |\n",
      "|    std                  | 6.67        |\n",
      "|    value_loss           | 87.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1358        |\n",
      "|    time_elapsed         | 25177       |\n",
      "|    total_timesteps      | 2781184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011826709 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 13570       |\n",
      "|    policy_gradient_loss | -0.00975    |\n",
      "|    reward               | 2.5430055   |\n",
      "|    std                  | 6.67        |\n",
      "|    value_loss           | 78.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1359        |\n",
      "|    time_elapsed         | 25196       |\n",
      "|    total_timesteps      | 2783232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004869935 |\n",
      "|    clip_fraction        | 0.0101      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.8        |\n",
      "|    n_updates            | 13580       |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    reward               | -0.6178408  |\n",
      "|    std                  | 6.68        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1360         |\n",
      "|    time_elapsed         | 25214        |\n",
      "|    total_timesteps      | 2785280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024129935 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.9        |\n",
      "|    explained_variance   | 0.761        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.4         |\n",
      "|    n_updates            | 13590        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    reward               | 0.022873234  |\n",
      "|    std                  | 6.68         |\n",
      "|    value_loss           | 147          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1361        |\n",
      "|    time_elapsed         | 25232       |\n",
      "|    total_timesteps      | 2787328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011825755 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 13600       |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    reward               | -3.2839518  |\n",
      "|    std                  | 6.68        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1362        |\n",
      "|    time_elapsed         | 25251       |\n",
      "|    total_timesteps      | 2789376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005416521 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.2        |\n",
      "|    n_updates            | 13610       |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    reward               | 2.0641897   |\n",
      "|    std                  | 6.68        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1363         |\n",
      "|    time_elapsed         | 25270        |\n",
      "|    total_timesteps      | 2791424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023629945 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.9        |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.2         |\n",
      "|    n_updates            | 13620        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | -0.4281384   |\n",
      "|    std                  | 6.69         |\n",
      "|    value_loss           | 155          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1364        |\n",
      "|    time_elapsed         | 25288       |\n",
      "|    total_timesteps      | 2793472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008574548 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.2        |\n",
      "|    n_updates            | 13630       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | 1.5126036   |\n",
      "|    std                  | 6.69        |\n",
      "|    value_loss           | 60.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1365         |\n",
      "|    time_elapsed         | 25307        |\n",
      "|    total_timesteps      | 2795520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098043075 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.9        |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 13640        |\n",
      "|    policy_gradient_loss | -0.00679     |\n",
      "|    reward               | 1.682914     |\n",
      "|    std                  | 6.69         |\n",
      "|    value_loss           | 81.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1366        |\n",
      "|    time_elapsed         | 25326       |\n",
      "|    total_timesteps      | 2797568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005513599 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96         |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 13650       |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    reward               | -0.18259314 |\n",
      "|    std                  | 6.69        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1367         |\n",
      "|    time_elapsed         | 25345        |\n",
      "|    total_timesteps      | 2799616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064762086 |\n",
      "|    clip_fraction        | 0.0413       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96          |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.4         |\n",
      "|    n_updates            | 13660        |\n",
      "|    policy_gradient_loss | -0.00637     |\n",
      "|    reward               | 3.4574594    |\n",
      "|    std                  | 6.7          |\n",
      "|    value_loss           | 146          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1368        |\n",
      "|    time_elapsed         | 25364       |\n",
      "|    total_timesteps      | 2801664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011020731 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96         |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 13670       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 0.3000967   |\n",
      "|    std                  | 6.71        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5700740.64\n",
      "total_reward: 4700740.64\n",
      "total_cost: 182398.64\n",
      "total_trades: 58886\n",
      "Sharpe: 0.810\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1369        |\n",
      "|    time_elapsed         | 25382       |\n",
      "|    total_timesteps      | 2803712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005167336 |\n",
      "|    clip_fraction        | 0.0189      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96         |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 13680       |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | -0.27791062 |\n",
      "|    std                  | 6.71        |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1370         |\n",
      "|    time_elapsed         | 25400        |\n",
      "|    total_timesteps      | 2805760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035934458 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96          |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.3         |\n",
      "|    n_updates            | 13690        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | 0.3057761    |\n",
      "|    std                  | 6.72         |\n",
      "|    value_loss           | 192          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1371        |\n",
      "|    time_elapsed         | 25419       |\n",
      "|    total_timesteps      | 2807808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009211989 |\n",
      "|    clip_fraction        | 0.0995      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.1       |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 13700       |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | 0.96309155  |\n",
      "|    std                  | 6.73        |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1372        |\n",
      "|    time_elapsed         | 25437       |\n",
      "|    total_timesteps      | 2809856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009598806 |\n",
      "|    clip_fraction        | 0.0348      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.1       |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 13710       |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    reward               | -2.4711115  |\n",
      "|    std                  | 6.73        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1373         |\n",
      "|    time_elapsed         | 25456        |\n",
      "|    total_timesteps      | 2811904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016185701 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.1        |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.9         |\n",
      "|    n_updates            | 13720        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | -1.1293195   |\n",
      "|    std                  | 6.74         |\n",
      "|    value_loss           | 167          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1374         |\n",
      "|    time_elapsed         | 25475        |\n",
      "|    total_timesteps      | 2813952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077210567 |\n",
      "|    clip_fraction        | 0.0403       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.2        |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53           |\n",
      "|    n_updates            | 13730        |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    reward               | -0.089262396 |\n",
      "|    std                  | 6.74         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1375        |\n",
      "|    time_elapsed         | 25493       |\n",
      "|    total_timesteps      | 2816000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009205129 |\n",
      "|    clip_fraction        | 0.0787      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.9        |\n",
      "|    n_updates            | 13740       |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    reward               | -3.1863706  |\n",
      "|    std                  | 6.74        |\n",
      "|    value_loss           | 77.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1376         |\n",
      "|    time_elapsed         | 25511        |\n",
      "|    total_timesteps      | 2818048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075780633 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.2        |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.8         |\n",
      "|    n_updates            | 13750        |\n",
      "|    policy_gradient_loss | -0.00789     |\n",
      "|    reward               | 0.5209106    |\n",
      "|    std                  | 6.75         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1377         |\n",
      "|    time_elapsed         | 25530        |\n",
      "|    total_timesteps      | 2820096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022713942 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.2        |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.3         |\n",
      "|    n_updates            | 13760        |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    reward               | -3.721315    |\n",
      "|    std                  | 6.75         |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1378        |\n",
      "|    time_elapsed         | 25549       |\n",
      "|    total_timesteps      | 2822144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011786064 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.3       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 13770       |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    reward               | -0.8831024  |\n",
      "|    std                  | 6.77        |\n",
      "|    value_loss           | 42.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1379         |\n",
      "|    time_elapsed         | 25568        |\n",
      "|    total_timesteps      | 2824192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049228733 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.3        |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82.1         |\n",
      "|    n_updates            | 13780        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | -0.73210984  |\n",
      "|    std                  | 6.78         |\n",
      "|    value_loss           | 156          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1380        |\n",
      "|    time_elapsed         | 25586       |\n",
      "|    total_timesteps      | 2826240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002994918 |\n",
      "|    clip_fraction        | 0.00337     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.3       |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.4        |\n",
      "|    n_updates            | 13790       |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    reward               | -3.2726846  |\n",
      "|    std                  | 6.78        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1381        |\n",
      "|    time_elapsed         | 25604       |\n",
      "|    total_timesteps      | 2828288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007945088 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.4       |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.2        |\n",
      "|    n_updates            | 13800       |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    reward               | -4.0511813  |\n",
      "|    std                  | 6.79        |\n",
      "|    value_loss           | 90.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1382        |\n",
      "|    time_elapsed         | 25623       |\n",
      "|    total_timesteps      | 2830336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011905467 |\n",
      "|    clip_fraction        | 0.0943      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.4       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.9        |\n",
      "|    n_updates            | 13810       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 0.001057715 |\n",
      "|    std                  | 6.8         |\n",
      "|    value_loss           | 93.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5875767.01\n",
      "total_reward: 4875767.01\n",
      "total_cost: 256332.42\n",
      "total_trades: 62723\n",
      "Sharpe: 0.810\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1383         |\n",
      "|    time_elapsed         | 25641        |\n",
      "|    total_timesteps      | 2832384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035758007 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.4        |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75           |\n",
      "|    n_updates            | 13820        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | 0.72663057   |\n",
      "|    std                  | 6.8          |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1384         |\n",
      "|    time_elapsed         | 25660        |\n",
      "|    total_timesteps      | 2834432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042976197 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.4        |\n",
      "|    explained_variance   | 0.267        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 89.8         |\n",
      "|    n_updates            | 13830        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    reward               | 1.4517554    |\n",
      "|    std                  | 6.81         |\n",
      "|    value_loss           | 156          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1385       |\n",
      "|    time_elapsed         | 25679      |\n",
      "|    total_timesteps      | 2836480    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01741857 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96.5      |\n",
      "|    explained_variance   | 0.437      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16         |\n",
      "|    n_updates            | 13840      |\n",
      "|    policy_gradient_loss | -0.00859   |\n",
      "|    reward               | -1.20895   |\n",
      "|    std                  | 6.82       |\n",
      "|    value_loss           | 36.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1386         |\n",
      "|    time_elapsed         | 25697        |\n",
      "|    total_timesteps      | 2838528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046906266 |\n",
      "|    clip_fraction        | 0.0301       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.5        |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 89.3         |\n",
      "|    n_updates            | 13850        |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    reward               | -0.98627985  |\n",
      "|    std                  | 6.83         |\n",
      "|    value_loss           | 165          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1387        |\n",
      "|    time_elapsed         | 25715       |\n",
      "|    total_timesteps      | 2840576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008698732 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.5       |\n",
      "|    explained_variance   | 0.0192      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 189         |\n",
      "|    n_updates            | 13860       |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    reward               | -0.8870383  |\n",
      "|    std                  | 6.83        |\n",
      "|    value_loss           | 356         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1388        |\n",
      "|    time_elapsed         | 25733       |\n",
      "|    total_timesteps      | 2842624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009944409 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.3        |\n",
      "|    n_updates            | 13870       |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    reward               | -0.33190504 |\n",
      "|    std                  | 6.83        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1389        |\n",
      "|    time_elapsed         | 25751       |\n",
      "|    total_timesteps      | 2844672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005765712 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 13880       |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    reward               | 0.085515045 |\n",
      "|    std                  | 6.84        |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1390        |\n",
      "|    time_elapsed         | 25770       |\n",
      "|    total_timesteps      | 2846720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002455242 |\n",
      "|    clip_fraction        | 0.00278     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.1        |\n",
      "|    n_updates            | 13890       |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    reward               | -0.5087036  |\n",
      "|    std                  | 6.84        |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1391        |\n",
      "|    time_elapsed         | 25789       |\n",
      "|    total_timesteps      | 2848768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002433771 |\n",
      "|    clip_fraction        | 0.00132     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70          |\n",
      "|    n_updates            | 13900       |\n",
      "|    policy_gradient_loss | -0.00244    |\n",
      "|    reward               | -1.1754736  |\n",
      "|    std                  | 6.84        |\n",
      "|    value_loss           | 230         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1392        |\n",
      "|    time_elapsed         | 25807       |\n",
      "|    total_timesteps      | 2850816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012634685 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 13910       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 1.4227355   |\n",
      "|    std                  | 6.87        |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1393         |\n",
      "|    time_elapsed         | 25825        |\n",
      "|    total_timesteps      | 2852864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038706511 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.7        |\n",
      "|    explained_variance   | 0.269        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 283          |\n",
      "|    n_updates            | 13920        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    reward               | 0.30169824   |\n",
      "|    std                  | 6.88         |\n",
      "|    value_loss           | 226          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1394         |\n",
      "|    time_elapsed         | 25844        |\n",
      "|    total_timesteps      | 2854912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011225506 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.7        |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.9         |\n",
      "|    n_updates            | 13930        |\n",
      "|    policy_gradient_loss | -0.000401    |\n",
      "|    reward               | 0.026195724  |\n",
      "|    std                  | 6.88         |\n",
      "|    value_loss           | 266          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1395        |\n",
      "|    time_elapsed         | 25862       |\n",
      "|    total_timesteps      | 2856960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007724409 |\n",
      "|    clip_fraction        | 0.0345      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 13940       |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | 6.8529425   |\n",
      "|    std                  | 6.88        |\n",
      "|    value_loss           | 70.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1396        |\n",
      "|    time_elapsed         | 25881       |\n",
      "|    total_timesteps      | 2859008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005986561 |\n",
      "|    clip_fraction        | 0.0373      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.8       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 169         |\n",
      "|    n_updates            | 13950       |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | 0.296732    |\n",
      "|    std                  | 6.89        |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1397         |\n",
      "|    time_elapsed         | 25899        |\n",
      "|    total_timesteps      | 2861056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030053002 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.8        |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 126          |\n",
      "|    n_updates            | 13960        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    reward               | 3.0134003    |\n",
      "|    std                  | 6.89         |\n",
      "|    value_loss           | 175          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5507569.06\n",
      "total_reward: 4507569.06\n",
      "total_cost: 245825.18\n",
      "total_trades: 63155\n",
      "Sharpe: 0.790\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1398         |\n",
      "|    time_elapsed         | 25918        |\n",
      "|    total_timesteps      | 2863104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029447596 |\n",
      "|    clip_fraction        | 0.00376      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.8        |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42           |\n",
      "|    n_updates            | 13970        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | 1.1888603    |\n",
      "|    std                  | 6.9          |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1399        |\n",
      "|    time_elapsed         | 25936       |\n",
      "|    total_timesteps      | 2865152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011173134 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.9       |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 13980       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 1.4185208   |\n",
      "|    std                  | 6.91        |\n",
      "|    value_loss           | 92.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1400        |\n",
      "|    time_elapsed         | 25955       |\n",
      "|    total_timesteps      | 2867200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003992241 |\n",
      "|    clip_fraction        | 0.00967     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.9       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98.9        |\n",
      "|    n_updates            | 13990       |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    reward               | 0.103632815 |\n",
      "|    std                  | 6.92        |\n",
      "|    value_loss           | 317         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1401         |\n",
      "|    time_elapsed         | 25974        |\n",
      "|    total_timesteps      | 2869248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044697495 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.9        |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 116          |\n",
      "|    n_updates            | 14000        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | 8.042982     |\n",
      "|    std                  | 6.92         |\n",
      "|    value_loss           | 195          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1402        |\n",
      "|    time_elapsed         | 25992       |\n",
      "|    total_timesteps      | 2871296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009936295 |\n",
      "|    clip_fraction        | 0.0946      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.9       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 14010       |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    reward               | -2.9357548  |\n",
      "|    std                  | 6.93        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1403        |\n",
      "|    time_elapsed         | 26010       |\n",
      "|    total_timesteps      | 2873344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006116095 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.6        |\n",
      "|    n_updates            | 14020       |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    reward               | -1.1355364  |\n",
      "|    std                  | 6.94        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1404        |\n",
      "|    time_elapsed         | 26029       |\n",
      "|    total_timesteps      | 2875392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004100177 |\n",
      "|    clip_fraction        | 0.00732     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.1        |\n",
      "|    n_updates            | 14030       |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    reward               | -2.939169   |\n",
      "|    std                  | 6.94        |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1405        |\n",
      "|    time_elapsed         | 26048       |\n",
      "|    total_timesteps      | 2877440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008381665 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.8        |\n",
      "|    n_updates            | 14040       |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    reward               | 2.337476    |\n",
      "|    std                  | 6.95        |\n",
      "|    value_loss           | 94.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1406        |\n",
      "|    time_elapsed         | 26066       |\n",
      "|    total_timesteps      | 2879488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010532552 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.1       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37          |\n",
      "|    n_updates            | 14050       |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    reward               | 0.49949482  |\n",
      "|    std                  | 6.97        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1407        |\n",
      "|    time_elapsed         | 26085       |\n",
      "|    total_timesteps      | 2881536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004730821 |\n",
      "|    clip_fraction        | 0.028       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.1       |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 14060       |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    reward               | 0.020047935 |\n",
      "|    std                  | 6.97        |\n",
      "|    value_loss           | 217         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1408         |\n",
      "|    time_elapsed         | 26105        |\n",
      "|    total_timesteps      | 2883584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039387653 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.1        |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 124          |\n",
      "|    n_updates            | 14070        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | -5.0006027   |\n",
      "|    std                  | 6.97         |\n",
      "|    value_loss           | 182          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1409        |\n",
      "|    time_elapsed         | 26123       |\n",
      "|    total_timesteps      | 2885632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012355477 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.2       |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 14080       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 1.1564906   |\n",
      "|    std                  | 6.98        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1410        |\n",
      "|    time_elapsed         | 26141       |\n",
      "|    total_timesteps      | 2887680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004422065 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.2       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81          |\n",
      "|    n_updates            | 14090       |\n",
      "|    policy_gradient_loss | -0.0025     |\n",
      "|    reward               | -1.3635463  |\n",
      "|    std                  | 6.99        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1411         |\n",
      "|    time_elapsed         | 26160        |\n",
      "|    total_timesteps      | 2889728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066461624 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.2        |\n",
      "|    explained_variance   | 0.0738       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 175          |\n",
      "|    n_updates            | 14100        |\n",
      "|    policy_gradient_loss | -0.0073      |\n",
      "|    reward               | -1.6909953   |\n",
      "|    std                  | 6.99         |\n",
      "|    value_loss           | 300          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5575521.81\n",
      "total_reward: 4575521.81\n",
      "total_cost: 304288.16\n",
      "total_trades: 66191\n",
      "Sharpe: 0.776\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1412        |\n",
      "|    time_elapsed         | 26178       |\n",
      "|    total_timesteps      | 2891776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009881691 |\n",
      "|    clip_fraction        | 0.0579      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.2       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 14110       |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | -7.3619924  |\n",
      "|    std                  | 6.99        |\n",
      "|    value_loss           | 68.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1413        |\n",
      "|    time_elapsed         | 26197       |\n",
      "|    total_timesteps      | 2893824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009619411 |\n",
      "|    clip_fraction        | 0.0687      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.2       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 14120       |\n",
      "|    policy_gradient_loss | -0.00618    |\n",
      "|    reward               | 1.1480837   |\n",
      "|    std                  | 6.99        |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1414         |\n",
      "|    time_elapsed         | 26215        |\n",
      "|    total_timesteps      | 2895872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018373256 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.2        |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 131          |\n",
      "|    n_updates            | 14130        |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    reward               | 3.3636148    |\n",
      "|    std                  | 6.99         |\n",
      "|    value_loss           | 285          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1415         |\n",
      "|    time_elapsed         | 26234        |\n",
      "|    total_timesteps      | 2897920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036668715 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.2        |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.6         |\n",
      "|    n_updates            | 14140        |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | -1.8939718   |\n",
      "|    std                  | 7            |\n",
      "|    value_loss           | 147          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1416        |\n",
      "|    time_elapsed         | 26252       |\n",
      "|    total_timesteps      | 2899968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012811804 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | -0.047      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 14150       |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    reward               | 1.6784499   |\n",
      "|    std                  | 7.01        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1417       |\n",
      "|    time_elapsed         | 26270      |\n",
      "|    total_timesteps      | 2902016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01144287 |\n",
      "|    clip_fraction        | 0.093      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.3      |\n",
      "|    explained_variance   | -0.0201    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.1       |\n",
      "|    n_updates            | 14160      |\n",
      "|    policy_gradient_loss | -0.00903   |\n",
      "|    reward               | -4.8685193 |\n",
      "|    std                  | 7.03       |\n",
      "|    value_loss           | 153        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1418         |\n",
      "|    time_elapsed         | 26289        |\n",
      "|    total_timesteps      | 2904064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046327817 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.4        |\n",
      "|    explained_variance   | 0.0649       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 197          |\n",
      "|    n_updates            | 14170        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    reward               | -7.3671265   |\n",
      "|    std                  | 7.04         |\n",
      "|    value_loss           | 433          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1419        |\n",
      "|    time_elapsed         | 26307       |\n",
      "|    total_timesteps      | 2906112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013145307 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 14180       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 0.6700263   |\n",
      "|    std                  | 7.07        |\n",
      "|    value_loss           | 42.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1420        |\n",
      "|    time_elapsed         | 26325       |\n",
      "|    total_timesteps      | 2908160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010712159 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 14190       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 1.9713786   |\n",
      "|    std                  | 7.07        |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1421        |\n",
      "|    time_elapsed         | 26344       |\n",
      "|    total_timesteps      | 2910208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007414255 |\n",
      "|    clip_fraction        | 0.0559      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.0831      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.6        |\n",
      "|    n_updates            | 14200       |\n",
      "|    policy_gradient_loss | -0.00999    |\n",
      "|    reward               | 6.7716327   |\n",
      "|    std                  | 7.08        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1422        |\n",
      "|    time_elapsed         | 26363       |\n",
      "|    total_timesteps      | 2912256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006927483 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.6       |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.2        |\n",
      "|    n_updates            | 14210       |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    reward               | -0.50773776 |\n",
      "|    std                  | 7.08        |\n",
      "|    value_loss           | 82.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1423       |\n",
      "|    time_elapsed         | 26381      |\n",
      "|    total_timesteps      | 2914304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0111829  |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.6      |\n",
      "|    explained_variance   | 0.364      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 42.2       |\n",
      "|    n_updates            | 14220      |\n",
      "|    policy_gradient_loss | -0.0098    |\n",
      "|    reward               | 0.06741008 |\n",
      "|    std                  | 7.1        |\n",
      "|    value_loss           | 85.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1424        |\n",
      "|    time_elapsed         | 26399       |\n",
      "|    total_timesteps      | 2916352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004658201 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.7       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.4        |\n",
      "|    n_updates            | 14230       |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    reward               | 2.9947336   |\n",
      "|    std                  | 7.1         |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1425         |\n",
      "|    time_elapsed         | 26417        |\n",
      "|    total_timesteps      | 2918400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064896974 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.7        |\n",
      "|    explained_variance   | 0.231        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.9         |\n",
      "|    n_updates            | 14240        |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    reward               | 0.21220489   |\n",
      "|    std                  | 7.11         |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5838534.79\n",
      "total_reward: 4838534.79\n",
      "total_cost: 265073.06\n",
      "total_trades: 64718\n",
      "Sharpe: 0.817\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1426        |\n",
      "|    time_elapsed         | 26437       |\n",
      "|    total_timesteps      | 2920448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010434625 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.7       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 14250       |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    reward               | -0.5466749  |\n",
      "|    std                  | 7.13        |\n",
      "|    value_loss           | 49          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1427        |\n",
      "|    time_elapsed         | 26455       |\n",
      "|    total_timesteps      | 2922496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00935416  |\n",
      "|    clip_fraction        | 0.0452      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 14260       |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    reward               | -0.45732155 |\n",
      "|    std                  | 7.12        |\n",
      "|    value_loss           | 98.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1428        |\n",
      "|    time_elapsed         | 26473       |\n",
      "|    total_timesteps      | 2924544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002319335 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 14270       |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    reward               | -1.6271791  |\n",
      "|    std                  | 7.13        |\n",
      "|    value_loss           | 93.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1429       |\n",
      "|    time_elapsed         | 26492      |\n",
      "|    total_timesteps      | 2926592    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00899361 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.8      |\n",
      "|    explained_variance   | 0.142      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 39.9       |\n",
      "|    n_updates            | 14280      |\n",
      "|    policy_gradient_loss | -0.00691   |\n",
      "|    reward               | -9.916125  |\n",
      "|    std                  | 7.13       |\n",
      "|    value_loss           | 82.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1430        |\n",
      "|    time_elapsed         | 26511       |\n",
      "|    total_timesteps      | 2928640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009362961 |\n",
      "|    clip_fraction        | 0.0508      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.9        |\n",
      "|    n_updates            | 14290       |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | 1.2257489   |\n",
      "|    std                  | 7.14        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1431         |\n",
      "|    time_elapsed         | 26531        |\n",
      "|    total_timesteps      | 2930688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007577448  |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.9        |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 14300        |\n",
      "|    policy_gradient_loss | -0.00703     |\n",
      "|    reward               | -0.064810164 |\n",
      "|    std                  | 7.15         |\n",
      "|    value_loss           | 155          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1432        |\n",
      "|    time_elapsed         | 26549       |\n",
      "|    total_timesteps      | 2932736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007952932 |\n",
      "|    clip_fraction        | 0.0342      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.4        |\n",
      "|    n_updates            | 14310       |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    reward               | -1.5033681  |\n",
      "|    std                  | 7.15        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1433        |\n",
      "|    time_elapsed         | 26567       |\n",
      "|    total_timesteps      | 2934784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009999209 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 14320       |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    reward               | 2.5215533   |\n",
      "|    std                  | 7.17        |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1434         |\n",
      "|    time_elapsed         | 26585        |\n",
      "|    total_timesteps      | 2936832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052443417 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.9        |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.7         |\n",
      "|    n_updates            | 14330        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | 0.14485504   |\n",
      "|    std                  | 7.17         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1435        |\n",
      "|    time_elapsed         | 26603       |\n",
      "|    total_timesteps      | 2938880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006882929 |\n",
      "|    clip_fraction        | 0.0265      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.1        |\n",
      "|    n_updates            | 14340       |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    reward               | -4.699025   |\n",
      "|    std                  | 7.17        |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1436        |\n",
      "|    time_elapsed         | 26622       |\n",
      "|    total_timesteps      | 2940928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007437961 |\n",
      "|    clip_fraction        | 0.0317      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98         |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.8        |\n",
      "|    n_updates            | 14350       |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    reward               | 5.1472344   |\n",
      "|    std                  | 7.18        |\n",
      "|    value_loss           | 87.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1437         |\n",
      "|    time_elapsed         | 26640        |\n",
      "|    total_timesteps      | 2942976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090513425 |\n",
      "|    clip_fraction        | 0.0553       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98          |\n",
      "|    explained_variance   | 0.295        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.2         |\n",
      "|    n_updates            | 14360        |\n",
      "|    policy_gradient_loss | -0.00841     |\n",
      "|    reward               | -0.90649164  |\n",
      "|    std                  | 7.19         |\n",
      "|    value_loss           | 93           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1438        |\n",
      "|    time_elapsed         | 26658       |\n",
      "|    total_timesteps      | 2945024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006080903 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98         |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.7        |\n",
      "|    n_updates            | 14370       |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    reward               | -13.087347  |\n",
      "|    std                  | 7.19        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1439         |\n",
      "|    time_elapsed         | 26676        |\n",
      "|    total_timesteps      | 2947072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074393097 |\n",
      "|    clip_fraction        | 0.0475       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98          |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.8         |\n",
      "|    n_updates            | 14380        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    reward               | -0.6591314   |\n",
      "|    std                  | 7.2          |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5732687.71\n",
      "total_reward: 4732687.71\n",
      "total_cost: 191845.10\n",
      "total_trades: 60442\n",
      "Sharpe: 0.776\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1440         |\n",
      "|    time_elapsed         | 26695        |\n",
      "|    total_timesteps      | 2949120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014757113  |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.1        |\n",
      "|    explained_variance   | 0.172        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 14390        |\n",
      "|    policy_gradient_loss | -0.00856     |\n",
      "|    reward               | -0.084179804 |\n",
      "|    std                  | 7.22         |\n",
      "|    value_loss           | 50.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1441        |\n",
      "|    time_elapsed         | 26713       |\n",
      "|    total_timesteps      | 2951168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009403847 |\n",
      "|    clip_fraction        | 0.0468      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.4        |\n",
      "|    n_updates            | 14400       |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | 0.19286086  |\n",
      "|    std                  | 7.23        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1442         |\n",
      "|    time_elapsed         | 26732        |\n",
      "|    total_timesteps      | 2953216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063492507 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.2        |\n",
      "|    explained_variance   | 0.26         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.8         |\n",
      "|    n_updates            | 14410        |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    reward               | 3.1343176    |\n",
      "|    std                  | 7.23         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1443        |\n",
      "|    time_elapsed         | 26751       |\n",
      "|    total_timesteps      | 2955264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010148942 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.2       |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 14420       |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    reward               | -4.439338   |\n",
      "|    std                  | 7.24        |\n",
      "|    value_loss           | 55.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1444        |\n",
      "|    time_elapsed         | 26770       |\n",
      "|    total_timesteps      | 2957312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009855589 |\n",
      "|    clip_fraction        | 0.0752      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.3       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.1        |\n",
      "|    n_updates            | 14430       |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    reward               | 1.7025949   |\n",
      "|    std                  | 7.26        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1445        |\n",
      "|    time_elapsed         | 26789       |\n",
      "|    total_timesteps      | 2959360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007643724 |\n",
      "|    clip_fraction        | 0.0541      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.3       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.8        |\n",
      "|    n_updates            | 14440       |\n",
      "|    policy_gradient_loss | -0.00745    |\n",
      "|    reward               | 2.933422    |\n",
      "|    std                  | 7.26        |\n",
      "|    value_loss           | 92.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1446        |\n",
      "|    time_elapsed         | 26808       |\n",
      "|    total_timesteps      | 2961408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007684837 |\n",
      "|    clip_fraction        | 0.0378      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.3       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 14450       |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    reward               | -1.0971812  |\n",
      "|    std                  | 7.26        |\n",
      "|    value_loss           | 84.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1447        |\n",
      "|    time_elapsed         | 26827       |\n",
      "|    total_timesteps      | 2963456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011091335 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.3       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 14460       |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    reward               | 1.9025023   |\n",
      "|    std                  | 7.28        |\n",
      "|    value_loss           | 68.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1448        |\n",
      "|    time_elapsed         | 26846       |\n",
      "|    total_timesteps      | 2965504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012590541 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.9        |\n",
      "|    n_updates            | 14470       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.6857418   |\n",
      "|    std                  | 7.29        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1449        |\n",
      "|    time_elapsed         | 26866       |\n",
      "|    total_timesteps      | 2967552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008554606 |\n",
      "|    clip_fraction        | 0.0306      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.0511      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 14480       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | -1.4319999  |\n",
      "|    std                  | 7.29        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1450         |\n",
      "|    time_elapsed         | 26884        |\n",
      "|    total_timesteps      | 2969600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092350375 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.5        |\n",
      "|    explained_variance   | 0.288        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 14490        |\n",
      "|    policy_gradient_loss | -0.00898     |\n",
      "|    reward               | 3.1248407    |\n",
      "|    std                  | 7.31         |\n",
      "|    value_loss           | 40.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1451        |\n",
      "|    time_elapsed         | 26903       |\n",
      "|    total_timesteps      | 2971648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010705132 |\n",
      "|    clip_fraction        | 0.0634      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.5       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.2        |\n",
      "|    n_updates            | 14500       |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    reward               | 0.2922386   |\n",
      "|    std                  | 7.33        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1452         |\n",
      "|    time_elapsed         | 26922        |\n",
      "|    total_timesteps      | 2973696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068967957 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.6        |\n",
      "|    explained_variance   | 0.142        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.4         |\n",
      "|    n_updates            | 14510        |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    reward               | -2.7031615   |\n",
      "|    std                  | 7.33         |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1453         |\n",
      "|    time_elapsed         | 26941        |\n",
      "|    total_timesteps      | 2975744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070198188 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.6        |\n",
      "|    explained_variance   | 0.188        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38           |\n",
      "|    n_updates            | 14520        |\n",
      "|    policy_gradient_loss | -0.00654     |\n",
      "|    reward               | 0.6396444    |\n",
      "|    std                  | 7.34         |\n",
      "|    value_loss           | 74.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6002275.95\n",
      "total_reward: 5002275.95\n",
      "total_cost: 196856.57\n",
      "total_trades: 61055\n",
      "Sharpe: 0.840\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1454        |\n",
      "|    time_elapsed         | 26959       |\n",
      "|    total_timesteps      | 2977792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007259678 |\n",
      "|    clip_fraction        | 0.0379      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.6       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 14530       |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | -0.6365093  |\n",
      "|    std                  | 7.35        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1455         |\n",
      "|    time_elapsed         | 26977        |\n",
      "|    total_timesteps      | 2979840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075398386 |\n",
      "|    clip_fraction        | 0.0316       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.7        |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.1         |\n",
      "|    n_updates            | 14540        |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    reward               | 1.98599      |\n",
      "|    std                  | 7.36         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1456        |\n",
      "|    time_elapsed         | 26996       |\n",
      "|    total_timesteps      | 2981888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010067304 |\n",
      "|    clip_fraction        | 0.0409      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 14550       |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    reward               | 0.46656364  |\n",
      "|    std                  | 7.37        |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1457        |\n",
      "|    time_elapsed         | 27014       |\n",
      "|    total_timesteps      | 2983936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007675653 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.8       |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 14560       |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    reward               | -1.0584985  |\n",
      "|    std                  | 7.39        |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1458         |\n",
      "|    time_elapsed         | 27032        |\n",
      "|    total_timesteps      | 2985984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102481395 |\n",
      "|    clip_fraction        | 0.0813       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.9        |\n",
      "|    explained_variance   | 0.312        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.8         |\n",
      "|    n_updates            | 14570        |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    reward               | 0.9606174    |\n",
      "|    std                  | 7.41         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1459        |\n",
      "|    time_elapsed         | 27051       |\n",
      "|    total_timesteps      | 2988032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010738032 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99         |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 14580       |\n",
      "|    policy_gradient_loss | -0.00762    |\n",
      "|    reward               | -8.100336   |\n",
      "|    std                  | 7.44        |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1460         |\n",
      "|    time_elapsed         | 27069        |\n",
      "|    total_timesteps      | 2990080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077667697 |\n",
      "|    clip_fraction        | 0.0667       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99          |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.2         |\n",
      "|    n_updates            | 14590        |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    reward               | -2.977789    |\n",
      "|    std                  | 7.44         |\n",
      "|    value_loss           | 65.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1461        |\n",
      "|    time_elapsed         | 27088       |\n",
      "|    total_timesteps      | 2992128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006389498 |\n",
      "|    clip_fraction        | 0.0337      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99         |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.3        |\n",
      "|    n_updates            | 14600       |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    reward               | 2.5033844   |\n",
      "|    std                  | 7.45        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1462        |\n",
      "|    time_elapsed         | 27106       |\n",
      "|    total_timesteps      | 2994176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005652642 |\n",
      "|    clip_fraction        | 0.0238      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99         |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57          |\n",
      "|    n_updates            | 14610       |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    reward               | 30.331411   |\n",
      "|    std                  | 7.44        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1463        |\n",
      "|    time_elapsed         | 27125       |\n",
      "|    total_timesteps      | 2996224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005792289 |\n",
      "|    clip_fraction        | 0.0174      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99         |\n",
      "|    explained_variance   | 0.0436      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.8        |\n",
      "|    n_updates            | 14620       |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    reward               | 0.47216603  |\n",
      "|    std                  | 7.45        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1464         |\n",
      "|    time_elapsed         | 27143        |\n",
      "|    total_timesteps      | 2998272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075065373 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.1        |\n",
      "|    explained_variance   | 0.235        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 14630        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    reward               | 2.2473788    |\n",
      "|    std                  | 7.46         |\n",
      "|    value_loss           | 65.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1465         |\n",
      "|    time_elapsed         | 27162        |\n",
      "|    total_timesteps      | 3000320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047189677 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.1        |\n",
      "|    explained_variance   | 0.233        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 14640        |\n",
      "|    policy_gradient_loss | -0.00524     |\n",
      "|    reward               | 0.73494375   |\n",
      "|    std                  | 7.45         |\n",
      "|    value_loss           | 191          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1466         |\n",
      "|    time_elapsed         | 27180        |\n",
      "|    total_timesteps      | 3002368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031202934 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.1        |\n",
      "|    explained_variance   | 0.107        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 14650        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | 5.121604     |\n",
      "|    std                  | 7.46         |\n",
      "|    value_loss           | 197          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1467        |\n",
      "|    time_elapsed         | 27198       |\n",
      "|    total_timesteps      | 3004416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005994732 |\n",
      "|    clip_fraction        | 0.0293      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.1       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 14660       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | 0.5522588   |\n",
      "|    std                  | 7.46        |\n",
      "|    value_loss           | 83.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6359041.47\n",
      "total_reward: 5359041.47\n",
      "total_cost: 213544.22\n",
      "total_trades: 61339\n",
      "Sharpe: 0.858\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1468        |\n",
      "|    time_elapsed         | 27216       |\n",
      "|    total_timesteps      | 3006464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010593529 |\n",
      "|    clip_fraction        | 0.0639      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.1       |\n",
      "|    explained_variance   | 0.0406      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.4        |\n",
      "|    n_updates            | 14670       |\n",
      "|    policy_gradient_loss | -0.00895    |\n",
      "|    reward               | -1.1653696  |\n",
      "|    std                  | 7.46        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1469         |\n",
      "|    time_elapsed         | 27234        |\n",
      "|    total_timesteps      | 3008512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071951896 |\n",
      "|    clip_fraction        | 0.0595       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.1        |\n",
      "|    explained_variance   | 0.0509       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 88.7         |\n",
      "|    n_updates            | 14680        |\n",
      "|    policy_gradient_loss | -0.00781     |\n",
      "|    reward               | 3.8928082    |\n",
      "|    std                  | 7.46         |\n",
      "|    value_loss           | 175          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1470         |\n",
      "|    time_elapsed         | 27253        |\n",
      "|    total_timesteps      | 3010560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061528767 |\n",
      "|    clip_fraction        | 0.0346       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.1        |\n",
      "|    explained_variance   | 0.126        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37           |\n",
      "|    n_updates            | 14690        |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    reward               | 0.45660868   |\n",
      "|    std                  | 7.46         |\n",
      "|    value_loss           | 99.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1471        |\n",
      "|    time_elapsed         | 27272       |\n",
      "|    total_timesteps      | 3012608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009222165 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.2       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.4        |\n",
      "|    n_updates            | 14700       |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | -0.64027405 |\n",
      "|    std                  | 7.49        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1472        |\n",
      "|    time_elapsed         | 27291       |\n",
      "|    total_timesteps      | 3014656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006884235 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.2       |\n",
      "|    explained_variance   | 0.0645      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.8        |\n",
      "|    n_updates            | 14710       |\n",
      "|    policy_gradient_loss | -0.00648    |\n",
      "|    reward               | 0.8653111   |\n",
      "|    std                  | 7.51        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1473        |\n",
      "|    time_elapsed         | 27309       |\n",
      "|    total_timesteps      | 3016704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009683146 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.3       |\n",
      "|    explained_variance   | 0.18        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 14720       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -0.7178359  |\n",
      "|    std                  | 7.51        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1474        |\n",
      "|    time_elapsed         | 27328       |\n",
      "|    total_timesteps      | 3018752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010495288 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.3       |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 14730       |\n",
      "|    policy_gradient_loss | -0.00889    |\n",
      "|    reward               | -1.3005813  |\n",
      "|    std                  | 7.53        |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1475        |\n",
      "|    time_elapsed         | 27345       |\n",
      "|    total_timesteps      | 3020800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009543037 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.4       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 14740       |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    reward               | -0.10255998 |\n",
      "|    std                  | 7.55        |\n",
      "|    value_loss           | 99.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1476        |\n",
      "|    time_elapsed         | 27364       |\n",
      "|    total_timesteps      | 3022848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004431475 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.5       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.9        |\n",
      "|    n_updates            | 14750       |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    reward               | 2.7337682   |\n",
      "|    std                  | 7.56        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1477         |\n",
      "|    time_elapsed         | 27382        |\n",
      "|    total_timesteps      | 3024896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045296503 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.5        |\n",
      "|    explained_variance   | 0.27         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.4         |\n",
      "|    n_updates            | 14760        |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    reward               | -4.738515    |\n",
      "|    std                  | 7.57         |\n",
      "|    value_loss           | 61.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1478         |\n",
      "|    time_elapsed         | 27401        |\n",
      "|    total_timesteps      | 3026944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060406113 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.5        |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36           |\n",
      "|    n_updates            | 14770        |\n",
      "|    policy_gradient_loss | -0.00669     |\n",
      "|    reward               | -2.3646557   |\n",
      "|    std                  | 7.57         |\n",
      "|    value_loss           | 73.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1479         |\n",
      "|    time_elapsed         | 27420        |\n",
      "|    total_timesteps      | 3028992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042837886 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.5        |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.9         |\n",
      "|    n_updates            | 14780        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    reward               | 0.18249337   |\n",
      "|    std                  | 7.58         |\n",
      "|    value_loss           | 99.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1480         |\n",
      "|    time_elapsed         | 27438        |\n",
      "|    total_timesteps      | 3031040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056991475 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.6        |\n",
      "|    explained_variance   | 0.182        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.6         |\n",
      "|    n_updates            | 14790        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | -1.710075    |\n",
      "|    std                  | 7.58         |\n",
      "|    value_loss           | 146          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1481        |\n",
      "|    time_elapsed         | 27457       |\n",
      "|    total_timesteps      | 3033088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010090267 |\n",
      "|    clip_fraction        | 0.0767      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.6       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 14800       |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    reward               | -0.74701184 |\n",
      "|    std                  | 7.61        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4690083.88\n",
      "total_reward: 3690083.88\n",
      "total_cost: 201787.29\n",
      "total_trades: 61425\n",
      "Sharpe: 0.746\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1482        |\n",
      "|    time_elapsed         | 27475       |\n",
      "|    total_timesteps      | 3035136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005852559 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.3        |\n",
      "|    n_updates            | 14810       |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    reward               | 2.448165    |\n",
      "|    std                  | 7.62        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1483         |\n",
      "|    time_elapsed         | 27493        |\n",
      "|    total_timesteps      | 3037184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017304496 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.7        |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.4         |\n",
      "|    n_updates            | 14820        |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    reward               | -0.37470454  |\n",
      "|    std                  | 7.62         |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1484         |\n",
      "|    time_elapsed         | 27511        |\n",
      "|    total_timesteps      | 3039232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030558691 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.7        |\n",
      "|    explained_variance   | 0.189        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.6         |\n",
      "|    n_updates            | 14830        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    reward               | -7.182576    |\n",
      "|    std                  | 7.63         |\n",
      "|    value_loss           | 73.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1485        |\n",
      "|    time_elapsed         | 27529       |\n",
      "|    total_timesteps      | 3041280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010171145 |\n",
      "|    clip_fraction        | 0.07        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.8       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 14840       |\n",
      "|    policy_gradient_loss | -0.00916    |\n",
      "|    reward               | 0.37392607  |\n",
      "|    std                  | 7.65        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1486        |\n",
      "|    time_elapsed         | 27548       |\n",
      "|    total_timesteps      | 3043328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004066164 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.8       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.2        |\n",
      "|    n_updates            | 14850       |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    reward               | 5.806002    |\n",
      "|    std                  | 7.65        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1487         |\n",
      "|    time_elapsed         | 27567        |\n",
      "|    total_timesteps      | 3045376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050396705 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.8        |\n",
      "|    explained_variance   | 0.17         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.2         |\n",
      "|    n_updates            | 14860        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | -0.54943365  |\n",
      "|    std                  | 7.66         |\n",
      "|    value_loss           | 95.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1488        |\n",
      "|    time_elapsed         | 27585       |\n",
      "|    total_timesteps      | 3047424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009249196 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.9       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 14870       |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | 1.892788    |\n",
      "|    std                  | 7.67        |\n",
      "|    value_loss           | 85.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1489       |\n",
      "|    time_elapsed         | 27603      |\n",
      "|    total_timesteps      | 3049472    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00711508 |\n",
      "|    clip_fraction        | 0.0391     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -99.9      |\n",
      "|    explained_variance   | 0.214      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 41.6       |\n",
      "|    n_updates            | 14880      |\n",
      "|    policy_gradient_loss | -0.0066    |\n",
      "|    reward               | 0.5379538  |\n",
      "|    std                  | 7.68       |\n",
      "|    value_loss           | 106        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1490        |\n",
      "|    time_elapsed         | 27621       |\n",
      "|    total_timesteps      | 3051520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011959436 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 14890       |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | -2.963629   |\n",
      "|    std                  | 7.7         |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1491        |\n",
      "|    time_elapsed         | 27638       |\n",
      "|    total_timesteps      | 3053568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012145158 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 14900       |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    reward               | -1.704651   |\n",
      "|    std                  | 7.73        |\n",
      "|    value_loss           | 53.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1492        |\n",
      "|    time_elapsed         | 27657       |\n",
      "|    total_timesteps      | 3055616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008985434 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.0734      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.3        |\n",
      "|    n_updates            | 14910       |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    reward               | -0.49282423 |\n",
      "|    std                  | 7.73        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1493        |\n",
      "|    time_elapsed         | 27676       |\n",
      "|    total_timesteps      | 3057664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006619972 |\n",
      "|    clip_fraction        | 0.0555      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.0811      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.1        |\n",
      "|    n_updates            | 14920       |\n",
      "|    policy_gradient_loss | -0.00187    |\n",
      "|    reward               | -0.8981201  |\n",
      "|    std                  | 7.74        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1494        |\n",
      "|    time_elapsed         | 27695       |\n",
      "|    total_timesteps      | 3059712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010144112 |\n",
      "|    clip_fraction        | 0.0931      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.0345      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.6        |\n",
      "|    n_updates            | 14930       |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | -1.1429865  |\n",
      "|    std                  | 7.74        |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1495         |\n",
      "|    time_elapsed         | 27713        |\n",
      "|    total_timesteps      | 3061760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070566125 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.149        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.8         |\n",
      "|    n_updates            | 14940        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    reward               | -2.6055572   |\n",
      "|    std                  | 7.74         |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7467542.93\n",
      "total_reward: 6467542.93\n",
      "total_cost: 163430.67\n",
      "total_trades: 58859\n",
      "Sharpe: 0.934\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1496        |\n",
      "|    time_elapsed         | 27731       |\n",
      "|    total_timesteps      | 3063808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009589121 |\n",
      "|    clip_fraction        | 0.079       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.0768      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.1        |\n",
      "|    n_updates            | 14950       |\n",
      "|    policy_gradient_loss | -0.00882    |\n",
      "|    reward               | 0.8625909   |\n",
      "|    std                  | 7.74        |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1497        |\n",
      "|    time_elapsed         | 27750       |\n",
      "|    total_timesteps      | 3065856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007415862 |\n",
      "|    clip_fraction        | 0.0308      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.0787      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.7        |\n",
      "|    n_updates            | 14960       |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    reward               | -0.42792696 |\n",
      "|    std                  | 7.74        |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1498        |\n",
      "|    time_elapsed         | 27768       |\n",
      "|    total_timesteps      | 3067904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008638954 |\n",
      "|    clip_fraction        | 0.0773      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.7        |\n",
      "|    n_updates            | 14970       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | -0.9537869  |\n",
      "|    std                  | 7.76        |\n",
      "|    value_loss           | 68.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1499        |\n",
      "|    time_elapsed         | 27787       |\n",
      "|    total_timesteps      | 3069952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008004743 |\n",
      "|    clip_fraction        | 0.0452      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.9        |\n",
      "|    n_updates            | 14980       |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    reward               | -1.1141489  |\n",
      "|    std                  | 7.76        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1500       |\n",
      "|    time_elapsed         | 27805      |\n",
      "|    total_timesteps      | 3072000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00895598 |\n",
      "|    clip_fraction        | 0.0519     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -100       |\n",
      "|    explained_variance   | 0.33       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 69         |\n",
      "|    n_updates            | 14990      |\n",
      "|    policy_gradient_loss | -0.00918   |\n",
      "|    reward               | 5.8845015  |\n",
      "|    std                  | 7.77       |\n",
      "|    value_loss           | 156        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1501        |\n",
      "|    time_elapsed         | 27823       |\n",
      "|    total_timesteps      | 3074048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013357366 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35          |\n",
      "|    n_updates            | 15000       |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    reward               | -6.8815556  |\n",
      "|    std                  | 7.78        |\n",
      "|    value_loss           | 75.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1502        |\n",
      "|    time_elapsed         | 27841       |\n",
      "|    total_timesteps      | 3076096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009751428 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.7        |\n",
      "|    n_updates            | 15010       |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | -2.0782983  |\n",
      "|    std                  | 7.8         |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1503         |\n",
      "|    time_elapsed         | 27860        |\n",
      "|    total_timesteps      | 3078144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069897454 |\n",
      "|    clip_fraction        | 0.0367       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 103          |\n",
      "|    n_updates            | 15020        |\n",
      "|    policy_gradient_loss | -0.00769     |\n",
      "|    reward               | 11.26753     |\n",
      "|    std                  | 7.81         |\n",
      "|    value_loss           | 177          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1504         |\n",
      "|    time_elapsed         | 27879        |\n",
      "|    total_timesteps      | 3080192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076836925 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 101          |\n",
      "|    n_updates            | 15030        |\n",
      "|    policy_gradient_loss | -0.00524     |\n",
      "|    reward               | 0.3750467    |\n",
      "|    std                  | 7.82         |\n",
      "|    value_loss           | 195          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1505         |\n",
      "|    time_elapsed         | 27897        |\n",
      "|    total_timesteps      | 3082240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093505215 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.199        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.2         |\n",
      "|    n_updates            | 15040        |\n",
      "|    policy_gradient_loss | -0.00826     |\n",
      "|    reward               | -2.3108675   |\n",
      "|    std                  | 7.84         |\n",
      "|    value_loss           | 58.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1506        |\n",
      "|    time_elapsed         | 27916       |\n",
      "|    total_timesteps      | 3084288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009315539 |\n",
      "|    clip_fraction        | 0.0447      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.8        |\n",
      "|    n_updates            | 15050       |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    reward               | -0.16685683 |\n",
      "|    std                  | 7.85        |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1507        |\n",
      "|    time_elapsed         | 27935       |\n",
      "|    total_timesteps      | 3086336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008887196 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.8        |\n",
      "|    n_updates            | 15060       |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    reward               | 2.514416    |\n",
      "|    std                  | 7.86        |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1508        |\n",
      "|    time_elapsed         | 27953       |\n",
      "|    total_timesteps      | 3088384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009452321 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 15070       |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    reward               | -9.276764   |\n",
      "|    std                  | 7.87        |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1509         |\n",
      "|    time_elapsed         | 27971        |\n",
      "|    total_timesteps      | 3090432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054739416 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.357        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 85.6         |\n",
      "|    n_updates            | 15080        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | 2.0547564    |\n",
      "|    std                  | 7.88         |\n",
      "|    value_loss           | 177          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1510        |\n",
      "|    time_elapsed         | 27989       |\n",
      "|    total_timesteps      | 3092480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013853934 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.0901      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 15090       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 5.2384005   |\n",
      "|    std                  | 7.89        |\n",
      "|    value_loss           | 263         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8548957.81\n",
      "total_reward: 7548957.81\n",
      "total_cost: 172837.48\n",
      "total_trades: 58960\n",
      "Sharpe: 1.007\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1511        |\n",
      "|    time_elapsed         | 28008       |\n",
      "|    total_timesteps      | 3094528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008284133 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.0878      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.2        |\n",
      "|    n_updates            | 15100       |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    reward               | 2.8556192   |\n",
      "|    std                  | 7.91        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1512        |\n",
      "|    time_elapsed         | 28027       |\n",
      "|    total_timesteps      | 3096576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014793581 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94.7        |\n",
      "|    n_updates            | 15110       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | -1.6791399  |\n",
      "|    std                  | 7.93        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1513         |\n",
      "|    time_elapsed         | 28045        |\n",
      "|    total_timesteps      | 3098624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087507935 |\n",
      "|    clip_fraction        | 0.0634       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.174        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 97.9         |\n",
      "|    n_updates            | 15120        |\n",
      "|    policy_gradient_loss | -0.00855     |\n",
      "|    reward               | 0.003270641  |\n",
      "|    std                  | 7.94         |\n",
      "|    value_loss           | 208          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1514         |\n",
      "|    time_elapsed         | 28063        |\n",
      "|    total_timesteps      | 3100672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071239816 |\n",
      "|    clip_fraction        | 0.0376       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.237        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.9         |\n",
      "|    n_updates            | 15130        |\n",
      "|    policy_gradient_loss | -0.00634     |\n",
      "|    reward               | -1.2512991   |\n",
      "|    std                  | 7.96         |\n",
      "|    value_loss           | 159          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1515        |\n",
      "|    time_elapsed         | 28082       |\n",
      "|    total_timesteps      | 3102720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007861118 |\n",
      "|    clip_fraction        | 0.0697      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 15140       |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    reward               | 1.0412753   |\n",
      "|    std                  | 7.97        |\n",
      "|    value_loss           | 61.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1516         |\n",
      "|    time_elapsed         | 28102        |\n",
      "|    total_timesteps      | 3104768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059332103 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 15150        |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    reward               | 2.123245     |\n",
      "|    std                  | 7.98         |\n",
      "|    value_loss           | 179          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1517         |\n",
      "|    time_elapsed         | 28120        |\n",
      "|    total_timesteps      | 3106816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027426481 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 120          |\n",
      "|    n_updates            | 15160        |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    reward               | 1.0620762    |\n",
      "|    std                  | 7.98         |\n",
      "|    value_loss           | 223          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1518         |\n",
      "|    time_elapsed         | 28139        |\n",
      "|    total_timesteps      | 3108864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057494636 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.0964       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.1         |\n",
      "|    n_updates            | 15170        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    reward               | -7.473016    |\n",
      "|    std                  | 7.99         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1519        |\n",
      "|    time_elapsed         | 28158       |\n",
      "|    total_timesteps      | 3110912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010448612 |\n",
      "|    clip_fraction        | 0.0767      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.7        |\n",
      "|    n_updates            | 15180       |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    reward               | -0.58136874 |\n",
      "|    std                  | 8.01        |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1520        |\n",
      "|    time_elapsed         | 28176       |\n",
      "|    total_timesteps      | 3112960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003605967 |\n",
      "|    clip_fraction        | 0.00469     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88.3        |\n",
      "|    n_updates            | 15190       |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | 0.038473137 |\n",
      "|    std                  | 8.01        |\n",
      "|    value_loss           | 256         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1521        |\n",
      "|    time_elapsed         | 28195       |\n",
      "|    total_timesteps      | 3115008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006389905 |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 123         |\n",
      "|    n_updates            | 15200       |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | 2.7229354   |\n",
      "|    std                  | 8.02        |\n",
      "|    value_loss           | 231         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1522       |\n",
      "|    time_elapsed         | 28214      |\n",
      "|    total_timesteps      | 3117056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00638546 |\n",
      "|    clip_fraction        | 0.0186     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -101       |\n",
      "|    explained_variance   | 0.447      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 46.4       |\n",
      "|    n_updates            | 15210      |\n",
      "|    policy_gradient_loss | -0.00348   |\n",
      "|    reward               | -3.6837814 |\n",
      "|    std                  | 8.02       |\n",
      "|    value_loss           | 90.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1523         |\n",
      "|    time_elapsed         | 28232        |\n",
      "|    total_timesteps      | 3119104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069704913 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.6         |\n",
      "|    n_updates            | 15220        |\n",
      "|    policy_gradient_loss | -0.00636     |\n",
      "|    reward               | 2.1638792    |\n",
      "|    std                  | 8.04         |\n",
      "|    value_loss           | 236          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1524         |\n",
      "|    time_elapsed         | 28250        |\n",
      "|    total_timesteps      | 3121152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053411233 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 109          |\n",
      "|    n_updates            | 15230        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | -21.865694   |\n",
      "|    std                  | 8.05         |\n",
      "|    value_loss           | 257          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1080\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9280100.41\n",
      "total_reward: 8280100.41\n",
      "total_cost: 161032.39\n",
      "total_trades: 57370\n",
      "Sharpe: 1.010\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1525         |\n",
      "|    time_elapsed         | 28268        |\n",
      "|    total_timesteps      | 3123200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042088064 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.361        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.6         |\n",
      "|    n_updates            | 15240        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | -0.71727645  |\n",
      "|    std                  | 8.05         |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1526         |\n",
      "|    time_elapsed         | 28287        |\n",
      "|    total_timesteps      | 3125248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060766945 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.8         |\n",
      "|    n_updates            | 15250        |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    reward               | 1.8601557    |\n",
      "|    std                  | 8.07         |\n",
      "|    value_loss           | 219          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1527         |\n",
      "|    time_elapsed         | 28305        |\n",
      "|    total_timesteps      | 3127296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044668345 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.223        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 192          |\n",
      "|    n_updates            | 15260        |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    reward               | 12.581072    |\n",
      "|    std                  | 8.08         |\n",
      "|    value_loss           | 365          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1528        |\n",
      "|    time_elapsed         | 28324       |\n",
      "|    total_timesteps      | 3129344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000847192 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 200         |\n",
      "|    n_updates            | 15270       |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    reward               | -1.7139488  |\n",
      "|    std                  | 8.08        |\n",
      "|    value_loss           | 306         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1529         |\n",
      "|    time_elapsed         | 28343        |\n",
      "|    total_timesteps      | 3131392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065477947 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.4         |\n",
      "|    n_updates            | 15280        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    reward               | -2.1745567   |\n",
      "|    std                  | 8.11         |\n",
      "|    value_loss           | 85.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1530        |\n",
      "|    time_elapsed         | 28362       |\n",
      "|    total_timesteps      | 3133440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009738178 |\n",
      "|    clip_fraction        | 0.0645      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.4        |\n",
      "|    n_updates            | 15290       |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    reward               | 1.6419877   |\n",
      "|    std                  | 8.11        |\n",
      "|    value_loss           | 275         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1531         |\n",
      "|    time_elapsed         | 28380        |\n",
      "|    total_timesteps      | 3135488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061523207 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.274        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 195          |\n",
      "|    n_updates            | 15300        |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    reward               | 11.0735035   |\n",
      "|    std                  | 8.11         |\n",
      "|    value_loss           | 414          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1532         |\n",
      "|    time_elapsed         | 28399        |\n",
      "|    total_timesteps      | 3137536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021239913 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 15310        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | 2.9985485    |\n",
      "|    std                  | 8.12         |\n",
      "|    value_loss           | 81           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1533        |\n",
      "|    time_elapsed         | 28418       |\n",
      "|    total_timesteps      | 3139584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008031091 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 15320       |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    reward               | 1.4821814   |\n",
      "|    std                  | 8.13        |\n",
      "|    value_loss           | 294         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1534         |\n",
      "|    time_elapsed         | 28436        |\n",
      "|    total_timesteps      | 3141632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035807525 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 141          |\n",
      "|    n_updates            | 15330        |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | 17.52044     |\n",
      "|    std                  | 8.15         |\n",
      "|    value_loss           | 304          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1535         |\n",
      "|    time_elapsed         | 28454        |\n",
      "|    total_timesteps      | 3143680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068541276 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.9         |\n",
      "|    n_updates            | 15340        |\n",
      "|    policy_gradient_loss | -0.00742     |\n",
      "|    reward               | -12.68113    |\n",
      "|    std                  | 8.15         |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1536        |\n",
      "|    time_elapsed         | 28473       |\n",
      "|    total_timesteps      | 3145728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008871937 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.7        |\n",
      "|    n_updates            | 15350       |\n",
      "|    policy_gradient_loss | -0.00754    |\n",
      "|    reward               | -2.3468156  |\n",
      "|    std                  | 8.18        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1537         |\n",
      "|    time_elapsed         | 28492        |\n",
      "|    total_timesteps      | 3147776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045203893 |\n",
      "|    clip_fraction        | 0.00962      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90.3         |\n",
      "|    n_updates            | 15360        |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    reward               | 0.5624846    |\n",
      "|    std                  | 8.19         |\n",
      "|    value_loss           | 261          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1538         |\n",
      "|    time_elapsed         | 28511        |\n",
      "|    total_timesteps      | 3149824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030220246 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.342        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 116          |\n",
      "|    n_updates            | 15370        |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    reward               | 0.21870305   |\n",
      "|    std                  | 8.19         |\n",
      "|    value_loss           | 367          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1090\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8831112.97\n",
      "total_reward: 7831112.97\n",
      "total_cost: 153904.78\n",
      "total_trades: 57305\n",
      "Sharpe: 0.976\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1539        |\n",
      "|    time_elapsed         | 28529       |\n",
      "|    total_timesteps      | 3151872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006533023 |\n",
      "|    clip_fraction        | 0.0194      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.9        |\n",
      "|    n_updates            | 15380       |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    reward               | 0.9105      |\n",
      "|    std                  | 8.2         |\n",
      "|    value_loss           | 68.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1540        |\n",
      "|    time_elapsed         | 28547       |\n",
      "|    total_timesteps      | 3153920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004397438 |\n",
      "|    clip_fraction        | 0.00669     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 15390       |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    reward               | -2.531301   |\n",
      "|    std                  | 8.22        |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1541        |\n",
      "|    time_elapsed         | 28565       |\n",
      "|    total_timesteps      | 3155968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013938075 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 228         |\n",
      "|    n_updates            | 15400       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 11.602282   |\n",
      "|    std                  | 8.26        |\n",
      "|    value_loss           | 402         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1542       |\n",
      "|    time_elapsed         | 28584      |\n",
      "|    total_timesteps      | 3158016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00776501 |\n",
      "|    clip_fraction        | 0.0465     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -102       |\n",
      "|    explained_variance   | 0.202      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 98.8       |\n",
      "|    n_updates            | 15410      |\n",
      "|    policy_gradient_loss | -0.0034    |\n",
      "|    reward               | -7.8608418 |\n",
      "|    std                  | 8.27       |\n",
      "|    value_loss           | 175        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1543        |\n",
      "|    time_elapsed         | 28603       |\n",
      "|    total_timesteps      | 3160064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006825423 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.3        |\n",
      "|    n_updates            | 15420       |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    reward               | 1.05422     |\n",
      "|    std                  | 8.28        |\n",
      "|    value_loss           | 237         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1544          |\n",
      "|    time_elapsed         | 28621         |\n",
      "|    total_timesteps      | 3162112       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092950545 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -102          |\n",
      "|    explained_variance   | 0.455         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 95.7          |\n",
      "|    n_updates            | 15430         |\n",
      "|    policy_gradient_loss | -0.0011       |\n",
      "|    reward               | 0.9740765     |\n",
      "|    std                  | 8.29          |\n",
      "|    value_loss           | 297           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1545        |\n",
      "|    time_elapsed         | 28639       |\n",
      "|    total_timesteps      | 3164160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004998862 |\n",
      "|    clip_fraction        | 0.00908     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 15440       |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    reward               | 1.0875523   |\n",
      "|    std                  | 8.31        |\n",
      "|    value_loss           | 255         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1546       |\n",
      "|    time_elapsed         | 28657      |\n",
      "|    total_timesteps      | 3166208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01365757 |\n",
      "|    clip_fraction        | 0.067      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -102       |\n",
      "|    explained_variance   | 0.448      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.5       |\n",
      "|    n_updates            | 15450      |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    reward               | 3.370714   |\n",
      "|    std                  | 8.32       |\n",
      "|    value_loss           | 66.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1547         |\n",
      "|    time_elapsed         | 28676        |\n",
      "|    total_timesteps      | 3168256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057858303 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.1         |\n",
      "|    n_updates            | 15460        |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    reward               | 2.4653213    |\n",
      "|    std                  | 8.32         |\n",
      "|    value_loss           | 272          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1548         |\n",
      "|    time_elapsed         | 28695        |\n",
      "|    total_timesteps      | 3170304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019304013 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.412        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 179          |\n",
      "|    n_updates            | 15470        |\n",
      "|    policy_gradient_loss | 0.00152      |\n",
      "|    reward               | 2.6798744    |\n",
      "|    std                  | 8.32         |\n",
      "|    value_loss           | 296          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1549         |\n",
      "|    time_elapsed         | 28713        |\n",
      "|    total_timesteps      | 3172352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029241224 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.5         |\n",
      "|    n_updates            | 15480        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | -1.1989331   |\n",
      "|    std                  | 8.32         |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1550        |\n",
      "|    time_elapsed         | 28732       |\n",
      "|    total_timesteps      | 3174400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008711526 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 188         |\n",
      "|    n_updates            | 15490       |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | -0.11420269 |\n",
      "|    std                  | 8.34        |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1551         |\n",
      "|    time_elapsed         | 28751        |\n",
      "|    total_timesteps      | 3176448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043475046 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.3         |\n",
      "|    n_updates            | 15500        |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    reward               | -18.46411    |\n",
      "|    std                  | 8.34         |\n",
      "|    value_loss           | 227          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1552         |\n",
      "|    time_elapsed         | 28769        |\n",
      "|    total_timesteps      | 3178496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027104712 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 97.4         |\n",
      "|    n_updates            | 15510        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | 2.324357     |\n",
      "|    std                  | 8.35         |\n",
      "|    value_loss           | 254          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7686866.20\n",
      "total_reward: 6686866.20\n",
      "total_cost: 143697.62\n",
      "total_trades: 57021\n",
      "Sharpe: 0.908\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1553        |\n",
      "|    time_elapsed         | 28787       |\n",
      "|    total_timesteps      | 3180544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009040687 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.4        |\n",
      "|    n_updates            | 15520       |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    reward               | 2.447018    |\n",
      "|    std                  | 8.37        |\n",
      "|    value_loss           | 88          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1554         |\n",
      "|    time_elapsed         | 28804        |\n",
      "|    total_timesteps      | 3182592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007024166  |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.387        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 87.4         |\n",
      "|    n_updates            | 15530        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | 0.0024702856 |\n",
      "|    std                  | 8.38         |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1555        |\n",
      "|    time_elapsed         | 28822       |\n",
      "|    total_timesteps      | 3184640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006390994 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.1        |\n",
      "|    n_updates            | 15540       |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    reward               | -10.837214  |\n",
      "|    std                  | 8.38        |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1556         |\n",
      "|    time_elapsed         | 28841        |\n",
      "|    total_timesteps      | 3186688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062981416 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.277        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.5         |\n",
      "|    n_updates            | 15550        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    reward               | -8.690512    |\n",
      "|    std                  | 8.39         |\n",
      "|    value_loss           | 74.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1557         |\n",
      "|    time_elapsed         | 28859        |\n",
      "|    total_timesteps      | 3188736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046441304 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 145          |\n",
      "|    n_updates            | 15560        |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    reward               | -2.8973162   |\n",
      "|    std                  | 8.39         |\n",
      "|    value_loss           | 187          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1558         |\n",
      "|    time_elapsed         | 28877        |\n",
      "|    total_timesteps      | 3190784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019231581 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 120          |\n",
      "|    n_updates            | 15570        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | 2.4348862    |\n",
      "|    std                  | 8.4          |\n",
      "|    value_loss           | 206          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1559         |\n",
      "|    time_elapsed         | 28896        |\n",
      "|    total_timesteps      | 3192832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036257936 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 94.3         |\n",
      "|    n_updates            | 15580        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | 0.74501544   |\n",
      "|    std                  | 8.41         |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1560         |\n",
      "|    time_elapsed         | 28914        |\n",
      "|    total_timesteps      | 3194880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063932585 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82.4         |\n",
      "|    n_updates            | 15590        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | -0.13243243  |\n",
      "|    std                  | 8.42         |\n",
      "|    value_loss           | 158          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1561       |\n",
      "|    time_elapsed         | 28932      |\n",
      "|    total_timesteps      | 3196928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00652174 |\n",
      "|    clip_fraction        | 0.0301     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -103       |\n",
      "|    explained_variance   | 0.721      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 94.3       |\n",
      "|    n_updates            | 15600      |\n",
      "|    policy_gradient_loss | -0.00578   |\n",
      "|    reward               | 0.48143467 |\n",
      "|    std                  | 8.43       |\n",
      "|    value_loss           | 258        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1562         |\n",
      "|    time_elapsed         | 28951        |\n",
      "|    total_timesteps      | 3198976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021743672 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 15610        |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    reward               | 1.4708248    |\n",
      "|    std                  | 8.44         |\n",
      "|    value_loss           | 271          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1563        |\n",
      "|    time_elapsed         | 28970       |\n",
      "|    total_timesteps      | 3201024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010192548 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.1        |\n",
      "|    n_updates            | 15620       |\n",
      "|    policy_gradient_loss | -0.00916    |\n",
      "|    reward               | -0.4250772  |\n",
      "|    std                  | 8.45        |\n",
      "|    value_loss           | 83.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1564        |\n",
      "|    time_elapsed         | 28989       |\n",
      "|    total_timesteps      | 3203072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004474957 |\n",
      "|    clip_fraction        | 0.0085      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 15630       |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    reward               | 0.036892466 |\n",
      "|    std                  | 8.45        |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1565        |\n",
      "|    time_elapsed         | 29008       |\n",
      "|    total_timesteps      | 3205120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004991159 |\n",
      "|    clip_fraction        | 0.00928     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 174         |\n",
      "|    n_updates            | 15640       |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    reward               | 1.4034371   |\n",
      "|    std                  | 8.45        |\n",
      "|    value_loss           | 256         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1566        |\n",
      "|    time_elapsed         | 29026       |\n",
      "|    total_timesteps      | 3207168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010992056 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | -0.0122     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.7        |\n",
      "|    n_updates            | 15650       |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | -1.207193   |\n",
      "|    std                  | 8.47        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8537060.06\n",
      "total_reward: 7537060.06\n",
      "total_cost: 153305.19\n",
      "total_trades: 57976\n",
      "Sharpe: 0.978\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1567        |\n",
      "|    time_elapsed         | 29045       |\n",
      "|    total_timesteps      | 3209216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009283863 |\n",
      "|    clip_fraction        | 0.0564      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 15660       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -2.0435011  |\n",
      "|    std                  | 8.49        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1568         |\n",
      "|    time_elapsed         | 29064        |\n",
      "|    total_timesteps      | 3211264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031936856 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 89.5         |\n",
      "|    n_updates            | 15670        |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    reward               | -2.1407406   |\n",
      "|    std                  | 8.49         |\n",
      "|    value_loss           | 238          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1569         |\n",
      "|    time_elapsed         | 29083        |\n",
      "|    total_timesteps      | 3213312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028977534 |\n",
      "|    clip_fraction        | 0.00483      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.177        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 161          |\n",
      "|    n_updates            | 15680        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | -0.86959314  |\n",
      "|    std                  | 8.5          |\n",
      "|    value_loss           | 298          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1570        |\n",
      "|    time_elapsed         | 29102       |\n",
      "|    total_timesteps      | 3215360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014720519 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.0203      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.4        |\n",
      "|    n_updates            | 15690       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | 0.058244467 |\n",
      "|    std                  | 8.56        |\n",
      "|    value_loss           | 81.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1571        |\n",
      "|    time_elapsed         | 29121       |\n",
      "|    total_timesteps      | 3217408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006269362 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 15700       |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | 1.1809369   |\n",
      "|    std                  | 8.57        |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1572        |\n",
      "|    time_elapsed         | 29140       |\n",
      "|    total_timesteps      | 3219456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008659229 |\n",
      "|    clip_fraction        | 0.0449      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 159         |\n",
      "|    n_updates            | 15710       |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    reward               | -2.690428   |\n",
      "|    std                  | 8.57        |\n",
      "|    value_loss           | 321         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1573         |\n",
      "|    time_elapsed         | 29158        |\n",
      "|    total_timesteps      | 3221504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088203605 |\n",
      "|    clip_fraction        | 0.0622       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.0645       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.8         |\n",
      "|    n_updates            | 15720        |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    reward               | -1.4204816   |\n",
      "|    std                  | 8.6          |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1574        |\n",
      "|    time_elapsed         | 29177       |\n",
      "|    total_timesteps      | 3223552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011940166 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | -0.00189    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.9        |\n",
      "|    n_updates            | 15730       |\n",
      "|    policy_gradient_loss | -0.00937    |\n",
      "|    reward               | 0.71113425  |\n",
      "|    std                  | 8.62        |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1575         |\n",
      "|    time_elapsed         | 29195        |\n",
      "|    total_timesteps      | 3225600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064100376 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.0767       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 131          |\n",
      "|    n_updates            | 15740        |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    reward               | 0.77038246   |\n",
      "|    std                  | 8.62         |\n",
      "|    value_loss           | 218          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1576         |\n",
      "|    time_elapsed         | 29213        |\n",
      "|    total_timesteps      | 3227648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034727436 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.106        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90.7         |\n",
      "|    n_updates            | 15750        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | -0.33813718  |\n",
      "|    std                  | 8.62         |\n",
      "|    value_loss           | 178          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1577         |\n",
      "|    time_elapsed         | 29232        |\n",
      "|    total_timesteps      | 3229696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061651208 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 97.3         |\n",
      "|    n_updates            | 15760        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    reward               | 1.8712049    |\n",
      "|    std                  | 8.63         |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1578         |\n",
      "|    time_elapsed         | 29250        |\n",
      "|    total_timesteps      | 3231744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075188475 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.0451       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 97.4         |\n",
      "|    n_updates            | 15770        |\n",
      "|    policy_gradient_loss | -0.00817     |\n",
      "|    reward               | -2.310159    |\n",
      "|    std                  | 8.63         |\n",
      "|    value_loss           | 240          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1579         |\n",
      "|    time_elapsed         | 29268        |\n",
      "|    total_timesteps      | 3233792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040677316 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.0876       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 126          |\n",
      "|    n_updates            | 15780        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | 10.187269    |\n",
      "|    std                  | 8.64         |\n",
      "|    value_loss           | 260          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1580       |\n",
      "|    time_elapsed         | 29287      |\n",
      "|    total_timesteps      | 3235840    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01008982 |\n",
      "|    clip_fraction        | 0.0743     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -103       |\n",
      "|    explained_variance   | 0.124      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38.4       |\n",
      "|    n_updates            | 15790      |\n",
      "|    policy_gradient_loss | -0.00689   |\n",
      "|    reward               | 2.3405578  |\n",
      "|    std                  | 8.67       |\n",
      "|    value_loss           | 91.9       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7800009.43\n",
      "total_reward: 6800009.43\n",
      "total_cost: 164416.46\n",
      "total_trades: 58292\n",
      "Sharpe: 0.952\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1581         |\n",
      "|    time_elapsed         | 29305        |\n",
      "|    total_timesteps      | 3237888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087314565 |\n",
      "|    clip_fraction        | 0.0551       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.155        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.7         |\n",
      "|    n_updates            | 15800        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    reward               | 1.5922434    |\n",
      "|    std                  | 8.68         |\n",
      "|    value_loss           | 187          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1582         |\n",
      "|    time_elapsed         | 29323        |\n",
      "|    total_timesteps      | 3239936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023224123 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.177        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 15810        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | 17.814054    |\n",
      "|    std                  | 8.68         |\n",
      "|    value_loss           | 225          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1583        |\n",
      "|    time_elapsed         | 29342       |\n",
      "|    total_timesteps      | 3241984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006710595 |\n",
      "|    clip_fraction        | 0.0271      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | -0.000723   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.3        |\n",
      "|    n_updates            | 15820       |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    reward               | 1.2564813   |\n",
      "|    std                  | 8.68        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1584        |\n",
      "|    time_elapsed         | 29360       |\n",
      "|    total_timesteps      | 3244032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010470152 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88          |\n",
      "|    n_updates            | 15830       |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | 0.3016771   |\n",
      "|    std                  | 8.71        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1585        |\n",
      "|    time_elapsed         | 29379       |\n",
      "|    total_timesteps      | 3246080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003440842 |\n",
      "|    clip_fraction        | 0.00269     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 15840       |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    reward               | 1.3694295   |\n",
      "|    std                  | 8.71        |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1586         |\n",
      "|    time_elapsed         | 29397        |\n",
      "|    total_timesteps      | 3248128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064619486 |\n",
      "|    clip_fraction        | 0.0298       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 101          |\n",
      "|    n_updates            | 15850        |\n",
      "|    policy_gradient_loss | -0.00734     |\n",
      "|    reward               | 1.4243139    |\n",
      "|    std                  | 8.73         |\n",
      "|    value_loss           | 324          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1587        |\n",
      "|    time_elapsed         | 29415       |\n",
      "|    total_timesteps      | 3250176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008329796 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 15860       |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    reward               | 1.3174021   |\n",
      "|    std                  | 8.74        |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1588        |\n",
      "|    time_elapsed         | 29433       |\n",
      "|    total_timesteps      | 3252224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009366746 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.5        |\n",
      "|    n_updates            | 15870       |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | -1.665108   |\n",
      "|    std                  | 8.74        |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1589         |\n",
      "|    time_elapsed         | 29451        |\n",
      "|    total_timesteps      | 3254272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013951169 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.0454       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.7         |\n",
      "|    n_updates            | 15880        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | 3.8728743    |\n",
      "|    std                  | 8.74         |\n",
      "|    value_loss           | 214          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1590         |\n",
      "|    time_elapsed         | 29470        |\n",
      "|    total_timesteps      | 3256320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037316184 |\n",
      "|    clip_fraction        | 0.004        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.00238      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.5         |\n",
      "|    n_updates            | 15890        |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    reward               | -10.08381    |\n",
      "|    std                  | 8.75         |\n",
      "|    value_loss           | 122          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1591        |\n",
      "|    time_elapsed         | 29489       |\n",
      "|    total_timesteps      | 3258368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009504429 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.4        |\n",
      "|    n_updates            | 15900       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -2.673334   |\n",
      "|    std                  | 8.75        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1592         |\n",
      "|    time_elapsed         | 29507        |\n",
      "|    total_timesteps      | 3260416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055361628 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.3         |\n",
      "|    n_updates            | 15910        |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    reward               | -0.20137936  |\n",
      "|    std                  | 8.75         |\n",
      "|    value_loss           | 191          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1593       |\n",
      "|    time_elapsed         | 29526      |\n",
      "|    total_timesteps      | 3262464    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00792961 |\n",
      "|    clip_fraction        | 0.0766     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -104       |\n",
      "|    explained_variance   | 0.0173     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 113        |\n",
      "|    n_updates            | 15920      |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    reward               | 6.1025743  |\n",
      "|    std                  | 8.75       |\n",
      "|    value_loss           | 210        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1594        |\n",
      "|    time_elapsed         | 29545       |\n",
      "|    total_timesteps      | 3264512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010086432 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.0836      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 15930       |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    reward               | -1.2182655  |\n",
      "|    std                  | 8.77        |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8086910.79\n",
      "total_reward: 7086910.79\n",
      "total_cost: 152763.90\n",
      "total_trades: 57223\n",
      "Sharpe: 0.976\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1595        |\n",
      "|    time_elapsed         | 29564       |\n",
      "|    total_timesteps      | 3266560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006247987 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.2        |\n",
      "|    n_updates            | 15940       |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    reward               | 0.043246422 |\n",
      "|    std                  | 8.77        |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1596        |\n",
      "|    time_elapsed         | 29584       |\n",
      "|    total_timesteps      | 3268608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008065048 |\n",
      "|    clip_fraction        | 0.0272      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.0726      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 15950       |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    reward               | 7.8229537   |\n",
      "|    std                  | 8.78        |\n",
      "|    value_loss           | 265         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1597        |\n",
      "|    time_elapsed         | 29602       |\n",
      "|    total_timesteps      | 3270656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009835749 |\n",
      "|    clip_fraction        | 0.0841      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41          |\n",
      "|    n_updates            | 15960       |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    reward               | -12.272227  |\n",
      "|    std                  | 8.78        |\n",
      "|    value_loss           | 66          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1598         |\n",
      "|    time_elapsed         | 29621        |\n",
      "|    total_timesteps      | 3272704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065393155 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 87.2         |\n",
      "|    n_updates            | 15970        |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    reward               | 0.79782295   |\n",
      "|    std                  | 8.79         |\n",
      "|    value_loss           | 171          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1599        |\n",
      "|    time_elapsed         | 29639       |\n",
      "|    total_timesteps      | 3274752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012112545 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 15980       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | -6.4837813  |\n",
      "|    std                  | 8.84        |\n",
      "|    value_loss           | 283         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1600        |\n",
      "|    time_elapsed         | 29658       |\n",
      "|    total_timesteps      | 3276800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011435167 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.0435      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.9        |\n",
      "|    n_updates            | 15990       |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    reward               | -6.5363297  |\n",
      "|    std                  | 8.85        |\n",
      "|    value_loss           | 207         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1601         |\n",
      "|    time_elapsed         | 29676        |\n",
      "|    total_timesteps      | 3278848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066460995 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.0845       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.2         |\n",
      "|    n_updates            | 16000        |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    reward               | -3.7259707   |\n",
      "|    std                  | 8.86         |\n",
      "|    value_loss           | 159          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1602        |\n",
      "|    time_elapsed         | 29695       |\n",
      "|    total_timesteps      | 3280896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006085677 |\n",
      "|    clip_fraction        | 0.0112      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.0873      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.7        |\n",
      "|    n_updates            | 16010       |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    reward               | -0.34244478 |\n",
      "|    std                  | 8.88        |\n",
      "|    value_loss           | 216         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1603        |\n",
      "|    time_elapsed         | 29713       |\n",
      "|    total_timesteps      | 3282944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007497334 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.3        |\n",
      "|    n_updates            | 16020       |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | 10.6549835  |\n",
      "|    std                  | 8.89        |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1604         |\n",
      "|    time_elapsed         | 29732        |\n",
      "|    total_timesteps      | 3284992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077073765 |\n",
      "|    clip_fraction        | 0.0457       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.0562       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37           |\n",
      "|    n_updates            | 16030        |\n",
      "|    policy_gradient_loss | -0.00656     |\n",
      "|    reward               | 2.417762     |\n",
      "|    std                  | 8.9          |\n",
      "|    value_loss           | 73.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1605        |\n",
      "|    time_elapsed         | 29751       |\n",
      "|    total_timesteps      | 3287040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008748224 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.0914      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.5        |\n",
      "|    n_updates            | 16040       |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    reward               | 1.1746856   |\n",
      "|    std                  | 8.91        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1606        |\n",
      "|    time_elapsed         | 29769       |\n",
      "|    total_timesteps      | 3289088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004551774 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.6        |\n",
      "|    n_updates            | 16050       |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    reward               | 5.114313    |\n",
      "|    std                  | 8.92        |\n",
      "|    value_loss           | 190         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1607         |\n",
      "|    time_elapsed         | 29787        |\n",
      "|    total_timesteps      | 3291136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046301344 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.129        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.2         |\n",
      "|    n_updates            | 16060        |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    reward               | -3.4261656   |\n",
      "|    std                  | 8.92         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1608        |\n",
      "|    time_elapsed         | 29805       |\n",
      "|    total_timesteps      | 3293184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010204714 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | -0.00038    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 16070       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | -1.5550752  |\n",
      "|    std                  | 8.94        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6888548.39\n",
      "total_reward: 5888548.39\n",
      "total_cost: 145349.33\n",
      "total_trades: 56182\n",
      "Sharpe: 0.850\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1609         |\n",
      "|    time_elapsed         | 29824        |\n",
      "|    total_timesteps      | 3295232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022284756 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.121        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 114          |\n",
      "|    n_updates            | 16080        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    reward               | 1.6927956    |\n",
      "|    std                  | 8.94         |\n",
      "|    value_loss           | 187          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1610          |\n",
      "|    time_elapsed         | 29842         |\n",
      "|    total_timesteps      | 3297280       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034884413 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -104          |\n",
      "|    explained_variance   | 0.158         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 103           |\n",
      "|    n_updates            | 16090         |\n",
      "|    policy_gradient_loss | -0.00115      |\n",
      "|    reward               | 2.4946103     |\n",
      "|    std                  | 8.94          |\n",
      "|    value_loss           | 235           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1611        |\n",
      "|    time_elapsed         | 29860       |\n",
      "|    total_timesteps      | 3299328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003605915 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 16100       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | 2.892714    |\n",
      "|    std                  | 8.95        |\n",
      "|    value_loss           | 99.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1612       |\n",
      "|    time_elapsed         | 29877      |\n",
      "|    total_timesteps      | 3301376    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00614814 |\n",
      "|    clip_fraction        | 0.0198     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -104       |\n",
      "|    explained_variance   | 0.0548     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 100        |\n",
      "|    n_updates            | 16110      |\n",
      "|    policy_gradient_loss | -0.00451   |\n",
      "|    reward               | 0.21836594 |\n",
      "|    std                  | 8.96       |\n",
      "|    value_loss           | 173        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1613        |\n",
      "|    time_elapsed         | 29896       |\n",
      "|    total_timesteps      | 3303424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010349695 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.0651      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.4        |\n",
      "|    n_updates            | 16120       |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    reward               | -5.7118826  |\n",
      "|    std                  | 8.97        |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1614         |\n",
      "|    time_elapsed         | 29915        |\n",
      "|    total_timesteps      | 3305472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047985343 |\n",
      "|    clip_fraction        | 0.00923      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.134        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.2         |\n",
      "|    n_updates            | 16130        |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    reward               | 3.8152463    |\n",
      "|    std                  | 8.98         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1615        |\n",
      "|    time_elapsed         | 29934       |\n",
      "|    total_timesteps      | 3307520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005921089 |\n",
      "|    clip_fraction        | 0.0269      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.8        |\n",
      "|    n_updates            | 16140       |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | -0.24663098 |\n",
      "|    std                  | 9.01        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1616         |\n",
      "|    time_elapsed         | 29952        |\n",
      "|    total_timesteps      | 3309568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036154925 |\n",
      "|    clip_fraction        | 0.00825      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.152        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48           |\n",
      "|    n_updates            | 16150        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | -1.9900055   |\n",
      "|    std                  | 9.01         |\n",
      "|    value_loss           | 178          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1617        |\n",
      "|    time_elapsed         | 29970       |\n",
      "|    total_timesteps      | 3311616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009613197 |\n",
      "|    clip_fraction        | 0.0706      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.0764      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 16160       |\n",
      "|    policy_gradient_loss | -0.00981    |\n",
      "|    reward               | 2.3233664   |\n",
      "|    std                  | 9.01        |\n",
      "|    value_loss           | 234         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1618        |\n",
      "|    time_elapsed         | 29988       |\n",
      "|    total_timesteps      | 3313664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012590293 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | -0.0291     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.4        |\n",
      "|    n_updates            | 16170       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 0.41924784  |\n",
      "|    std                  | 9.08        |\n",
      "|    value_loss           | 84.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1619         |\n",
      "|    time_elapsed         | 30007        |\n",
      "|    total_timesteps      | 3315712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055801715 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.0178       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 126          |\n",
      "|    n_updates            | 16180        |\n",
      "|    policy_gradient_loss | -0.00498     |\n",
      "|    reward               | 1.3880912    |\n",
      "|    std                  | 9.1          |\n",
      "|    value_loss           | 176          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1620         |\n",
      "|    time_elapsed         | 30025        |\n",
      "|    total_timesteps      | 3317760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057416866 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.0682       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 96.5         |\n",
      "|    n_updates            | 16190        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    reward               | 0.13404596   |\n",
      "|    std                  | 9.11         |\n",
      "|    value_loss           | 199          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1621         |\n",
      "|    time_elapsed         | 30044        |\n",
      "|    total_timesteps      | 3319808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079123145 |\n",
      "|    clip_fraction        | 0.0592       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.105        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.2         |\n",
      "|    n_updates            | 16200        |\n",
      "|    policy_gradient_loss | -0.00639     |\n",
      "|    reward               | 0.99288523   |\n",
      "|    std                  | 9.13         |\n",
      "|    value_loss           | 70.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1622         |\n",
      "|    time_elapsed         | 30062        |\n",
      "|    total_timesteps      | 3321856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029873336 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.226        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.1         |\n",
      "|    n_updates            | 16210        |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    reward               | -2.8771238   |\n",
      "|    std                  | 9.13         |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1623        |\n",
      "|    time_elapsed         | 30081       |\n",
      "|    total_timesteps      | 3323904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004044546 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.4        |\n",
      "|    n_updates            | 16220       |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    reward               | 2.2047231   |\n",
      "|    std                  | 9.14        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6340396.79\n",
      "total_reward: 5340396.79\n",
      "total_cost: 167646.42\n",
      "total_trades: 57366\n",
      "Sharpe: 0.827\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1624         |\n",
      "|    time_elapsed         | 30099        |\n",
      "|    total_timesteps      | 3325952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053264583 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.0052       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 101          |\n",
      "|    n_updates            | 16230        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | 4.625105     |\n",
      "|    std                  | 9.15         |\n",
      "|    value_loss           | 186          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1625        |\n",
      "|    time_elapsed         | 30118       |\n",
      "|    total_timesteps      | 3328000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012033751 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 16240       |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    reward               | 0.18575883  |\n",
      "|    std                  | 9.16        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1626        |\n",
      "|    time_elapsed         | 30136       |\n",
      "|    total_timesteps      | 3330048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005874416 |\n",
      "|    clip_fraction        | 0.0238      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.7        |\n",
      "|    n_updates            | 16250       |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    reward               | -1.6011407  |\n",
      "|    std                  | 9.16        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1627         |\n",
      "|    time_elapsed         | 30154        |\n",
      "|    total_timesteps      | 3332096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048547667 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.124        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.7         |\n",
      "|    n_updates            | 16260        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | 2.567048     |\n",
      "|    std                  | 9.17         |\n",
      "|    value_loss           | 208          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1628         |\n",
      "|    time_elapsed         | 30173        |\n",
      "|    total_timesteps      | 3334144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059003723 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.0712       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.8         |\n",
      "|    n_updates            | 16270        |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    reward               | -2.2806938   |\n",
      "|    std                  | 9.19         |\n",
      "|    value_loss           | 83.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1629        |\n",
      "|    time_elapsed         | 30192       |\n",
      "|    total_timesteps      | 3336192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009095232 |\n",
      "|    clip_fraction        | 0.0493      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.3        |\n",
      "|    n_updates            | 16280       |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    reward               | 1.9691491   |\n",
      "|    std                  | 9.19        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1630         |\n",
      "|    time_elapsed         | 30210        |\n",
      "|    total_timesteps      | 3338240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062928637 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.181        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 87.2         |\n",
      "|    n_updates            | 16290        |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    reward               | -4.873778    |\n",
      "|    std                  | 9.21         |\n",
      "|    value_loss           | 160          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1631        |\n",
      "|    time_elapsed         | 30229       |\n",
      "|    total_timesteps      | 3340288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009943256 |\n",
      "|    clip_fraction        | 0.0736      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.7        |\n",
      "|    n_updates            | 16300       |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    reward               | -4.7099385  |\n",
      "|    std                  | 9.22        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1632         |\n",
      "|    time_elapsed         | 30248        |\n",
      "|    total_timesteps      | 3342336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036840772 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.293        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.2         |\n",
      "|    n_updates            | 16310        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | -0.6324339   |\n",
      "|    std                  | 9.23         |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1633         |\n",
      "|    time_elapsed         | 30267        |\n",
      "|    total_timesteps      | 3344384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032921904 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 88.7         |\n",
      "|    n_updates            | 16320        |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    reward               | 1.3059578    |\n",
      "|    std                  | 9.24         |\n",
      "|    value_loss           | 175          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1634         |\n",
      "|    time_elapsed         | 30285        |\n",
      "|    total_timesteps      | 3346432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038604366 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.149        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 128          |\n",
      "|    n_updates            | 16330        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | 1.8793291    |\n",
      "|    std                  | 9.24         |\n",
      "|    value_loss           | 235          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1635         |\n",
      "|    time_elapsed         | 30304        |\n",
      "|    total_timesteps      | 3348480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067167925 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.109        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.9         |\n",
      "|    n_updates            | 16340        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    reward               | -5.491258    |\n",
      "|    std                  | 9.24         |\n",
      "|    value_loss           | 90           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1636        |\n",
      "|    time_elapsed         | 30322       |\n",
      "|    total_timesteps      | 3350528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005421972 |\n",
      "|    clip_fraction        | 0.00928     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.1        |\n",
      "|    n_updates            | 16350       |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | -1.3276746  |\n",
      "|    std                  | 9.25        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1637         |\n",
      "|    time_elapsed         | 30341        |\n",
      "|    total_timesteps      | 3352576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040536053 |\n",
      "|    clip_fraction        | 0.00933      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.244        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.7         |\n",
      "|    n_updates            | 16360        |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    reward               | -6.834304    |\n",
      "|    std                  | 9.25         |\n",
      "|    value_loss           | 189          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5643215.39\n",
      "total_reward: 4643215.39\n",
      "total_cost: 132139.28\n",
      "total_trades: 54958\n",
      "Sharpe: 0.769\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1638        |\n",
      "|    time_elapsed         | 30360       |\n",
      "|    total_timesteps      | 3354624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009550213 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.9        |\n",
      "|    n_updates            | 16370       |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | 2.1396887   |\n",
      "|    std                  | 9.26        |\n",
      "|    value_loss           | 95.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1639         |\n",
      "|    time_elapsed         | 30378        |\n",
      "|    total_timesteps      | 3356672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051042894 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.7         |\n",
      "|    n_updates            | 16380        |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    reward               | 0.7382287    |\n",
      "|    std                  | 9.25         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1640        |\n",
      "|    time_elapsed         | 30397       |\n",
      "|    total_timesteps      | 3358720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004280964 |\n",
      "|    clip_fraction        | 0.0175      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.7        |\n",
      "|    n_updates            | 16390       |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    reward               | 22.685349   |\n",
      "|    std                  | 9.25        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1641        |\n",
      "|    time_elapsed         | 30416       |\n",
      "|    total_timesteps      | 3360768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010128525 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 16400       |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | 3.070925    |\n",
      "|    std                  | 9.26        |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1642         |\n",
      "|    time_elapsed         | 30434        |\n",
      "|    total_timesteps      | 3362816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077044712 |\n",
      "|    clip_fraction        | 0.0351       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.5         |\n",
      "|    n_updates            | 16410        |\n",
      "|    policy_gradient_loss | -0.00551     |\n",
      "|    reward               | 3.3820186    |\n",
      "|    std                  | 9.28         |\n",
      "|    value_loss           | 91.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1643       |\n",
      "|    time_elapsed         | 30452      |\n",
      "|    total_timesteps      | 3364864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00864483 |\n",
      "|    clip_fraction        | 0.0617     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -105       |\n",
      "|    explained_variance   | 0.23       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 85.8       |\n",
      "|    n_updates            | 16420      |\n",
      "|    policy_gradient_loss | -0.00977   |\n",
      "|    reward               | 0.11328041 |\n",
      "|    std                  | 9.3        |\n",
      "|    value_loss           | 172        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1644         |\n",
      "|    time_elapsed         | 30471        |\n",
      "|    total_timesteps      | 3366912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071910564 |\n",
      "|    clip_fraction        | 0.0503       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.233        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 124          |\n",
      "|    n_updates            | 16430        |\n",
      "|    policy_gradient_loss | -0.00952     |\n",
      "|    reward               | 2.724638     |\n",
      "|    std                  | 9.31         |\n",
      "|    value_loss           | 211          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1645        |\n",
      "|    time_elapsed         | 30490       |\n",
      "|    total_timesteps      | 3368960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008720029 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 16440       |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    reward               | -4.2635207  |\n",
      "|    std                  | 9.33        |\n",
      "|    value_loss           | 94.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1646         |\n",
      "|    time_elapsed         | 30508        |\n",
      "|    total_timesteps      | 3371008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006212704  |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.3         |\n",
      "|    n_updates            | 16450        |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    reward               | 0.0030656657 |\n",
      "|    std                  | 9.35         |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1647        |\n",
      "|    time_elapsed         | 30526       |\n",
      "|    total_timesteps      | 3373056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004982503 |\n",
      "|    clip_fraction        | 0.0131      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96.8        |\n",
      "|    n_updates            | 16460       |\n",
      "|    policy_gradient_loss | -0.00552    |\n",
      "|    reward               | 4.2877483   |\n",
      "|    std                  | 9.35        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1648         |\n",
      "|    time_elapsed         | 30544        |\n",
      "|    total_timesteps      | 3375104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062297266 |\n",
      "|    clip_fraction        | 0.0603       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.0969       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.7         |\n",
      "|    n_updates            | 16470        |\n",
      "|    policy_gradient_loss | -0.00738     |\n",
      "|    reward               | 3.7668235    |\n",
      "|    std                  | 9.37         |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1649        |\n",
      "|    time_elapsed         | 30562       |\n",
      "|    total_timesteps      | 3377152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011529328 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 16480       |\n",
      "|    policy_gradient_loss | -0.00834    |\n",
      "|    reward               | -2.0267212  |\n",
      "|    std                  | 9.38        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1650         |\n",
      "|    time_elapsed         | 30580        |\n",
      "|    total_timesteps      | 3379200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004759086  |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.249        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82.5         |\n",
      "|    n_updates            | 16490        |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    reward               | -0.035132706 |\n",
      "|    std                  | 9.39         |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1651       |\n",
      "|    time_elapsed         | 30599      |\n",
      "|    total_timesteps      | 3381248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00854425 |\n",
      "|    clip_fraction        | 0.066      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -106       |\n",
      "|    explained_variance   | 0.1        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 86.5       |\n",
      "|    n_updates            | 16500      |\n",
      "|    policy_gradient_loss | -0.00985   |\n",
      "|    reward               | 0.35336027 |\n",
      "|    std                  | 9.4        |\n",
      "|    value_loss           | 193        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5807215.44\n",
      "total_reward: 4807215.44\n",
      "total_cost: 127536.59\n",
      "total_trades: 55390\n",
      "Sharpe: 0.800\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1652       |\n",
      "|    time_elapsed         | 30617      |\n",
      "|    total_timesteps      | 3383296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01016999 |\n",
      "|    clip_fraction        | 0.0705     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -106       |\n",
      "|    explained_variance   | 0.129      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 51.1       |\n",
      "|    n_updates            | 16510      |\n",
      "|    policy_gradient_loss | -0.00716   |\n",
      "|    reward               | -0.4045129 |\n",
      "|    std                  | 9.43       |\n",
      "|    value_loss           | 82         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1653         |\n",
      "|    time_elapsed         | 30636        |\n",
      "|    total_timesteps      | 3385344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031649524 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.41         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.9         |\n",
      "|    n_updates            | 16520        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | -0.3109043   |\n",
      "|    std                  | 9.43         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1654         |\n",
      "|    time_elapsed         | 30654        |\n",
      "|    total_timesteps      | 3387392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073270677 |\n",
      "|    clip_fraction        | 0.0482       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.216        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 94.9         |\n",
      "|    n_updates            | 16530        |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    reward               | -0.2775318   |\n",
      "|    std                  | 9.44         |\n",
      "|    value_loss           | 188          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1655       |\n",
      "|    time_elapsed         | 30673      |\n",
      "|    total_timesteps      | 3389440    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00980383 |\n",
      "|    clip_fraction        | 0.0822     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -106       |\n",
      "|    explained_variance   | 0.241      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 51.9       |\n",
      "|    n_updates            | 16540      |\n",
      "|    policy_gradient_loss | -0.00779   |\n",
      "|    reward               | 1.5995917  |\n",
      "|    std                  | 9.45       |\n",
      "|    value_loss           | 98.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1656        |\n",
      "|    time_elapsed         | 30692       |\n",
      "|    total_timesteps      | 3391488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009749959 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.4        |\n",
      "|    n_updates            | 16550       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 2.306648    |\n",
      "|    std                  | 9.46        |\n",
      "|    value_loss           | 98.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1657        |\n",
      "|    time_elapsed         | 30710       |\n",
      "|    total_timesteps      | 3393536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009018323 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.6        |\n",
      "|    n_updates            | 16560       |\n",
      "|    policy_gradient_loss | -0.00873    |\n",
      "|    reward               | 2.169589    |\n",
      "|    std                  | 9.47        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1658        |\n",
      "|    time_elapsed         | 30728       |\n",
      "|    total_timesteps      | 3395584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00822535  |\n",
      "|    clip_fraction        | 0.0735      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 16570       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -0.18721014 |\n",
      "|    std                  | 9.49        |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1659        |\n",
      "|    time_elapsed         | 30747       |\n",
      "|    total_timesteps      | 3397632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011015596 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.0531      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 16580       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -0.6858412  |\n",
      "|    std                  | 9.51        |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1660         |\n",
      "|    time_elapsed         | 30765        |\n",
      "|    total_timesteps      | 3399680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096097635 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.7         |\n",
      "|    n_updates            | 16590        |\n",
      "|    policy_gradient_loss | -0.00821     |\n",
      "|    reward               | 0.09438215   |\n",
      "|    std                  | 9.52         |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1661        |\n",
      "|    time_elapsed         | 30783       |\n",
      "|    total_timesteps      | 3401728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008622963 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.0459      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 16600       |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    reward               | 0.6282132   |\n",
      "|    std                  | 9.54        |\n",
      "|    value_loss           | 220         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1662        |\n",
      "|    time_elapsed         | 30802       |\n",
      "|    total_timesteps      | 3403776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009205863 |\n",
      "|    clip_fraction        | 0.0913      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.0897      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 16610       |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    reward               | -9.3518     |\n",
      "|    std                  | 9.55        |\n",
      "|    value_loss           | 80.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1663        |\n",
      "|    time_elapsed         | 30820       |\n",
      "|    total_timesteps      | 3405824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009079693 |\n",
      "|    clip_fraction        | 0.0447      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.7        |\n",
      "|    n_updates            | 16620       |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    reward               | 1.4981867   |\n",
      "|    std                  | 9.56        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1664         |\n",
      "|    time_elapsed         | 30839        |\n",
      "|    total_timesteps      | 3407872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015930942 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 119          |\n",
      "|    n_updates            | 16630        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | -16.623438   |\n",
      "|    std                  | 9.57         |\n",
      "|    value_loss           | 195          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1665        |\n",
      "|    time_elapsed         | 30857       |\n",
      "|    total_timesteps      | 3409920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007244692 |\n",
      "|    clip_fraction        | 0.0373      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.2        |\n",
      "|    n_updates            | 16640       |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    reward               | 1.4666518   |\n",
      "|    std                  | 9.56        |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7432898.58\n",
      "total_reward: 6432898.58\n",
      "total_cost: 107033.57\n",
      "total_trades: 54797\n",
      "Sharpe: 0.932\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1666        |\n",
      "|    time_elapsed         | 30874       |\n",
      "|    total_timesteps      | 3411968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007862559 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 16650       |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | 4.0570025   |\n",
      "|    std                  | 9.57        |\n",
      "|    value_loss           | 88.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1667         |\n",
      "|    time_elapsed         | 30892        |\n",
      "|    total_timesteps      | 3414016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032935827 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.198        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 105          |\n",
      "|    n_updates            | 16660        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | -1.0483497   |\n",
      "|    std                  | 9.58         |\n",
      "|    value_loss           | 184          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1668         |\n",
      "|    time_elapsed         | 30911        |\n",
      "|    total_timesteps      | 3416064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064425343 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.186        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 16670        |\n",
      "|    policy_gradient_loss | -0.00847     |\n",
      "|    reward               | -2.1721396   |\n",
      "|    std                  | 9.59         |\n",
      "|    value_loss           | 261          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1669        |\n",
      "|    time_elapsed         | 30930       |\n",
      "|    total_timesteps      | 3418112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010914659 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.7        |\n",
      "|    n_updates            | 16680       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 2.4269981   |\n",
      "|    std                  | 9.62        |\n",
      "|    value_loss           | 86.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1670        |\n",
      "|    time_elapsed         | 30948       |\n",
      "|    total_timesteps      | 3420160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009776257 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98.1        |\n",
      "|    n_updates            | 16690       |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    reward               | -2.3492565  |\n",
      "|    std                  | 9.63        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1671         |\n",
      "|    time_elapsed         | 30967        |\n",
      "|    total_timesteps      | 3422208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065705404 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.339        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.3         |\n",
      "|    n_updates            | 16700        |\n",
      "|    policy_gradient_loss | -0.00691     |\n",
      "|    reward               | 2.0325491    |\n",
      "|    std                  | 9.64         |\n",
      "|    value_loss           | 189          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1672       |\n",
      "|    time_elapsed         | 30986      |\n",
      "|    total_timesteps      | 3424256    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01080388 |\n",
      "|    clip_fraction        | 0.0615     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -107       |\n",
      "|    explained_variance   | 0.101      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 80.4       |\n",
      "|    n_updates            | 16710      |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    reward               | 1.227741   |\n",
      "|    std                  | 9.67       |\n",
      "|    value_loss           | 149        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1673        |\n",
      "|    time_elapsed         | 31005       |\n",
      "|    total_timesteps      | 3426304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007374501 |\n",
      "|    clip_fraction        | 0.0307      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.6        |\n",
      "|    n_updates            | 16720       |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | 0.9681895   |\n",
      "|    std                  | 9.69        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1674          |\n",
      "|    time_elapsed         | 31024         |\n",
      "|    total_timesteps      | 3428352       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082342816 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -107          |\n",
      "|    explained_variance   | 0.458         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 63.1          |\n",
      "|    n_updates            | 16730         |\n",
      "|    policy_gradient_loss | -0.00222      |\n",
      "|    reward               | 1.390693      |\n",
      "|    std                  | 9.69          |\n",
      "|    value_loss           | 192           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1675        |\n",
      "|    time_elapsed         | 31044       |\n",
      "|    total_timesteps      | 3430400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008355425 |\n",
      "|    clip_fraction        | 0.0536      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.5        |\n",
      "|    n_updates            | 16740       |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    reward               | -4.621047   |\n",
      "|    std                  | 9.7         |\n",
      "|    value_loss           | 231         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1676        |\n",
      "|    time_elapsed         | 31062       |\n",
      "|    total_timesteps      | 3432448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009704674 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 16750       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -4.0397415  |\n",
      "|    std                  | 9.72        |\n",
      "|    value_loss           | 81.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1677         |\n",
      "|    time_elapsed         | 31081        |\n",
      "|    total_timesteps      | 3434496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058107604 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.1         |\n",
      "|    n_updates            | 16760        |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    reward               | 1.1550138    |\n",
      "|    std                  | 9.73         |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1678         |\n",
      "|    time_elapsed         | 31100        |\n",
      "|    total_timesteps      | 3436544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060455287 |\n",
      "|    clip_fraction        | 0.0255       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82.5         |\n",
      "|    n_updates            | 16770        |\n",
      "|    policy_gradient_loss | -0.0072      |\n",
      "|    reward               | 0.58173674   |\n",
      "|    std                  | 9.74         |\n",
      "|    value_loss           | 256          |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 1679      |\n",
      "|    time_elapsed         | 31120     |\n",
      "|    total_timesteps      | 3438592   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0090211 |\n",
      "|    clip_fraction        | 0.0586    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -107      |\n",
      "|    explained_variance   | 0.186     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 59.9      |\n",
      "|    n_updates            | 16780     |\n",
      "|    policy_gradient_loss | -0.00782  |\n",
      "|    reward               | 8.741934  |\n",
      "|    std                  | 9.76      |\n",
      "|    value_loss           | 126       |\n",
      "---------------------------------------\n",
      "day: 2892, episode: 1190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7207248.04\n",
      "total_reward: 6207248.04\n",
      "total_cost: 102998.24\n",
      "total_trades: 54296\n",
      "Sharpe: 0.904\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1680        |\n",
      "|    time_elapsed         | 31137       |\n",
      "|    total_timesteps      | 3440640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008714866 |\n",
      "|    clip_fraction        | 0.0472      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.6        |\n",
      "|    n_updates            | 16790       |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    reward               | 3.607565    |\n",
      "|    std                  | 9.76        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1681        |\n",
      "|    time_elapsed         | 31156       |\n",
      "|    total_timesteps      | 3442688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006901289 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 16800       |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    reward               | -1.3012097  |\n",
      "|    std                  | 9.77        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1682        |\n",
      "|    time_elapsed         | 31175       |\n",
      "|    total_timesteps      | 3444736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003453034 |\n",
      "|    clip_fraction        | 0.00542     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 16810       |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    reward               | 2.1210961   |\n",
      "|    std                  | 9.78        |\n",
      "|    value_loss           | 248         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1683        |\n",
      "|    time_elapsed         | 31194       |\n",
      "|    total_timesteps      | 3446784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009527431 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 16820       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -4.7408185  |\n",
      "|    std                  | 9.78        |\n",
      "|    value_loss           | 82.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1684        |\n",
      "|    time_elapsed         | 31213       |\n",
      "|    total_timesteps      | 3448832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004682998 |\n",
      "|    clip_fraction        | 0.00923     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 86.6        |\n",
      "|    n_updates            | 16830       |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    reward               | -1.0476497  |\n",
      "|    std                  | 9.8         |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1685        |\n",
      "|    time_elapsed         | 31230       |\n",
      "|    total_timesteps      | 3450880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008234546 |\n",
      "|    clip_fraction        | 0.0718      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 16840       |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    reward               | -0.96299946 |\n",
      "|    std                  | 9.82        |\n",
      "|    value_loss           | 217         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1686         |\n",
      "|    time_elapsed         | 31248        |\n",
      "|    total_timesteps      | 3452928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073617776 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.162        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 85           |\n",
      "|    n_updates            | 16850        |\n",
      "|    policy_gradient_loss | -0.0071      |\n",
      "|    reward               | -0.03604364  |\n",
      "|    std                  | 9.84         |\n",
      "|    value_loss           | 128          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1687        |\n",
      "|    time_elapsed         | 31267       |\n",
      "|    total_timesteps      | 3454976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009938338 |\n",
      "|    clip_fraction        | 0.0772      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.3        |\n",
      "|    n_updates            | 16860       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 4.0324187   |\n",
      "|    std                  | 9.85        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1688         |\n",
      "|    time_elapsed         | 31285        |\n",
      "|    total_timesteps      | 3457024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055786115 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 114          |\n",
      "|    n_updates            | 16870        |\n",
      "|    policy_gradient_loss | -0.00699     |\n",
      "|    reward               | -3.454245    |\n",
      "|    std                  | 9.86         |\n",
      "|    value_loss           | 192          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1689         |\n",
      "|    time_elapsed         | 31303        |\n",
      "|    total_timesteps      | 3459072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068676677 |\n",
      "|    clip_fraction        | 0.0337       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.146        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.6         |\n",
      "|    n_updates            | 16880        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    reward               | -5.2613664   |\n",
      "|    std                  | 9.87         |\n",
      "|    value_loss           | 183          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1690         |\n",
      "|    time_elapsed         | 31321        |\n",
      "|    total_timesteps      | 3461120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0132304765 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.352        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.7         |\n",
      "|    n_updates            | 16890        |\n",
      "|    policy_gradient_loss | -0.0129      |\n",
      "|    reward               | -0.54934424  |\n",
      "|    std                  | 9.9          |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1691         |\n",
      "|    time_elapsed         | 31339        |\n",
      "|    total_timesteps      | 3463168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020756114 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 96.6         |\n",
      "|    n_updates            | 16900        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | 0.430128     |\n",
      "|    std                  | 9.91         |\n",
      "|    value_loss           | 178          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1692         |\n",
      "|    time_elapsed         | 31357        |\n",
      "|    total_timesteps      | 3465216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018113686 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.421        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 103          |\n",
      "|    n_updates            | 16910        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    reward               | 11.039422    |\n",
      "|    std                  | 9.92         |\n",
      "|    value_loss           | 209          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1693        |\n",
      "|    time_elapsed         | 31375       |\n",
      "|    total_timesteps      | 3467264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008057588 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.4        |\n",
      "|    n_updates            | 16920       |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    reward               | -3.2036135  |\n",
      "|    std                  | 9.93        |\n",
      "|    value_loss           | 95.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6542767.46\n",
      "total_reward: 5542767.46\n",
      "total_cost: 124023.18\n",
      "total_trades: 55705\n",
      "Sharpe: 0.842\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1694         |\n",
      "|    time_elapsed         | 31395        |\n",
      "|    total_timesteps      | 3469312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018189248 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.477        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.5         |\n",
      "|    n_updates            | 16930        |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    reward               | -0.37276113  |\n",
      "|    std                  | 9.94         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1695         |\n",
      "|    time_elapsed         | 31414        |\n",
      "|    total_timesteps      | 3471360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069862213 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.6         |\n",
      "|    n_updates            | 16940        |\n",
      "|    policy_gradient_loss | -0.00661     |\n",
      "|    reward               | -4.208798    |\n",
      "|    std                  | 9.95         |\n",
      "|    value_loss           | 189          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1696        |\n",
      "|    time_elapsed         | 31432       |\n",
      "|    total_timesteps      | 3473408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003935227 |\n",
      "|    clip_fraction        | 0.00459     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.7        |\n",
      "|    n_updates            | 16950       |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | 0.26507363  |\n",
      "|    std                  | 9.97        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1697         |\n",
      "|    time_elapsed         | 31452        |\n",
      "|    total_timesteps      | 3475456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067372713 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.9         |\n",
      "|    n_updates            | 16960        |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    reward               | -1.073827    |\n",
      "|    std                  | 9.98         |\n",
      "|    value_loss           | 138          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1698        |\n",
      "|    time_elapsed         | 31470       |\n",
      "|    total_timesteps      | 3477504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007885069 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.8        |\n",
      "|    n_updates            | 16970       |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    reward               | 0.5788893   |\n",
      "|    std                  | 10          |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1699        |\n",
      "|    time_elapsed         | 31489       |\n",
      "|    total_timesteps      | 3479552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008424301 |\n",
      "|    clip_fraction        | 0.0424      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 16980       |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    reward               | -12.974499  |\n",
      "|    std                  | 10          |\n",
      "|    value_loss           | 230         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1700         |\n",
      "|    time_elapsed         | 31508        |\n",
      "|    total_timesteps      | 3481600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126192225 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.179        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.2         |\n",
      "|    n_updates            | 16990        |\n",
      "|    policy_gradient_loss | -0.0092      |\n",
      "|    reward               | -3.536885    |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1701         |\n",
      "|    time_elapsed         | 31527        |\n",
      "|    total_timesteps      | 3483648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064211637 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 110          |\n",
      "|    n_updates            | 17000        |\n",
      "|    policy_gradient_loss | -0.00893     |\n",
      "|    reward               | -0.045858093 |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 180          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1702         |\n",
      "|    time_elapsed         | 31546        |\n",
      "|    total_timesteps      | 3485696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033470183 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 144          |\n",
      "|    n_updates            | 17010        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | -8.63642     |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 262          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1703        |\n",
      "|    time_elapsed         | 31564       |\n",
      "|    total_timesteps      | 3487744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010990964 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.5        |\n",
      "|    n_updates            | 17020       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -7.561802   |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1704        |\n",
      "|    time_elapsed         | 31583       |\n",
      "|    total_timesteps      | 3489792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007553637 |\n",
      "|    clip_fraction        | 0.053       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 99.8        |\n",
      "|    n_updates            | 17030       |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    reward               | 6.033989    |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1705        |\n",
      "|    time_elapsed         | 31602       |\n",
      "|    total_timesteps      | 3491840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008307192 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 17040       |\n",
      "|    policy_gradient_loss | -0.00947    |\n",
      "|    reward               | 21.486927   |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 230         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1706        |\n",
      "|    time_elapsed         | 31621       |\n",
      "|    total_timesteps      | 3493888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005852163 |\n",
      "|    clip_fraction        | 0.0274      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 226         |\n",
      "|    n_updates            | 17050       |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    reward               | -0.9256324  |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 258         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1707        |\n",
      "|    time_elapsed         | 31640       |\n",
      "|    total_timesteps      | 3495936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012265303 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.9        |\n",
      "|    n_updates            | 17060       |\n",
      "|    policy_gradient_loss | -0.00814    |\n",
      "|    reward               | 0.33382735  |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 86.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8207456.22\n",
      "total_reward: 7207456.22\n",
      "total_cost: 113777.51\n",
      "total_trades: 55622\n",
      "Sharpe: 0.925\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1708         |\n",
      "|    time_elapsed         | 31679        |\n",
      "|    total_timesteps      | 3497984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071231825 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.8         |\n",
      "|    n_updates            | 17070        |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    reward               | -5.481845    |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 160          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1709        |\n",
      "|    time_elapsed         | 31698       |\n",
      "|    total_timesteps      | 3500032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005082694 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 17080       |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    reward               | 2.3295858   |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 263         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1710        |\n",
      "|    time_elapsed         | 31716       |\n",
      "|    total_timesteps      | 3502080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009324509 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55          |\n",
      "|    n_updates            | 17090       |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | -2.1067894  |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1711        |\n",
      "|    time_elapsed         | 31735       |\n",
      "|    total_timesteps      | 3504128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005092211 |\n",
      "|    clip_fraction        | 0.0183      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 99.2        |\n",
      "|    n_updates            | 17100       |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    reward               | -1.067897   |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1712        |\n",
      "|    time_elapsed         | 31753       |\n",
      "|    total_timesteps      | 3506176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006686638 |\n",
      "|    clip_fraction        | 0.0284      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.9        |\n",
      "|    n_updates            | 17110       |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | 3.416103    |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 259         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1713         |\n",
      "|    time_elapsed         | 31772        |\n",
      "|    total_timesteps      | 3508224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062581724 |\n",
      "|    clip_fraction        | 0.0257       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.466        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.6         |\n",
      "|    n_updates            | 17120        |\n",
      "|    policy_gradient_loss | -0.00694     |\n",
      "|    reward               | -1.2120577   |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 182          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1714        |\n",
      "|    time_elapsed         | 31792       |\n",
      "|    total_timesteps      | 3510272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008675881 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.6        |\n",
      "|    n_updates            | 17130       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 3.1587334   |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1715         |\n",
      "|    time_elapsed         | 31810        |\n",
      "|    total_timesteps      | 3512320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038213672 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.7         |\n",
      "|    n_updates            | 17140        |\n",
      "|    policy_gradient_loss | -0.00648     |\n",
      "|    reward               | -0.25979108  |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 197          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1716        |\n",
      "|    time_elapsed         | 31830       |\n",
      "|    total_timesteps      | 3514368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001962796 |\n",
      "|    clip_fraction        | 0.000781    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 17150       |\n",
      "|    policy_gradient_loss | -0.00256    |\n",
      "|    reward               | 4.836942    |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 305         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1717       |\n",
      "|    time_elapsed         | 31849      |\n",
      "|    total_timesteps      | 3516416    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00887968 |\n",
      "|    clip_fraction        | 0.0448     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -108       |\n",
      "|    explained_variance   | 0.783      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 47.6       |\n",
      "|    n_updates            | 17160      |\n",
      "|    policy_gradient_loss | -0.00815   |\n",
      "|    reward               | 3.4722219  |\n",
      "|    std                  | 10.2       |\n",
      "|    value_loss           | 83.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1718        |\n",
      "|    time_elapsed         | 31868       |\n",
      "|    total_timesteps      | 3518464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003911405 |\n",
      "|    clip_fraction        | 0.00513     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.6        |\n",
      "|    n_updates            | 17170       |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    reward               | 0.7037758   |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 217         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1719         |\n",
      "|    time_elapsed         | 31887        |\n",
      "|    total_timesteps      | 3520512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035251384 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 109          |\n",
      "|    n_updates            | 17180        |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    reward               | 7.444545     |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 262          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1720        |\n",
      "|    time_elapsed         | 31906       |\n",
      "|    total_timesteps      | 3522560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003733947 |\n",
      "|    clip_fraction        | 0.00654     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.1        |\n",
      "|    n_updates            | 17190       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    reward               | -2.6913218  |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1721        |\n",
      "|    time_elapsed         | 31924       |\n",
      "|    total_timesteps      | 3524608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006462335 |\n",
      "|    clip_fraction        | 0.0237      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.5        |\n",
      "|    n_updates            | 17200       |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    reward               | 1.7914245   |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8815216.45\n",
      "total_reward: 7815216.45\n",
      "total_cost: 114250.50\n",
      "total_trades: 55182\n",
      "Sharpe: 0.969\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1722        |\n",
      "|    time_elapsed         | 31942       |\n",
      "|    total_timesteps      | 3526656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003620656 |\n",
      "|    clip_fraction        | 0.0103      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 17210       |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    reward               | 0.2240235   |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 240         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1723         |\n",
      "|    time_elapsed         | 31962        |\n",
      "|    total_timesteps      | 3528704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033805254 |\n",
      "|    clip_fraction        | 0.00747      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 106          |\n",
      "|    n_updates            | 17220        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    reward               | -4.984038    |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 301          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1724       |\n",
      "|    time_elapsed         | 31980      |\n",
      "|    total_timesteps      | 3530752    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00956093 |\n",
      "|    clip_fraction        | 0.0802     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -108       |\n",
      "|    explained_variance   | 0.584      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 43         |\n",
      "|    n_updates            | 17230      |\n",
      "|    policy_gradient_loss | -0.00773   |\n",
      "|    reward               | -0.1528207 |\n",
      "|    std                  | 10.3       |\n",
      "|    value_loss           | 72.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1725        |\n",
      "|    time_elapsed         | 31999       |\n",
      "|    total_timesteps      | 3532800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005423525 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 17240       |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    reward               | 0.15262634  |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 230         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1726        |\n",
      "|    time_elapsed         | 32017       |\n",
      "|    total_timesteps      | 3534848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004381575 |\n",
      "|    clip_fraction        | 0.00771     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 159         |\n",
      "|    n_updates            | 17250       |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | -1.3537072  |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 272         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1727         |\n",
      "|    time_elapsed         | 32036        |\n",
      "|    total_timesteps      | 3536896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074887555 |\n",
      "|    clip_fraction        | 0.0403       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.2         |\n",
      "|    n_updates            | 17260        |\n",
      "|    policy_gradient_loss | -0.00908     |\n",
      "|    reward               | -8.413065    |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1728         |\n",
      "|    time_elapsed         | 32055        |\n",
      "|    total_timesteps      | 3538944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068682213 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.69         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 109          |\n",
      "|    n_updates            | 17270        |\n",
      "|    policy_gradient_loss | -0.00551     |\n",
      "|    reward               | 0.5790281    |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 165          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1729        |\n",
      "|    time_elapsed         | 32073       |\n",
      "|    total_timesteps      | 3540992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005983681 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 17280       |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | 13.023914   |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 271         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1730         |\n",
      "|    time_elapsed         | 32092        |\n",
      "|    total_timesteps      | 3543040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042621153 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 253          |\n",
      "|    n_updates            | 17290        |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    reward               | -0.9825124   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 331          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1731         |\n",
      "|    time_elapsed         | 32111        |\n",
      "|    total_timesteps      | 3545088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0118556665 |\n",
      "|    clip_fraction        | 0.0979       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.3         |\n",
      "|    n_updates            | 17300        |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    reward               | -0.89416236  |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 90           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1732        |\n",
      "|    time_elapsed         | 32130       |\n",
      "|    total_timesteps      | 3547136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006794763 |\n",
      "|    clip_fraction        | 0.0393      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 230         |\n",
      "|    n_updates            | 17310       |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    reward               | 0.911254    |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 365         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1733         |\n",
      "|    time_elapsed         | 32150        |\n",
      "|    total_timesteps      | 3549184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034403037 |\n",
      "|    clip_fraction        | 0.00591      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 138          |\n",
      "|    n_updates            | 17320        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    reward               | -2.1938565   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 364          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1734        |\n",
      "|    time_elapsed         | 32169       |\n",
      "|    total_timesteps      | 3551232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009391329 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.8        |\n",
      "|    n_updates            | 17330       |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    reward               | 1.8488669   |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 96.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1735         |\n",
      "|    time_elapsed         | 32187        |\n",
      "|    total_timesteps      | 3553280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042197006 |\n",
      "|    clip_fraction        | 0.0082       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 126          |\n",
      "|    n_updates            | 17340        |\n",
      "|    policy_gradient_loss | -0.00739     |\n",
      "|    reward               | -0.39945042  |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 339          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1736         |\n",
      "|    time_elapsed         | 32206        |\n",
      "|    total_timesteps      | 3555328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030818265 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 174          |\n",
      "|    n_updates            | 17350        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    reward               | -7.5947776   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 322          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9977518.71\n",
      "total_reward: 8977518.71\n",
      "total_cost: 99968.14\n",
      "total_trades: 53633\n",
      "Sharpe: 1.025\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1737         |\n",
      "|    time_elapsed         | 32225        |\n",
      "|    total_timesteps      | 3557376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050755595 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 113          |\n",
      "|    n_updates            | 17360        |\n",
      "|    policy_gradient_loss | -0.00498     |\n",
      "|    reward               | -0.57032627  |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 182          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1738        |\n",
      "|    time_elapsed         | 32244       |\n",
      "|    total_timesteps      | 3559424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008700421 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 17370       |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    reward               | -2.046346   |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 217         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1739        |\n",
      "|    time_elapsed         | 32262       |\n",
      "|    total_timesteps      | 3561472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004044232 |\n",
      "|    clip_fraction        | 0.00742     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 199         |\n",
      "|    n_updates            | 17380       |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | -0.59038955 |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 337         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1740         |\n",
      "|    time_elapsed         | 32281        |\n",
      "|    total_timesteps      | 3563520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022397717 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.392        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 180          |\n",
      "|    n_updates            | 17390        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | -1.7761552   |\n",
      "|    std                  | 10.5         |\n",
      "|    value_loss           | 378          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1741        |\n",
      "|    time_elapsed         | 32300       |\n",
      "|    total_timesteps      | 3565568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012331103 |\n",
      "|    clip_fraction        | 0.0919      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.1        |\n",
      "|    n_updates            | 17400       |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    reward               | 0.8942287   |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 83.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1742         |\n",
      "|    time_elapsed         | 32319        |\n",
      "|    total_timesteps      | 3567616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018909279 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 179          |\n",
      "|    n_updates            | 17410        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    reward               | -1.4240093   |\n",
      "|    std                  | 10.5         |\n",
      "|    value_loss           | 280          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1743         |\n",
      "|    time_elapsed         | 32338        |\n",
      "|    total_timesteps      | 3569664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021564784 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 163          |\n",
      "|    n_updates            | 17420        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | -0.7962106   |\n",
      "|    std                  | 10.5         |\n",
      "|    value_loss           | 372          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1744        |\n",
      "|    time_elapsed         | 32355       |\n",
      "|    total_timesteps      | 3571712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007967791 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98.7        |\n",
      "|    n_updates            | 17430       |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    reward               | 3.807288    |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1745        |\n",
      "|    time_elapsed         | 32373       |\n",
      "|    total_timesteps      | 3573760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008408646 |\n",
      "|    clip_fraction        | 0.0444      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 17440       |\n",
      "|    policy_gradient_loss | -0.00917    |\n",
      "|    reward               | 0.9937309   |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 217         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1746         |\n",
      "|    time_elapsed         | 32391        |\n",
      "|    total_timesteps      | 3575808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034026573 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 132          |\n",
      "|    n_updates            | 17450        |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    reward               | 0.87415093   |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 290          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1747        |\n",
      "|    time_elapsed         | 32410       |\n",
      "|    total_timesteps      | 3577856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002757899 |\n",
      "|    clip_fraction        | 0.00132     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 17460       |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    reward               | 4.53636     |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 308         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1748        |\n",
      "|    time_elapsed         | 32429       |\n",
      "|    total_timesteps      | 3579904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013549035 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.9        |\n",
      "|    n_updates            | 17470       |\n",
      "|    policy_gradient_loss | -0.00948    |\n",
      "|    reward               | 3.9442165   |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 77.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1749         |\n",
      "|    time_elapsed         | 32447        |\n",
      "|    total_timesteps      | 3581952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023776381 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 129          |\n",
      "|    n_updates            | 17480        |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    reward               | -1.0235199   |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 272          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1750         |\n",
      "|    time_elapsed         | 32466        |\n",
      "|    total_timesteps      | 3584000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019394506 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 209          |\n",
      "|    n_updates            | 17490        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | -8.983003    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 335          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8991152.94\n",
      "total_reward: 7991152.94\n",
      "total_cost: 92101.24\n",
      "total_trades: 52739\n",
      "Sharpe: 0.961\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1751        |\n",
      "|    time_elapsed         | 32483       |\n",
      "|    total_timesteps      | 3586048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009005847 |\n",
      "|    clip_fraction        | 0.0466      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.4        |\n",
      "|    n_updates            | 17500       |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    reward               | -4.2472434  |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1752         |\n",
      "|    time_elapsed         | 32502        |\n",
      "|    total_timesteps      | 3588096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038527185 |\n",
      "|    clip_fraction        | 0.00542      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 115          |\n",
      "|    n_updates            | 17510        |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    reward               | 3.023012     |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 227          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1753         |\n",
      "|    time_elapsed         | 32521        |\n",
      "|    total_timesteps      | 3590144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011398377 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.716        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 87.6         |\n",
      "|    n_updates            | 17520        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | 53.262596    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 274          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1754         |\n",
      "|    time_elapsed         | 32539        |\n",
      "|    total_timesteps      | 3592192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031983354 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 192          |\n",
      "|    n_updates            | 17530        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | 3.3615167    |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 258          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1755        |\n",
      "|    time_elapsed         | 32559       |\n",
      "|    total_timesteps      | 3594240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009484883 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.5        |\n",
      "|    n_updates            | 17540       |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    reward               | 0.56848687  |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 97.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1756         |\n",
      "|    time_elapsed         | 32577        |\n",
      "|    total_timesteps      | 3596288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070971576 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 159          |\n",
      "|    n_updates            | 17550        |\n",
      "|    policy_gradient_loss | -0.00692     |\n",
      "|    reward               | 0.5287614    |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 296          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1757        |\n",
      "|    time_elapsed         | 32595       |\n",
      "|    total_timesteps      | 3598336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007074266 |\n",
      "|    clip_fraction        | 0.0427      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 17560       |\n",
      "|    policy_gradient_loss | -0.00896    |\n",
      "|    reward               | 7.3387156   |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 385         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1758        |\n",
      "|    time_elapsed         | 32614       |\n",
      "|    total_timesteps      | 3600384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008952465 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.4        |\n",
      "|    n_updates            | 17570       |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    reward               | 3.7383637   |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 89.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1759         |\n",
      "|    time_elapsed         | 32633        |\n",
      "|    total_timesteps      | 3602432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034724057 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.7         |\n",
      "|    n_updates            | 17580        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    reward               | -0.71361035  |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 275          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1760         |\n",
      "|    time_elapsed         | 32650        |\n",
      "|    total_timesteps      | 3604480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051009054 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 134          |\n",
      "|    n_updates            | 17590        |\n",
      "|    policy_gradient_loss | -0.00487     |\n",
      "|    reward               | 1.7369789    |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 286          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1761         |\n",
      "|    time_elapsed         | 32668        |\n",
      "|    total_timesteps      | 3606528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075699827 |\n",
      "|    clip_fraction        | 0.0382       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 17600        |\n",
      "|    policy_gradient_loss | -0.00865     |\n",
      "|    reward               | 3.5777166    |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 157          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1762        |\n",
      "|    time_elapsed         | 32686       |\n",
      "|    total_timesteps      | 3608576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009369608 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.7        |\n",
      "|    n_updates            | 17610       |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    reward               | 3.6848376   |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 198         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1763         |\n",
      "|    time_elapsed         | 32704        |\n",
      "|    total_timesteps      | 3610624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044500423 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 17620        |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    reward               | 1.6244509    |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 295          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1764         |\n",
      "|    time_elapsed         | 32723        |\n",
      "|    total_timesteps      | 3612672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038564466 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.402        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 117          |\n",
      "|    n_updates            | 17630        |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    reward               | 0.5526029    |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 318          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9571425.31\n",
      "total_reward: 8571425.31\n",
      "total_cost: 92725.18\n",
      "total_trades: 53216\n",
      "Sharpe: 0.983\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1765        |\n",
      "|    time_elapsed         | 32741       |\n",
      "|    total_timesteps      | 3614720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012599103 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.6        |\n",
      "|    n_updates            | 17640       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 3.9688947   |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 89.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1766         |\n",
      "|    time_elapsed         | 32758        |\n",
      "|    total_timesteps      | 3616768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038941107 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 17650        |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    reward               | 1.3865228    |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 246          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1767         |\n",
      "|    time_elapsed         | 32777        |\n",
      "|    total_timesteps      | 3618816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045077694 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 100          |\n",
      "|    n_updates            | 17660        |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    reward               | 7.4545417    |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 266          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1768       |\n",
      "|    time_elapsed         | 32795      |\n",
      "|    total_timesteps      | 3620864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01058967 |\n",
      "|    clip_fraction        | 0.0595     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -110       |\n",
      "|    explained_variance   | 0.564      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 44.6       |\n",
      "|    n_updates            | 17670      |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    reward               | 1.7896804  |\n",
      "|    std                  | 11         |\n",
      "|    value_loss           | 113        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1769        |\n",
      "|    time_elapsed         | 32814       |\n",
      "|    total_timesteps      | 3622912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008440855 |\n",
      "|    clip_fraction        | 0.0416      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94          |\n",
      "|    n_updates            | 17680       |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    reward               | -3.2202291  |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1770         |\n",
      "|    time_elapsed         | 32833        |\n",
      "|    total_timesteps      | 3624960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056272186 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 156          |\n",
      "|    n_updates            | 17690        |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    reward               | 0.059427924  |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 277          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1771        |\n",
      "|    time_elapsed         | 32851       |\n",
      "|    total_timesteps      | 3627008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005045059 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 158         |\n",
      "|    n_updates            | 17700       |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    reward               | -0.53714335 |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 345         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1772        |\n",
      "|    time_elapsed         | 32869       |\n",
      "|    total_timesteps      | 3629056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010791518 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 17710       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 0.7251707   |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 84.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1773         |\n",
      "|    time_elapsed         | 32888        |\n",
      "|    total_timesteps      | 3631104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041605523 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 168          |\n",
      "|    n_updates            | 17720        |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    reward               | -1.3965979   |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 267          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1774         |\n",
      "|    time_elapsed         | 32906        |\n",
      "|    total_timesteps      | 3633152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030014166 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 143          |\n",
      "|    n_updates            | 17730        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | -3.079505    |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 334          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1775         |\n",
      "|    time_elapsed         | 32925        |\n",
      "|    total_timesteps      | 3635200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075936625 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48           |\n",
      "|    n_updates            | 17740        |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    reward               | 8.214343     |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1776        |\n",
      "|    time_elapsed         | 32944       |\n",
      "|    total_timesteps      | 3637248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008112036 |\n",
      "|    clip_fraction        | 0.0481      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 17750       |\n",
      "|    policy_gradient_loss | -0.00909    |\n",
      "|    reward               | 0.25093034  |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1777        |\n",
      "|    time_elapsed         | 32962       |\n",
      "|    total_timesteps      | 3639296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004393476 |\n",
      "|    clip_fraction        | 0.00786     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 188         |\n",
      "|    n_updates            | 17760       |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    reward               | -3.6907713  |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 354         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1778         |\n",
      "|    time_elapsed         | 32981        |\n",
      "|    total_timesteps      | 3641344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036658095 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 145          |\n",
      "|    n_updates            | 17770        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    reward               | 2.8883464    |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 292          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9273271.76\n",
      "total_reward: 8273271.76\n",
      "total_cost: 80937.59\n",
      "total_trades: 52528\n",
      "Sharpe: 0.960\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1779        |\n",
      "|    time_elapsed         | 32999       |\n",
      "|    total_timesteps      | 3643392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007575362 |\n",
      "|    clip_fraction        | 0.0386      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.2        |\n",
      "|    n_updates            | 17780       |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    reward               | 0.8686048   |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1780         |\n",
      "|    time_elapsed         | 33018        |\n",
      "|    total_timesteps      | 3645440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011544896 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 180          |\n",
      "|    n_updates            | 17790        |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    reward               | -0.18906489  |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 407          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1781         |\n",
      "|    time_elapsed         | 33037        |\n",
      "|    total_timesteps      | 3647488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006307916  |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 311          |\n",
      "|    n_updates            | 17800        |\n",
      "|    policy_gradient_loss | -0.00686     |\n",
      "|    reward               | -0.014141539 |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 407          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1782       |\n",
      "|    time_elapsed         | 33055      |\n",
      "|    total_timesteps      | 3649536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00961641 |\n",
      "|    clip_fraction        | 0.0894     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -111       |\n",
      "|    explained_variance   | 0.654      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 47.3       |\n",
      "|    n_updates            | 17810      |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    reward               | 0.49714464 |\n",
      "|    std                  | 11.2       |\n",
      "|    value_loss           | 109        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1783        |\n",
      "|    time_elapsed         | 33074       |\n",
      "|    total_timesteps      | 3651584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010999893 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 17820       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | 0.61748314  |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 388         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1784          |\n",
      "|    time_elapsed         | 33092         |\n",
      "|    total_timesteps      | 3653632       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089667225 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -111          |\n",
      "|    explained_variance   | 0.633         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 147           |\n",
      "|    n_updates            | 17830         |\n",
      "|    policy_gradient_loss | -0.00188      |\n",
      "|    reward               | 3.458478      |\n",
      "|    std                  | 11.3          |\n",
      "|    value_loss           | 503           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1785        |\n",
      "|    time_elapsed         | 33111       |\n",
      "|    total_timesteps      | 3655680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006997506 |\n",
      "|    clip_fraction        | 0.0165      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82          |\n",
      "|    n_updates            | 17840       |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    reward               | 2.6956964   |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1786        |\n",
      "|    time_elapsed         | 33130       |\n",
      "|    total_timesteps      | 3657728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009488707 |\n",
      "|    clip_fraction        | 0.0595      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.3        |\n",
      "|    n_updates            | 17850       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 0.824899    |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1787        |\n",
      "|    time_elapsed         | 33149       |\n",
      "|    total_timesteps      | 3659776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002975988 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 17860       |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | 2.6997993   |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 378         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1788         |\n",
      "|    time_elapsed         | 33168        |\n",
      "|    total_timesteps      | 3661824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036800413 |\n",
      "|    clip_fraction        | 0.00684      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 184          |\n",
      "|    n_updates            | 17870        |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    reward               | 2.9123263    |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 394          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1789        |\n",
      "|    time_elapsed         | 33187       |\n",
      "|    total_timesteps      | 3663872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011270427 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.6        |\n",
      "|    n_updates            | 17880       |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    reward               | -8.795116   |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 73.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1790         |\n",
      "|    time_elapsed         | 33206        |\n",
      "|    total_timesteps      | 3665920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023197462 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 290          |\n",
      "|    n_updates            | 17890        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | 0.61369276   |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 361          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1791         |\n",
      "|    time_elapsed         | 33224        |\n",
      "|    total_timesteps      | 3667968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027448416 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 247          |\n",
      "|    n_updates            | 17900        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    reward               | 0.014112148  |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 474          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1792        |\n",
      "|    time_elapsed         | 33243       |\n",
      "|    total_timesteps      | 3670016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007935878 |\n",
      "|    clip_fraction        | 0.0509      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.7        |\n",
      "|    n_updates            | 17910       |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | 0.7637085   |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9445041.74\n",
      "total_reward: 8445041.74\n",
      "total_cost: 94875.56\n",
      "total_trades: 52967\n",
      "Sharpe: 0.969\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1793       |\n",
      "|    time_elapsed         | 33262      |\n",
      "|    total_timesteps      | 3672064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00916799 |\n",
      "|    clip_fraction        | 0.0517     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -111       |\n",
      "|    explained_variance   | 0.688      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 99.4       |\n",
      "|    n_updates            | 17920      |\n",
      "|    policy_gradient_loss | -0.00617   |\n",
      "|    reward               | -1.2911637 |\n",
      "|    std                  | 11.4       |\n",
      "|    value_loss           | 253        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1794         |\n",
      "|    time_elapsed         | 33281        |\n",
      "|    total_timesteps      | 3674112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035002343 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 151          |\n",
      "|    n_updates            | 17930        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    reward               | -0.029649667 |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 280          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1795        |\n",
      "|    time_elapsed         | 33301       |\n",
      "|    total_timesteps      | 3676160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003630089 |\n",
      "|    clip_fraction        | 0.00356     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 173         |\n",
      "|    n_updates            | 17940       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | 0.774663    |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 386         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1796        |\n",
      "|    time_elapsed         | 33319       |\n",
      "|    total_timesteps      | 3678208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009852546 |\n",
      "|    clip_fraction        | 0.0871      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.6        |\n",
      "|    n_updates            | 17950       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 4.2383385   |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 74.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1797         |\n",
      "|    time_elapsed         | 33337        |\n",
      "|    total_timesteps      | 3680256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044555515 |\n",
      "|    clip_fraction        | 0.00688      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 229          |\n",
      "|    n_updates            | 17960        |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    reward               | -1.0474516   |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 273          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1798       |\n",
      "|    time_elapsed         | 33355      |\n",
      "|    total_timesteps      | 3682304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00607198 |\n",
      "|    clip_fraction        | 0.0186     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -111       |\n",
      "|    explained_variance   | 0.696      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 156        |\n",
      "|    n_updates            | 17970      |\n",
      "|    policy_gradient_loss | -0.00596   |\n",
      "|    reward               | -7.4095173 |\n",
      "|    std                  | 11.5       |\n",
      "|    value_loss           | 300        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1799        |\n",
      "|    time_elapsed         | 33372       |\n",
      "|    total_timesteps      | 3684352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007078911 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.6        |\n",
      "|    n_updates            | 17980       |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | -0.33548954 |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 97.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1800         |\n",
      "|    time_elapsed         | 33390        |\n",
      "|    total_timesteps      | 3686400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028269887 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 124          |\n",
      "|    n_updates            | 17990        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | 4.376518     |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 209          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1801        |\n",
      "|    time_elapsed         | 33409       |\n",
      "|    total_timesteps      | 3688448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005601843 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 158         |\n",
      "|    n_updates            | 18000       |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    reward               | 2.858179    |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 249         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1802         |\n",
      "|    time_elapsed         | 33428        |\n",
      "|    total_timesteps      | 3690496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029135873 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 162          |\n",
      "|    n_updates            | 18010        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    reward               | -1.0350609   |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 307          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1803        |\n",
      "|    time_elapsed         | 33447       |\n",
      "|    total_timesteps      | 3692544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006807925 |\n",
      "|    clip_fraction        | 0.0324      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.1        |\n",
      "|    n_updates            | 18020       |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    reward               | -6.4757643  |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1804         |\n",
      "|    time_elapsed         | 33465        |\n",
      "|    total_timesteps      | 3694592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016628618 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 156          |\n",
      "|    n_updates            | 18030        |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | 0.018726286  |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 266          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1805         |\n",
      "|    time_elapsed         | 33483        |\n",
      "|    total_timesteps      | 3696640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015588342 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 147          |\n",
      "|    n_updates            | 18040        |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    reward               | -0.43318093  |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 314          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1806        |\n",
      "|    time_elapsed         | 33501       |\n",
      "|    total_timesteps      | 3698688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010681925 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.3        |\n",
      "|    n_updates            | 18050       |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    reward               | 0.08487752  |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 83.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8658362.08\n",
      "total_reward: 7658362.08\n",
      "total_cost: 90139.34\n",
      "total_trades: 53465\n",
      "Sharpe: 0.949\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1807         |\n",
      "|    time_elapsed         | 33520        |\n",
      "|    total_timesteps      | 3700736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024550217 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 98.9         |\n",
      "|    n_updates            | 18060        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | -0.67424244  |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 337          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1808         |\n",
      "|    time_elapsed         | 33538        |\n",
      "|    total_timesteps      | 3702784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026108976 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.646        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 103          |\n",
      "|    n_updates            | 18070        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | 6.462466     |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 307          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1809        |\n",
      "|    time_elapsed         | 33556       |\n",
      "|    total_timesteps      | 3704832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008876745 |\n",
      "|    clip_fraction        | 0.0441      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74          |\n",
      "|    n_updates            | 18080       |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | 6.94421     |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1810        |\n",
      "|    time_elapsed         | 33574       |\n",
      "|    total_timesteps      | 3706880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008864277 |\n",
      "|    clip_fraction        | 0.0616      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.6        |\n",
      "|    n_updates            | 18090       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -1.0733835  |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1811        |\n",
      "|    time_elapsed         | 33593       |\n",
      "|    total_timesteps      | 3708928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002701461 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 18100       |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    reward               | 1.5003303   |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 282         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1812         |\n",
      "|    time_elapsed         | 33613        |\n",
      "|    total_timesteps      | 3710976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041290745 |\n",
      "|    clip_fraction        | 0.0062       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 137          |\n",
      "|    n_updates            | 18110        |\n",
      "|    policy_gradient_loss | -0.00556     |\n",
      "|    reward               | 3.2617595    |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 279          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1813        |\n",
      "|    time_elapsed         | 33632       |\n",
      "|    total_timesteps      | 3713024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009987123 |\n",
      "|    clip_fraction        | 0.0677      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 18120       |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    reward               | 2.5683358   |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 65.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1814         |\n",
      "|    time_elapsed         | 33650        |\n",
      "|    total_timesteps      | 3715072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023545206 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 241          |\n",
      "|    n_updates            | 18130        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | -0.6161849   |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 285          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1815        |\n",
      "|    time_elapsed         | 33669       |\n",
      "|    total_timesteps      | 3717120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004742545 |\n",
      "|    clip_fraction        | 0.0118      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 18140       |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    reward               | -9.652794   |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 243         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1816         |\n",
      "|    time_elapsed         | 33687        |\n",
      "|    total_timesteps      | 3719168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093724765 |\n",
      "|    clip_fraction        | 0.0549       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.317        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.5         |\n",
      "|    n_updates            | 18150        |\n",
      "|    policy_gradient_loss | -0.00777     |\n",
      "|    reward               | 4.8401837    |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1817        |\n",
      "|    time_elapsed         | 33705       |\n",
      "|    total_timesteps      | 3721216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004824275 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88.9        |\n",
      "|    n_updates            | 18160       |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    reward               | 1.559354    |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1818         |\n",
      "|    time_elapsed         | 33724        |\n",
      "|    total_timesteps      | 3723264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058489353 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.742        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 142          |\n",
      "|    n_updates            | 18170        |\n",
      "|    policy_gradient_loss | -0.006       |\n",
      "|    reward               | 4.949262     |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 258          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1819         |\n",
      "|    time_elapsed         | 33742        |\n",
      "|    total_timesteps      | 3725312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018559935 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 18180        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | -2.3502164   |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 297          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1820        |\n",
      "|    time_elapsed         | 33761       |\n",
      "|    total_timesteps      | 3727360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008192126 |\n",
      "|    clip_fraction        | 0.0558      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 18190       |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    reward               | -0.48153234 |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 87.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8323727.21\n",
      "total_reward: 7323727.21\n",
      "total_cost: 90872.77\n",
      "total_trades: 53481\n",
      "Sharpe: 0.927\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1821         |\n",
      "|    time_elapsed         | 33779        |\n",
      "|    total_timesteps      | 3729408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044999057 |\n",
      "|    clip_fraction        | 0.00928      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 172          |\n",
      "|    n_updates            | 18200        |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    reward               | 0.4649399    |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 270          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1822        |\n",
      "|    time_elapsed         | 33797       |\n",
      "|    total_timesteps      | 3731456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003182503 |\n",
      "|    clip_fraction        | 0.00474     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 18210       |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    reward               | -3.9043546  |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 231         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1823        |\n",
      "|    time_elapsed         | 33815       |\n",
      "|    total_timesteps      | 3733504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010169722 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.4        |\n",
      "|    n_updates            | 18220       |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    reward               | -3.9434545  |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1824        |\n",
      "|    time_elapsed         | 33834       |\n",
      "|    total_timesteps      | 3735552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005284464 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.3        |\n",
      "|    n_updates            | 18230       |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    reward               | 1.4781274   |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1825         |\n",
      "|    time_elapsed         | 33852        |\n",
      "|    total_timesteps      | 3737600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033080115 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 205          |\n",
      "|    n_updates            | 18240        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    reward               | 7.6491246    |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 298          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1826        |\n",
      "|    time_elapsed         | 33871       |\n",
      "|    total_timesteps      | 3739648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002794024 |\n",
      "|    clip_fraction        | 0.00229     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 18250       |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    reward               | -0.71251404 |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1827        |\n",
      "|    time_elapsed         | 33890       |\n",
      "|    total_timesteps      | 3741696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009988958 |\n",
      "|    clip_fraction        | 0.0559      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.7        |\n",
      "|    n_updates            | 18260       |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    reward               | -0.7034021  |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1828         |\n",
      "|    time_elapsed         | 33909        |\n",
      "|    total_timesteps      | 3743744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058066584 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 124          |\n",
      "|    n_updates            | 18270        |\n",
      "|    policy_gradient_loss | -0.00579     |\n",
      "|    reward               | -0.47817078  |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 283          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1829        |\n",
      "|    time_elapsed         | 33929       |\n",
      "|    total_timesteps      | 3745792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002891874 |\n",
      "|    clip_fraction        | 0.00132     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 170         |\n",
      "|    n_updates            | 18280       |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    reward               | 1.6228359   |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 347         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1830        |\n",
      "|    time_elapsed         | 33947       |\n",
      "|    total_timesteps      | 3747840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012343148 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.8        |\n",
      "|    n_updates            | 18290       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    reward               | 4.0847526   |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 66.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1831        |\n",
      "|    time_elapsed         | 33965       |\n",
      "|    total_timesteps      | 3749888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004573509 |\n",
      "|    clip_fraction        | 0.00674     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.5        |\n",
      "|    n_updates            | 18300       |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    reward               | 1.2197278   |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1832       |\n",
      "|    time_elapsed         | 33984      |\n",
      "|    total_timesteps      | 3751936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00502244 |\n",
      "|    clip_fraction        | 0.00986    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -113       |\n",
      "|    explained_variance   | 0.589      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 199        |\n",
      "|    n_updates            | 18310      |\n",
      "|    policy_gradient_loss | -0.00529   |\n",
      "|    reward               | 6.4500146  |\n",
      "|    std                  | 12.1       |\n",
      "|    value_loss           | 307        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1833        |\n",
      "|    time_elapsed         | 34003       |\n",
      "|    total_timesteps      | 3753984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007852618 |\n",
      "|    clip_fraction        | 0.0379      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.9        |\n",
      "|    n_updates            | 18320       |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    reward               | -3.879011   |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1834        |\n",
      "|    time_elapsed         | 34021       |\n",
      "|    total_timesteps      | 3756032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003170173 |\n",
      "|    clip_fraction        | 0.00264     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 18330       |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    reward               | -0.99506676 |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 210         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8994992.39\n",
      "total_reward: 7994992.39\n",
      "total_cost: 80863.03\n",
      "total_trades: 53347\n",
      "Sharpe: 0.957\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1835         |\n",
      "|    time_elapsed         | 34040        |\n",
      "|    total_timesteps      | 3758080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031020897 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 186          |\n",
      "|    n_updates            | 18340        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    reward               | -3.2867296   |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 350          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1836         |\n",
      "|    time_elapsed         | 34059        |\n",
      "|    total_timesteps      | 3760128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021392952 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 134          |\n",
      "|    n_updates            | 18350        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | 4.1196995    |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 475          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1837        |\n",
      "|    time_elapsed         | 34078       |\n",
      "|    total_timesteps      | 3762176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009840229 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 18360       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -3.2380111  |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 72.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1838         |\n",
      "|    time_elapsed         | 34097        |\n",
      "|    total_timesteps      | 3764224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050505386 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 18370        |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    reward               | 1.5550003    |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 228          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1839         |\n",
      "|    time_elapsed         | 34116        |\n",
      "|    total_timesteps      | 3766272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023345565 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 172          |\n",
      "|    n_updates            | 18380        |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    reward               | 4.3495955    |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 282          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1840        |\n",
      "|    time_elapsed         | 34134       |\n",
      "|    total_timesteps      | 3768320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006202329 |\n",
      "|    clip_fraction        | 0.018       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.9        |\n",
      "|    n_updates            | 18390       |\n",
      "|    policy_gradient_loss | -0.0066     |\n",
      "|    reward               | 3.1171525   |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1841        |\n",
      "|    time_elapsed         | 34152       |\n",
      "|    total_timesteps      | 3770368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006487878 |\n",
      "|    clip_fraction        | 0.0255      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 18400       |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    reward               | -0.87847096 |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1842        |\n",
      "|    time_elapsed         | 34170       |\n",
      "|    total_timesteps      | 3772416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001970277 |\n",
      "|    clip_fraction        | 0.000146    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 18410       |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    reward               | 9.437096    |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 336         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1843        |\n",
      "|    time_elapsed         | 34188       |\n",
      "|    total_timesteps      | 3774464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004726396 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 18420       |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    reward               | -3.9162629  |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1844       |\n",
      "|    time_elapsed         | 34207      |\n",
      "|    total_timesteps      | 3776512    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00945932 |\n",
      "|    clip_fraction        | 0.0764     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -113       |\n",
      "|    explained_variance   | 0.605      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 36.4       |\n",
      "|    n_updates            | 18430      |\n",
      "|    policy_gradient_loss | -0.00974   |\n",
      "|    reward               | 4.293577   |\n",
      "|    std                  | 12.2       |\n",
      "|    value_loss           | 90.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1845        |\n",
      "|    time_elapsed         | 34227       |\n",
      "|    total_timesteps      | 3778560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005597649 |\n",
      "|    clip_fraction        | 0.0181      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.6        |\n",
      "|    n_updates            | 18440       |\n",
      "|    policy_gradient_loss | -0.00743    |\n",
      "|    reward               | 0.11156543  |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 244         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1846         |\n",
      "|    time_elapsed         | 34246        |\n",
      "|    total_timesteps      | 3780608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032781006 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 18450        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | 12.421193    |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 311          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1847        |\n",
      "|    time_elapsed         | 34264       |\n",
      "|    total_timesteps      | 3782656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008122755 |\n",
      "|    clip_fraction        | 0.0589      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.7        |\n",
      "|    n_updates            | 18460       |\n",
      "|    policy_gradient_loss | -0.00962    |\n",
      "|    reward               | 4.3579645   |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 98          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1848         |\n",
      "|    time_elapsed         | 34283        |\n",
      "|    total_timesteps      | 3784704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035276269 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 257          |\n",
      "|    n_updates            | 18470        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    reward               | -0.40660387  |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 236          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1849         |\n",
      "|    time_elapsed         | 34301        |\n",
      "|    total_timesteps      | 3786752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019266652 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 126          |\n",
      "|    n_updates            | 18480        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | 1.054122     |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 292          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9074524.13\n",
      "total_reward: 8074524.13\n",
      "total_cost: 87838.20\n",
      "total_trades: 53561\n",
      "Sharpe: 0.959\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1850         |\n",
      "|    time_elapsed         | 34319        |\n",
      "|    total_timesteps      | 3788800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030990948 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 170          |\n",
      "|    n_updates            | 18490        |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    reward               | 1.3559414    |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 226          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1851        |\n",
      "|    time_elapsed         | 34337       |\n",
      "|    total_timesteps      | 3790848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009346673 |\n",
      "|    clip_fraction        | 0.0476      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 18500       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -3.3529956  |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 190         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1852         |\n",
      "|    time_elapsed         | 34356        |\n",
      "|    total_timesteps      | 3792896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006471617 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.382        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 184          |\n",
      "|    n_updates            | 18510        |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    reward               | 1.52957      |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 440          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1853       |\n",
      "|    time_elapsed         | 34375      |\n",
      "|    total_timesteps      | 3794944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00521316 |\n",
      "|    clip_fraction        | 0.0157     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -113       |\n",
      "|    explained_variance   | 0.571      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 170        |\n",
      "|    n_updates            | 18520      |\n",
      "|    policy_gradient_loss | -0.00524   |\n",
      "|    reward               | 5.6696568  |\n",
      "|    std                  | 12.3       |\n",
      "|    value_loss           | 308        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1854        |\n",
      "|    time_elapsed         | 34394       |\n",
      "|    total_timesteps      | 3796992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013608683 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.9        |\n",
      "|    n_updates            | 18530       |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    reward               | -2.8870707  |\n",
      "|    std                  | 12.4        |\n",
      "|    value_loss           | 68.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1855         |\n",
      "|    time_elapsed         | 34412        |\n",
      "|    total_timesteps      | 3799040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026328661 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 89           |\n",
      "|    n_updates            | 18540        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    reward               | -1.8994491   |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 180          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1856         |\n",
      "|    time_elapsed         | 34430        |\n",
      "|    total_timesteps      | 3801088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021313683 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 122          |\n",
      "|    n_updates            | 18550        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | 2.6694226    |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 257          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1857         |\n",
      "|    time_elapsed         | 34449        |\n",
      "|    total_timesteps      | 3803136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054429523 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.4         |\n",
      "|    n_updates            | 18560        |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    reward               | 1.2037678    |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 146          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1858         |\n",
      "|    time_elapsed         | 34467        |\n",
      "|    total_timesteps      | 3805184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055405726 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90.2         |\n",
      "|    n_updates            | 18570        |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    reward               | 2.6629045    |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 203          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1859         |\n",
      "|    time_elapsed         | 34486        |\n",
      "|    total_timesteps      | 3807232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039375788 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 135          |\n",
      "|    n_updates            | 18580        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    reward               | -0.54868734  |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 237          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1860         |\n",
      "|    time_elapsed         | 34505        |\n",
      "|    total_timesteps      | 3809280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024171171 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 160          |\n",
      "|    n_updates            | 18590        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | -1.1783885   |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 285          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1861        |\n",
      "|    time_elapsed         | 34523       |\n",
      "|    total_timesteps      | 3811328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012094994 |\n",
      "|    clip_fraction        | 0.0952      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 18600       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 0.22911528  |\n",
      "|    std                  | 12.6        |\n",
      "|    value_loss           | 65.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1862          |\n",
      "|    time_elapsed         | 34542         |\n",
      "|    total_timesteps      | 3813376       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020129827 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -114          |\n",
      "|    explained_variance   | 0.122         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 103           |\n",
      "|    n_updates            | 18610         |\n",
      "|    policy_gradient_loss | -0.00063      |\n",
      "|    reward               | 0.013759262   |\n",
      "|    std                  | 12.6          |\n",
      "|    value_loss           | 325           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1863         |\n",
      "|    time_elapsed         | 34560        |\n",
      "|    total_timesteps      | 3815424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011506308 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.335        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 91.8         |\n",
      "|    n_updates            | 18620        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    reward               | -2.0889053   |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 224          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8297692.61\n",
      "total_reward: 7297692.61\n",
      "total_cost: 94924.94\n",
      "total_trades: 53942\n",
      "Sharpe: 0.923\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1864         |\n",
      "|    time_elapsed         | 34579        |\n",
      "|    total_timesteps      | 3817472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077537624 |\n",
      "|    clip_fraction        | 0.0538       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 18630        |\n",
      "|    policy_gradient_loss | -0.00936     |\n",
      "|    reward               | 0.5802592    |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 98.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1865       |\n",
      "|    time_elapsed         | 34598      |\n",
      "|    total_timesteps      | 3819520    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00384082 |\n",
      "|    clip_fraction        | 0.0063     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -114       |\n",
      "|    explained_variance   | 0.723      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 98.4       |\n",
      "|    n_updates            | 18640      |\n",
      "|    policy_gradient_loss | -0.00359   |\n",
      "|    reward               | -0.9436935 |\n",
      "|    std                  | 12.6       |\n",
      "|    value_loss           | 181        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1866         |\n",
      "|    time_elapsed         | 34616        |\n",
      "|    total_timesteps      | 3821568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041237036 |\n",
      "|    clip_fraction        | 0.00728      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.382        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71           |\n",
      "|    n_updates            | 18650        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | 51.3553      |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 202          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1867         |\n",
      "|    time_elapsed         | 34635        |\n",
      "|    total_timesteps      | 3823616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033260805 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.9         |\n",
      "|    n_updates            | 18660        |\n",
      "|    policy_gradient_loss | -0.00536     |\n",
      "|    reward               | -3.1349645   |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 177          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1868        |\n",
      "|    time_elapsed         | 34654       |\n",
      "|    total_timesteps      | 3825664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010281994 |\n",
      "|    clip_fraction        | 0.0758      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 18670       |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    reward               | 3.8583107   |\n",
      "|    std                  | 12.7        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1869         |\n",
      "|    time_elapsed         | 34673        |\n",
      "|    total_timesteps      | 3827712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005458268  |\n",
      "|    clip_fraction        | 0.0267       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.8         |\n",
      "|    n_updates            | 18680        |\n",
      "|    policy_gradient_loss | -0.00707     |\n",
      "|    reward               | -0.081580974 |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 198          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1870         |\n",
      "|    time_elapsed         | 34692        |\n",
      "|    total_timesteps      | 3829760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015460709 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.6         |\n",
      "|    n_updates            | 18690        |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    reward               | -13.98224    |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 204          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1871        |\n",
      "|    time_elapsed         | 34712       |\n",
      "|    total_timesteps      | 3831808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008873352 |\n",
      "|    clip_fraction        | 0.0697      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35          |\n",
      "|    n_updates            | 18700       |\n",
      "|    policy_gradient_loss | -0.00881    |\n",
      "|    reward               | 0.15776542  |\n",
      "|    std                  | 12.7        |\n",
      "|    value_loss           | 81.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1872         |\n",
      "|    time_elapsed         | 34730        |\n",
      "|    total_timesteps      | 3833856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063317176 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 94.8         |\n",
      "|    n_updates            | 18710        |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    reward               | -0.21601617  |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 131          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1873       |\n",
      "|    time_elapsed         | 34749      |\n",
      "|    total_timesteps      | 3835904    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00229186 |\n",
      "|    clip_fraction        | 0.000586   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -115       |\n",
      "|    explained_variance   | 0.504      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 73.5       |\n",
      "|    n_updates            | 18720      |\n",
      "|    policy_gradient_loss | -0.0031    |\n",
      "|    reward               | 14.337427  |\n",
      "|    std                  | 12.8       |\n",
      "|    value_loss           | 210        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1874        |\n",
      "|    time_elapsed         | 34767       |\n",
      "|    total_timesteps      | 3837952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007650162 |\n",
      "|    clip_fraction        | 0.0303      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.7        |\n",
      "|    n_updates            | 18730       |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    reward               | 0.4662439   |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1875         |\n",
      "|    time_elapsed         | 34787        |\n",
      "|    total_timesteps      | 3840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008814506  |\n",
      "|    clip_fraction        | 0.0456       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.8         |\n",
      "|    n_updates            | 18740        |\n",
      "|    policy_gradient_loss | -0.00959     |\n",
      "|    reward               | -0.011321386 |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1876         |\n",
      "|    time_elapsed         | 34804        |\n",
      "|    total_timesteps      | 3842048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023711335 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 18750        |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    reward               | 1.263411     |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 213          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1877         |\n",
      "|    time_elapsed         | 34823        |\n",
      "|    total_timesteps      | 3844096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013395741 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 101          |\n",
      "|    n_updates            | 18760        |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    reward               | -2.8452313   |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 246          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7847624.25\n",
      "total_reward: 6847624.25\n",
      "total_cost: 114394.72\n",
      "total_trades: 55352\n",
      "Sharpe: 0.896\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1878        |\n",
      "|    time_elapsed         | 34840       |\n",
      "|    total_timesteps      | 3846144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008369258 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 18770       |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    reward               | 1.0600833   |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 75          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1879         |\n",
      "|    time_elapsed         | 34859        |\n",
      "|    total_timesteps      | 3848192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023784777 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.752        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.3         |\n",
      "|    n_updates            | 18780        |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    reward               | -0.46611992  |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 159          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1880         |\n",
      "|    time_elapsed         | 34878        |\n",
      "|    total_timesteps      | 3850240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018723528 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 92.3         |\n",
      "|    n_updates            | 18790        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | -2.9798422   |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 235          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1881       |\n",
      "|    time_elapsed         | 34896      |\n",
      "|    total_timesteps      | 3852288    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00518729 |\n",
      "|    clip_fraction        | 0.00874    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -115       |\n",
      "|    explained_variance   | 0.212      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 89.7       |\n",
      "|    n_updates            | 18800      |\n",
      "|    policy_gradient_loss | -0.00629   |\n",
      "|    reward               | 4.402394   |\n",
      "|    std                  | 12.9       |\n",
      "|    value_loss           | 128        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1882        |\n",
      "|    time_elapsed         | 34914       |\n",
      "|    total_timesteps      | 3854336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006672471 |\n",
      "|    clip_fraction        | 0.0203      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.3        |\n",
      "|    n_updates            | 18810       |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    reward               | -4.040749   |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1883        |\n",
      "|    time_elapsed         | 34933       |\n",
      "|    total_timesteps      | 3856384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006617575 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.4        |\n",
      "|    n_updates            | 18820       |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    reward               | 0.21370685  |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1884         |\n",
      "|    time_elapsed         | 34951        |\n",
      "|    total_timesteps      | 3858432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019163524 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 130          |\n",
      "|    n_updates            | 18830        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | 4.294957     |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 245          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1885        |\n",
      "|    time_elapsed         | 34970       |\n",
      "|    total_timesteps      | 3860480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007508329 |\n",
      "|    clip_fraction        | 0.0445      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 18840       |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    reward               | -1.4780947  |\n",
      "|    std                  | 13          |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1886         |\n",
      "|    time_elapsed         | 34989        |\n",
      "|    total_timesteps      | 3862528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027256133 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 18850        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    reward               | -1.5028114   |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 188          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1887         |\n",
      "|    time_elapsed         | 35007        |\n",
      "|    total_timesteps      | 3864576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048632296 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.8         |\n",
      "|    n_updates            | 18860        |\n",
      "|    policy_gradient_loss | -0.00545     |\n",
      "|    reward               | -0.43274635  |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 191          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1888        |\n",
      "|    time_elapsed         | 35025       |\n",
      "|    total_timesteps      | 3866624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009648858 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.0152      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.8        |\n",
      "|    n_updates            | 18870       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 2.2054954   |\n",
      "|    std                  | 13.1        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1889         |\n",
      "|    time_elapsed         | 35043        |\n",
      "|    total_timesteps      | 3868672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043669906 |\n",
      "|    clip_fraction        | 0.0085       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.321        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.2         |\n",
      "|    n_updates            | 18880        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    reward               | -0.66696346  |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 152          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1890          |\n",
      "|    time_elapsed         | 35062         |\n",
      "|    total_timesteps      | 3870720       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00091805327 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -115          |\n",
      "|    explained_variance   | 0.248         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 71.3          |\n",
      "|    n_updates            | 18890         |\n",
      "|    policy_gradient_loss | -0.00196      |\n",
      "|    reward               | 5.268775      |\n",
      "|    std                  | 13.1          |\n",
      "|    value_loss           | 217           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1891        |\n",
      "|    time_elapsed         | 35079       |\n",
      "|    total_timesteps      | 3872768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007515984 |\n",
      "|    clip_fraction        | 0.056       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.8        |\n",
      "|    n_updates            | 18900       |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    reward               | -1.7442858  |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7376668.53\n",
      "total_reward: 6376668.53\n",
      "total_cost: 98135.77\n",
      "total_trades: 53671\n",
      "Sharpe: 0.870\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1892        |\n",
      "|    time_elapsed         | 35097       |\n",
      "|    total_timesteps      | 3874816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010842722 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 18910       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 2.0905077   |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 94          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1893         |\n",
      "|    time_elapsed         | 35115        |\n",
      "|    total_timesteps      | 3876864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031050704 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.5         |\n",
      "|    n_updates            | 18920        |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    reward               | 1.7981331    |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 152          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1894        |\n",
      "|    time_elapsed         | 35132       |\n",
      "|    total_timesteps      | 3878912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003648476 |\n",
      "|    clip_fraction        | 0.00396     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 18930       |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    reward               | 2.189739    |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1895        |\n",
      "|    time_elapsed         | 35151       |\n",
      "|    total_timesteps      | 3880960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012861528 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.6        |\n",
      "|    n_updates            | 18940       |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    reward               | -2.0602856  |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 80.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1896          |\n",
      "|    time_elapsed         | 35169         |\n",
      "|    total_timesteps      | 3883008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087369606 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -115          |\n",
      "|    explained_variance   | 0.635         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 52.1          |\n",
      "|    n_updates            | 18950         |\n",
      "|    policy_gradient_loss | -0.00138      |\n",
      "|    reward               | -0.7800168    |\n",
      "|    std                  | 13.2          |\n",
      "|    value_loss           | 143           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1897          |\n",
      "|    time_elapsed         | 35188         |\n",
      "|    total_timesteps      | 3885056       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067632244 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -115          |\n",
      "|    explained_variance   | 0.569         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 80.1          |\n",
      "|    n_updates            | 18960         |\n",
      "|    policy_gradient_loss | -0.00185      |\n",
      "|    reward               | 0.7807566     |\n",
      "|    std                  | 13.2          |\n",
      "|    value_loss           | 223           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1898          |\n",
      "|    time_elapsed         | 35207         |\n",
      "|    total_timesteps      | 3887104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086068606 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -115          |\n",
      "|    explained_variance   | 0.553         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 51.5          |\n",
      "|    n_updates            | 18970         |\n",
      "|    policy_gradient_loss | -0.00176      |\n",
      "|    reward               | 1.1342123     |\n",
      "|    std                  | 13.2          |\n",
      "|    value_loss           | 135           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1899        |\n",
      "|    time_elapsed         | 35226       |\n",
      "|    total_timesteps      | 3889152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006544989 |\n",
      "|    clip_fraction        | 0.0245      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.4        |\n",
      "|    n_updates            | 18980       |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    reward               | -2.1406589  |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1900        |\n",
      "|    time_elapsed         | 35244       |\n",
      "|    total_timesteps      | 3891200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000412757 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.1        |\n",
      "|    n_updates            | 18990       |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    reward               | 0.9802      |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1901          |\n",
      "|    time_elapsed         | 35263         |\n",
      "|    total_timesteps      | 3893248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048098285 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -116          |\n",
      "|    explained_variance   | 0.64          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 104           |\n",
      "|    n_updates            | 19000         |\n",
      "|    policy_gradient_loss | -0.00116      |\n",
      "|    reward               | 3.3198159     |\n",
      "|    std                  | 13.3          |\n",
      "|    value_loss           | 258           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1902        |\n",
      "|    time_elapsed         | 35282       |\n",
      "|    total_timesteps      | 3895296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011268611 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 19010       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 3.9833364   |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 64.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1903         |\n",
      "|    time_elapsed         | 35301        |\n",
      "|    total_timesteps      | 3897344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022098373 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.1         |\n",
      "|    n_updates            | 19020        |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | -0.1448126   |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 137          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1904         |\n",
      "|    time_elapsed         | 35320        |\n",
      "|    total_timesteps      | 3899392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012396271 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.6         |\n",
      "|    n_updates            | 19030        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    reward               | 2.2707098    |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 175          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1905         |\n",
      "|    time_elapsed         | 35340        |\n",
      "|    total_timesteps      | 3901440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030544656 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.1         |\n",
      "|    n_updates            | 19040        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    reward               | -6.3457823   |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 92.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6900443.81\n",
      "total_reward: 5900443.81\n",
      "total_cost: 122809.66\n",
      "total_trades: 55017\n",
      "Sharpe: 0.847\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1906         |\n",
      "|    time_elapsed         | 35358        |\n",
      "|    total_timesteps      | 3903488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063831587 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.4         |\n",
      "|    n_updates            | 19050        |\n",
      "|    policy_gradient_loss | -0.00757     |\n",
      "|    reward               | 1.2647036    |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1907         |\n",
      "|    time_elapsed         | 35378        |\n",
      "|    total_timesteps      | 3905536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030743126 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.2         |\n",
      "|    n_updates            | 19060        |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    reward               | -31.228424   |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1908         |\n",
      "|    time_elapsed         | 35396        |\n",
      "|    total_timesteps      | 3907584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037239157 |\n",
      "|    clip_fraction        | 0.00581      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 137          |\n",
      "|    n_updates            | 19070        |\n",
      "|    policy_gradient_loss | -0.00636     |\n",
      "|    reward               | 10.708569    |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 193          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1909        |\n",
      "|    time_elapsed         | 35415       |\n",
      "|    total_timesteps      | 3909632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011001994 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.8        |\n",
      "|    n_updates            | 19080       |\n",
      "|    policy_gradient_loss | -0.00956    |\n",
      "|    reward               | -0.5508544  |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 76.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1910         |\n",
      "|    time_elapsed         | 35433        |\n",
      "|    total_timesteps      | 3911680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030105086 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 84.3         |\n",
      "|    n_updates            | 19090        |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    reward               | 0.067973174  |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1911         |\n",
      "|    time_elapsed         | 35451        |\n",
      "|    total_timesteps      | 3913728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031929417 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.8         |\n",
      "|    n_updates            | 19100        |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    reward               | 3.7080057    |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 184          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1912         |\n",
      "|    time_elapsed         | 35469        |\n",
      "|    total_timesteps      | 3915776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025692552 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.9         |\n",
      "|    n_updates            | 19110        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    reward               | 2.3039403    |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1913        |\n",
      "|    time_elapsed         | 35487       |\n",
      "|    total_timesteps      | 3917824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003722069 |\n",
      "|    clip_fraction        | 0.00288     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.6        |\n",
      "|    n_updates            | 19120       |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    reward               | 1.7233367   |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1914         |\n",
      "|    time_elapsed         | 35505        |\n",
      "|    total_timesteps      | 3919872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012629993 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 19130        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    reward               | 3.5104642    |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 179          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1915        |\n",
      "|    time_elapsed         | 35524       |\n",
      "|    total_timesteps      | 3921920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005334487 |\n",
      "|    clip_fraction        | 0.0103      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.2        |\n",
      "|    n_updates            | 19140       |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    reward               | 1.8089643   |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1916         |\n",
      "|    time_elapsed         | 35543        |\n",
      "|    total_timesteps      | 3923968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076322714 |\n",
      "|    clip_fraction        | 0.0392       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 19150        |\n",
      "|    policy_gradient_loss | -0.00784     |\n",
      "|    reward               | 0.28767243   |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 80.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1917         |\n",
      "|    time_elapsed         | 35562        |\n",
      "|    total_timesteps      | 3926016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026377551 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.752        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.7         |\n",
      "|    n_updates            | 19160        |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    reward               | 2.7550075    |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1918         |\n",
      "|    time_elapsed         | 35580        |\n",
      "|    total_timesteps      | 3928064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062359083 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.3         |\n",
      "|    n_updates            | 19170        |\n",
      "|    policy_gradient_loss | -0.00679     |\n",
      "|    reward               | -0.9219648   |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1919        |\n",
      "|    time_elapsed         | 35598       |\n",
      "|    total_timesteps      | 3930112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009253394 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 19180       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -0.21377213 |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 71.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6826074.24\n",
      "total_reward: 5826074.24\n",
      "total_cost: 128881.99\n",
      "total_trades: 55269\n",
      "Sharpe: 0.844\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1920         |\n",
      "|    time_elapsed         | 35616        |\n",
      "|    total_timesteps      | 3932160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035251144 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 19190        |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    reward               | -0.35197634  |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 198          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1921         |\n",
      "|    time_elapsed         | 35634        |\n",
      "|    total_timesteps      | 3934208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046858364 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 87.6         |\n",
      "|    n_updates            | 19200        |\n",
      "|    policy_gradient_loss | -0.00652     |\n",
      "|    reward               | 10.407325    |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 171          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1922         |\n",
      "|    time_elapsed         | 35652        |\n",
      "|    total_timesteps      | 3936256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037058042 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.1         |\n",
      "|    n_updates            | 19210        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | -5.584233    |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1923        |\n",
      "|    time_elapsed         | 35670       |\n",
      "|    total_timesteps      | 3938304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009109556 |\n",
      "|    clip_fraction        | 0.0409      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.4        |\n",
      "|    n_updates            | 19220       |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    reward               | -0.34925762 |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1924         |\n",
      "|    time_elapsed         | 35688        |\n",
      "|    total_timesteps      | 3940352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027316217 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 86           |\n",
      "|    n_updates            | 19230        |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | -2.7054756   |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 188          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1925         |\n",
      "|    time_elapsed         | 35706        |\n",
      "|    total_timesteps      | 3942400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027130446 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 94.1         |\n",
      "|    n_updates            | 19240        |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    reward               | 1.204188     |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 213          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1926         |\n",
      "|    time_elapsed         | 35724        |\n",
      "|    total_timesteps      | 3944448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073989416 |\n",
      "|    clip_fraction        | 0.059        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.392        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35           |\n",
      "|    n_updates            | 19250        |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    reward               | 1.5756859    |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 60.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1927         |\n",
      "|    time_elapsed         | 35742        |\n",
      "|    total_timesteps      | 3946496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021138345 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.8         |\n",
      "|    n_updates            | 19260        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    reward               | 0.15766      |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1928         |\n",
      "|    time_elapsed         | 35761        |\n",
      "|    total_timesteps      | 3948544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014710535 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 19270        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | 4.9063764    |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 245          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1929        |\n",
      "|    time_elapsed         | 35779       |\n",
      "|    total_timesteps      | 3950592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004092243 |\n",
      "|    clip_fraction        | 0.0041      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.2        |\n",
      "|    n_updates            | 19280       |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    reward               | -2.1851835  |\n",
      "|    std                  | 13.6        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1930       |\n",
      "|    time_elapsed         | 35797      |\n",
      "|    total_timesteps      | 3952640    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00615723 |\n",
      "|    clip_fraction        | 0.0186     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -116       |\n",
      "|    explained_variance   | 0.732      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 72.8       |\n",
      "|    n_updates            | 19290      |\n",
      "|    policy_gradient_loss | -0.00748   |\n",
      "|    reward               | 0.43884873 |\n",
      "|    std                  | 13.6       |\n",
      "|    value_loss           | 151        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1931        |\n",
      "|    time_elapsed         | 35815       |\n",
      "|    total_timesteps      | 3954688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005073552 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 19300       |\n",
      "|    policy_gradient_loss | -0.00681    |\n",
      "|    reward               | 11.624232   |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 270         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1932         |\n",
      "|    time_elapsed         | 35833        |\n",
      "|    total_timesteps      | 3956736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016138995 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 162          |\n",
      "|    n_updates            | 19310        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    reward               | -1.002603    |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 234          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1933        |\n",
      "|    time_elapsed         | 35852       |\n",
      "|    total_timesteps      | 3958784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008744257 |\n",
      "|    clip_fraction        | 0.0533      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.7        |\n",
      "|    n_updates            | 19320       |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    reward               | 1.8197048   |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 72.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7023171.49\n",
      "total_reward: 6023171.49\n",
      "total_cost: 153884.13\n",
      "total_trades: 56439\n",
      "Sharpe: 0.847\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1934         |\n",
      "|    time_elapsed         | 35870        |\n",
      "|    total_timesteps      | 3960832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054592974 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.1         |\n",
      "|    n_updates            | 19330        |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    reward               | -0.20397285  |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 180          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1935        |\n",
      "|    time_elapsed         | 35889       |\n",
      "|    total_timesteps      | 3962880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004588088 |\n",
      "|    clip_fraction        | 0.00879     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85          |\n",
      "|    n_updates            | 19340       |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    reward               | 2.694363    |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1936        |\n",
      "|    time_elapsed         | 35907       |\n",
      "|    total_timesteps      | 3964928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011620876 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 19350       |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    reward               | -0.5442666  |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 59          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1937         |\n",
      "|    time_elapsed         | 35926        |\n",
      "|    total_timesteps      | 3966976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038101727 |\n",
      "|    clip_fraction        | 0.00659      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.9         |\n",
      "|    n_updates            | 19360        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | -2.3985417   |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1938         |\n",
      "|    time_elapsed         | 35944        |\n",
      "|    total_timesteps      | 3969024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028839167 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 112          |\n",
      "|    n_updates            | 19370        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | 0.3974453    |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 187          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1939         |\n",
      "|    time_elapsed         | 35962        |\n",
      "|    total_timesteps      | 3971072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020463394 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.1         |\n",
      "|    n_updates            | 19380        |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    reward               | 0.94139844   |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 139          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1940        |\n",
      "|    time_elapsed         | 35981       |\n",
      "|    total_timesteps      | 3973120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006840284 |\n",
      "|    clip_fraction        | 0.0279      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 19390       |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    reward               | -0.58674186 |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1941         |\n",
      "|    time_elapsed         | 36001        |\n",
      "|    total_timesteps      | 3975168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049198377 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 87           |\n",
      "|    n_updates            | 19400        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    reward               | 0.116480194  |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 256          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1942        |\n",
      "|    time_elapsed         | 36019       |\n",
      "|    total_timesteps      | 3977216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003336085 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 19410       |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    reward               | -4.257705   |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 223         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1943        |\n",
      "|    time_elapsed         | 36038       |\n",
      "|    total_timesteps      | 3979264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007736661 |\n",
      "|    clip_fraction        | 0.0439      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 19420       |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    reward               | 1.2709186   |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 62.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1944         |\n",
      "|    time_elapsed         | 36057        |\n",
      "|    total_timesteps      | 3981312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036498983 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82.1         |\n",
      "|    n_updates            | 19430        |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    reward               | -0.55770487  |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 185          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1945         |\n",
      "|    time_elapsed         | 36076        |\n",
      "|    total_timesteps      | 3983360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027524107 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 130          |\n",
      "|    n_updates            | 19440        |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    reward               | 7.4030633    |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 267          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1946        |\n",
      "|    time_elapsed         | 36094       |\n",
      "|    total_timesteps      | 3985408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008809039 |\n",
      "|    clip_fraction        | 0.0432      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.5        |\n",
      "|    n_updates            | 19450       |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    reward               | 1.9786574   |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1947         |\n",
      "|    time_elapsed         | 36113        |\n",
      "|    total_timesteps      | 3987456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028981813 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.6         |\n",
      "|    n_updates            | 19460        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | -1.2186964   |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 151          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7996914.79\n",
      "total_reward: 6996914.79\n",
      "total_cost: 139824.20\n",
      "total_trades: 55442\n",
      "Sharpe: 0.928\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1948          |\n",
      "|    time_elapsed         | 36131         |\n",
      "|    total_timesteps      | 3989504       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069710915 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -117          |\n",
      "|    explained_variance   | 0.351         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 168           |\n",
      "|    n_updates            | 19470         |\n",
      "|    policy_gradient_loss | -0.00144      |\n",
      "|    reward               | 1.3894768     |\n",
      "|    std                  | 14.1          |\n",
      "|    value_loss           | 368           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1949        |\n",
      "|    time_elapsed         | 36150       |\n",
      "|    total_timesteps      | 3991552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006942456 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 19480       |\n",
      "|    policy_gradient_loss | -0.00814    |\n",
      "|    reward               | 0.35173297  |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 205         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1950        |\n",
      "|    time_elapsed         | 36168       |\n",
      "|    total_timesteps      | 3993600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009877001 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 19490       |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    reward               | -1.0150201  |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 60.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1951         |\n",
      "|    time_elapsed         | 36186        |\n",
      "|    total_timesteps      | 3995648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054534622 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.4         |\n",
      "|    n_updates            | 19500        |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    reward               | -1.9803096   |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 211          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1952         |\n",
      "|    time_elapsed         | 36204        |\n",
      "|    total_timesteps      | 3997696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015583837 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90.7         |\n",
      "|    n_updates            | 19510        |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    reward               | -8.942681    |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 314          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1953         |\n",
      "|    time_elapsed         | 36223        |\n",
      "|    total_timesteps      | 3999744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058597676 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.5         |\n",
      "|    n_updates            | 19520        |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    reward               | -1.9615334   |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1954         |\n",
      "|    time_elapsed         | 36241        |\n",
      "|    total_timesteps      | 4001792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047251005 |\n",
      "|    clip_fraction        | 0.00942      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 88.7         |\n",
      "|    n_updates            | 19530        |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    reward               | 0.474512     |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 210          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1955         |\n",
      "|    time_elapsed         | 36259        |\n",
      "|    total_timesteps      | 4003840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014437784 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.466        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 198          |\n",
      "|    n_updates            | 19540        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    reward               | -7.856012    |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 395          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1956          |\n",
      "|    time_elapsed         | 36278         |\n",
      "|    total_timesteps      | 4005888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075044506 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -117          |\n",
      "|    explained_variance   | 0.243         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 81.9          |\n",
      "|    n_updates            | 19550         |\n",
      "|    policy_gradient_loss | -0.00207      |\n",
      "|    reward               | 4.477886      |\n",
      "|    std                  | 14.2          |\n",
      "|    value_loss           | 260           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1957         |\n",
      "|    time_elapsed         | 36296        |\n",
      "|    total_timesteps      | 4007936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065223468 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.5         |\n",
      "|    n_updates            | 19560        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    reward               | -0.2915339   |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1958         |\n",
      "|    time_elapsed         | 36314        |\n",
      "|    total_timesteps      | 4009984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015536179 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 195          |\n",
      "|    n_updates            | 19570        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | -0.9086071   |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 362          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1959         |\n",
      "|    time_elapsed         | 36332        |\n",
      "|    total_timesteps      | 4012032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026123715 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.427        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 199          |\n",
      "|    n_updates            | 19580        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    reward               | 2.5848677    |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 354          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1960       |\n",
      "|    time_elapsed         | 36350      |\n",
      "|    total_timesteps      | 4014080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00793718 |\n",
      "|    clip_fraction        | 0.052      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -118       |\n",
      "|    explained_variance   | 0.551      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.9       |\n",
      "|    n_updates            | 19590      |\n",
      "|    policy_gradient_loss | -0.00748   |\n",
      "|    reward               | 2.7972429  |\n",
      "|    std                  | 14.3       |\n",
      "|    value_loss           | 65.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1961         |\n",
      "|    time_elapsed         | 36369        |\n",
      "|    total_timesteps      | 4016128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037959586 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 150          |\n",
      "|    n_updates            | 19600        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    reward               | 0.15751012   |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 218          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1962         |\n",
      "|    time_elapsed         | 36388        |\n",
      "|    total_timesteps      | 4018176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027765231 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 116          |\n",
      "|    n_updates            | 19610        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | -8.229799    |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 282          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8183351.75\n",
      "total_reward: 7183351.75\n",
      "total_cost: 139683.63\n",
      "total_trades: 55331\n",
      "Sharpe: 0.905\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1963        |\n",
      "|    time_elapsed         | 36406       |\n",
      "|    total_timesteps      | 4020224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007196514 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 19620       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -0.48498178 |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1964         |\n",
      "|    time_elapsed         | 36424        |\n",
      "|    total_timesteps      | 4022272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035462484 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.6         |\n",
      "|    n_updates            | 19630        |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    reward               | -1.2438676   |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1965         |\n",
      "|    time_elapsed         | 36442        |\n",
      "|    total_timesteps      | 4024320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011498638 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 176          |\n",
      "|    n_updates            | 19640        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    reward               | 1.5995542    |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 326          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1966         |\n",
      "|    time_elapsed         | 36460        |\n",
      "|    total_timesteps      | 4026368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037098369 |\n",
      "|    clip_fraction        | 0.00581      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 111          |\n",
      "|    n_updates            | 19650        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    reward               | 2.0318646    |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 280          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1967        |\n",
      "|    time_elapsed         | 36479       |\n",
      "|    total_timesteps      | 4028416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008063627 |\n",
      "|    clip_fraction        | 0.0641      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 19660       |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | -0.32389644 |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 54.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1968         |\n",
      "|    time_elapsed         | 36498        |\n",
      "|    total_timesteps      | 4030464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035371585 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 268          |\n",
      "|    n_updates            | 19670        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    reward               | -3.2125828   |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 233          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1969         |\n",
      "|    time_elapsed         | 36516        |\n",
      "|    total_timesteps      | 4032512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007731811 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 148          |\n",
      "|    n_updates            | 19680        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    reward               | 3.7321744    |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 323          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1970         |\n",
      "|    time_elapsed         | 36535        |\n",
      "|    total_timesteps      | 4034560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042799828 |\n",
      "|    clip_fraction        | 0.00957      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.9         |\n",
      "|    n_updates            | 19690        |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    reward               | -0.7826626   |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1971        |\n",
      "|    time_elapsed         | 36553       |\n",
      "|    total_timesteps      | 4036608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00791868  |\n",
      "|    clip_fraction        | 0.0238      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.4        |\n",
      "|    n_updates            | 19700       |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    reward               | -0.36002368 |\n",
      "|    std                  | 14.5        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1972         |\n",
      "|    time_elapsed         | 36572        |\n",
      "|    total_timesteps      | 4038656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011656241 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.9         |\n",
      "|    n_updates            | 19710        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | 0.17705655   |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 242          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1973         |\n",
      "|    time_elapsed         | 36590        |\n",
      "|    total_timesteps      | 4040704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016856358 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 168          |\n",
      "|    n_updates            | 19720        |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | -0.08172526  |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 371          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1974        |\n",
      "|    time_elapsed         | 36609       |\n",
      "|    total_timesteps      | 4042752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009570945 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 19730       |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | -2.4384592  |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 57.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1975         |\n",
      "|    time_elapsed         | 36628        |\n",
      "|    total_timesteps      | 4044800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017890059 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 241          |\n",
      "|    n_updates            | 19740        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | -0.8269554   |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 318          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1976         |\n",
      "|    time_elapsed         | 36646        |\n",
      "|    total_timesteps      | 4046848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011613388 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 148          |\n",
      "|    n_updates            | 19750        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | -0.5429685   |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 274          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8358115.55\n",
      "total_reward: 7358115.55\n",
      "total_cost: 140589.77\n",
      "total_trades: 55030\n",
      "Sharpe: 0.917\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1977         |\n",
      "|    time_elapsed         | 36665        |\n",
      "|    total_timesteps      | 4048896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074333735 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 19760        |\n",
      "|    policy_gradient_loss | -0.00755     |\n",
      "|    reward               | -2.0643651   |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 72.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1978         |\n",
      "|    time_elapsed         | 36684        |\n",
      "|    total_timesteps      | 4050944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040122513 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 110          |\n",
      "|    n_updates            | 19770        |\n",
      "|    policy_gradient_loss | -0.00472     |\n",
      "|    reward               | -0.9473008   |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 216          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1979          |\n",
      "|    time_elapsed         | 36703         |\n",
      "|    total_timesteps      | 4052992       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040032077 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -118          |\n",
      "|    explained_variance   | 0.717         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 158           |\n",
      "|    n_updates            | 19780         |\n",
      "|    policy_gradient_loss | -0.000899     |\n",
      "|    reward               | 7.90513       |\n",
      "|    std                  | 14.6          |\n",
      "|    value_loss           | 296           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1980        |\n",
      "|    time_elapsed         | 36722       |\n",
      "|    total_timesteps      | 4055040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003669723 |\n",
      "|    clip_fraction        | 0.00415     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 19790       |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    reward               | -1.0948136  |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1981         |\n",
      "|    time_elapsed         | 36741        |\n",
      "|    total_timesteps      | 4057088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048577646 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 114          |\n",
      "|    n_updates            | 19800        |\n",
      "|    policy_gradient_loss | -0.00712     |\n",
      "|    reward               | 1.5921482    |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 165          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1982        |\n",
      "|    time_elapsed         | 36760       |\n",
      "|    total_timesteps      | 4059136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00312477  |\n",
      "|    clip_fraction        | 0.00303     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 194         |\n",
      "|    n_updates            | 19810       |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    reward               | -0.54755026 |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 249         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1983         |\n",
      "|    time_elapsed         | 36779        |\n",
      "|    total_timesteps      | 4061184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033893827 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.4         |\n",
      "|    n_updates            | 19820        |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    reward               | -6.0016522   |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 241          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1984        |\n",
      "|    time_elapsed         | 36798       |\n",
      "|    total_timesteps      | 4063232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013325674 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.7        |\n",
      "|    n_updates            | 19830       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 11.12755    |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 74.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1985        |\n",
      "|    time_elapsed         | 36816       |\n",
      "|    total_timesteps      | 4065280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002324541 |\n",
      "|    clip_fraction        | 0.00103     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 19840       |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    reward               | 0.5022634   |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1986         |\n",
      "|    time_elapsed         | 36835        |\n",
      "|    total_timesteps      | 4067328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017375017 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 19850        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | -7.3070035   |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 272          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1987         |\n",
      "|    time_elapsed         | 36853        |\n",
      "|    total_timesteps      | 4069376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027167734 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.7         |\n",
      "|    n_updates            | 19860        |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    reward               | -0.016938081 |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1988        |\n",
      "|    time_elapsed         | 36872       |\n",
      "|    total_timesteps      | 4071424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003952152 |\n",
      "|    clip_fraction        | 0.00571     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 19870       |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | 0.5601586   |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 186         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1989       |\n",
      "|    time_elapsed         | 36891      |\n",
      "|    total_timesteps      | 4073472    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00429298 |\n",
      "|    clip_fraction        | 0.0085     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -119       |\n",
      "|    explained_variance   | 0.774      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 112        |\n",
      "|    n_updates            | 19880      |\n",
      "|    policy_gradient_loss | -0.00665   |\n",
      "|    reward               | 2.4523327  |\n",
      "|    std                  | 14.9       |\n",
      "|    value_loss           | 202        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1990        |\n",
      "|    time_elapsed         | 36910       |\n",
      "|    total_timesteps      | 4075520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003008896 |\n",
      "|    clip_fraction        | 0.00264     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 19890       |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    reward               | -0.29544988 |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 250         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8396032.86\n",
      "total_reward: 7396032.86\n",
      "total_cost: 115999.90\n",
      "total_trades: 53636\n",
      "Sharpe: 0.930\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1991        |\n",
      "|    time_elapsed         | 36928       |\n",
      "|    total_timesteps      | 4077568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011198016 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 19900       |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    reward               | 0.6173731   |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 55.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1992          |\n",
      "|    time_elapsed         | 36947         |\n",
      "|    total_timesteps      | 4079616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075242086 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -119          |\n",
      "|    explained_variance   | 0.757         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 73.9          |\n",
      "|    n_updates            | 19910         |\n",
      "|    policy_gradient_loss | -0.00159      |\n",
      "|    reward               | -0.65932894   |\n",
      "|    std                  | 14.9          |\n",
      "|    value_loss           | 226           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1993         |\n",
      "|    time_elapsed         | 36965        |\n",
      "|    total_timesteps      | 4081664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017999448 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 157          |\n",
      "|    n_updates            | 19920        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | -2.6134086   |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 242          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1994        |\n",
      "|    time_elapsed         | 36984       |\n",
      "|    total_timesteps      | 4083712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008018609 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.6        |\n",
      "|    n_updates            | 19930       |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    reward               | -5.1303554  |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1995         |\n",
      "|    time_elapsed         | 37002        |\n",
      "|    total_timesteps      | 4085760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022265494 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60           |\n",
      "|    n_updates            | 19940        |\n",
      "|    policy_gradient_loss | -0.00487     |\n",
      "|    reward               | -1.4027098   |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 199          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1996         |\n",
      "|    time_elapsed         | 37020        |\n",
      "|    total_timesteps      | 4087808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021488117 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.467        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 146          |\n",
      "|    n_updates            | 19950        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    reward               | 7.8814826    |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 209          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1997          |\n",
      "|    time_elapsed         | 37039         |\n",
      "|    total_timesteps      | 4089856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022195763 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -119          |\n",
      "|    explained_variance   | 0.74          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 175           |\n",
      "|    n_updates            | 19960         |\n",
      "|    policy_gradient_loss | -0.00128      |\n",
      "|    reward               | 1.18064       |\n",
      "|    std                  | 15.1          |\n",
      "|    value_loss           | 562           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1998        |\n",
      "|    time_elapsed         | 37058       |\n",
      "|    total_timesteps      | 4091904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010872031 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 19970       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | 1.4487185   |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 53.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1999         |\n",
      "|    time_elapsed         | 37076        |\n",
      "|    total_timesteps      | 4093952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010833184 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 19980        |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    reward               | -2.849665    |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 232          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2000         |\n",
      "|    time_elapsed         | 37096        |\n",
      "|    total_timesteps      | 4096000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003900261 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 170          |\n",
      "|    n_updates            | 19990        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    reward               | 3.331798     |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 243          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2001        |\n",
      "|    time_elapsed         | 37114       |\n",
      "|    total_timesteps      | 4098048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012896223 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 20000       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 2.111868    |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 66.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2002         |\n",
      "|    time_elapsed         | 37133        |\n",
      "|    total_timesteps      | 4100096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007399849 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.3         |\n",
      "|    n_updates            | 20010        |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    reward               | -0.7385507   |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 183          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2003          |\n",
      "|    time_elapsed         | 37152         |\n",
      "|    total_timesteps      | 4102144       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00097482733 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -119          |\n",
      "|    explained_variance   | 0.783         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 128           |\n",
      "|    n_updates            | 20020         |\n",
      "|    policy_gradient_loss | -0.00278      |\n",
      "|    reward               | -0.0709668    |\n",
      "|    std                  | 15.1          |\n",
      "|    value_loss           | 211           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2004         |\n",
      "|    time_elapsed         | 37171        |\n",
      "|    total_timesteps      | 4104192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018111928 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52           |\n",
      "|    n_updates            | 20030        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | -2.519816    |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 156          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8076062.76\n",
      "total_reward: 7076062.76\n",
      "total_cost: 129027.43\n",
      "total_trades: 54240\n",
      "Sharpe: 0.924\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2005         |\n",
      "|    time_elapsed         | 37190        |\n",
      "|    total_timesteps      | 4106240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059516504 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.9         |\n",
      "|    n_updates            | 20040        |\n",
      "|    policy_gradient_loss | -0.00656     |\n",
      "|    reward               | 6.2007146    |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2006          |\n",
      "|    time_elapsed         | 37209         |\n",
      "|    total_timesteps      | 4108288       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031163628 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -119          |\n",
      "|    explained_variance   | 0.792         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 156           |\n",
      "|    n_updates            | 20050         |\n",
      "|    policy_gradient_loss | -0.00093      |\n",
      "|    reward               | -2.038769     |\n",
      "|    std                  | 15.2          |\n",
      "|    value_loss           | 271           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2007        |\n",
      "|    time_elapsed         | 37228       |\n",
      "|    total_timesteps      | 4110336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000704389 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 20060       |\n",
      "|    policy_gradient_loss | -0.00225    |\n",
      "|    reward               | -0.3359008  |\n",
      "|    std                  | 15.2        |\n",
      "|    value_loss           | 230         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2008        |\n",
      "|    time_elapsed         | 37247       |\n",
      "|    total_timesteps      | 4112384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009737047 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 20070       |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    reward               | 4.7392707   |\n",
      "|    std                  | 15.2        |\n",
      "|    value_loss           | 69.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2009         |\n",
      "|    time_elapsed         | 37265        |\n",
      "|    total_timesteps      | 4114432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008103226 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 91.9         |\n",
      "|    n_updates            | 20080        |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    reward               | 0.38554707   |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 167          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2010         |\n",
      "|    time_elapsed         | 37283        |\n",
      "|    total_timesteps      | 4116480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006619023 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 101          |\n",
      "|    n_updates            | 20090        |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    reward               | 2.6904829    |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 201          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2011        |\n",
      "|    time_elapsed         | 37301       |\n",
      "|    total_timesteps      | 4118528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008352725 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.1        |\n",
      "|    n_updates            | 20100       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | -3.884541   |\n",
      "|    std                  | 15.3        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 2012      |\n",
      "|    time_elapsed         | 37320     |\n",
      "|    total_timesteps      | 4120576   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0039895 |\n",
      "|    clip_fraction        | 0.00649   |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -120      |\n",
      "|    explained_variance   | 0.534     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 49.4      |\n",
      "|    n_updates            | 20110     |\n",
      "|    policy_gradient_loss | -0.00492  |\n",
      "|    reward               | 0.6789587 |\n",
      "|    std                  | 15.3      |\n",
      "|    value_loss           | 136       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2013         |\n",
      "|    time_elapsed         | 37337        |\n",
      "|    total_timesteps      | 4122624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009807289 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.3         |\n",
      "|    n_updates            | 20120        |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    reward               | -1.195488    |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 196          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2014         |\n",
      "|    time_elapsed         | 37356        |\n",
      "|    total_timesteps      | 4124672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012299923 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.43         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 151          |\n",
      "|    n_updates            | 20130        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | 3.8105729    |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 300          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2015        |\n",
      "|    time_elapsed         | 37374       |\n",
      "|    total_timesteps      | 4126720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008726127 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 20140       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -2.7691984  |\n",
      "|    std                  | 15.4        |\n",
      "|    value_loss           | 59          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2016          |\n",
      "|    time_elapsed         | 37393         |\n",
      "|    total_timesteps      | 4128768       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036887795 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -120          |\n",
      "|    explained_variance   | 0.47          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 95.6          |\n",
      "|    n_updates            | 20150         |\n",
      "|    policy_gradient_loss | -0.00149      |\n",
      "|    reward               | -0.78813785   |\n",
      "|    std                  | 15.4          |\n",
      "|    value_loss           | 263           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2017         |\n",
      "|    time_elapsed         | 37412        |\n",
      "|    total_timesteps      | 4130816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012546157 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.295        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 178          |\n",
      "|    n_updates            | 20160        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | -15.057823   |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 236          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2018        |\n",
      "|    time_elapsed         | 37431       |\n",
      "|    total_timesteps      | 4132864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006631907 |\n",
      "|    clip_fraction        | 0.0231      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67          |\n",
      "|    n_updates            | 20170       |\n",
      "|    policy_gradient_loss | -0.00745    |\n",
      "|    reward               | 3.9992106   |\n",
      "|    std                  | 15.4        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8273858.64\n",
      "total_reward: 7273858.64\n",
      "total_cost: 117252.22\n",
      "total_trades: 53152\n",
      "Sharpe: 0.934\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2019         |\n",
      "|    time_elapsed         | 37449        |\n",
      "|    total_timesteps      | 4134912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005181788  |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.5         |\n",
      "|    n_updates            | 20180        |\n",
      "|    policy_gradient_loss | -0.00772     |\n",
      "|    reward               | -0.055629224 |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 156          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2020         |\n",
      "|    time_elapsed         | 37467        |\n",
      "|    total_timesteps      | 4136960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026383945 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 159          |\n",
      "|    n_updates            | 20190        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    reward               | -9.541399    |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 211          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2021         |\n",
      "|    time_elapsed         | 37486        |\n",
      "|    total_timesteps      | 4139008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031687315 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 112          |\n",
      "|    n_updates            | 20200        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | 4.039569     |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 188          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2022         |\n",
      "|    time_elapsed         | 37504        |\n",
      "|    total_timesteps      | 4141056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065618786 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.8         |\n",
      "|    n_updates            | 20210        |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    reward               | -0.23295628  |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 71.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2023         |\n",
      "|    time_elapsed         | 37522        |\n",
      "|    total_timesteps      | 4143104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051054126 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 160          |\n",
      "|    n_updates            | 20220        |\n",
      "|    policy_gradient_loss | -0.00831     |\n",
      "|    reward               | 0.5294233    |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 269          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2024        |\n",
      "|    time_elapsed         | 37540       |\n",
      "|    total_timesteps      | 4145152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001888641 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.1        |\n",
      "|    n_updates            | 20230       |\n",
      "|    policy_gradient_loss | -0.00387    |\n",
      "|    reward               | 1.9280607   |\n",
      "|    std                  | 15.5        |\n",
      "|    value_loss           | 232         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2025        |\n",
      "|    time_elapsed         | 37559       |\n",
      "|    total_timesteps      | 4147200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010808401 |\n",
      "|    clip_fraction        | 0.0689      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.6        |\n",
      "|    n_updates            | 20240       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    reward               | -0.33243698 |\n",
      "|    std                  | 15.6        |\n",
      "|    value_loss           | 92.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2026         |\n",
      "|    time_elapsed         | 37578        |\n",
      "|    total_timesteps      | 4149248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055642417 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.1         |\n",
      "|    n_updates            | 20250        |\n",
      "|    policy_gradient_loss | -0.00914     |\n",
      "|    reward               | -2.6796877   |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 218          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2027         |\n",
      "|    time_elapsed         | 37596        |\n",
      "|    total_timesteps      | 4151296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016518936 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.6         |\n",
      "|    n_updates            | 20260        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | 0.5336428    |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 185          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2028        |\n",
      "|    time_elapsed         | 37615       |\n",
      "|    total_timesteps      | 4153344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008527972 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.4        |\n",
      "|    n_updates            | 20270       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 2.6082022   |\n",
      "|    std                  | 15.7        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2029        |\n",
      "|    time_elapsed         | 37634       |\n",
      "|    total_timesteps      | 4155392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006903722 |\n",
      "|    clip_fraction        | 0.0236      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46          |\n",
      "|    n_updates            | 20280       |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    reward               | 2.0977142   |\n",
      "|    std                  | 15.8        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2030          |\n",
      "|    time_elapsed         | 37653         |\n",
      "|    total_timesteps      | 4157440       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063730206 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -121          |\n",
      "|    explained_variance   | 0.0857        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 121           |\n",
      "|    n_updates            | 20290         |\n",
      "|    policy_gradient_loss | -0.00159      |\n",
      "|    reward               | -2.0602338    |\n",
      "|    std                  | 15.8          |\n",
      "|    value_loss           | 383           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2031         |\n",
      "|    time_elapsed         | 37672        |\n",
      "|    total_timesteps      | 4159488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051702945 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 87.2         |\n",
      "|    n_updates            | 20300        |\n",
      "|    policy_gradient_loss | -0.00844     |\n",
      "|    reward               | -0.294661    |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 219          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2032        |\n",
      "|    time_elapsed         | 37691       |\n",
      "|    total_timesteps      | 4161536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008300848 |\n",
      "|    clip_fraction        | 0.0666      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 20310       |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | 10.669982   |\n",
      "|    std                  | 15.9        |\n",
      "|    value_loss           | 70.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7871922.98\n",
      "total_reward: 6871922.98\n",
      "total_cost: 118821.40\n",
      "total_trades: 52763\n",
      "Sharpe: 0.918\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2033         |\n",
      "|    time_elapsed         | 37709        |\n",
      "|    total_timesteps      | 4163584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040374408 |\n",
      "|    clip_fraction        | 0.0062       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 111          |\n",
      "|    n_updates            | 20320        |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    reward               | 0.9731553    |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 183          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2034         |\n",
      "|    time_elapsed         | 37728        |\n",
      "|    total_timesteps      | 4165632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017746944 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.7         |\n",
      "|    n_updates            | 20330        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | -5.457868    |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 204          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2035         |\n",
      "|    time_elapsed         | 37746        |\n",
      "|    total_timesteps      | 4167680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052163536 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 86           |\n",
      "|    n_updates            | 20340        |\n",
      "|    policy_gradient_loss | -0.0062      |\n",
      "|    reward               | -3.2097754   |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2036         |\n",
      "|    time_elapsed         | 37765        |\n",
      "|    total_timesteps      | 4169728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075135804 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.3         |\n",
      "|    n_updates            | 20350        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    reward               | 1.063956     |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 131          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2037         |\n",
      "|    time_elapsed         | 37784        |\n",
      "|    total_timesteps      | 4171776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021186243 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 118          |\n",
      "|    n_updates            | 20360        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    reward               | 0.6791128    |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 240          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2038         |\n",
      "|    time_elapsed         | 37802        |\n",
      "|    total_timesteps      | 4173824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011648717 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 150          |\n",
      "|    n_updates            | 20370        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    reward               | 6.531875     |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 362          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2039        |\n",
      "|    time_elapsed         | 37820       |\n",
      "|    total_timesteps      | 4175872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010242097 |\n",
      "|    clip_fraction        | 0.0674      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 20380       |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    reward               | -7.658702   |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 67.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2040          |\n",
      "|    time_elapsed         | 37839         |\n",
      "|    total_timesteps      | 4177920       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051305495 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -121          |\n",
      "|    explained_variance   | 0.699         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 158           |\n",
      "|    n_updates            | 20390         |\n",
      "|    policy_gradient_loss | -0.00108      |\n",
      "|    reward               | 0.87673676    |\n",
      "|    std                  | 16.1          |\n",
      "|    value_loss           | 379           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2041          |\n",
      "|    time_elapsed         | 37858         |\n",
      "|    total_timesteps      | 4179968       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033573122 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -121          |\n",
      "|    explained_variance   | 0.563         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 103           |\n",
      "|    n_updates            | 20400         |\n",
      "|    policy_gradient_loss | -0.00127      |\n",
      "|    reward               | 4.849646      |\n",
      "|    std                  | 16.1          |\n",
      "|    value_loss           | 319           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2042        |\n",
      "|    time_elapsed         | 37876       |\n",
      "|    total_timesteps      | 4182016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007791221 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.3        |\n",
      "|    n_updates            | 20410       |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    reward               | -1.9291099  |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 96.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2043         |\n",
      "|    time_elapsed         | 37894        |\n",
      "|    total_timesteps      | 4184064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055468106 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34           |\n",
      "|    n_updates            | 20420        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | -1.0730546   |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 164          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2044         |\n",
      "|    time_elapsed         | 37912        |\n",
      "|    total_timesteps      | 4186112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018669823 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 122          |\n",
      "|    n_updates            | 20430        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    reward               | -7.7215185   |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 228          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2045         |\n",
      "|    time_elapsed         | 37930        |\n",
      "|    total_timesteps      | 4188160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013468312 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93           |\n",
      "|    n_updates            | 20440        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | 1.1764026    |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 231          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2046       |\n",
      "|    time_elapsed         | 37949      |\n",
      "|    total_timesteps      | 4190208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01067718 |\n",
      "|    clip_fraction        | 0.0911     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -121       |\n",
      "|    explained_variance   | 0.496      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 41         |\n",
      "|    n_updates            | 20450      |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    reward               | -0.5754436 |\n",
      "|    std                  | 16.2       |\n",
      "|    value_loss           | 80.3       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8202939.56\n",
      "total_reward: 7202939.56\n",
      "total_cost: 113356.44\n",
      "total_trades: 52418\n",
      "Sharpe: 0.939\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2047        |\n",
      "|    time_elapsed         | 37967       |\n",
      "|    total_timesteps      | 4192256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000715235 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 169         |\n",
      "|    n_updates            | 20460       |\n",
      "|    policy_gradient_loss | -0.00165    |\n",
      "|    reward               | 0.25843367  |\n",
      "|    std                  | 16.2        |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2048         |\n",
      "|    time_elapsed         | 37985        |\n",
      "|    total_timesteps      | 4194304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010166019 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 177          |\n",
      "|    n_updates            | 20470        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    reward               | -0.5570251   |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 334          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2049         |\n",
      "|    time_elapsed         | 38004        |\n",
      "|    total_timesteps      | 4196352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049561323 |\n",
      "|    clip_fraction        | 0.00991      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.347        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.4         |\n",
      "|    n_updates            | 20480        |\n",
      "|    policy_gradient_loss | -0.00534     |\n",
      "|    reward               | 1.8988378    |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2050         |\n",
      "|    time_elapsed         | 38022        |\n",
      "|    total_timesteps      | 4198400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031669145 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 139          |\n",
      "|    n_updates            | 20490        |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    reward               | 3.3574274    |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 232          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2051         |\n",
      "|    time_elapsed         | 38040        |\n",
      "|    total_timesteps      | 4200448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024180615 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 116          |\n",
      "|    n_updates            | 20500        |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    reward               | -14.440367   |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 271          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2052         |\n",
      "|    time_elapsed         | 38058        |\n",
      "|    total_timesteps      | 4202496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032862434 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.9         |\n",
      "|    n_updates            | 20510        |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    reward               | 7.0122123    |\n",
      "|    std                  | 16.4         |\n",
      "|    value_loss           | 180          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2053         |\n",
      "|    time_elapsed         | 38076        |\n",
      "|    total_timesteps      | 4204544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074522505 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.9         |\n",
      "|    n_updates            | 20520        |\n",
      "|    policy_gradient_loss | -0.00921     |\n",
      "|    reward               | -4.34404     |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2054         |\n",
      "|    time_elapsed         | 38095        |\n",
      "|    total_timesteps      | 4206592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010174587 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 181          |\n",
      "|    n_updates            | 20530        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | 1.0255526    |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 299          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2055         |\n",
      "|    time_elapsed         | 38113        |\n",
      "|    total_timesteps      | 4208640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036299003 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.763        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 198          |\n",
      "|    n_updates            | 20540        |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    reward               | 1.1177405    |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 246          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2056        |\n",
      "|    time_elapsed         | 38132       |\n",
      "|    total_timesteps      | 4210688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010319769 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 20550       |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    reward               | 2.0660043   |\n",
      "|    std                  | 16.5        |\n",
      "|    value_loss           | 65.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2057         |\n",
      "|    time_elapsed         | 38151        |\n",
      "|    total_timesteps      | 4212736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018309318 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 129          |\n",
      "|    n_updates            | 20560        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    reward               | -0.19256707  |\n",
      "|    std                  | 16.6         |\n",
      "|    value_loss           | 257          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2058         |\n",
      "|    time_elapsed         | 38170        |\n",
      "|    total_timesteps      | 4214784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012734717 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 20570        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | 4.4597483    |\n",
      "|    std                  | 16.6         |\n",
      "|    value_loss           | 267          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2059         |\n",
      "|    time_elapsed         | 38189        |\n",
      "|    total_timesteps      | 4216832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050376942 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.3         |\n",
      "|    n_updates            | 20580        |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    reward               | 3.5173085    |\n",
      "|    std                  | 16.6         |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2060        |\n",
      "|    time_elapsed         | 38207       |\n",
      "|    total_timesteps      | 4218880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007012796 |\n",
      "|    clip_fraction        | 0.0258      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.3        |\n",
      "|    n_updates            | 20590       |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    reward               | -0.4485905  |\n",
      "|    std                  | 16.7        |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8915880.57\n",
      "total_reward: 7915880.57\n",
      "total_cost: 111865.84\n",
      "total_trades: 52036\n",
      "Sharpe: 0.974\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2061        |\n",
      "|    time_elapsed         | 38226       |\n",
      "|    total_timesteps      | 4220928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003333017 |\n",
      "|    clip_fraction        | 0.00386     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 175         |\n",
      "|    n_updates            | 20600       |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    reward               | 0.885108    |\n",
      "|    std                  | 16.7        |\n",
      "|    value_loss           | 249         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2062         |\n",
      "|    time_elapsed         | 38244        |\n",
      "|    total_timesteps      | 4222976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063314233 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 178          |\n",
      "|    n_updates            | 20610        |\n",
      "|    policy_gradient_loss | -0.00932     |\n",
      "|    reward               | -2.2624905   |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 309          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2063        |\n",
      "|    time_elapsed         | 38263       |\n",
      "|    total_timesteps      | 4225024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008806711 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 20620       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -2.2973964  |\n",
      "|    std                  | 16.7        |\n",
      "|    value_loss           | 75.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2064         |\n",
      "|    time_elapsed         | 38281        |\n",
      "|    total_timesteps      | 4227072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018389305 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 94.7         |\n",
      "|    n_updates            | 20630        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | 1.5907903    |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 359          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2065         |\n",
      "|    time_elapsed         | 38299        |\n",
      "|    total_timesteps      | 4229120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010097728 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 237          |\n",
      "|    n_updates            | 20640        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | -4.053125    |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 358          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2066         |\n",
      "|    time_elapsed         | 38317        |\n",
      "|    total_timesteps      | 4231168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054464103 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.296        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.7         |\n",
      "|    n_updates            | 20650        |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    reward               | 0.23990767   |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 149          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2067         |\n",
      "|    time_elapsed         | 38335        |\n",
      "|    total_timesteps      | 4233216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061991354 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 91.7         |\n",
      "|    n_updates            | 20660        |\n",
      "|    policy_gradient_loss | -0.00691     |\n",
      "|    reward               | 0.23109382   |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 174          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2068        |\n",
      "|    time_elapsed         | 38354       |\n",
      "|    total_timesteps      | 4235264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001756747 |\n",
      "|    clip_fraction        | 9.77e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 20670       |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    reward               | 12.735477   |\n",
      "|    std                  | 16.8        |\n",
      "|    value_loss           | 316         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2069         |\n",
      "|    time_elapsed         | 38373        |\n",
      "|    total_timesteps      | 4237312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035868152 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 128          |\n",
      "|    n_updates            | 20680        |\n",
      "|    policy_gradient_loss | -0.00545     |\n",
      "|    reward               | -1.438084    |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 233          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2070        |\n",
      "|    time_elapsed         | 38392       |\n",
      "|    total_timesteps      | 4239360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009167643 |\n",
      "|    clip_fraction        | 0.041       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.2        |\n",
      "|    n_updates            | 20690       |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    reward               | -1.4050087  |\n",
      "|    std                  | 16.9        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2071         |\n",
      "|    time_elapsed         | 38411        |\n",
      "|    total_timesteps      | 4241408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020076362 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 141          |\n",
      "|    n_updates            | 20700        |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    reward               | -0.43361473  |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 361          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2072        |\n",
      "|    time_elapsed         | 38430       |\n",
      "|    total_timesteps      | 4243456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002497118 |\n",
      "|    clip_fraction        | 0.00127     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 20710       |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    reward               | -0.6449338  |\n",
      "|    std                  | 16.9        |\n",
      "|    value_loss           | 369         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2073        |\n",
      "|    time_elapsed         | 38448       |\n",
      "|    total_timesteps      | 4245504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007990682 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.3        |\n",
      "|    n_updates            | 20720       |\n",
      "|    policy_gradient_loss | -0.00955    |\n",
      "|    reward               | 0.27453893  |\n",
      "|    std                  | 17          |\n",
      "|    value_loss           | 86.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2074         |\n",
      "|    time_elapsed         | 38466        |\n",
      "|    total_timesteps      | 4247552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017997688 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 218          |\n",
      "|    n_updates            | 20730        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | 1.0996497    |\n",
      "|    std                  | 17           |\n",
      "|    value_loss           | 297          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2075        |\n",
      "|    time_elapsed         | 38485       |\n",
      "|    total_timesteps      | 4249600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001394375 |\n",
      "|    clip_fraction        | 0.000244    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 20740       |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    reward               | 5.479204    |\n",
      "|    std                  | 17          |\n",
      "|    value_loss           | 346         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9598534.72\n",
      "total_reward: 8598534.72\n",
      "total_cost: 151734.52\n",
      "total_trades: 54154\n",
      "Sharpe: 1.001\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2076         |\n",
      "|    time_elapsed         | 38504        |\n",
      "|    total_timesteps      | 4251648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060426053 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.4         |\n",
      "|    n_updates            | 20750        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    reward               | 4.041349     |\n",
      "|    std                  | 17           |\n",
      "|    value_loss           | 183          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2077        |\n",
      "|    time_elapsed         | 38522       |\n",
      "|    total_timesteps      | 4253696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006470116 |\n",
      "|    clip_fraction        | 0.0244      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 20760       |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    reward               | -0.44271857 |\n",
      "|    std                  | 17          |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2078        |\n",
      "|    time_elapsed         | 38540       |\n",
      "|    total_timesteps      | 4255744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001415414 |\n",
      "|    clip_fraction        | 0.000146    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 272         |\n",
      "|    n_updates            | 20770       |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    reward               | -0.19896051 |\n",
      "|    std                  | 17          |\n",
      "|    value_loss           | 359         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2079        |\n",
      "|    time_elapsed         | 38558       |\n",
      "|    total_timesteps      | 4257792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002289651 |\n",
      "|    clip_fraction        | 0.00181     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 174         |\n",
      "|    n_updates            | 20780       |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    reward               | -3.8135118  |\n",
      "|    std                  | 17          |\n",
      "|    value_loss           | 370         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2080        |\n",
      "|    time_elapsed         | 38577       |\n",
      "|    total_timesteps      | 4259840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009927506 |\n",
      "|    clip_fraction        | 0.0849      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.6        |\n",
      "|    n_updates            | 20790       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 0.26802194  |\n",
      "|    std                  | 17.1        |\n",
      "|    value_loss           | 81.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2081          |\n",
      "|    time_elapsed         | 38595         |\n",
      "|    total_timesteps      | 4261888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0006176197  |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -123          |\n",
      "|    explained_variance   | 0.741         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 88.3          |\n",
      "|    n_updates            | 20800         |\n",
      "|    policy_gradient_loss | -0.00161      |\n",
      "|    reward               | -0.0027200207 |\n",
      "|    std                  | 17.1          |\n",
      "|    value_loss           | 266           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2082         |\n",
      "|    time_elapsed         | 38614        |\n",
      "|    total_timesteps      | 4263936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015273888 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 117          |\n",
      "|    n_updates            | 20810        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | 1.5456507    |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 280          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2083       |\n",
      "|    time_elapsed         | 38633      |\n",
      "|    total_timesteps      | 4265984    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00492764 |\n",
      "|    clip_fraction        | 0.0164     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -123       |\n",
      "|    explained_variance   | 0.525      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 75.4       |\n",
      "|    n_updates            | 20820      |\n",
      "|    policy_gradient_loss | -0.00778   |\n",
      "|    reward               | 7.663072   |\n",
      "|    std                  | 17.2       |\n",
      "|    value_loss           | 148        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2084        |\n",
      "|    time_elapsed         | 38652       |\n",
      "|    total_timesteps      | 4268032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004261401 |\n",
      "|    clip_fraction        | 0.00435     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 20830       |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | 1.6879356   |\n",
      "|    std                  | 17.2        |\n",
      "|    value_loss           | 238         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2085        |\n",
      "|    time_elapsed         | 38670       |\n",
      "|    total_timesteps      | 4270080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002333175 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 200         |\n",
      "|    n_updates            | 20840       |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    reward               | 0.4960994   |\n",
      "|    std                  | 17.2        |\n",
      "|    value_loss           | 329         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2086         |\n",
      "|    time_elapsed         | 38688        |\n",
      "|    total_timesteps      | 4272128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013504075 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 213          |\n",
      "|    n_updates            | 20850        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | 3.128067     |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 408          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2087        |\n",
      "|    time_elapsed         | 38706       |\n",
      "|    total_timesteps      | 4274176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007810924 |\n",
      "|    clip_fraction        | 0.0417      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 20860       |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    reward               | -0.424865   |\n",
      "|    std                  | 17.3        |\n",
      "|    value_loss           | 62.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2088         |\n",
      "|    time_elapsed         | 38725        |\n",
      "|    total_timesteps      | 4276224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003264425 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.0793       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 215          |\n",
      "|    n_updates            | 20870        |\n",
      "|    policy_gradient_loss | -0.001       |\n",
      "|    reward               | -0.28381845  |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 551          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2089         |\n",
      "|    time_elapsed         | 38744        |\n",
      "|    total_timesteps      | 4278272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043398794 |\n",
      "|    clip_fraction        | 0.00908      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 146          |\n",
      "|    n_updates            | 20880        |\n",
      "|    policy_gradient_loss | -0.00639     |\n",
      "|    reward               | -1.2985303   |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 392          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9876858.48\n",
      "total_reward: 8876858.48\n",
      "total_cost: 175388.79\n",
      "total_trades: 55762\n",
      "Sharpe: 1.067\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2090         |\n",
      "|    time_elapsed         | 38762        |\n",
      "|    total_timesteps      | 4280320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073217796 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.5         |\n",
      "|    n_updates            | 20890        |\n",
      "|    policy_gradient_loss | -0.00606     |\n",
      "|    reward               | 1.4368461    |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 85.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2091        |\n",
      "|    time_elapsed         | 38781       |\n",
      "|    total_timesteps      | 4282368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005205326 |\n",
      "|    clip_fraction        | 0.0158      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 155         |\n",
      "|    n_updates            | 20900       |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | -2.142625   |\n",
      "|    std                  | 17.4        |\n",
      "|    value_loss           | 297         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2092          |\n",
      "|    time_elapsed         | 38799         |\n",
      "|    total_timesteps      | 4284416       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038130133 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -123          |\n",
      "|    explained_variance   | 0.515         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 224           |\n",
      "|    n_updates            | 20910         |\n",
      "|    policy_gradient_loss | -0.000989     |\n",
      "|    reward               | -5.563767     |\n",
      "|    std                  | 17.4          |\n",
      "|    value_loss           | 395           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2093        |\n",
      "|    time_elapsed         | 38817       |\n",
      "|    total_timesteps      | 4286464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005135382 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 20920       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | 1.3918846   |\n",
      "|    std                  | 17.4        |\n",
      "|    value_loss           | 259         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2094        |\n",
      "|    time_elapsed         | 38835       |\n",
      "|    total_timesteps      | 4288512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007376197 |\n",
      "|    clip_fraction        | 0.0326      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 99.7        |\n",
      "|    n_updates            | 20930       |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    reward               | 0.7341453   |\n",
      "|    std                  | 17.5        |\n",
      "|    value_loss           | 224         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2095         |\n",
      "|    time_elapsed         | 38854        |\n",
      "|    total_timesteps      | 4290560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033231343 |\n",
      "|    clip_fraction        | 0.00527      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 176          |\n",
      "|    n_updates            | 20940        |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    reward               | -0.6334426   |\n",
      "|    std                  | 17.5         |\n",
      "|    value_loss           | 342          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2096        |\n",
      "|    time_elapsed         | 38872       |\n",
      "|    total_timesteps      | 4292608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002780722 |\n",
      "|    clip_fraction        | 0.00171     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 20950       |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    reward               | 13.536203   |\n",
      "|    std                  | 17.5        |\n",
      "|    value_loss           | 351         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2097        |\n",
      "|    time_elapsed         | 38890       |\n",
      "|    total_timesteps      | 4294656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008663472 |\n",
      "|    clip_fraction        | 0.0355      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 20960       |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    reward               | -1.8735994  |\n",
      "|    std                  | 17.6        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2098         |\n",
      "|    time_elapsed         | 38908        |\n",
      "|    total_timesteps      | 4296704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023628203 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.646        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.9         |\n",
      "|    n_updates            | 20970        |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    reward               | -0.12987319  |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 262          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2099         |\n",
      "|    time_elapsed         | 38926        |\n",
      "|    total_timesteps      | 4298752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013539717 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 251          |\n",
      "|    n_updates            | 20980        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | -7.102183    |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 397          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2100         |\n",
      "|    time_elapsed         | 38944        |\n",
      "|    total_timesteps      | 4300800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005300329 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.324        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 118          |\n",
      "|    n_updates            | 20990        |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    reward               | -1.1512572   |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 278          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2101        |\n",
      "|    time_elapsed         | 38963       |\n",
      "|    total_timesteps      | 4302848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005987702 |\n",
      "|    clip_fraction        | 0.0223      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 180         |\n",
      "|    n_updates            | 21000       |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    reward               | -0.2540693  |\n",
      "|    std                  | 17.6        |\n",
      "|    value_loss           | 216         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2102         |\n",
      "|    time_elapsed         | 38982        |\n",
      "|    total_timesteps      | 4304896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016709089 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.393        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 21010        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    reward               | -1.9659065   |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 278          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2103        |\n",
      "|    time_elapsed         | 38999       |\n",
      "|    total_timesteps      | 4306944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005183845 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 21020       |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    reward               | 10.200675   |\n",
      "|    std                  | 17.6        |\n",
      "|    value_loss           | 241         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10022307.09\n",
      "total_reward: 9022307.09\n",
      "total_cost: 193897.91\n",
      "total_trades: 57081\n",
      "Sharpe: 1.084\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2104        |\n",
      "|    time_elapsed         | 39018       |\n",
      "|    total_timesteps      | 4308992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007961009 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 21030       |\n",
      "|    policy_gradient_loss | -0.00818    |\n",
      "|    reward               | -1.8228414  |\n",
      "|    std                  | 17.7        |\n",
      "|    value_loss           | 65.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2105        |\n",
      "|    time_elapsed         | 39037       |\n",
      "|    total_timesteps      | 4311040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008140788 |\n",
      "|    clip_fraction        | 0.0483      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 221         |\n",
      "|    n_updates            | 21040       |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    reward               | -1.1375093  |\n",
      "|    std                  | 17.8        |\n",
      "|    value_loss           | 360         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2106         |\n",
      "|    time_elapsed         | 39055        |\n",
      "|    total_timesteps      | 4313088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016557397 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 145          |\n",
      "|    n_updates            | 21050        |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    reward               | 17.802015    |\n",
      "|    std                  | 17.8         |\n",
      "|    value_loss           | 265          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2107         |\n",
      "|    time_elapsed         | 39075        |\n",
      "|    total_timesteps      | 4315136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013266371 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.227        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 168          |\n",
      "|    n_updates            | 21060        |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    reward               | 20.027122    |\n",
      "|    std                  | 17.8         |\n",
      "|    value_loss           | 338          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2108        |\n",
      "|    time_elapsed         | 39093       |\n",
      "|    total_timesteps      | 4317184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001967919 |\n",
      "|    clip_fraction        | 0.000928    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 21070       |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    reward               | 4.2172756   |\n",
      "|    std                  | 17.8        |\n",
      "|    value_loss           | 311         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2109         |\n",
      "|    time_elapsed         | 39112        |\n",
      "|    total_timesteps      | 4319232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017997054 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.325        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 84.1         |\n",
      "|    n_updates            | 21080        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | 3.9622836    |\n",
      "|    std                  | 17.8         |\n",
      "|    value_loss           | 301          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2110          |\n",
      "|    time_elapsed         | 39130         |\n",
      "|    total_timesteps      | 4321280       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071407174 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -124          |\n",
      "|    explained_variance   | 0.32          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 108           |\n",
      "|    n_updates            | 21090         |\n",
      "|    policy_gradient_loss | -0.0022       |\n",
      "|    reward               | 4.304702      |\n",
      "|    std                  | 17.8          |\n",
      "|    value_loss           | 331           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2111        |\n",
      "|    time_elapsed         | 39148       |\n",
      "|    total_timesteps      | 4323328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010125579 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32          |\n",
      "|    n_updates            | 21100       |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    reward               | 2.5337143   |\n",
      "|    std                  | 17.9        |\n",
      "|    value_loss           | 57.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2112         |\n",
      "|    time_elapsed         | 39166        |\n",
      "|    total_timesteps      | 4325376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010476572 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.4         |\n",
      "|    n_updates            | 21110        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | 2.573701     |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 258          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2113          |\n",
      "|    time_elapsed         | 39184         |\n",
      "|    total_timesteps      | 4327424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051096105 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -124          |\n",
      "|    explained_variance   | 0.512         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 151           |\n",
      "|    n_updates            | 21120         |\n",
      "|    policy_gradient_loss | -0.00181      |\n",
      "|    reward               | 0.46000382    |\n",
      "|    std                  | 17.9          |\n",
      "|    value_loss           | 529           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2114        |\n",
      "|    time_elapsed         | 39204       |\n",
      "|    total_timesteps      | 4329472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009727847 |\n",
      "|    clip_fraction        | 0.0699      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.5        |\n",
      "|    n_updates            | 21130       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 4.649934    |\n",
      "|    std                  | 18          |\n",
      "|    value_loss           | 94          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2115         |\n",
      "|    time_elapsed         | 39222        |\n",
      "|    total_timesteps      | 4331520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023957952 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 242          |\n",
      "|    n_updates            | 21140        |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    reward               | 0.9115742    |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 386          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2116          |\n",
      "|    time_elapsed         | 39241         |\n",
      "|    total_timesteps      | 4333568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011236494 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -124          |\n",
      "|    explained_variance   | 0.727         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 137           |\n",
      "|    n_updates            | 21150         |\n",
      "|    policy_gradient_loss | -0.000701     |\n",
      "|    reward               | -7.600226     |\n",
      "|    std                  | 18            |\n",
      "|    value_loss           | 397           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2117          |\n",
      "|    time_elapsed         | 39260         |\n",
      "|    total_timesteps      | 4335616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045317507 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -124          |\n",
      "|    explained_variance   | 0.388         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 73.9          |\n",
      "|    n_updates            | 21160         |\n",
      "|    policy_gradient_loss | -0.00152      |\n",
      "|    reward               | -1.2921067    |\n",
      "|    std                  | 18            |\n",
      "|    value_loss           | 285           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11078794.82\n",
      "total_reward: 10078794.82\n",
      "total_cost: 232313.53\n",
      "total_trades: 58690\n",
      "Sharpe: 1.117\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2118         |\n",
      "|    time_elapsed         | 39278        |\n",
      "|    total_timesteps      | 4337664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044490285 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.7         |\n",
      "|    n_updates            | 21170        |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    reward               | 0.8813638    |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 156          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2119        |\n",
      "|    time_elapsed         | 39296       |\n",
      "|    total_timesteps      | 4339712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005838849 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 21180       |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    reward               | 0.11388462  |\n",
      "|    std                  | 18.1        |\n",
      "|    value_loss           | 504         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2120         |\n",
      "|    time_elapsed         | 39315        |\n",
      "|    total_timesteps      | 4341760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022556444 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 169          |\n",
      "|    n_updates            | 21190        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | -0.034084797 |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 355          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2121         |\n",
      "|    time_elapsed         | 39334        |\n",
      "|    total_timesteps      | 4343808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013942098 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.775        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.3         |\n",
      "|    n_updates            | 21200        |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    reward               | 1.3537637    |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 97           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2122         |\n",
      "|    time_elapsed         | 39353        |\n",
      "|    total_timesteps      | 4345856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062169908 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 429          |\n",
      "|    n_updates            | 21210        |\n",
      "|    policy_gradient_loss | -0.00888     |\n",
      "|    reward               | 0.27671486   |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 482          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2123         |\n",
      "|    time_elapsed         | 39371        |\n",
      "|    total_timesteps      | 4347904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005359476 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 159          |\n",
      "|    n_updates            | 21220        |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    reward               | 1.9293476    |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 322          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2124         |\n",
      "|    time_elapsed         | 39390        |\n",
      "|    total_timesteps      | 4349952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035478035 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93.3         |\n",
      "|    n_updates            | 21230        |\n",
      "|    policy_gradient_loss | -0.00524     |\n",
      "|    reward               | -1.8359512   |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 157          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2125        |\n",
      "|    time_elapsed         | 39408       |\n",
      "|    total_timesteps      | 4352000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002369319 |\n",
      "|    clip_fraction        | 0.000635    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.3        |\n",
      "|    n_updates            | 21240       |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    reward               | -0.9818759  |\n",
      "|    std                  | 18.2        |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2126         |\n",
      "|    time_elapsed         | 39427        |\n",
      "|    total_timesteps      | 4354048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013469837 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90.6         |\n",
      "|    n_updates            | 21250        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    reward               | 1.8577775    |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 278          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2127         |\n",
      "|    time_elapsed         | 39446        |\n",
      "|    total_timesteps      | 4356096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005548808 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.4         |\n",
      "|    n_updates            | 21260        |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    reward               | 0.1286625    |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 352          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2128        |\n",
      "|    time_elapsed         | 39465       |\n",
      "|    total_timesteps      | 4358144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010449357 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 21270       |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    reward               | 1.3050718   |\n",
      "|    std                  | 18.4        |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2129        |\n",
      "|    time_elapsed         | 39485       |\n",
      "|    total_timesteps      | 4360192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005268361 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 156         |\n",
      "|    n_updates            | 21280       |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    reward               | -1.369682   |\n",
      "|    std                  | 18.4        |\n",
      "|    value_loss           | 373         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2130         |\n",
      "|    time_elapsed         | 39503        |\n",
      "|    total_timesteps      | 4362240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003010437 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.169        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 311          |\n",
      "|    n_updates            | 21290        |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    reward               | -21.812414   |\n",
      "|    std                  | 18.4         |\n",
      "|    value_loss           | 424          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2131         |\n",
      "|    time_elapsed         | 39521        |\n",
      "|    total_timesteps      | 4364288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070440276 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.5         |\n",
      "|    n_updates            | 21300        |\n",
      "|    policy_gradient_loss | -0.00903     |\n",
      "|    reward               | 1.5330887    |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10297808.68\n",
      "total_reward: 9297808.68\n",
      "total_cost: 233765.74\n",
      "total_trades: 58959\n",
      "Sharpe: 1.069\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2132        |\n",
      "|    time_elapsed         | 39540       |\n",
      "|    total_timesteps      | 4366336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003182806 |\n",
      "|    clip_fraction        | 0.00283     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.1        |\n",
      "|    n_updates            | 21310       |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    reward               | -1.7819384  |\n",
      "|    std                  | 18.5        |\n",
      "|    value_loss           | 282         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2133        |\n",
      "|    time_elapsed         | 39558       |\n",
      "|    total_timesteps      | 4368384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000526674 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 244         |\n",
      "|    n_updates            | 21320       |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    reward               | 6.5050683   |\n",
      "|    std                  | 18.5        |\n",
      "|    value_loss           | 498         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2134          |\n",
      "|    time_elapsed         | 39576         |\n",
      "|    total_timesteps      | 4370432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023887269 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -125          |\n",
      "|    explained_variance   | 0.0342        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 275           |\n",
      "|    n_updates            | 21330         |\n",
      "|    policy_gradient_loss | -0.00131      |\n",
      "|    reward               | -0.31928638   |\n",
      "|    std                  | 18.5          |\n",
      "|    value_loss           | 570           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2135        |\n",
      "|    time_elapsed         | 39595       |\n",
      "|    total_timesteps      | 4372480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009735229 |\n",
      "|    clip_fraction        | 0.0621      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 21340       |\n",
      "|    policy_gradient_loss | -0.00977    |\n",
      "|    reward               | 0.6689179   |\n",
      "|    std                  | 18.6        |\n",
      "|    value_loss           | 75.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2136         |\n",
      "|    time_elapsed         | 39614        |\n",
      "|    total_timesteps      | 4374528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033222446 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 112          |\n",
      "|    n_updates            | 21350        |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    reward               | -0.80551845  |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 277          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2137         |\n",
      "|    time_elapsed         | 39632        |\n",
      "|    total_timesteps      | 4376576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017195911 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 285          |\n",
      "|    n_updates            | 21360        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | 1.1561358    |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 594          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2138        |\n",
      "|    time_elapsed         | 39650       |\n",
      "|    total_timesteps      | 4378624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005382545 |\n",
      "|    clip_fraction        | 0.0218      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.2        |\n",
      "|    n_updates            | 21370       |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    reward               | -2.8990526  |\n",
      "|    std                  | 18.7        |\n",
      "|    value_loss           | 76.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2139        |\n",
      "|    time_elapsed         | 39670       |\n",
      "|    total_timesteps      | 4380672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006197466 |\n",
      "|    clip_fraction        | 0.0144      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 294         |\n",
      "|    n_updates            | 21380       |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | 0.13928139  |\n",
      "|    std                  | 18.6        |\n",
      "|    value_loss           | 490         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2140         |\n",
      "|    time_elapsed         | 39689        |\n",
      "|    total_timesteps      | 4382720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013800772 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 182          |\n",
      "|    n_updates            | 21390        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | 6.44885      |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 402          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2141         |\n",
      "|    time_elapsed         | 39707        |\n",
      "|    total_timesteps      | 4384768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011001143 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 98.9         |\n",
      "|    n_updates            | 21400        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    reward               | -4.502883    |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 260          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2142       |\n",
      "|    time_elapsed         | 39726      |\n",
      "|    total_timesteps      | 4386816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00377829 |\n",
      "|    clip_fraction        | 0.00479    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -125       |\n",
      "|    explained_variance   | 0.405      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 200        |\n",
      "|    n_updates            | 21410      |\n",
      "|    policy_gradient_loss | -0.00582   |\n",
      "|    reward               | -3.0129304 |\n",
      "|    std                  | 18.7       |\n",
      "|    value_loss           | 413        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2143         |\n",
      "|    time_elapsed         | 39745        |\n",
      "|    total_timesteps      | 4388864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039378805 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 497          |\n",
      "|    n_updates            | 21420        |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    reward               | -0.87713075  |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 641          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2144         |\n",
      "|    time_elapsed         | 39763        |\n",
      "|    total_timesteps      | 4390912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016488512 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 186          |\n",
      "|    n_updates            | 21430        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    reward               | 0.11933044   |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 487          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2145         |\n",
      "|    time_elapsed         | 39782        |\n",
      "|    total_timesteps      | 4392960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058558034 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 21440        |\n",
      "|    policy_gradient_loss | -0.00706     |\n",
      "|    reward               | -1.80605     |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 66.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10309700.17\n",
      "total_reward: 9309700.17\n",
      "total_cost: 222810.96\n",
      "total_trades: 58290\n",
      "Sharpe: 1.087\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2146        |\n",
      "|    time_elapsed         | 39801       |\n",
      "|    total_timesteps      | 4395008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009090109 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 309         |\n",
      "|    n_updates            | 21450       |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | 1.3132949   |\n",
      "|    std                  | 18.8        |\n",
      "|    value_loss           | 524         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2147         |\n",
      "|    time_elapsed         | 39819        |\n",
      "|    total_timesteps      | 4397056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022186511 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.408        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 302          |\n",
      "|    n_updates            | 21460        |\n",
      "|    policy_gradient_loss | -0.00479     |\n",
      "|    reward               | 9.936257     |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 493          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2148         |\n",
      "|    time_elapsed         | 39838        |\n",
      "|    total_timesteps      | 4399104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016111745 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 86.8         |\n",
      "|    n_updates            | 21470        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | -2.4887989   |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 200          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2149         |\n",
      "|    time_elapsed         | 39857        |\n",
      "|    total_timesteps      | 4401152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035577032 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 128          |\n",
      "|    n_updates            | 21480        |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    reward               | 3.8425424    |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 375          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2150         |\n",
      "|    time_elapsed         | 39876        |\n",
      "|    total_timesteps      | 4403200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031422589 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 234          |\n",
      "|    n_updates            | 21490        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    reward               | 2.174105     |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 474          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2151         |\n",
      "|    time_elapsed         | 39894        |\n",
      "|    total_timesteps      | 4405248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012579851 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.54         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 171          |\n",
      "|    n_updates            | 21500        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | -0.55707914  |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 279          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2152        |\n",
      "|    time_elapsed         | 39913       |\n",
      "|    total_timesteps      | 4407296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007830505 |\n",
      "|    clip_fraction        | 0.049       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.784       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 21510       |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    reward               | 1.2866602   |\n",
      "|    std                  | 19          |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2153         |\n",
      "|    time_elapsed         | 39931        |\n",
      "|    total_timesteps      | 4409344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009132734 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 183          |\n",
      "|    n_updates            | 21520        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    reward               | -1.602879    |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 313          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2154         |\n",
      "|    time_elapsed         | 39950        |\n",
      "|    total_timesteps      | 4411392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014808837 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 211          |\n",
      "|    n_updates            | 21530        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | -22.340363   |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 399          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2155         |\n",
      "|    time_elapsed         | 39969        |\n",
      "|    total_timesteps      | 4413440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037857874 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.9         |\n",
      "|    n_updates            | 21540        |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    reward               | -3.4344904   |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 152          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2156         |\n",
      "|    time_elapsed         | 39989        |\n",
      "|    total_timesteps      | 4415488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025233235 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.273        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 106          |\n",
      "|    n_updates            | 21550        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | -0.13689737  |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 312          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2157         |\n",
      "|    time_elapsed         | 40032        |\n",
      "|    total_timesteps      | 4417536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012352563 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 237          |\n",
      "|    n_updates            | 21560        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    reward               | -129.92168   |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 351          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2158         |\n",
      "|    time_elapsed         | 40051        |\n",
      "|    total_timesteps      | 4419584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042254715 |\n",
      "|    clip_fraction        | 0.00791      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.233        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 198          |\n",
      "|    n_updates            | 21570        |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    reward               | 0.5552711    |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 318          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2159        |\n",
      "|    time_elapsed         | 40069       |\n",
      "|    total_timesteps      | 4421632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007153224 |\n",
      "|    clip_fraction        | 0.0284      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.7        |\n",
      "|    n_updates            | 21580       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | 0.39631543  |\n",
      "|    std                  | 19.2        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9435892.78\n",
      "total_reward: 8435892.78\n",
      "total_cost: 224048.07\n",
      "total_trades: 59260\n",
      "Sharpe: 1.026\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2160         |\n",
      "|    time_elapsed         | 40087        |\n",
      "|    total_timesteps      | 4423680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011535967 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 251          |\n",
      "|    n_updates            | 21590        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | 0.35879046   |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 423          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2161          |\n",
      "|    time_elapsed         | 40105         |\n",
      "|    total_timesteps      | 4425728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021568648 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -126          |\n",
      "|    explained_variance   | 0.258         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 259           |\n",
      "|    n_updates            | 21600         |\n",
      "|    policy_gradient_loss | -0.000776     |\n",
      "|    reward               | 1.2211059     |\n",
      "|    std                  | 19.2          |\n",
      "|    value_loss           | 653           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2162        |\n",
      "|    time_elapsed         | 40123       |\n",
      "|    total_timesteps      | 4427776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010410534 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 21610       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 3.1600473   |\n",
      "|    std                  | 19.3        |\n",
      "|    value_loss           | 58.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2163        |\n",
      "|    time_elapsed         | 40142       |\n",
      "|    total_timesteps      | 4429824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002727662 |\n",
      "|    clip_fraction        | 0.00127     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 21620       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | 1.217177    |\n",
      "|    std                  | 19.3        |\n",
      "|    value_loss           | 268         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2164          |\n",
      "|    time_elapsed         | 40161         |\n",
      "|    total_timesteps      | 4431872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00088257797 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -126          |\n",
      "|    explained_variance   | 0.58          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 172           |\n",
      "|    n_updates            | 21630         |\n",
      "|    policy_gradient_loss | -0.00196      |\n",
      "|    reward               | 5.7097974     |\n",
      "|    std                  | 19.3          |\n",
      "|    value_loss           | 336           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2165         |\n",
      "|    time_elapsed         | 40179        |\n",
      "|    total_timesteps      | 4433920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047333855 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.6         |\n",
      "|    n_updates            | 21640        |\n",
      "|    policy_gradient_loss | -0.00776     |\n",
      "|    reward               | 2.258457     |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 179          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2166         |\n",
      "|    time_elapsed         | 40198        |\n",
      "|    total_timesteps      | 4435968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037038357 |\n",
      "|    clip_fraction        | 0.00532      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 114          |\n",
      "|    n_updates            | 21650        |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    reward               | -0.3351912   |\n",
      "|    std                  | 19.4         |\n",
      "|    value_loss           | 179          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2167         |\n",
      "|    time_elapsed         | 40216        |\n",
      "|    total_timesteps      | 4438016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009993087 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 117          |\n",
      "|    n_updates            | 21660        |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    reward               | 0.54758704   |\n",
      "|    std                  | 19.4         |\n",
      "|    value_loss           | 322          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2168          |\n",
      "|    time_elapsed         | 40235         |\n",
      "|    total_timesteps      | 4440064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00049413485 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -126          |\n",
      "|    explained_variance   | 0.696         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 241           |\n",
      "|    n_updates            | 21670         |\n",
      "|    policy_gradient_loss | -0.0017       |\n",
      "|    reward               | 1.9224819     |\n",
      "|    std                  | 19.4          |\n",
      "|    value_loss           | 338           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2169        |\n",
      "|    time_elapsed         | 40254       |\n",
      "|    total_timesteps      | 4442112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015805425 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | -0.157      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 21680       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 3.0507872   |\n",
      "|    std                  | 19.5        |\n",
      "|    value_loss           | 46.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2170         |\n",
      "|    time_elapsed         | 40272        |\n",
      "|    total_timesteps      | 4444160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010583529 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 274          |\n",
      "|    n_updates            | 21690        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 0.58036083   |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 271          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2171         |\n",
      "|    time_elapsed         | 40290        |\n",
      "|    total_timesteps      | 4446208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034557437 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.344        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 123          |\n",
      "|    n_updates            | 21700        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | -5.919555    |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 364          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2172         |\n",
      "|    time_elapsed         | 40308        |\n",
      "|    total_timesteps      | 4448256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030454523 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.251        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.9         |\n",
      "|    n_updates            | 21710        |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | -4.6197114   |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2173         |\n",
      "|    time_elapsed         | 40327        |\n",
      "|    total_timesteps      | 4450304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011411147 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 163          |\n",
      "|    n_updates            | 21720        |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    reward               | 0.6692301    |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 211          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9570332.75\n",
      "total_reward: 8570332.75\n",
      "total_cost: 265957.20\n",
      "total_trades: 61525\n",
      "Sharpe: 1.023\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2174          |\n",
      "|    time_elapsed         | 40345         |\n",
      "|    total_timesteps      | 4452352       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095002714 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.523         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 124           |\n",
      "|    n_updates            | 21730         |\n",
      "|    policy_gradient_loss | -0.00183      |\n",
      "|    reward               | 0.05435065    |\n",
      "|    std                  | 19.6          |\n",
      "|    value_loss           | 321           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2175          |\n",
      "|    time_elapsed         | 40364         |\n",
      "|    total_timesteps      | 4454400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00083209143 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.385         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 97            |\n",
      "|    n_updates            | 21740         |\n",
      "|    policy_gradient_loss | -0.00218      |\n",
      "|    reward               | 0.055942703   |\n",
      "|    std                  | 19.6          |\n",
      "|    value_loss           | 423           |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2176       |\n",
      "|    time_elapsed         | 40383      |\n",
      "|    total_timesteps      | 4456448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01082428 |\n",
      "|    clip_fraction        | 0.0974     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -127       |\n",
      "|    explained_variance   | 0.0456     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.5       |\n",
      "|    n_updates            | 21750      |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    reward               | -0.992119  |\n",
      "|    std                  | 19.7       |\n",
      "|    value_loss           | 45.5       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2177          |\n",
      "|    time_elapsed         | 40401         |\n",
      "|    total_timesteps      | 4458496       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00085041765 |\n",
      "|    clip_fraction        | 0.000732      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.542         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 107           |\n",
      "|    n_updates            | 21760         |\n",
      "|    policy_gradient_loss | -0.00172      |\n",
      "|    reward               | 1.262198      |\n",
      "|    std                  | 19.7          |\n",
      "|    value_loss           | 263           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2178         |\n",
      "|    time_elapsed         | 40419        |\n",
      "|    total_timesteps      | 4460544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002933516 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 198          |\n",
      "|    n_updates            | 21770        |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    reward               | 5.9566336    |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 322          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2179         |\n",
      "|    time_elapsed         | 40439        |\n",
      "|    total_timesteps      | 4462592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013799006 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | -0.105       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49           |\n",
      "|    n_updates            | 21780        |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    reward               | 1.419237     |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 189          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2180         |\n",
      "|    time_elapsed         | 40458        |\n",
      "|    total_timesteps      | 4464640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014277278 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | -0.0179      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.8         |\n",
      "|    n_updates            | 21790        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    reward               | 1.319052     |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 270          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2181        |\n",
      "|    time_elapsed         | 40476       |\n",
      "|    total_timesteps      | 4466688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002971524 |\n",
      "|    clip_fraction        | 0.00273     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 21800       |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    reward               | 1.8417716   |\n",
      "|    std                  | 19.8        |\n",
      "|    value_loss           | 271         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2182        |\n",
      "|    time_elapsed         | 40495       |\n",
      "|    total_timesteps      | 4468736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004441551 |\n",
      "|    clip_fraction        | 0.00601     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.2        |\n",
      "|    n_updates            | 21810       |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    reward               | 1.8870608   |\n",
      "|    std                  | 19.9        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2183         |\n",
      "|    time_elapsed         | 40513        |\n",
      "|    total_timesteps      | 4470784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027847595 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.372        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90.8         |\n",
      "|    n_updates            | 21820        |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    reward               | -0.28749874  |\n",
      "|    std                  | 19.9         |\n",
      "|    value_loss           | 138          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2184         |\n",
      "|    time_elapsed         | 40533        |\n",
      "|    total_timesteps      | 4472832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019925993 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 112          |\n",
      "|    n_updates            | 21830        |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    reward               | -0.6356694   |\n",
      "|    std                  | 19.9         |\n",
      "|    value_loss           | 250          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2185        |\n",
      "|    time_elapsed         | 40552       |\n",
      "|    total_timesteps      | 4474880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001950491 |\n",
      "|    clip_fraction        | 0.000928    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 21840       |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    reward               | 8.585195    |\n",
      "|    std                  | 19.9        |\n",
      "|    value_loss           | 283         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2186        |\n",
      "|    time_elapsed         | 40571       |\n",
      "|    total_timesteps      | 4476928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008995252 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 21850       |\n",
      "|    policy_gradient_loss | -0.0093     |\n",
      "|    reward               | -0.68395555 |\n",
      "|    std                  | 20          |\n",
      "|    value_loss           | 53.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2187         |\n",
      "|    time_elapsed         | 40589        |\n",
      "|    total_timesteps      | 4478976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015039054 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.38         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 196          |\n",
      "|    n_updates            | 21860        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    reward               | -0.768071    |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 212          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2188        |\n",
      "|    time_elapsed         | 40608       |\n",
      "|    total_timesteps      | 4481024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002459345 |\n",
      "|    clip_fraction        | 0.00391     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.1        |\n",
      "|    n_updates            | 21870       |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    reward               | -3.8930638  |\n",
      "|    std                  | 20          |\n",
      "|    value_loss           | 279         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9326127.60\n",
      "total_reward: 8326127.60\n",
      "total_cost: 253614.57\n",
      "total_trades: 61253\n",
      "Sharpe: 1.060\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2189         |\n",
      "|    time_elapsed         | 40627        |\n",
      "|    total_timesteps      | 4483072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004541826 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.291        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82.1         |\n",
      "|    n_updates            | 21880        |\n",
      "|    policy_gradient_loss | -0.000532    |\n",
      "|    reward               | -0.94452614  |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 165          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2190        |\n",
      "|    time_elapsed         | 40646       |\n",
      "|    total_timesteps      | 4485120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004648874 |\n",
      "|    clip_fraction        | 0.00942     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.6        |\n",
      "|    n_updates            | 21890       |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    reward               | -4.189751   |\n",
      "|    std                  | 20.1        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2191         |\n",
      "|    time_elapsed         | 40665        |\n",
      "|    total_timesteps      | 4487168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013830645 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 193          |\n",
      "|    n_updates            | 21900        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | -2.3781724   |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 324          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2192         |\n",
      "|    time_elapsed         | 40683        |\n",
      "|    total_timesteps      | 4489216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007264038 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 21910        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | 1.0147556    |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 336          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2193        |\n",
      "|    time_elapsed         | 40703       |\n",
      "|    total_timesteps      | 4491264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010477437 |\n",
      "|    clip_fraction        | 0.0781      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 21920       |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    reward               | 1.4525545   |\n",
      "|    std                  | 20.2        |\n",
      "|    value_loss           | 52.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2194         |\n",
      "|    time_elapsed         | 40721        |\n",
      "|    total_timesteps      | 4493312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009375898 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 21930        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | 2.1897762    |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 341          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2195          |\n",
      "|    time_elapsed         | 40740         |\n",
      "|    total_timesteps      | 4495360       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011808466 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.296         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 404           |\n",
      "|    n_updates            | 21940         |\n",
      "|    policy_gradient_loss | -0.000925     |\n",
      "|    reward               | 2.933215      |\n",
      "|    std                  | 20.2          |\n",
      "|    value_loss           | 590           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2196         |\n",
      "|    time_elapsed         | 40760        |\n",
      "|    total_timesteps      | 4497408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031571006 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.247        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.4         |\n",
      "|    n_updates            | 21950        |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    reward               | 3.1995945    |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2197         |\n",
      "|    time_elapsed         | 40779        |\n",
      "|    total_timesteps      | 4499456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012295342 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 112          |\n",
      "|    n_updates            | 21960        |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    reward               | -3.6160522   |\n",
      "|    std                  | 20.3         |\n",
      "|    value_loss           | 237          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2198        |\n",
      "|    time_elapsed         | 40797       |\n",
      "|    total_timesteps      | 4501504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001137414 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 21970       |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    reward               | 7.463377    |\n",
      "|    std                  | 20.3        |\n",
      "|    value_loss           | 258         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2199         |\n",
      "|    time_elapsed         | 40817        |\n",
      "|    total_timesteps      | 4503552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005091907 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 115          |\n",
      "|    n_updates            | 21980        |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    reward               | 1.3467335    |\n",
      "|    std                  | 20.3         |\n",
      "|    value_loss           | 289          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2200       |\n",
      "|    time_elapsed         | 40836      |\n",
      "|    total_timesteps      | 4505600    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00977274 |\n",
      "|    clip_fraction        | 0.0732     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -128       |\n",
      "|    explained_variance   | 0.36       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.1       |\n",
      "|    n_updates            | 21990      |\n",
      "|    policy_gradient_loss | -0.00741   |\n",
      "|    reward               | -2.4954314 |\n",
      "|    std                  | 20.4       |\n",
      "|    value_loss           | 38.2       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2201          |\n",
      "|    time_elapsed         | 40854         |\n",
      "|    total_timesteps      | 4507648       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026543852 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.189         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 121           |\n",
      "|    n_updates            | 22000         |\n",
      "|    policy_gradient_loss | -0.000696     |\n",
      "|    reward               | -0.88346654   |\n",
      "|    std                  | 20.4          |\n",
      "|    value_loss           | 345           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2202          |\n",
      "|    time_elapsed         | 40874         |\n",
      "|    total_timesteps      | 4509696       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048918056 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.226         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 155           |\n",
      "|    n_updates            | 22010         |\n",
      "|    policy_gradient_loss | -0.00224      |\n",
      "|    reward               | 3.2002435     |\n",
      "|    std                  | 20.4          |\n",
      "|    value_loss           | 334           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8729135.85\n",
      "total_reward: 7729135.85\n",
      "total_cost: 269212.14\n",
      "total_trades: 61428\n",
      "Sharpe: 1.002\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2203        |\n",
      "|    time_elapsed         | 40893       |\n",
      "|    total_timesteps      | 4511744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010150737 |\n",
      "|    clip_fraction        | 0.0609      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.5        |\n",
      "|    n_updates            | 22020       |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    reward               | 0.6982197   |\n",
      "|    std                  | 20.4        |\n",
      "|    value_loss           | 61.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2204          |\n",
      "|    time_elapsed         | 40913         |\n",
      "|    total_timesteps      | 4513792       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089499546 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.0675        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 148           |\n",
      "|    n_updates            | 22030         |\n",
      "|    policy_gradient_loss | -0.00378      |\n",
      "|    reward               | -1.07724      |\n",
      "|    std                  | 20.4          |\n",
      "|    value_loss           | 288           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2205          |\n",
      "|    time_elapsed         | 40932         |\n",
      "|    total_timesteps      | 4515840       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00049840583 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.693         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 140           |\n",
      "|    n_updates            | 22040         |\n",
      "|    policy_gradient_loss | -0.00221      |\n",
      "|    reward               | 2.7614675     |\n",
      "|    std                  | 20.4          |\n",
      "|    value_loss           | 318           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2206          |\n",
      "|    time_elapsed         | 40951         |\n",
      "|    total_timesteps      | 4517888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037628837 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.21          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 86.6          |\n",
      "|    n_updates            | 22050         |\n",
      "|    policy_gradient_loss | -0.00018      |\n",
      "|    reward               | 0.792547      |\n",
      "|    std                  | 20.4          |\n",
      "|    value_loss           | 306           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2207         |\n",
      "|    time_elapsed         | 40970        |\n",
      "|    total_timesteps      | 4519936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048039407 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.6         |\n",
      "|    n_updates            | 22060        |\n",
      "|    policy_gradient_loss | -0.00741     |\n",
      "|    reward               | -1.8181185   |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2208         |\n",
      "|    time_elapsed         | 40988        |\n",
      "|    total_timesteps      | 4521984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007525255 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 105          |\n",
      "|    n_updates            | 22070        |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    reward               | 1.5098236    |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 290          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2209         |\n",
      "|    time_elapsed         | 41007        |\n",
      "|    total_timesteps      | 4524032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025685867 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 142          |\n",
      "|    n_updates            | 22080        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    reward               | 2.9034007    |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 337          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2210        |\n",
      "|    time_elapsed         | 41025       |\n",
      "|    total_timesteps      | 4526080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008069994 |\n",
      "|    clip_fraction        | 0.0483      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 22090       |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    reward               | 2.1402178   |\n",
      "|    std                  | 20.5        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2211          |\n",
      "|    time_elapsed         | 41044         |\n",
      "|    total_timesteps      | 4528128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033207497 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.775         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 94.4          |\n",
      "|    n_updates            | 22100         |\n",
      "|    policy_gradient_loss | -0.0012       |\n",
      "|    reward               | 0.32691193    |\n",
      "|    std                  | 20.5          |\n",
      "|    value_loss           | 246           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2212         |\n",
      "|    time_elapsed         | 41062        |\n",
      "|    total_timesteps      | 4530176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034371936 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 115          |\n",
      "|    n_updates            | 22110        |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    reward               | 10.064937    |\n",
      "|    std                  | 20.6         |\n",
      "|    value_loss           | 202          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2213        |\n",
      "|    time_elapsed         | 41081       |\n",
      "|    total_timesteps      | 4532224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007568697 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.7        |\n",
      "|    n_updates            | 22120       |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    reward               | -4.204455   |\n",
      "|    std                  | 20.7        |\n",
      "|    value_loss           | 93.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2214         |\n",
      "|    time_elapsed         | 41100        |\n",
      "|    total_timesteps      | 4534272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050320784 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.6         |\n",
      "|    n_updates            | 22130        |\n",
      "|    policy_gradient_loss | -0.00674     |\n",
      "|    reward               | -1.6981963   |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 153          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2215         |\n",
      "|    time_elapsed         | 41119        |\n",
      "|    total_timesteps      | 4536320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008054737 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 120          |\n",
      "|    n_updates            | 22140        |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    reward               | -0.97689086  |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 295          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2216          |\n",
      "|    time_elapsed         | 41139         |\n",
      "|    total_timesteps      | 4538368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090555806 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.174         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 114           |\n",
      "|    n_updates            | 22150         |\n",
      "|    policy_gradient_loss | -0.00256      |\n",
      "|    reward               | 0.6085475     |\n",
      "|    std                  | 20.7          |\n",
      "|    value_loss           | 339           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9468662.83\n",
      "total_reward: 8468662.83\n",
      "total_cost: 299788.45\n",
      "total_trades: 63538\n",
      "Sharpe: 1.048\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2217        |\n",
      "|    time_elapsed         | 41158       |\n",
      "|    total_timesteps      | 4540416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007508329 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 22160       |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    reward               | 1.6846374   |\n",
      "|    std                  | 20.8        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2218          |\n",
      "|    time_elapsed         | 41176         |\n",
      "|    total_timesteps      | 4542464       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041871515 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.755         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 93.1          |\n",
      "|    n_updates            | 22170         |\n",
      "|    policy_gradient_loss | -0.00188      |\n",
      "|    reward               | 0.7780211     |\n",
      "|    std                  | 20.8          |\n",
      "|    value_loss           | 287           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2219         |\n",
      "|    time_elapsed         | 41195        |\n",
      "|    total_timesteps      | 4544512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.477955e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 149          |\n",
      "|    n_updates            | 22180        |\n",
      "|    policy_gradient_loss | -0.000329    |\n",
      "|    reward               | -0.9303979   |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 411          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2220         |\n",
      "|    time_elapsed         | 41213        |\n",
      "|    total_timesteps      | 4546560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048124404 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.9         |\n",
      "|    n_updates            | 22190        |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    reward               | -4.004103    |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2221          |\n",
      "|    time_elapsed         | 41231         |\n",
      "|    total_timesteps      | 4548608       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00078058185 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.704         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 95.4          |\n",
      "|    n_updates            | 22200         |\n",
      "|    policy_gradient_loss | -0.00215      |\n",
      "|    reward               | -0.13353674   |\n",
      "|    std                  | 20.9          |\n",
      "|    value_loss           | 174           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2222          |\n",
      "|    time_elapsed         | 41250         |\n",
      "|    total_timesteps      | 4550656       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022923262 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.707         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 140           |\n",
      "|    n_updates            | 22210         |\n",
      "|    policy_gradient_loss | -0.00125      |\n",
      "|    reward               | 7.1809363     |\n",
      "|    std                  | 20.9          |\n",
      "|    value_loss           | 347           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2223          |\n",
      "|    time_elapsed         | 41269         |\n",
      "|    total_timesteps      | 4552704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019468385 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.691         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 127           |\n",
      "|    n_updates            | 22220         |\n",
      "|    policy_gradient_loss | -0.000889     |\n",
      "|    reward               | 0.37225896    |\n",
      "|    std                  | 20.9          |\n",
      "|    value_loss           | 225           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2224        |\n",
      "|    time_elapsed         | 41288       |\n",
      "|    total_timesteps      | 4554752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009991465 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 22230       |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    reward               | -4.24064    |\n",
      "|    std                  | 20.9        |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2225         |\n",
      "|    time_elapsed         | 41307        |\n",
      "|    total_timesteps      | 4556800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025392692 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.7         |\n",
      "|    n_updates            | 22240        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    reward               | -0.95659846  |\n",
      "|    std                  | 21           |\n",
      "|    value_loss           | 153          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2226         |\n",
      "|    time_elapsed         | 41324        |\n",
      "|    total_timesteps      | 4558848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009722016 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.606        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 194          |\n",
      "|    n_updates            | 22250        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | 0.40063283   |\n",
      "|    std                  | 21           |\n",
      "|    value_loss           | 353          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2227        |\n",
      "|    time_elapsed         | 41343       |\n",
      "|    total_timesteps      | 4560896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006844001 |\n",
      "|    clip_fraction        | 0.0494      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 22260       |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    reward               | 7.4079185   |\n",
      "|    std                  | 21          |\n",
      "|    value_loss           | 55.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2228         |\n",
      "|    time_elapsed         | 41361        |\n",
      "|    total_timesteps      | 4562944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006332704 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 139          |\n",
      "|    n_updates            | 22270        |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    reward               | 0.25661328   |\n",
      "|    std                  | 21           |\n",
      "|    value_loss           | 255          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2229          |\n",
      "|    time_elapsed         | 41379         |\n",
      "|    total_timesteps      | 4564992       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00057248346 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.756         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 158           |\n",
      "|    n_updates            | 22280         |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    reward               | 6.2717896     |\n",
      "|    std                  | 21.1          |\n",
      "|    value_loss           | 290           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2230         |\n",
      "|    time_elapsed         | 41398        |\n",
      "|    total_timesteps      | 4567040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006184502 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.824        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 94.5         |\n",
      "|    n_updates            | 22290        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    reward               | 3.5735874    |\n",
      "|    std                  | 21.1         |\n",
      "|    value_loss           | 188          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8433355.39\n",
      "total_reward: 7433355.39\n",
      "total_cost: 295554.05\n",
      "total_trades: 63437\n",
      "Sharpe: 0.965\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2231       |\n",
      "|    time_elapsed         | 41416      |\n",
      "|    total_timesteps      | 4569088    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00434126 |\n",
      "|    clip_fraction        | 0.0125     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -129       |\n",
      "|    explained_variance   | 0.712      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.7       |\n",
      "|    n_updates            | 22300      |\n",
      "|    policy_gradient_loss | -0.00515   |\n",
      "|    reward               | 2.094763   |\n",
      "|    std                  | 21.1       |\n",
      "|    value_loss           | 151        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2232         |\n",
      "|    time_elapsed         | 41434        |\n",
      "|    total_timesteps      | 4571136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017963727 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 172          |\n",
      "|    n_updates            | 22310        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    reward               | -0.62606007  |\n",
      "|    std                  | 21.1         |\n",
      "|    value_loss           | 283          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2233         |\n",
      "|    time_elapsed         | 41453        |\n",
      "|    total_timesteps      | 4573184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004135019 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 88.2         |\n",
      "|    n_updates            | 22320        |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    reward               | 6.046823     |\n",
      "|    std                  | 21.1         |\n",
      "|    value_loss           | 334          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2234        |\n",
      "|    time_elapsed         | 41471       |\n",
      "|    total_timesteps      | 4575232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010025671 |\n",
      "|    clip_fraction        | 0.0504      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 22330       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.40202686  |\n",
      "|    std                  | 21.1        |\n",
      "|    value_loss           | 43.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2235          |\n",
      "|    time_elapsed         | 41489         |\n",
      "|    total_timesteps      | 4577280       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092157105 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.752         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 104           |\n",
      "|    n_updates            | 22340         |\n",
      "|    policy_gradient_loss | -0.00231      |\n",
      "|    reward               | -2.8650918    |\n",
      "|    std                  | 21.1          |\n",
      "|    value_loss           | 257           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2236        |\n",
      "|    time_elapsed         | 41507       |\n",
      "|    total_timesteps      | 4579328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001979746 |\n",
      "|    clip_fraction        | 0.000342    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 22350       |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    reward               | -15.921649  |\n",
      "|    std                  | 21.2        |\n",
      "|    value_loss           | 247         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2237         |\n",
      "|    time_elapsed         | 41526        |\n",
      "|    total_timesteps      | 4581376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015882675 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.5         |\n",
      "|    n_updates            | 22360        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    reward               | -1.0389618   |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2238         |\n",
      "|    time_elapsed         | 41545        |\n",
      "|    total_timesteps      | 4583424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056715403 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.762        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 85.6         |\n",
      "|    n_updates            | 22370        |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    reward               | 0.20834246   |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 160          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2239         |\n",
      "|    time_elapsed         | 41564        |\n",
      "|    total_timesteps      | 4585472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.174496e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 209          |\n",
      "|    n_updates            | 22380        |\n",
      "|    policy_gradient_loss | -0.000554    |\n",
      "|    reward               | 2.3909092    |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 741          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2240          |\n",
      "|    time_elapsed         | 41582         |\n",
      "|    total_timesteps      | 4587520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070028997 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.553         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 197           |\n",
      "|    n_updates            | 22390         |\n",
      "|    policy_gradient_loss | -0.00243      |\n",
      "|    reward               | 0.028482102   |\n",
      "|    std                  | 21.3          |\n",
      "|    value_loss           | 366           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2241        |\n",
      "|    time_elapsed         | 41601       |\n",
      "|    total_timesteps      | 4589568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009233868 |\n",
      "|    clip_fraction        | 0.0537      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 22400       |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    reward               | 0.43266296  |\n",
      "|    std                  | 21.4        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2242         |\n",
      "|    time_elapsed         | 41619        |\n",
      "|    total_timesteps      | 4591616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009445455 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.716        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 189          |\n",
      "|    n_updates            | 22410        |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    reward               | 0.78924125   |\n",
      "|    std                  | 21.4         |\n",
      "|    value_loss           | 253          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2243        |\n",
      "|    time_elapsed         | 41637       |\n",
      "|    total_timesteps      | 4593664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000482461 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 22420       |\n",
      "|    policy_gradient_loss | -0.00129    |\n",
      "|    reward               | -7.724762   |\n",
      "|    std                  | 21.4        |\n",
      "|    value_loss           | 342         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2244         |\n",
      "|    time_elapsed         | 41656        |\n",
      "|    total_timesteps      | 4595712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037370534 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.1         |\n",
      "|    n_updates            | 22430        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | -0.91048545  |\n",
      "|    std                  | 21.4         |\n",
      "|    value_loss           | 88.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11527088.19\n",
      "total_reward: 10527088.19\n",
      "total_cost: 296328.25\n",
      "total_trades: 63425\n",
      "Sharpe: 1.117\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2245        |\n",
      "|    time_elapsed         | 41675       |\n",
      "|    total_timesteps      | 4597760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002365945 |\n",
      "|    clip_fraction        | 0.00156     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.7        |\n",
      "|    n_updates            | 22440       |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    reward               | -0.43632603 |\n",
      "|    std                  | 21.5        |\n",
      "|    value_loss           | 282         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2246         |\n",
      "|    time_elapsed         | 41693        |\n",
      "|    total_timesteps      | 4599808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020274897 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 561          |\n",
      "|    n_updates            | 22450        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | 13.048841    |\n",
      "|    std                  | 21.5         |\n",
      "|    value_loss           | 620          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2247          |\n",
      "|    time_elapsed         | 41711         |\n",
      "|    total_timesteps      | 4601856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066988904 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.673         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 93.4          |\n",
      "|    n_updates            | 22460         |\n",
      "|    policy_gradient_loss | -0.00152      |\n",
      "|    reward               | 2.485173      |\n",
      "|    std                  | 21.5          |\n",
      "|    value_loss           | 299           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2248        |\n",
      "|    time_elapsed         | 41731       |\n",
      "|    total_timesteps      | 4603904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005840984 |\n",
      "|    clip_fraction        | 0.0168      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 22470       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | 0.3745926   |\n",
      "|    std                  | 21.5        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2249         |\n",
      "|    time_elapsed         | 41749        |\n",
      "|    total_timesteps      | 4605952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007510707 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 183          |\n",
      "|    n_updates            | 22480        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | 0.38264555   |\n",
      "|    std                  | 21.5         |\n",
      "|    value_loss           | 482          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2250       |\n",
      "|    time_elapsed         | 41769      |\n",
      "|    total_timesteps      | 4608000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00046453 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -129       |\n",
      "|    explained_variance   | 0.633      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 212        |\n",
      "|    n_updates            | 22490      |\n",
      "|    policy_gradient_loss | -0.0019    |\n",
      "|    reward               | 5.811565   |\n",
      "|    std                  | 21.6       |\n",
      "|    value_loss           | 372        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2251        |\n",
      "|    time_elapsed         | 41788       |\n",
      "|    total_timesteps      | 4610048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006268541 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 22500       |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    reward               | -4.8287387  |\n",
      "|    std                  | 21.6        |\n",
      "|    value_loss           | 58.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2252        |\n",
      "|    time_elapsed         | 41806       |\n",
      "|    total_timesteps      | 4612096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005061402 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.5        |\n",
      "|    n_updates            | 22510       |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    reward               | -7.897082   |\n",
      "|    std                  | 21.6        |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2253          |\n",
      "|    time_elapsed         | 41824         |\n",
      "|    total_timesteps      | 4614144       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050874706 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.679         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 119           |\n",
      "|    n_updates            | 22520         |\n",
      "|    policy_gradient_loss | -0.00199      |\n",
      "|    reward               | -1.7151216    |\n",
      "|    std                  | 21.7          |\n",
      "|    value_loss           | 299           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2254         |\n",
      "|    time_elapsed         | 41843        |\n",
      "|    total_timesteps      | 4616192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017453285 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75           |\n",
      "|    n_updates            | 22530        |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    reward               | 0.35235903   |\n",
      "|    std                  | 21.7         |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2255        |\n",
      "|    time_elapsed         | 41861       |\n",
      "|    total_timesteps      | 4618240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005123663 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.0224      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.4        |\n",
      "|    n_updates            | 22540       |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    reward               | 1.4684688   |\n",
      "|    std                  | 21.7        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2256          |\n",
      "|    time_elapsed         | 41879         |\n",
      "|    total_timesteps      | 4620288       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035273054 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.486         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 101           |\n",
      "|    n_updates            | 22550         |\n",
      "|    policy_gradient_loss | -0.0015       |\n",
      "|    reward               | -2.2762861    |\n",
      "|    std                  | 21.7          |\n",
      "|    value_loss           | 270           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2257        |\n",
      "|    time_elapsed         | 41898       |\n",
      "|    total_timesteps      | 4622336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001619525 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87          |\n",
      "|    n_updates            | 22560       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    reward               | -5.868248   |\n",
      "|    std                  | 21.8        |\n",
      "|    value_loss           | 258         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2258         |\n",
      "|    time_elapsed         | 41917        |\n",
      "|    total_timesteps      | 4624384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093637025 |\n",
      "|    clip_fraction        | 0.0729       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.8         |\n",
      "|    n_updates            | 22570        |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    reward               | -1.1569947   |\n",
      "|    std                  | 21.8         |\n",
      "|    value_loss           | 41.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8539570.00\n",
      "total_reward: 7539570.00\n",
      "total_cost: 334306.57\n",
      "total_trades: 65365\n",
      "Sharpe: 0.966\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2259          |\n",
      "|    time_elapsed         | 41936         |\n",
      "|    total_timesteps      | 4626432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00080351776 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.703         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 77.2          |\n",
      "|    n_updates            | 22580         |\n",
      "|    policy_gradient_loss | -0.00158      |\n",
      "|    reward               | 0.45760027    |\n",
      "|    std                  | 21.8          |\n",
      "|    value_loss           | 218           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2260          |\n",
      "|    time_elapsed         | 41955         |\n",
      "|    total_timesteps      | 4628480       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053351175 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.633         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 222           |\n",
      "|    n_updates            | 22590         |\n",
      "|    policy_gradient_loss | -0.0016       |\n",
      "|    reward               | -3.044323     |\n",
      "|    std                  | 21.8          |\n",
      "|    value_loss           | 417           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2261         |\n",
      "|    time_elapsed         | 41973        |\n",
      "|    total_timesteps      | 4630528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017248276 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.9         |\n",
      "|    n_updates            | 22600        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    reward               | -1.4451892   |\n",
      "|    std                  | 21.9         |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2262         |\n",
      "|    time_elapsed         | 41992        |\n",
      "|    total_timesteps      | 4632576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058033713 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.8         |\n",
      "|    n_updates            | 22610        |\n",
      "|    policy_gradient_loss | -0.00856     |\n",
      "|    reward               | 1.2656487    |\n",
      "|    std                  | 22           |\n",
      "|    value_loss           | 193          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2263         |\n",
      "|    time_elapsed         | 42011        |\n",
      "|    total_timesteps      | 4634624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013823537 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.5         |\n",
      "|    n_updates            | 22620        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    reward               | -0.3925837   |\n",
      "|    std                  | 22           |\n",
      "|    value_loss           | 273          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2264          |\n",
      "|    time_elapsed         | 42031         |\n",
      "|    total_timesteps      | 4636672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036310402 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.657         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 119           |\n",
      "|    n_updates            | 22630         |\n",
      "|    policy_gradient_loss | -0.00126      |\n",
      "|    reward               | -1.2608658    |\n",
      "|    std                  | 22            |\n",
      "|    value_loss           | 298           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2265         |\n",
      "|    time_elapsed         | 42049        |\n",
      "|    total_timesteps      | 4638720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077494103 |\n",
      "|    clip_fraction        | 0.0296       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 22640        |\n",
      "|    policy_gradient_loss | -0.00809     |\n",
      "|    reward               | 0.9387917    |\n",
      "|    std                  | 22           |\n",
      "|    value_loss           | 36           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2266         |\n",
      "|    time_elapsed         | 42067        |\n",
      "|    total_timesteps      | 4640768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011828302 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.763        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.7         |\n",
      "|    n_updates            | 22650        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | -0.1984084   |\n",
      "|    std                  | 22           |\n",
      "|    value_loss           | 261          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2267        |\n",
      "|    time_elapsed         | 42085       |\n",
      "|    total_timesteps      | 4642816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002630955 |\n",
      "|    clip_fraction        | 0.00142     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 22660       |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    reward               | 2.0510807   |\n",
      "|    std                  | 22.1        |\n",
      "|    value_loss           | 311         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2268         |\n",
      "|    time_elapsed         | 42104        |\n",
      "|    total_timesteps      | 4644864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027609323 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.742        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.1         |\n",
      "|    n_updates            | 22670        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | -0.24262479  |\n",
      "|    std                  | 22.2         |\n",
      "|    value_loss           | 99.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2269        |\n",
      "|    time_elapsed         | 42122       |\n",
      "|    total_timesteps      | 4646912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002927157 |\n",
      "|    clip_fraction        | 0.00273     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.4        |\n",
      "|    n_updates            | 22680       |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | 1.1316354   |\n",
      "|    std                  | 22.2        |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2270         |\n",
      "|    time_elapsed         | 42140        |\n",
      "|    total_timesteps      | 4648960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016277249 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 193          |\n",
      "|    n_updates            | 22690        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | -16.663336   |\n",
      "|    std                  | 22.2         |\n",
      "|    value_loss           | 304          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2271         |\n",
      "|    time_elapsed         | 42159        |\n",
      "|    total_timesteps      | 4651008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004509683 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | -0.272       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 120          |\n",
      "|    n_updates            | 22700        |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    reward               | -2.0295763   |\n",
      "|    std                  | 22.2         |\n",
      "|    value_loss           | 315          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2272        |\n",
      "|    time_elapsed         | 42178       |\n",
      "|    total_timesteps      | 4653056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006837895 |\n",
      "|    clip_fraction        | 0.0249      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66          |\n",
      "|    n_updates            | 22710       |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    reward               | -2.6759315  |\n",
      "|    std                  | 22.3        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9012284.80\n",
      "total_reward: 8012284.80\n",
      "total_cost: 298652.02\n",
      "total_trades: 63759\n",
      "Sharpe: 0.997\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2273         |\n",
      "|    time_elapsed         | 42197        |\n",
      "|    total_timesteps      | 4655104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009863486 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 219          |\n",
      "|    n_updates            | 22720        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    reward               | -0.91823125  |\n",
      "|    std                  | 22.3         |\n",
      "|    value_loss           | 376          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2274          |\n",
      "|    time_elapsed         | 42215         |\n",
      "|    total_timesteps      | 4657152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018262249 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.37          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 259           |\n",
      "|    n_updates            | 22730         |\n",
      "|    policy_gradient_loss | -0.00107      |\n",
      "|    reward               | 0.46753064    |\n",
      "|    std                  | 22.4          |\n",
      "|    value_loss           | 440           |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2275       |\n",
      "|    time_elapsed         | 42234      |\n",
      "|    total_timesteps      | 4659200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0038367  |\n",
      "|    clip_fraction        | 0.00459    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -131       |\n",
      "|    explained_variance   | 0.514      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.7       |\n",
      "|    n_updates            | 22740      |\n",
      "|    policy_gradient_loss | -0.00484   |\n",
      "|    reward               | -0.7780447 |\n",
      "|    std                  | 22.4       |\n",
      "|    value_loss           | 56.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2276        |\n",
      "|    time_elapsed         | 42252       |\n",
      "|    total_timesteps      | 4661248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004832031 |\n",
      "|    clip_fraction        | 0.0083      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 22750       |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    reward               | 1.2424239   |\n",
      "|    std                  | 22.5        |\n",
      "|    value_loss           | 261         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2277        |\n",
      "|    time_elapsed         | 42271       |\n",
      "|    total_timesteps      | 4663296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003833514 |\n",
      "|    clip_fraction        | 0.00547     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 172         |\n",
      "|    n_updates            | 22760       |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | 10.975989   |\n",
      "|    std                  | 22.5        |\n",
      "|    value_loss           | 354         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2278       |\n",
      "|    time_elapsed         | 42291      |\n",
      "|    total_timesteps      | 4665344    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00637595 |\n",
      "|    clip_fraction        | 0.0183     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -131       |\n",
      "|    explained_variance   | 0.445      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 94.1       |\n",
      "|    n_updates            | 22770      |\n",
      "|    policy_gradient_loss | -0.00739   |\n",
      "|    reward               | 0.46103764 |\n",
      "|    std                  | 22.6       |\n",
      "|    value_loss           | 201        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2279       |\n",
      "|    time_elapsed         | 42309      |\n",
      "|    total_timesteps      | 4667392    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00520533 |\n",
      "|    clip_fraction        | 0.00928    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -131       |\n",
      "|    explained_variance   | 0.336      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.6       |\n",
      "|    n_updates            | 22780      |\n",
      "|    policy_gradient_loss | -0.00666   |\n",
      "|    reward               | 0.6327287  |\n",
      "|    std                  | 22.7       |\n",
      "|    value_loss           | 144        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2280         |\n",
      "|    time_elapsed         | 42328        |\n",
      "|    total_timesteps      | 4669440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029822052 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 157          |\n",
      "|    n_updates            | 22790        |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    reward               | 0.0023330704 |\n",
      "|    std                  | 22.7         |\n",
      "|    value_loss           | 226          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2281         |\n",
      "|    time_elapsed         | 42347        |\n",
      "|    total_timesteps      | 4671488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014646843 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 208          |\n",
      "|    n_updates            | 22800        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | -5.6577888   |\n",
      "|    std                  | 22.7         |\n",
      "|    value_loss           | 281          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2282         |\n",
      "|    time_elapsed         | 42366        |\n",
      "|    total_timesteps      | 4673536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065870974 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.856        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.1         |\n",
      "|    n_updates            | 22810        |\n",
      "|    policy_gradient_loss | -0.00818     |\n",
      "|    reward               | -0.12158649  |\n",
      "|    std                  | 22.8         |\n",
      "|    value_loss           | 78.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2283          |\n",
      "|    time_elapsed         | 42385         |\n",
      "|    total_timesteps      | 4675584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047307293 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.51          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 131           |\n",
      "|    n_updates            | 22820         |\n",
      "|    policy_gradient_loss | -0.00152      |\n",
      "|    reward               | 0.42416355    |\n",
      "|    std                  | 22.8          |\n",
      "|    value_loss           | 395           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2284         |\n",
      "|    time_elapsed         | 42404        |\n",
      "|    total_timesteps      | 4677632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024611773 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 112          |\n",
      "|    n_updates            | 22830        |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | 3.6891139    |\n",
      "|    std                  | 22.9         |\n",
      "|    value_loss           | 216          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2285         |\n",
      "|    time_elapsed         | 42422        |\n",
      "|    total_timesteps      | 4679680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090529295 |\n",
      "|    clip_fraction        | 0.0516       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.3         |\n",
      "|    n_updates            | 22840        |\n",
      "|    policy_gradient_loss | -0.00888     |\n",
      "|    reward               | 2.8404791    |\n",
      "|    std                  | 23           |\n",
      "|    value_loss           | 90.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2286         |\n",
      "|    time_elapsed         | 42441        |\n",
      "|    total_timesteps      | 4681728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067585977 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.4         |\n",
      "|    n_updates            | 22850        |\n",
      "|    policy_gradient_loss | -0.00801     |\n",
      "|    reward               | 1.5373915    |\n",
      "|    std                  | 23           |\n",
      "|    value_loss           | 138          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8748274.07\n",
      "total_reward: 7748274.07\n",
      "total_cost: 324133.75\n",
      "total_trades: 65307\n",
      "Sharpe: 1.000\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2287          |\n",
      "|    time_elapsed         | 42460         |\n",
      "|    total_timesteps      | 4683776       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00085673813 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.197         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 230           |\n",
      "|    n_updates            | 22860         |\n",
      "|    policy_gradient_loss | -0.00206      |\n",
      "|    reward               | 0.08240656    |\n",
      "|    std                  | 23            |\n",
      "|    value_loss           | 376           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2288         |\n",
      "|    time_elapsed         | 42478        |\n",
      "|    total_timesteps      | 4685824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031764663 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.179        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 117          |\n",
      "|    n_updates            | 22870        |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    reward               | -1.5629133   |\n",
      "|    std                  | 23.1         |\n",
      "|    value_loss           | 311          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2289         |\n",
      "|    time_elapsed         | 42497        |\n",
      "|    total_timesteps      | 4687872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054856827 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.7         |\n",
      "|    n_updates            | 22880        |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | -0.71661514  |\n",
      "|    std                  | 23.2         |\n",
      "|    value_loss           | 61.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2290         |\n",
      "|    time_elapsed         | 42517        |\n",
      "|    total_timesteps      | 4689920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010010173 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 180          |\n",
      "|    n_updates            | 22890        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | 0.26870188   |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 240          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2291         |\n",
      "|    time_elapsed         | 42536        |\n",
      "|    total_timesteps      | 4691968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.432223e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.292        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 131          |\n",
      "|    n_updates            | 22900        |\n",
      "|    policy_gradient_loss | -0.000514    |\n",
      "|    reward               | -0.9458162   |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 310          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2292        |\n",
      "|    time_elapsed         | 42554       |\n",
      "|    total_timesteps      | 4694016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007118568 |\n",
      "|    clip_fraction        | 0.0275      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | -0.00961    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 22910       |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    reward               | -6.332358   |\n",
      "|    std                  | 23.4        |\n",
      "|    value_loss           | 60.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2293       |\n",
      "|    time_elapsed         | 42573      |\n",
      "|    total_timesteps      | 4696064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00265327 |\n",
      "|    clip_fraction        | 0.00767    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -132       |\n",
      "|    explained_variance   | 0.783      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 52.4       |\n",
      "|    n_updates            | 22920      |\n",
      "|    policy_gradient_loss | -0.00431   |\n",
      "|    reward               | -1.4938388 |\n",
      "|    std                  | 23.4       |\n",
      "|    value_loss           | 152        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2294         |\n",
      "|    time_elapsed         | 42591        |\n",
      "|    total_timesteps      | 4698112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006382208 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.8         |\n",
      "|    n_updates            | 22930        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | 11.928001    |\n",
      "|    std                  | 23.4         |\n",
      "|    value_loss           | 188          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2295          |\n",
      "|    time_elapsed         | 42610         |\n",
      "|    total_timesteps      | 4700160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073463045 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.655         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 110           |\n",
      "|    n_updates            | 22940         |\n",
      "|    policy_gradient_loss | -0.00183      |\n",
      "|    reward               | -1.8084189    |\n",
      "|    std                  | 23.4          |\n",
      "|    value_loss           | 199           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2296        |\n",
      "|    time_elapsed         | 42628       |\n",
      "|    total_timesteps      | 4702208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008118885 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.8        |\n",
      "|    n_updates            | 22950       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -6.2890096  |\n",
      "|    std                  | 23.5        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2297          |\n",
      "|    time_elapsed         | 42646         |\n",
      "|    total_timesteps      | 4704256       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045149552 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.703         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 80            |\n",
      "|    n_updates            | 22960         |\n",
      "|    policy_gradient_loss | -0.00158      |\n",
      "|    reward               | 0.18996873    |\n",
      "|    std                  | 23.5          |\n",
      "|    value_loss           | 162           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2298        |\n",
      "|    time_elapsed         | 42664       |\n",
      "|    total_timesteps      | 4706304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002802888 |\n",
      "|    clip_fraction        | 0.00186     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.6        |\n",
      "|    n_updates            | 22970       |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    reward               | 0.37226686  |\n",
      "|    std                  | 23.5        |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2299         |\n",
      "|    time_elapsed         | 42682        |\n",
      "|    total_timesteps      | 4708352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047825547 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31           |\n",
      "|    n_updates            | 22980        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | 1.2520244    |\n",
      "|    std                  | 23.6         |\n",
      "|    value_loss           | 71.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2300          |\n",
      "|    time_elapsed         | 42700         |\n",
      "|    total_timesteps      | 4710400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077344757 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.797         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 73.9          |\n",
      "|    n_updates            | 22990         |\n",
      "|    policy_gradient_loss | -0.00265      |\n",
      "|    reward               | -1.3203044    |\n",
      "|    std                  | 23.6          |\n",
      "|    value_loss           | 166           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2301         |\n",
      "|    time_elapsed         | 42719        |\n",
      "|    total_timesteps      | 4712448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014238571 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 123          |\n",
      "|    n_updates            | 23000        |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    reward               | -10.004117   |\n",
      "|    std                  | 23.6         |\n",
      "|    value_loss           | 195          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7789004.50\n",
      "total_reward: 6789004.50\n",
      "total_cost: 259181.46\n",
      "total_trades: 61331\n",
      "Sharpe: 0.930\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2302         |\n",
      "|    time_elapsed         | 42738        |\n",
      "|    total_timesteps      | 4714496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008177117 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 23010        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    reward               | 1.2447197    |\n",
      "|    std                  | 23.7         |\n",
      "|    value_loss           | 159          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2303        |\n",
      "|    time_elapsed         | 42756       |\n",
      "|    total_timesteps      | 4716544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003426705 |\n",
      "|    clip_fraction        | 0.00444     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 23020       |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    reward               | 3.480945    |\n",
      "|    std                  | 23.7        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2304         |\n",
      "|    time_elapsed         | 42776        |\n",
      "|    total_timesteps      | 4718592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018020812 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.1         |\n",
      "|    n_updates            | 23030        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | -0.4935692   |\n",
      "|    std                  | 23.8         |\n",
      "|    value_loss           | 156          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2305          |\n",
      "|    time_elapsed         | 42794         |\n",
      "|    total_timesteps      | 4720640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042936567 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.506         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 94.7          |\n",
      "|    n_updates            | 23040         |\n",
      "|    policy_gradient_loss | -0.00157      |\n",
      "|    reward               | 0.98913664    |\n",
      "|    std                  | 23.8          |\n",
      "|    value_loss           | 266           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2306        |\n",
      "|    time_elapsed         | 42812       |\n",
      "|    total_timesteps      | 4722688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005190354 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 23050       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | -3.9673395  |\n",
      "|    std                  | 23.9        |\n",
      "|    value_loss           | 69          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2307        |\n",
      "|    time_elapsed         | 42831       |\n",
      "|    total_timesteps      | 4724736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002490671 |\n",
      "|    clip_fraction        | 0.000879    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 23060       |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    reward               | -0.7909511  |\n",
      "|    std                  | 23.9        |\n",
      "|    value_loss           | 216         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2308          |\n",
      "|    time_elapsed         | 42850         |\n",
      "|    total_timesteps      | 4726784       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037804275 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.365         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 148           |\n",
      "|    n_updates            | 23070         |\n",
      "|    policy_gradient_loss | -0.00157      |\n",
      "|    reward               | 6.586178      |\n",
      "|    std                  | 23.9          |\n",
      "|    value_loss           | 222           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2309         |\n",
      "|    time_elapsed         | 42868        |\n",
      "|    total_timesteps      | 4728832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013579495 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.3         |\n",
      "|    n_updates            | 23080        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    reward               | -15.40252    |\n",
      "|    std                  | 23.9         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2310         |\n",
      "|    time_elapsed         | 42886        |\n",
      "|    total_timesteps      | 4730880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016902613 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 154          |\n",
      "|    n_updates            | 23090        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | 1.1110399    |\n",
      "|    std                  | 24           |\n",
      "|    value_loss           | 197          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2311          |\n",
      "|    time_elapsed         | 42904         |\n",
      "|    total_timesteps      | 4732928       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067400804 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.517         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 92.6          |\n",
      "|    n_updates            | 23100         |\n",
      "|    policy_gradient_loss | -0.0016       |\n",
      "|    reward               | -0.0711009    |\n",
      "|    std                  | 24            |\n",
      "|    value_loss           | 214           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2312         |\n",
      "|    time_elapsed         | 42922        |\n",
      "|    total_timesteps      | 4734976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016428569 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 88.9         |\n",
      "|    n_updates            | 23110        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    reward               | -1.0355154   |\n",
      "|    std                  | 24.1         |\n",
      "|    value_loss           | 203          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2313       |\n",
      "|    time_elapsed         | 42941      |\n",
      "|    total_timesteps      | 4737024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00843316 |\n",
      "|    clip_fraction        | 0.0556     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -133       |\n",
      "|    explained_variance   | 0.305      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.2       |\n",
      "|    n_updates            | 23120      |\n",
      "|    policy_gradient_loss | -0.00828   |\n",
      "|    reward               | 1.3714806  |\n",
      "|    std                  | 24.1       |\n",
      "|    value_loss           | 46.1       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2314          |\n",
      "|    time_elapsed         | 42960         |\n",
      "|    total_timesteps      | 4739072       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035177518 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.383         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 95.4          |\n",
      "|    n_updates            | 23130         |\n",
      "|    policy_gradient_loss | -0.0015       |\n",
      "|    reward               | -2.1148438    |\n",
      "|    std                  | 24.1          |\n",
      "|    value_loss           | 188           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2315        |\n",
      "|    time_elapsed         | 42979       |\n",
      "|    total_timesteps      | 4741120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001912962 |\n",
      "|    clip_fraction        | 0.000586    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.3        |\n",
      "|    n_updates            | 23140       |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    reward               | 1.8666419   |\n",
      "|    std                  | 24.2        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7056349.41\n",
      "total_reward: 6056349.41\n",
      "total_cost: 243602.70\n",
      "total_trades: 60272\n",
      "Sharpe: 0.894\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2316         |\n",
      "|    time_elapsed         | 42998        |\n",
      "|    total_timesteps      | 4743168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015366145 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.178        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60           |\n",
      "|    n_updates            | 23150        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | 2.8454065    |\n",
      "|    std                  | 24.2         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2317          |\n",
      "|    time_elapsed         | 43016         |\n",
      "|    total_timesteps      | 4745216       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067532144 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.225         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 25.2          |\n",
      "|    n_updates            | 23160         |\n",
      "|    policy_gradient_loss | -0.0011       |\n",
      "|    reward               | 1.793354      |\n",
      "|    std                  | 24.2          |\n",
      "|    value_loss           | 119           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2318        |\n",
      "|    time_elapsed         | 43035       |\n",
      "|    total_timesteps      | 4747264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002723055 |\n",
      "|    clip_fraction        | 0.0021      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98.1        |\n",
      "|    n_updates            | 23170       |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    reward               | -2.6346579  |\n",
      "|    std                  | 24.2        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2319         |\n",
      "|    time_elapsed         | 43054        |\n",
      "|    total_timesteps      | 4749312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042675883 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.324        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44           |\n",
      "|    n_updates            | 23180        |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    reward               | 1.3271502    |\n",
      "|    std                  | 24.2         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2320         |\n",
      "|    time_elapsed         | 43072        |\n",
      "|    total_timesteps      | 4751360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063465396 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.421        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 23190        |\n",
      "|    policy_gradient_loss | -0.00771     |\n",
      "|    reward               | -0.30887428  |\n",
      "|    std                  | 24.3         |\n",
      "|    value_loss           | 89.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2321        |\n",
      "|    time_elapsed         | 43090       |\n",
      "|    total_timesteps      | 4753408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002246196 |\n",
      "|    clip_fraction        | 0.000879    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.9        |\n",
      "|    n_updates            | 23200       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | -2.8657968  |\n",
      "|    std                  | 24.3        |\n",
      "|    value_loss           | 214         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2322         |\n",
      "|    time_elapsed         | 43108        |\n",
      "|    total_timesteps      | 4755456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012430794 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.3         |\n",
      "|    n_updates            | 23210        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | -1.3973352   |\n",
      "|    std                  | 24.3         |\n",
      "|    value_loss           | 191          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2323        |\n",
      "|    time_elapsed         | 43127       |\n",
      "|    total_timesteps      | 4757504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009442972 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 23220       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 2.4385085   |\n",
      "|    std                  | 24.4        |\n",
      "|    value_loss           | 69.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2324        |\n",
      "|    time_elapsed         | 43146       |\n",
      "|    total_timesteps      | 4759552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005295979 |\n",
      "|    clip_fraction        | 0.0165      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 23230       |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    reward               | 0.58832145  |\n",
      "|    std                  | 24.4        |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2325         |\n",
      "|    time_elapsed         | 43164        |\n",
      "|    total_timesteps      | 4761600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011304199 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.445        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.5         |\n",
      "|    n_updates            | 23240        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    reward               | -1.6779339   |\n",
      "|    std                  | 24.4         |\n",
      "|    value_loss           | 206          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2326         |\n",
      "|    time_elapsed         | 43183        |\n",
      "|    total_timesteps      | 4763648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037576645 |\n",
      "|    clip_fraction        | 0.00591      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.247        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.4         |\n",
      "|    n_updates            | 23250        |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    reward               | 12.4829445   |\n",
      "|    std                  | 24.5         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2327         |\n",
      "|    time_elapsed         | 43201        |\n",
      "|    total_timesteps      | 4765696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041635167 |\n",
      "|    clip_fraction        | 0.00659      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.7         |\n",
      "|    n_updates            | 23260        |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    reward               | 0.44090378   |\n",
      "|    std                  | 24.6         |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2328         |\n",
      "|    time_elapsed         | 43219        |\n",
      "|    total_timesteps      | 4767744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036179312 |\n",
      "|    clip_fraction        | 0.00493      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 23270        |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    reward               | 1.1744305    |\n",
      "|    std                  | 24.6         |\n",
      "|    value_loss           | 243          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2329         |\n",
      "|    time_elapsed         | 43237        |\n",
      "|    total_timesteps      | 4769792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009968036 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 103          |\n",
      "|    n_updates            | 23280        |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    reward               | -4.636321    |\n",
      "|    std                  | 24.7         |\n",
      "|    value_loss           | 224          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7518578.19\n",
      "total_reward: 6518578.19\n",
      "total_cost: 228751.90\n",
      "total_trades: 58848\n",
      "Sharpe: 0.907\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2330         |\n",
      "|    time_elapsed         | 43255        |\n",
      "|    total_timesteps      | 4771840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039675776 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.155        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.2         |\n",
      "|    n_updates            | 23290        |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    reward               | 3.9247885    |\n",
      "|    std                  | 24.7         |\n",
      "|    value_loss           | 76.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2331         |\n",
      "|    time_elapsed         | 43274        |\n",
      "|    total_timesteps      | 4773888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034164826 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.4         |\n",
      "|    n_updates            | 23300        |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    reward               | -0.068466775 |\n",
      "|    std                  | 24.8         |\n",
      "|    value_loss           | 170          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2332         |\n",
      "|    time_elapsed         | 43291        |\n",
      "|    total_timesteps      | 4775936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008325897 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 133          |\n",
      "|    n_updates            | 23310        |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    reward               | 10.222313    |\n",
      "|    std                  | 24.8         |\n",
      "|    value_loss           | 218          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2333        |\n",
      "|    time_elapsed         | 43310       |\n",
      "|    total_timesteps      | 4777984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006571603 |\n",
      "|    clip_fraction        | 0.0372      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.7        |\n",
      "|    n_updates            | 23320       |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    reward               | 4.506108    |\n",
      "|    std                  | 24.8        |\n",
      "|    value_loss           | 99.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2334         |\n",
      "|    time_elapsed         | 43328        |\n",
      "|    total_timesteps      | 4780032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041204933 |\n",
      "|    clip_fraction        | 0.00737      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.445        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.8         |\n",
      "|    n_updates            | 23330        |\n",
      "|    policy_gradient_loss | -0.00661     |\n",
      "|    reward               | -0.4323205   |\n",
      "|    std                  | 24.8         |\n",
      "|    value_loss           | 159          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2335        |\n",
      "|    time_elapsed         | 43347       |\n",
      "|    total_timesteps      | 4782080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001980702 |\n",
      "|    clip_fraction        | 0.000928    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 23340       |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    reward               | 6.4589505   |\n",
      "|    std                  | 24.9        |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2336         |\n",
      "|    time_elapsed         | 43366        |\n",
      "|    total_timesteps      | 4784128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022886023 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.8         |\n",
      "|    n_updates            | 23350        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | 5.6377573    |\n",
      "|    std                  | 24.9         |\n",
      "|    value_loss           | 180          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2337         |\n",
      "|    time_elapsed         | 43384        |\n",
      "|    total_timesteps      | 4786176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059811166 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.5         |\n",
      "|    n_updates            | 23360        |\n",
      "|    policy_gradient_loss | -0.00683     |\n",
      "|    reward               | -1.2361759   |\n",
      "|    std                  | 25           |\n",
      "|    value_loss           | 67.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2338        |\n",
      "|    time_elapsed         | 43402       |\n",
      "|    total_timesteps      | 4788224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005928021 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.4        |\n",
      "|    n_updates            | 23370       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | 0.460159    |\n",
      "|    std                  | 25.1        |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2339         |\n",
      "|    time_elapsed         | 43420        |\n",
      "|    total_timesteps      | 4790272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012062772 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.38         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 91.2         |\n",
      "|    n_updates            | 23380        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -7.2142243   |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 224          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2340        |\n",
      "|    time_elapsed         | 43438       |\n",
      "|    total_timesteps      | 4792320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007883161 |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.5        |\n",
      "|    n_updates            | 23390       |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    reward               | -7.7734814  |\n",
      "|    std                  | 25.2        |\n",
      "|    value_loss           | 77.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2341         |\n",
      "|    time_elapsed         | 43456        |\n",
      "|    total_timesteps      | 4794368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014618991 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.7         |\n",
      "|    n_updates            | 23400        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | -1.5833647   |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 158          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2342         |\n",
      "|    time_elapsed         | 43475        |\n",
      "|    total_timesteps      | 4796416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042710067 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 148          |\n",
      "|    n_updates            | 23410        |\n",
      "|    policy_gradient_loss | -0.007       |\n",
      "|    reward               | -2.92708     |\n",
      "|    std                  | 25.3         |\n",
      "|    value_loss           | 239          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2343         |\n",
      "|    time_elapsed         | 43494        |\n",
      "|    total_timesteps      | 4798464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008664476 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.256        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82           |\n",
      "|    n_updates            | 23420        |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    reward               | -1.2955574   |\n",
      "|    std                  | 25.3         |\n",
      "|    value_loss           | 158          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7662327.95\n",
      "total_reward: 6662327.95\n",
      "total_cost: 226665.27\n",
      "total_trades: 59209\n",
      "Sharpe: 0.961\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2344        |\n",
      "|    time_elapsed         | 43512       |\n",
      "|    total_timesteps      | 4800512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005287001 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.2        |\n",
      "|    n_updates            | 23430       |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    reward               | -1.6392925  |\n",
      "|    std                  | 25.5        |\n",
      "|    value_loss           | 95.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2345         |\n",
      "|    time_elapsed         | 43531        |\n",
      "|    total_timesteps      | 4802560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044226483 |\n",
      "|    clip_fraction        | 0.00747      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 132          |\n",
      "|    n_updates            | 23440        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | 0.39657244   |\n",
      "|    std                  | 25.6         |\n",
      "|    value_loss           | 213          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2346         |\n",
      "|    time_elapsed         | 43548        |\n",
      "|    total_timesteps      | 4804608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056221928 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.207        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 138          |\n",
      "|    n_updates            | 23450        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    reward               | 3.764758     |\n",
      "|    std                  | 25.6         |\n",
      "|    value_loss           | 285          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2347        |\n",
      "|    time_elapsed         | 43566       |\n",
      "|    total_timesteps      | 4806656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003635496 |\n",
      "|    clip_fraction        | 0.00234     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 23460       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | 1.0660352   |\n",
      "|    std                  | 25.7        |\n",
      "|    value_loss           | 53.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2348         |\n",
      "|    time_elapsed         | 43585        |\n",
      "|    total_timesteps      | 4808704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025417334 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.407        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.4         |\n",
      "|    n_updates            | 23470        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | -2.2059853   |\n",
      "|    std                  | 25.7         |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2349         |\n",
      "|    time_elapsed         | 43603        |\n",
      "|    total_timesteps      | 4810752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040987814 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.248        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 150          |\n",
      "|    n_updates            | 23480        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    reward               | -0.5012952   |\n",
      "|    std                  | 25.7         |\n",
      "|    value_loss           | 387          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2350         |\n",
      "|    time_elapsed         | 43622        |\n",
      "|    total_timesteps      | 4812800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037229073 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 94.3         |\n",
      "|    n_updates            | 23490        |\n",
      "|    policy_gradient_loss | -0.00518     |\n",
      "|    reward               | -2.976975    |\n",
      "|    std                  | 25.7         |\n",
      "|    value_loss           | 234          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2351         |\n",
      "|    time_elapsed         | 43641        |\n",
      "|    total_timesteps      | 4814848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020539924 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.6         |\n",
      "|    n_updates            | 23500        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    reward               | -1.8021019   |\n",
      "|    std                  | 25.8         |\n",
      "|    value_loss           | 157          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2352         |\n",
      "|    time_elapsed         | 43659        |\n",
      "|    total_timesteps      | 4816896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019453451 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.5         |\n",
      "|    n_updates            | 23510        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | 0.4904109    |\n",
      "|    std                  | 25.8         |\n",
      "|    value_loss           | 199          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2353         |\n",
      "|    time_elapsed         | 43677        |\n",
      "|    total_timesteps      | 4818944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014318493 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 145          |\n",
      "|    n_updates            | 23520        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 3.081981     |\n",
      "|    std                  | 25.8         |\n",
      "|    value_loss           | 187          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2354         |\n",
      "|    time_elapsed         | 43696        |\n",
      "|    total_timesteps      | 4820992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076318504 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.606        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 23530        |\n",
      "|    policy_gradient_loss | -0.00982     |\n",
      "|    reward               | 1.6029475    |\n",
      "|    std                  | 25.9         |\n",
      "|    value_loss           | 46.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2355          |\n",
      "|    time_elapsed         | 43714         |\n",
      "|    total_timesteps      | 4823040       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068812387 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -135          |\n",
      "|    explained_variance   | 0.725         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 70.1          |\n",
      "|    n_updates            | 23540         |\n",
      "|    policy_gradient_loss | -0.00147      |\n",
      "|    reward               | 0.7502477     |\n",
      "|    std                  | 25.9          |\n",
      "|    value_loss           | 194           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2356          |\n",
      "|    time_elapsed         | 43734         |\n",
      "|    total_timesteps      | 4825088       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039349453 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -135          |\n",
      "|    explained_variance   | 0.652         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 193           |\n",
      "|    n_updates            | 23550         |\n",
      "|    policy_gradient_loss | -0.00231      |\n",
      "|    reward               | -5.9895177    |\n",
      "|    std                  | 25.9          |\n",
      "|    value_loss           | 289           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2357         |\n",
      "|    time_elapsed         | 43752        |\n",
      "|    total_timesteps      | 4827136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073227584 |\n",
      "|    clip_fraction        | 0.0303       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.4         |\n",
      "|    n_updates            | 23560        |\n",
      "|    policy_gradient_loss | -0.00965     |\n",
      "|    reward               | 1.0949062    |\n",
      "|    std                  | 26           |\n",
      "|    value_loss           | 74.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8499654.89\n",
      "total_reward: 7499654.89\n",
      "total_cost: 267306.12\n",
      "total_trades: 61526\n",
      "Sharpe: 0.982\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2358         |\n",
      "|    time_elapsed         | 43771        |\n",
      "|    total_timesteps      | 4829184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011040831 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.368        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 23570        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    reward               | 0.4268485    |\n",
      "|    std                  | 26           |\n",
      "|    value_loss           | 183          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2359          |\n",
      "|    time_elapsed         | 43788         |\n",
      "|    total_timesteps      | 4831232       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021982272 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -135          |\n",
      "|    explained_variance   | 0.58          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 104           |\n",
      "|    n_updates            | 23580         |\n",
      "|    policy_gradient_loss | -0.00126      |\n",
      "|    reward               | -26.074806    |\n",
      "|    std                  | 26.1          |\n",
      "|    value_loss           | 335           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2360          |\n",
      "|    time_elapsed         | 43807         |\n",
      "|    total_timesteps      | 4833280       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050845114 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -135          |\n",
      "|    explained_variance   | 0.649         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 68.4          |\n",
      "|    n_updates            | 23590         |\n",
      "|    policy_gradient_loss | -0.00183      |\n",
      "|    reward               | -11.541127    |\n",
      "|    std                  | 26.1          |\n",
      "|    value_loss           | 146           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2361        |\n",
      "|    time_elapsed         | 43826       |\n",
      "|    total_timesteps      | 4835328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005264746 |\n",
      "|    clip_fraction        | 0.0126      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 23600       |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | -3.7941067  |\n",
      "|    std                  | 26.1        |\n",
      "|    value_loss           | 94          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2362         |\n",
      "|    time_elapsed         | 43844        |\n",
      "|    total_timesteps      | 4837376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011004672 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.1         |\n",
      "|    n_updates            | 23610        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | -0.34094927  |\n",
      "|    std                  | 26.2         |\n",
      "|    value_loss           | 204          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2363          |\n",
      "|    time_elapsed         | 43863         |\n",
      "|    total_timesteps      | 4839424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051718764 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -135          |\n",
      "|    explained_variance   | 0.534         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 54.5          |\n",
      "|    n_updates            | 23620         |\n",
      "|    policy_gradient_loss | -0.00145      |\n",
      "|    reward               | 8.946294      |\n",
      "|    std                  | 26.2          |\n",
      "|    value_loss           | 202           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2364        |\n",
      "|    time_elapsed         | 43881       |\n",
      "|    total_timesteps      | 4841472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006821852 |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 23630       |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    reward               | 0.7864932   |\n",
      "|    std                  | 26.2        |\n",
      "|    value_loss           | 63.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2365         |\n",
      "|    time_elapsed         | 43900        |\n",
      "|    total_timesteps      | 4843520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005131728 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.4         |\n",
      "|    n_updates            | 23640        |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    reward               | 0.07078311   |\n",
      "|    std                  | 26.2         |\n",
      "|    value_loss           | 190          |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 110            |\n",
      "|    iterations           | 2366           |\n",
      "|    time_elapsed         | 43919          |\n",
      "|    total_timesteps      | 4845568        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000115904346 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -135           |\n",
      "|    explained_variance   | 0.641          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 97.5           |\n",
      "|    n_updates            | 23650          |\n",
      "|    policy_gradient_loss | -0.000715      |\n",
      "|    reward               | 7.7697697      |\n",
      "|    std                  | 26.2           |\n",
      "|    value_loss           | 390            |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2367         |\n",
      "|    time_elapsed         | 43937        |\n",
      "|    total_timesteps      | 4847616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008829866 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.294        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76           |\n",
      "|    n_updates            | 23660        |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    reward               | -10.965955   |\n",
      "|    std                  | 26.3         |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2368        |\n",
      "|    time_elapsed         | 43955       |\n",
      "|    total_timesteps      | 4849664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003230906 |\n",
      "|    clip_fraction        | 0.00586     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.2        |\n",
      "|    n_updates            | 23670       |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    reward               | 2.1917694   |\n",
      "|    std                  | 26.3        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2369        |\n",
      "|    time_elapsed         | 43973       |\n",
      "|    total_timesteps      | 4851712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000491941 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 301         |\n",
      "|    n_updates            | 23680       |\n",
      "|    policy_gradient_loss | -0.00205    |\n",
      "|    reward               | -1.0709292  |\n",
      "|    std                  | 26.4        |\n",
      "|    value_loss           | 302         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2370        |\n",
      "|    time_elapsed         | 43991       |\n",
      "|    total_timesteps      | 4853760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000615883 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 194         |\n",
      "|    n_updates            | 23690       |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    reward               | 1.256642    |\n",
      "|    std                  | 26.4        |\n",
      "|    value_loss           | 363         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2371         |\n",
      "|    time_elapsed         | 44010        |\n",
      "|    total_timesteps      | 4855808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052696476 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 23700        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    reward               | 1.6043807    |\n",
      "|    std                  | 26.4         |\n",
      "|    value_loss           | 53           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9291860.55\n",
      "total_reward: 8291860.55\n",
      "total_cost: 294423.49\n",
      "total_trades: 62939\n",
      "Sharpe: 1.040\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2372          |\n",
      "|    time_elapsed         | 44028         |\n",
      "|    total_timesteps      | 4857856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092487875 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -135          |\n",
      "|    explained_variance   | 0.688         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 95.7          |\n",
      "|    n_updates            | 23710         |\n",
      "|    policy_gradient_loss | -0.00297      |\n",
      "|    reward               | -0.07141735   |\n",
      "|    std                  | 26.4          |\n",
      "|    value_loss           | 298           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2373         |\n",
      "|    time_elapsed         | 44047        |\n",
      "|    total_timesteps      | 4859904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008799827 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 209          |\n",
      "|    n_updates            | 23720        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | 0.54775584   |\n",
      "|    std                  | 26.5         |\n",
      "|    value_loss           | 242          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2374         |\n",
      "|    time_elapsed         | 44065        |\n",
      "|    total_timesteps      | 4861952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015523171 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.7         |\n",
      "|    n_updates            | 23730        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | -0.5142835   |\n",
      "|    std                  | 26.5         |\n",
      "|    value_loss           | 131          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2375         |\n",
      "|    time_elapsed         | 44084        |\n",
      "|    total_timesteps      | 4864000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039038132 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.779        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.2         |\n",
      "|    n_updates            | 23740        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    reward               | 1.9869682    |\n",
      "|    std                  | 26.6         |\n",
      "|    value_loss           | 180          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2376         |\n",
      "|    time_elapsed         | 44102        |\n",
      "|    total_timesteps      | 4866048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016060916 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 135          |\n",
      "|    n_updates            | 23750        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | -0.09766873  |\n",
      "|    std                  | 26.7         |\n",
      "|    value_loss           | 263          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2377         |\n",
      "|    time_elapsed         | 44121        |\n",
      "|    total_timesteps      | 4868096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012483061 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 219          |\n",
      "|    n_updates            | 23760        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    reward               | -0.7681978   |\n",
      "|    std                  | 26.7         |\n",
      "|    value_loss           | 315          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2378       |\n",
      "|    time_elapsed         | 44139      |\n",
      "|    total_timesteps      | 4870144    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01086976 |\n",
      "|    clip_fraction        | 0.0866     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -136       |\n",
      "|    explained_variance   | 0.26       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25         |\n",
      "|    n_updates            | 23770      |\n",
      "|    policy_gradient_loss | -0.0127    |\n",
      "|    reward               | 2.069705   |\n",
      "|    std                  | 26.8       |\n",
      "|    value_loss           | 60         |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2379          |\n",
      "|    time_elapsed         | 44158         |\n",
      "|    total_timesteps      | 4872192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081558083 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.609         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 99.2          |\n",
      "|    n_updates            | 23780         |\n",
      "|    policy_gradient_loss | -0.00253      |\n",
      "|    reward               | 0.9137712     |\n",
      "|    std                  | 26.9          |\n",
      "|    value_loss           | 221           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2380         |\n",
      "|    time_elapsed         | 44176        |\n",
      "|    total_timesteps      | 4874240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010781537 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 145          |\n",
      "|    n_updates            | 23790        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    reward               | 1.1816849    |\n",
      "|    std                  | 26.9         |\n",
      "|    value_loss           | 253          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2381         |\n",
      "|    time_elapsed         | 44194        |\n",
      "|    total_timesteps      | 4876288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010593475 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.299        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.6         |\n",
      "|    n_updates            | 23800        |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    reward               | 5.6880627    |\n",
      "|    std                  | 26.9         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2382          |\n",
      "|    time_elapsed         | 44213         |\n",
      "|    total_timesteps      | 4878336       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067384634 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.653         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 103           |\n",
      "|    n_updates            | 23810         |\n",
      "|    policy_gradient_loss | -0.00205      |\n",
      "|    reward               | -0.000948674  |\n",
      "|    std                  | 26.9          |\n",
      "|    value_loss           | 203           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2383          |\n",
      "|    time_elapsed         | 44231         |\n",
      "|    total_timesteps      | 4880384       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019124168 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.787         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 168           |\n",
      "|    n_updates            | 23820         |\n",
      "|    policy_gradient_loss | -0.00101      |\n",
      "|    reward               | 15.019325     |\n",
      "|    std                  | 26.9          |\n",
      "|    value_loss           | 366           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2384          |\n",
      "|    time_elapsed         | 44250         |\n",
      "|    total_timesteps      | 4882432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022703191 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.61          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 79.7          |\n",
      "|    n_updates            | 23830         |\n",
      "|    policy_gradient_loss | -0.000899     |\n",
      "|    reward               | -2.4322622    |\n",
      "|    std                  | 26.9          |\n",
      "|    value_loss           | 266           |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2385       |\n",
      "|    time_elapsed         | 44268      |\n",
      "|    total_timesteps      | 4884480    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00638845 |\n",
      "|    clip_fraction        | 0.0195     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -136       |\n",
      "|    explained_variance   | 0.74       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 68.6       |\n",
      "|    n_updates            | 23840      |\n",
      "|    policy_gradient_loss | -0.00835   |\n",
      "|    reward               | 0.8052766  |\n",
      "|    std                  | 26.9       |\n",
      "|    value_loss           | 128        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9562975.00\n",
      "total_reward: 8562975.00\n",
      "total_cost: 286486.16\n",
      "total_trades: 63247\n",
      "Sharpe: 1.042\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2386         |\n",
      "|    time_elapsed         | 44287        |\n",
      "|    total_timesteps      | 4886528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008576043 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 23850        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    reward               | -0.17662421  |\n",
      "|    std                  | 27           |\n",
      "|    value_loss           | 341          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2387          |\n",
      "|    time_elapsed         | 44305         |\n",
      "|    total_timesteps      | 4888576       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00094589515 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.677         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 158           |\n",
      "|    n_updates            | 23860         |\n",
      "|    policy_gradient_loss | -0.00251      |\n",
      "|    reward               | -2.5010324    |\n",
      "|    std                  | 27            |\n",
      "|    value_loss           | 328           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2388        |\n",
      "|    time_elapsed         | 44324       |\n",
      "|    total_timesteps      | 4890624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005301545 |\n",
      "|    clip_fraction        | 0.011       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 23870       |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    reward               | -4.3848376  |\n",
      "|    std                  | 27          |\n",
      "|    value_loss           | 87.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2389         |\n",
      "|    time_elapsed         | 44343        |\n",
      "|    total_timesteps      | 4892672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026165503 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.794        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 23880        |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    reward               | -1.2833418   |\n",
      "|    std                  | 27.1         |\n",
      "|    value_loss           | 214          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2390         |\n",
      "|    time_elapsed         | 44361        |\n",
      "|    total_timesteps      | 4894720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002810412 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 223          |\n",
      "|    n_updates            | 23890        |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    reward               | -3.7859237   |\n",
      "|    std                  | 27.1         |\n",
      "|    value_loss           | 481          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2391         |\n",
      "|    time_elapsed         | 44381        |\n",
      "|    total_timesteps      | 4896768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022935462 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 110          |\n",
      "|    n_updates            | 23900        |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    reward               | 3.1697278    |\n",
      "|    std                  | 27.2         |\n",
      "|    value_loss           | 175          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2392        |\n",
      "|    time_elapsed         | 44399       |\n",
      "|    total_timesteps      | 4898816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004999019 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.7        |\n",
      "|    n_updates            | 23910       |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    reward               | 1.1138314   |\n",
      "|    std                  | 27.2        |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2393         |\n",
      "|    time_elapsed         | 44418        |\n",
      "|    total_timesteps      | 4900864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012345377 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 288          |\n",
      "|    n_updates            | 23920        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | 0.5671364    |\n",
      "|    std                  | 27.2         |\n",
      "|    value_loss           | 406          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2394        |\n",
      "|    time_elapsed         | 44436       |\n",
      "|    total_timesteps      | 4902912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000924268 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 23930       |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    reward               | 0.34473166  |\n",
      "|    std                  | 27.3        |\n",
      "|    value_loss           | 335         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2395        |\n",
      "|    time_elapsed         | 44454       |\n",
      "|    total_timesteps      | 4904960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005523321 |\n",
      "|    clip_fraction        | 0.0178      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 23940       |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    reward               | 3.011125    |\n",
      "|    std                  | 27.4        |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2396         |\n",
      "|    time_elapsed         | 44472        |\n",
      "|    total_timesteps      | 4907008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007062099 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 110          |\n",
      "|    n_updates            | 23950        |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    reward               | -0.26799348  |\n",
      "|    std                  | 27.5         |\n",
      "|    value_loss           | 292          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2397         |\n",
      "|    time_elapsed         | 44490        |\n",
      "|    total_timesteps      | 4909056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004174395 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 229          |\n",
      "|    n_updates            | 23960        |\n",
      "|    policy_gradient_loss | -0.00149     |\n",
      "|    reward               | 6.2298126    |\n",
      "|    std                  | 27.5         |\n",
      "|    value_loss           | 439          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2398         |\n",
      "|    time_elapsed         | 44509        |\n",
      "|    total_timesteps      | 4911104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029064866 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.2         |\n",
      "|    n_updates            | 23970        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    reward               | 4.6455255    |\n",
      "|    std                  | 27.6         |\n",
      "|    value_loss           | 151          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2399         |\n",
      "|    time_elapsed         | 44527        |\n",
      "|    total_timesteps      | 4913152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.001992804  |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.762        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 163          |\n",
      "|    n_updates            | 23980        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | -0.018175645 |\n",
      "|    std                  | 27.6         |\n",
      "|    value_loss           | 310          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2400         |\n",
      "|    time_elapsed         | 44545        |\n",
      "|    total_timesteps      | 4915200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008005006 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 264          |\n",
      "|    n_updates            | 23990        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | 20.973114    |\n",
      "|    std                  | 27.7         |\n",
      "|    value_loss           | 414          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10062908.70\n",
      "total_reward: 9062908.70\n",
      "total_cost: 254655.21\n",
      "total_trades: 61156\n",
      "Sharpe: 1.061\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2401         |\n",
      "|    time_elapsed         | 44563        |\n",
      "|    total_timesteps      | 4917248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010020478 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 188          |\n",
      "|    n_updates            | 24000        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    reward               | 0.97211903   |\n",
      "|    std                  | 27.7         |\n",
      "|    value_loss           | 348          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2402        |\n",
      "|    time_elapsed         | 44582       |\n",
      "|    total_timesteps      | 4919296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006523384 |\n",
      "|    clip_fraction        | 0.0295      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 24010       |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | -2.2070935  |\n",
      "|    std                  | 27.8        |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2403         |\n",
      "|    time_elapsed         | 44600        |\n",
      "|    total_timesteps      | 4921344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009231976 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 123          |\n",
      "|    n_updates            | 24020        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    reward               | -1.0790808   |\n",
      "|    std                  | 27.8         |\n",
      "|    value_loss           | 298          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2404          |\n",
      "|    time_elapsed         | 44619         |\n",
      "|    total_timesteps      | 4923392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060986436 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -137          |\n",
      "|    explained_variance   | 0.741         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 133           |\n",
      "|    n_updates            | 24030         |\n",
      "|    policy_gradient_loss | -0.00238      |\n",
      "|    reward               | -0.75827485   |\n",
      "|    std                  | 27.8          |\n",
      "|    value_loss           | 407           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2405         |\n",
      "|    time_elapsed         | 44637        |\n",
      "|    total_timesteps      | 4925440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078368485 |\n",
      "|    clip_fraction        | 0.0421       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.4         |\n",
      "|    n_updates            | 24040        |\n",
      "|    policy_gradient_loss | -0.0093      |\n",
      "|    reward               | 2.103859     |\n",
      "|    std                  | 27.9         |\n",
      "|    value_loss           | 80.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2406          |\n",
      "|    time_elapsed         | 44655         |\n",
      "|    total_timesteps      | 4927488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089863216 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -137          |\n",
      "|    explained_variance   | 0.635         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 168           |\n",
      "|    n_updates            | 24050         |\n",
      "|    policy_gradient_loss | -0.00257      |\n",
      "|    reward               | -2.8048155    |\n",
      "|    std                  | 28            |\n",
      "|    value_loss           | 326           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2407         |\n",
      "|    time_elapsed         | 44673        |\n",
      "|    total_timesteps      | 4929536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005375099 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 162          |\n",
      "|    n_updates            | 24060        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | 12.085418    |\n",
      "|    std                  | 28           |\n",
      "|    value_loss           | 421          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2408         |\n",
      "|    time_elapsed         | 44691        |\n",
      "|    total_timesteps      | 4931584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006912332 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 89.7         |\n",
      "|    n_updates            | 24070        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | 0.72904664   |\n",
      "|    std                  | 28.1         |\n",
      "|    value_loss           | 273          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2409         |\n",
      "|    time_elapsed         | 44710        |\n",
      "|    total_timesteps      | 4933632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010697615 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.3         |\n",
      "|    n_updates            | 24080        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | 2.2028522    |\n",
      "|    std                  | 28.1         |\n",
      "|    value_loss           | 171          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2410          |\n",
      "|    time_elapsed         | 44729         |\n",
      "|    total_timesteps      | 4935680       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010032422 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -137          |\n",
      "|    explained_variance   | 0.238         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 283           |\n",
      "|    n_updates            | 24090         |\n",
      "|    policy_gradient_loss | -0.000653     |\n",
      "|    reward               | -0.28268772   |\n",
      "|    std                  | 28.1          |\n",
      "|    value_loss           | 743           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2411         |\n",
      "|    time_elapsed         | 44747        |\n",
      "|    total_timesteps      | 4937728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.462717e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.315        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 168          |\n",
      "|    n_updates            | 24100        |\n",
      "|    policy_gradient_loss | -0.000507    |\n",
      "|    reward               | 0.8450924    |\n",
      "|    std                  | 28.1         |\n",
      "|    value_loss           | 433          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2412        |\n",
      "|    time_elapsed         | 44765       |\n",
      "|    total_timesteps      | 4939776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005460496 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 24110       |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    reward               | -1.5371702  |\n",
      "|    std                  | 28.2        |\n",
      "|    value_loss           | 55          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2413         |\n",
      "|    time_elapsed         | 44784        |\n",
      "|    total_timesteps      | 4941824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004987287 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 158          |\n",
      "|    n_updates            | 24120        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | 0.25949827   |\n",
      "|    std                  | 28.2         |\n",
      "|    value_loss           | 293          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2414         |\n",
      "|    time_elapsed         | 44802        |\n",
      "|    total_timesteps      | 4943872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005222677 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 215          |\n",
      "|    n_updates            | 24130        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | 1.5586979    |\n",
      "|    std                  | 28.3         |\n",
      "|    value_loss           | 345          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10399814.20\n",
      "total_reward: 9399814.20\n",
      "total_cost: 262940.45\n",
      "total_trades: 62186\n",
      "Sharpe: 1.053\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2415         |\n",
      "|    time_elapsed         | 44820        |\n",
      "|    total_timesteps      | 4945920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012710694 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.3         |\n",
      "|    n_updates            | 24140        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | 1.2291869    |\n",
      "|    std                  | 28.3         |\n",
      "|    value_loss           | 172          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2416         |\n",
      "|    time_elapsed         | 44839        |\n",
      "|    total_timesteps      | 4947968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036252532 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 128          |\n",
      "|    n_updates            | 24150        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    reward               | 0.1002626    |\n",
      "|    std                  | 28.4         |\n",
      "|    value_loss           | 200          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2417         |\n",
      "|    time_elapsed         | 44857        |\n",
      "|    total_timesteps      | 4950016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025417972 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90.1         |\n",
      "|    n_updates            | 24160        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    reward               | 1.7662231    |\n",
      "|    std                  | 28.5         |\n",
      "|    value_loss           | 309          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2418        |\n",
      "|    time_elapsed         | 44876       |\n",
      "|    total_timesteps      | 4952064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000742969 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 346         |\n",
      "|    n_updates            | 24170       |\n",
      "|    policy_gradient_loss | -0.00263    |\n",
      "|    reward               | -3.3731377  |\n",
      "|    std                  | 28.5        |\n",
      "|    value_loss           | 598         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2419        |\n",
      "|    time_elapsed         | 44895       |\n",
      "|    total_timesteps      | 4954112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010561712 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 24180       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 2.3501885   |\n",
      "|    std                  | 28.6        |\n",
      "|    value_loss           | 50.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2420          |\n",
      "|    time_elapsed         | 44914         |\n",
      "|    total_timesteps      | 4956160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00085128995 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.525         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 156           |\n",
      "|    n_updates            | 24190         |\n",
      "|    policy_gradient_loss | -0.00231      |\n",
      "|    reward               | 0.8947922     |\n",
      "|    std                  | 28.7          |\n",
      "|    value_loss           | 287           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2421         |\n",
      "|    time_elapsed         | 44933        |\n",
      "|    total_timesteps      | 4958208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031057352 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 156          |\n",
      "|    n_updates            | 24200        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    reward               | -4.10009     |\n",
      "|    std                  | 28.7         |\n",
      "|    value_loss           | 515          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2422         |\n",
      "|    time_elapsed         | 44952        |\n",
      "|    total_timesteps      | 4960256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058452813 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44           |\n",
      "|    n_updates            | 24210        |\n",
      "|    policy_gradient_loss | -0.00749     |\n",
      "|    reward               | -0.87392014  |\n",
      "|    std                  | 28.8         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2423         |\n",
      "|    time_elapsed         | 44972        |\n",
      "|    total_timesteps      | 4962304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014435196 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.6         |\n",
      "|    n_updates            | 24220        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    reward               | 0.9950694    |\n",
      "|    std                  | 28.9         |\n",
      "|    value_loss           | 217          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2424         |\n",
      "|    time_elapsed         | 44989        |\n",
      "|    total_timesteps      | 4964352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010228744 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 156          |\n",
      "|    n_updates            | 24230        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | 13.24644     |\n",
      "|    std                  | 28.9         |\n",
      "|    value_loss           | 387          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2425         |\n",
      "|    time_elapsed         | 45008        |\n",
      "|    total_timesteps      | 4966400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007992544 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 201          |\n",
      "|    n_updates            | 24240        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | -0.047063265 |\n",
      "|    std                  | 28.9         |\n",
      "|    value_loss           | 362          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2426         |\n",
      "|    time_elapsed         | 45026        |\n",
      "|    total_timesteps      | 4968448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047680554 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.2         |\n",
      "|    n_updates            | 24250        |\n",
      "|    policy_gradient_loss | -0.00641     |\n",
      "|    reward               | 0.75383115   |\n",
      "|    std                  | 29           |\n",
      "|    value_loss           | 86.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2427         |\n",
      "|    time_elapsed         | 45044        |\n",
      "|    total_timesteps      | 4970496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015148296 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.785        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 123          |\n",
      "|    n_updates            | 24260        |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | 0.666206     |\n",
      "|    std                  | 29.1         |\n",
      "|    value_loss           | 328          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2428         |\n",
      "|    time_elapsed         | 45063        |\n",
      "|    total_timesteps      | 4972544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032766326 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 241          |\n",
      "|    n_updates            | 24270        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    reward               | 6.53034      |\n",
      "|    std                  | 29.1         |\n",
      "|    value_loss           | 391          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10515071.55\n",
      "total_reward: 9515071.55\n",
      "total_cost: 286088.46\n",
      "total_trades: 63857\n",
      "Sharpe: 1.069\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2429         |\n",
      "|    time_elapsed         | 45082        |\n",
      "|    total_timesteps      | 4974592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077451877 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.9         |\n",
      "|    n_updates            | 24280        |\n",
      "|    policy_gradient_loss | -0.00843     |\n",
      "|    reward               | 0.5621465    |\n",
      "|    std                  | 29.1         |\n",
      "|    value_loss           | 79           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2430          |\n",
      "|    time_elapsed         | 45101         |\n",
      "|    total_timesteps      | 4976640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00097338017 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.718         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 160           |\n",
      "|    n_updates            | 24290         |\n",
      "|    policy_gradient_loss | -0.00279      |\n",
      "|    reward               | 2.2225225     |\n",
      "|    std                  | 29.2          |\n",
      "|    value_loss           | 271           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2431          |\n",
      "|    time_elapsed         | 45118         |\n",
      "|    total_timesteps      | 4978688       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020481949 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.589         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 270           |\n",
      "|    n_updates            | 24300         |\n",
      "|    policy_gradient_loss | -0.000956     |\n",
      "|    reward               | 3.8939786     |\n",
      "|    std                  | 29.2          |\n",
      "|    value_loss           | 505           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2432         |\n",
      "|    time_elapsed         | 45137        |\n",
      "|    total_timesteps      | 4980736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028350446 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.3         |\n",
      "|    n_updates            | 24310        |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    reward               | -5.3072333   |\n",
      "|    std                  | 29.2         |\n",
      "|    value_loss           | 242          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2433        |\n",
      "|    time_elapsed         | 45156       |\n",
      "|    total_timesteps      | 4982784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004044665 |\n",
      "|    clip_fraction        | 0.00601     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.1        |\n",
      "|    n_updates            | 24320       |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | 0.2908537   |\n",
      "|    std                  | 29.3        |\n",
      "|    value_loss           | 190         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2434         |\n",
      "|    time_elapsed         | 45174        |\n",
      "|    total_timesteps      | 4984832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002630503 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 292          |\n",
      "|    n_updates            | 24330        |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    reward               | 0.26761815   |\n",
      "|    std                  | 29.3         |\n",
      "|    value_loss           | 669          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2435         |\n",
      "|    time_elapsed         | 45192        |\n",
      "|    total_timesteps      | 4986880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012689499 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 243          |\n",
      "|    n_updates            | 24340        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | -0.987641    |\n",
      "|    std                  | 29.3         |\n",
      "|    value_loss           | 510          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2436        |\n",
      "|    time_elapsed         | 45211       |\n",
      "|    total_timesteps      | 4988928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004730638 |\n",
      "|    clip_fraction        | 0.0112      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.9        |\n",
      "|    n_updates            | 24350       |\n",
      "|    policy_gradient_loss | -0.00618    |\n",
      "|    reward               | 2.5688941   |\n",
      "|    std                  | 29.3        |\n",
      "|    value_loss           | 69.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2437         |\n",
      "|    time_elapsed         | 45229        |\n",
      "|    total_timesteps      | 4990976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007683553 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 232          |\n",
      "|    n_updates            | 24360        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    reward               | 0.93376374   |\n",
      "|    std                  | 29.3         |\n",
      "|    value_loss           | 355          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2438          |\n",
      "|    time_elapsed         | 45248         |\n",
      "|    total_timesteps      | 4993024       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014691343 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.656         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 512           |\n",
      "|    n_updates            | 24370         |\n",
      "|    policy_gradient_loss | -0.00107      |\n",
      "|    reward               | -2.0846415    |\n",
      "|    std                  | 29.3          |\n",
      "|    value_loss           | 628           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2439        |\n",
      "|    time_elapsed         | 45266       |\n",
      "|    total_timesteps      | 4995072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006200181 |\n",
      "|    clip_fraction        | 0.0241      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.9        |\n",
      "|    n_updates            | 24380       |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    reward               | 3.3211877   |\n",
      "|    std                  | 29.4        |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2440         |\n",
      "|    time_elapsed         | 45285        |\n",
      "|    total_timesteps      | 4997120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044615287 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.282        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 198          |\n",
      "|    n_updates            | 24390        |\n",
      "|    policy_gradient_loss | -0.00835     |\n",
      "|    reward               | 0.11082713   |\n",
      "|    std                  | 29.5         |\n",
      "|    value_loss           | 359          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2441         |\n",
      "|    time_elapsed         | 45304        |\n",
      "|    total_timesteps      | 4999168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017407096 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 242          |\n",
      "|    n_updates            | 24400        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | -0.3010306   |\n",
      "|    std                  | 29.6         |\n",
      "|    value_loss           | 459          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2442         |\n",
      "|    time_elapsed         | 45322        |\n",
      "|    total_timesteps      | 5001216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006549661 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 155          |\n",
      "|    n_updates            | 24410        |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    reward               | -0.56716967  |\n",
      "|    std                  | 29.6         |\n",
      "|    value_loss           | 466          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11042188.59\n",
      "total_reward: 10042188.59\n",
      "total_cost: 274099.17\n",
      "total_trades: 63566\n",
      "Sharpe: 1.081\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2443        |\n",
      "|    time_elapsed         | 45340       |\n",
      "|    total_timesteps      | 5003264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006615998 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 24420       |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | 2.2257426   |\n",
      "|    std                  | 29.8        |\n",
      "|    value_loss           | 58.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2444         |\n",
      "|    time_elapsed         | 45359        |\n",
      "|    total_timesteps      | 5005312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012380744 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 293          |\n",
      "|    n_updates            | 24430        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | -1.4628634   |\n",
      "|    std                  | 29.8         |\n",
      "|    value_loss           | 495          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2445         |\n",
      "|    time_elapsed         | 45377        |\n",
      "|    total_timesteps      | 5007360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012619501 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.48         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 440          |\n",
      "|    n_updates            | 24440        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -20.698973   |\n",
      "|    std                  | 29.8         |\n",
      "|    value_loss           | 525          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2446        |\n",
      "|    time_elapsed         | 45395       |\n",
      "|    total_timesteps      | 5009408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003869204 |\n",
      "|    clip_fraction        | 0.00767     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.4        |\n",
      "|    n_updates            | 24450       |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    reward               | 2.856501    |\n",
      "|    std                  | 29.9        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2447         |\n",
      "|    time_elapsed         | 45413        |\n",
      "|    total_timesteps      | 5011456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026786071 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.285        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 308          |\n",
      "|    n_updates            | 24460        |\n",
      "|    policy_gradient_loss | -0.00455     |\n",
      "|    reward               | 0.6370953    |\n",
      "|    std                  | 30           |\n",
      "|    value_loss           | 517          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2448          |\n",
      "|    time_elapsed         | 45431         |\n",
      "|    total_timesteps      | 5013504       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060497306 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.61          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 303           |\n",
      "|    n_updates            | 24470         |\n",
      "|    policy_gradient_loss | -0.00232      |\n",
      "|    reward               | 23.987608     |\n",
      "|    std                  | 30            |\n",
      "|    value_loss           | 568           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2449        |\n",
      "|    time_elapsed         | 45450       |\n",
      "|    total_timesteps      | 5015552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002351591 |\n",
      "|    clip_fraction        | 0.0019      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 169         |\n",
      "|    n_updates            | 24480       |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | 5.4507284   |\n",
      "|    std                  | 30          |\n",
      "|    value_loss           | 492         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2450         |\n",
      "|    time_elapsed         | 45469        |\n",
      "|    total_timesteps      | 5017600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036679793 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.468        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.6         |\n",
      "|    n_updates            | 24490        |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    reward               | 1.0034971    |\n",
      "|    std                  | 30.1         |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2451         |\n",
      "|    time_elapsed         | 45488        |\n",
      "|    total_timesteps      | 5019648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008671767 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 241          |\n",
      "|    n_updates            | 24500        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | 9.93835e-05  |\n",
      "|    std                  | 30.1         |\n",
      "|    value_loss           | 413          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2452         |\n",
      "|    time_elapsed         | 45506        |\n",
      "|    total_timesteps      | 5021696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028411304 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 303          |\n",
      "|    n_updates            | 24510        |\n",
      "|    policy_gradient_loss | -0.00455     |\n",
      "|    reward               | -0.5828397   |\n",
      "|    std                  | 30.2         |\n",
      "|    value_loss           | 480          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2453        |\n",
      "|    time_elapsed         | 45524       |\n",
      "|    total_timesteps      | 5023744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008057048 |\n",
      "|    clip_fraction        | 0.0397      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 24520       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 1.3785583   |\n",
      "|    std                  | 30.2        |\n",
      "|    value_loss           | 77          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2454         |\n",
      "|    time_elapsed         | 45543        |\n",
      "|    total_timesteps      | 5025792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029161996 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 231          |\n",
      "|    n_updates            | 24530        |\n",
      "|    policy_gradient_loss | -0.00549     |\n",
      "|    reward               | 0.88192326   |\n",
      "|    std                  | 30.4         |\n",
      "|    value_loss           | 446          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2455          |\n",
      "|    time_elapsed         | 45561         |\n",
      "|    total_timesteps      | 5027840       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036126756 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.697         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 417           |\n",
      "|    n_updates            | 24540         |\n",
      "|    policy_gradient_loss | -0.00167      |\n",
      "|    reward               | -3.2010257    |\n",
      "|    std                  | 30.4          |\n",
      "|    value_loss           | 829           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2456         |\n",
      "|    time_elapsed         | 45580        |\n",
      "|    total_timesteps      | 5029888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021298013 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93.6         |\n",
      "|    n_updates            | 24550        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | 8.738256     |\n",
      "|    std                  | 30.5         |\n",
      "|    value_loss           | 222          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11089327.48\n",
      "total_reward: 10089327.48\n",
      "total_cost: 263223.97\n",
      "total_trades: 62152\n",
      "Sharpe: 1.084\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2457         |\n",
      "|    time_elapsed         | 45599        |\n",
      "|    total_timesteps      | 5031936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030308154 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 193          |\n",
      "|    n_updates            | 24560        |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    reward               | -0.9263891   |\n",
      "|    std                  | 30.5         |\n",
      "|    value_loss           | 353          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2458         |\n",
      "|    time_elapsed         | 45617        |\n",
      "|    total_timesteps      | 5033984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011829288 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 246          |\n",
      "|    n_updates            | 24570        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    reward               | 0.02586536   |\n",
      "|    std                  | 30.6         |\n",
      "|    value_loss           | 557          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2459         |\n",
      "|    time_elapsed         | 45635        |\n",
      "|    total_timesteps      | 5036032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007762392 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 179          |\n",
      "|    n_updates            | 24580        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | 5.280956     |\n",
      "|    std                  | 30.6         |\n",
      "|    value_loss           | 300          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2460        |\n",
      "|    time_elapsed         | 45653       |\n",
      "|    total_timesteps      | 5038080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008740689 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 24590       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 0.88575584  |\n",
      "|    std                  | 30.7        |\n",
      "|    value_loss           | 58.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2461         |\n",
      "|    time_elapsed         | 45672        |\n",
      "|    total_timesteps      | 5040128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018698145 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 262          |\n",
      "|    n_updates            | 24600        |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    reward               | -3.1231318   |\n",
      "|    std                  | 30.7         |\n",
      "|    value_loss           | 429          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2462          |\n",
      "|    time_elapsed         | 45692         |\n",
      "|    total_timesteps      | 5042176       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013653672 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.742         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 186           |\n",
      "|    n_updates            | 24610         |\n",
      "|    policy_gradient_loss | -0.000838     |\n",
      "|    reward               | 19.10016      |\n",
      "|    std                  | 30.7          |\n",
      "|    value_loss           | 389           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2463        |\n",
      "|    time_elapsed         | 45711       |\n",
      "|    total_timesteps      | 5044224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001944705 |\n",
      "|    clip_fraction        | 0.00103     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.9        |\n",
      "|    n_updates            | 24620       |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    reward               | -3.309211   |\n",
      "|    std                  | 30.8        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2464         |\n",
      "|    time_elapsed         | 45730        |\n",
      "|    total_timesteps      | 5046272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018753943 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 233          |\n",
      "|    n_updates            | 24630        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | 5.3462486    |\n",
      "|    std                  | 30.9         |\n",
      "|    value_loss           | 281          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2465          |\n",
      "|    time_elapsed         | 45749         |\n",
      "|    total_timesteps      | 5048320       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062836555 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.668         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 137           |\n",
      "|    n_updates            | 24640         |\n",
      "|    policy_gradient_loss | -0.00205      |\n",
      "|    reward               | 2.063913      |\n",
      "|    std                  | 30.9          |\n",
      "|    value_loss           | 463           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2466         |\n",
      "|    time_elapsed         | 45768        |\n",
      "|    total_timesteps      | 5050368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005822094 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 170          |\n",
      "|    n_updates            | 24650        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    reward               | -0.9554172   |\n",
      "|    std                  | 30.9         |\n",
      "|    value_loss           | 427          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2467         |\n",
      "|    time_elapsed         | 45787        |\n",
      "|    total_timesteps      | 5052416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024402505 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.843        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.6         |\n",
      "|    n_updates            | 24660        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | 0.89385444   |\n",
      "|    std                  | 31           |\n",
      "|    value_loss           | 67.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2468          |\n",
      "|    time_elapsed         | 45805         |\n",
      "|    total_timesteps      | 5054464       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044317415 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.645         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 849           |\n",
      "|    n_updates            | 24670         |\n",
      "|    policy_gradient_loss | -0.00148      |\n",
      "|    reward               | -0.014057262  |\n",
      "|    std                  | 31            |\n",
      "|    value_loss           | 654           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2469          |\n",
      "|    time_elapsed         | 45824         |\n",
      "|    total_timesteps      | 5056512       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032574736 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.36          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 180           |\n",
      "|    n_updates            | 24680         |\n",
      "|    policy_gradient_loss | -0.00132      |\n",
      "|    reward               | 8.205892      |\n",
      "|    std                  | 31.1          |\n",
      "|    value_loss           | 497           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2470        |\n",
      "|    time_elapsed         | 45842       |\n",
      "|    total_timesteps      | 5058560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007834431 |\n",
      "|    clip_fraction        | 0.0326      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.5        |\n",
      "|    n_updates            | 24690       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 3.2069862   |\n",
      "|    std                  | 31.1        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10229766.62\n",
      "total_reward: 9229766.62\n",
      "total_cost: 251811.40\n",
      "total_trades: 61874\n",
      "Sharpe: 1.058\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2471         |\n",
      "|    time_elapsed         | 45860        |\n",
      "|    total_timesteps      | 5060608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013406818 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 126          |\n",
      "|    n_updates            | 24700        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | 1.1811228    |\n",
      "|    std                  | 31.2         |\n",
      "|    value_loss           | 351          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2472          |\n",
      "|    time_elapsed         | 45879         |\n",
      "|    total_timesteps      | 5062656       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036862568 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.547         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 150           |\n",
      "|    n_updates            | 24710         |\n",
      "|    policy_gradient_loss | -0.00173      |\n",
      "|    reward               | -16.578705    |\n",
      "|    std                  | 31.2          |\n",
      "|    value_loss           | 414           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2473         |\n",
      "|    time_elapsed         | 45898        |\n",
      "|    total_timesteps      | 5064704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017470418 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 105          |\n",
      "|    n_updates            | 24720        |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    reward               | 4.3004813    |\n",
      "|    std                  | 31.3         |\n",
      "|    value_loss           | 217          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2474        |\n",
      "|    time_elapsed         | 45917       |\n",
      "|    total_timesteps      | 5066752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007984422 |\n",
      "|    clip_fraction        | 0.0458      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 189         |\n",
      "|    n_updates            | 24730       |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    reward               | -1.9832463  |\n",
      "|    std                  | 31.4        |\n",
      "|    value_loss           | 222         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2475         |\n",
      "|    time_elapsed         | 45937        |\n",
      "|    total_timesteps      | 5068800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007472788 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.8         |\n",
      "|    n_updates            | 24740        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | -2.9364762   |\n",
      "|    std                  | 31.4         |\n",
      "|    value_loss           | 429          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2476          |\n",
      "|    time_elapsed         | 45956         |\n",
      "|    total_timesteps      | 5070848       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039751356 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.434         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 157           |\n",
      "|    n_updates            | 24750         |\n",
      "|    policy_gradient_loss | -0.00156      |\n",
      "|    reward               | 0.71823025    |\n",
      "|    std                  | 31.4          |\n",
      "|    value_loss           | 358           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2477        |\n",
      "|    time_elapsed         | 45975       |\n",
      "|    total_timesteps      | 5072896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007820101 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 24760       |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    reward               | 0.34889376  |\n",
      "|    std                  | 31.6        |\n",
      "|    value_loss           | 72.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2478        |\n",
      "|    time_elapsed         | 45993       |\n",
      "|    total_timesteps      | 5074944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000358219 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 161         |\n",
      "|    n_updates            | 24770       |\n",
      "|    policy_gradient_loss | -0.00161    |\n",
      "|    reward               | -1.827969   |\n",
      "|    std                  | 31.6        |\n",
      "|    value_loss           | 363         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2479          |\n",
      "|    time_elapsed         | 46012         |\n",
      "|    total_timesteps      | 5076992       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012077144 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.79          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 201           |\n",
      "|    n_updates            | 24780         |\n",
      "|    policy_gradient_loss | -0.000924     |\n",
      "|    reward               | 20.615877     |\n",
      "|    std                  | 31.6          |\n",
      "|    value_loss           | 537           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2480         |\n",
      "|    time_elapsed         | 46031        |\n",
      "|    total_timesteps      | 5079040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003355503 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.6         |\n",
      "|    n_updates            | 24790        |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    reward               | -2.5817559   |\n",
      "|    std                  | 31.7         |\n",
      "|    value_loss           | 210          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2481         |\n",
      "|    time_elapsed         | 46050        |\n",
      "|    total_timesteps      | 5081088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028970065 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 119          |\n",
      "|    n_updates            | 24800        |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    reward               | 2.6924348    |\n",
      "|    std                  | 31.7         |\n",
      "|    value_loss           | 197          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2482          |\n",
      "|    time_elapsed         | 46069         |\n",
      "|    total_timesteps      | 5083136       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069047837 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.694         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 246           |\n",
      "|    n_updates            | 24810         |\n",
      "|    policy_gradient_loss | -0.00187      |\n",
      "|    reward               | 0.009202919   |\n",
      "|    std                  | 31.8          |\n",
      "|    value_loss           | 473           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2483          |\n",
      "|    time_elapsed         | 46088         |\n",
      "|    total_timesteps      | 5085184       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051802245 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.496         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 143           |\n",
      "|    n_updates            | 24820         |\n",
      "|    policy_gradient_loss | -0.00196      |\n",
      "|    reward               | -1.1110412    |\n",
      "|    std                  | 31.8          |\n",
      "|    value_loss           | 294           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2484         |\n",
      "|    time_elapsed         | 46107        |\n",
      "|    total_timesteps      | 5087232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074564237 |\n",
      "|    clip_fraction        | 0.0374       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.431        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.2         |\n",
      "|    n_updates            | 24830        |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    reward               | -1.0368077   |\n",
      "|    std                  | 32           |\n",
      "|    value_loss           | 57.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9992516.43\n",
      "total_reward: 8992516.43\n",
      "total_cost: 300068.28\n",
      "total_trades: 64256\n",
      "Sharpe: 1.020\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2485        |\n",
      "|    time_elapsed         | 46126       |\n",
      "|    total_timesteps      | 5089280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000623649 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 187         |\n",
      "|    n_updates            | 24840       |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    reward               | 0.6760225   |\n",
      "|    std                  | 32.1        |\n",
      "|    value_loss           | 311         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2486          |\n",
      "|    time_elapsed         | 46145         |\n",
      "|    total_timesteps      | 5091328       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5310117e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.54          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 324           |\n",
      "|    n_updates            | 24850         |\n",
      "|    policy_gradient_loss | -0.000311     |\n",
      "|    reward               | -8.280342     |\n",
      "|    std                  | 32.1          |\n",
      "|    value_loss           | 668           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2487         |\n",
      "|    time_elapsed         | 46163        |\n",
      "|    total_timesteps      | 5093376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005857553 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.3         |\n",
      "|    n_updates            | 24860        |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    reward               | -6.2800627   |\n",
      "|    std                  | 32.1         |\n",
      "|    value_loss           | 198          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2488         |\n",
      "|    time_elapsed         | 46183        |\n",
      "|    total_timesteps      | 5095424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042372504 |\n",
      "|    clip_fraction        | 0.00811      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.833        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 142          |\n",
      "|    n_updates            | 24870        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    reward               | -0.39764515  |\n",
      "|    std                  | 32.2         |\n",
      "|    value_loss           | 255          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2489          |\n",
      "|    time_elapsed         | 46202         |\n",
      "|    total_timesteps      | 5097472       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029500446 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.778         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 142           |\n",
      "|    n_updates            | 24880         |\n",
      "|    policy_gradient_loss | -0.00132      |\n",
      "|    reward               | -0.37470037   |\n",
      "|    std                  | 32.2          |\n",
      "|    value_loss           | 329           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2490          |\n",
      "|    time_elapsed         | 46220         |\n",
      "|    total_timesteps      | 5099520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033715044 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.781         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 220           |\n",
      "|    n_updates            | 24890         |\n",
      "|    policy_gradient_loss | -0.00108      |\n",
      "|    reward               | -0.28912815   |\n",
      "|    std                  | 32.3          |\n",
      "|    value_loss           | 395           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2491        |\n",
      "|    time_elapsed         | 46238       |\n",
      "|    total_timesteps      | 5101568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009688238 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 24900       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 0.227903    |\n",
      "|    std                  | 32.3        |\n",
      "|    value_loss           | 50.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2492          |\n",
      "|    time_elapsed         | 46257         |\n",
      "|    total_timesteps      | 5103616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047632665 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.738         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 151           |\n",
      "|    n_updates            | 24910         |\n",
      "|    policy_gradient_loss | -0.00251      |\n",
      "|    reward               | 2.736568      |\n",
      "|    std                  | 32.4          |\n",
      "|    value_loss           | 281           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2493          |\n",
      "|    time_elapsed         | 46276         |\n",
      "|    total_timesteps      | 5105664       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010834355 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.578         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 231           |\n",
      "|    n_updates            | 24920         |\n",
      "|    policy_gradient_loss | -0.00102      |\n",
      "|    reward               | 10.774973     |\n",
      "|    std                  | 32.4          |\n",
      "|    value_loss           | 454           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2494        |\n",
      "|    time_elapsed         | 46294       |\n",
      "|    total_timesteps      | 5107712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006706124 |\n",
      "|    clip_fraction        | 0.0271      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 24930       |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    reward               | -0.538078   |\n",
      "|    std                  | 32.5        |\n",
      "|    value_loss           | 84.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2495         |\n",
      "|    time_elapsed         | 46313        |\n",
      "|    total_timesteps      | 5109760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003552761 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.1         |\n",
      "|    n_updates            | 24940        |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    reward               | 2.532061     |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 255          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2496         |\n",
      "|    time_elapsed         | 46331        |\n",
      "|    total_timesteps      | 5111808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.609604e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.363        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 155          |\n",
      "|    n_updates            | 24950        |\n",
      "|    policy_gradient_loss | -0.000666    |\n",
      "|    reward               | 6.08847      |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 392          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2497         |\n",
      "|    time_elapsed         | 46350        |\n",
      "|    total_timesteps      | 5113856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012161315 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.3         |\n",
      "|    n_updates            | 24960        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | -0.26542813  |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 185          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2498         |\n",
      "|    time_elapsed         | 46369        |\n",
      "|    total_timesteps      | 5115904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020753508 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.762        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 122          |\n",
      "|    n_updates            | 24970        |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | 2.893705     |\n",
      "|    std                  | 32.6         |\n",
      "|    value_loss           | 155          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11315825.97\n",
      "total_reward: 10315825.97\n",
      "total_cost: 271634.74\n",
      "total_trades: 62699\n",
      "Sharpe: 1.108\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2499          |\n",
      "|    time_elapsed         | 46387         |\n",
      "|    total_timesteps      | 5117952       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00049744366 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.704         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 142           |\n",
      "|    n_updates            | 24980         |\n",
      "|    policy_gradient_loss | -0.00236      |\n",
      "|    reward               | -1.0381975    |\n",
      "|    std                  | 32.6          |\n",
      "|    value_loss           | 330           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2500          |\n",
      "|    time_elapsed         | 46405         |\n",
      "|    total_timesteps      | 5120000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031428566 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.524         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 104           |\n",
      "|    n_updates            | 24990         |\n",
      "|    policy_gradient_loss | -0.00137      |\n",
      "|    reward               | -10.35869     |\n",
      "|    std                  | 32.6          |\n",
      "|    value_loss           | 399           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2501         |\n",
      "|    time_elapsed         | 46424        |\n",
      "|    total_timesteps      | 5122048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045656906 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.9         |\n",
      "|    n_updates            | 25000        |\n",
      "|    policy_gradient_loss | -0.00747     |\n",
      "|    reward               | -0.6883337   |\n",
      "|    std                  | 32.7         |\n",
      "|    value_loss           | 72.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2502          |\n",
      "|    time_elapsed         | 46442         |\n",
      "|    total_timesteps      | 5124096       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040591578 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.643         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 501           |\n",
      "|    n_updates            | 25010         |\n",
      "|    policy_gradient_loss | -0.00159      |\n",
      "|    reward               | -0.9116903    |\n",
      "|    std                  | 32.7          |\n",
      "|    value_loss           | 600           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2503          |\n",
      "|    time_elapsed         | 46461         |\n",
      "|    total_timesteps      | 5126144       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.2387855e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.232         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 240           |\n",
      "|    n_updates            | 25020         |\n",
      "|    policy_gradient_loss | -0.000518     |\n",
      "|    reward               | 2.2853372     |\n",
      "|    std                  | 32.7          |\n",
      "|    value_loss           | 767           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2504          |\n",
      "|    time_elapsed         | 46479         |\n",
      "|    total_timesteps      | 5128192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090804795 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.315         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 80.6          |\n",
      "|    n_updates            | 25030         |\n",
      "|    policy_gradient_loss | -0.00255      |\n",
      "|    reward               | -0.69655657   |\n",
      "|    std                  | 32.7          |\n",
      "|    value_loss           | 176           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2505        |\n",
      "|    time_elapsed         | 46498       |\n",
      "|    total_timesteps      | 5130240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001617479 |\n",
      "|    clip_fraction        | 0.000586    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 211         |\n",
      "|    n_updates            | 25040       |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    reward               | -1.2630192  |\n",
      "|    std                  | 32.7        |\n",
      "|    value_loss           | 279         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2506         |\n",
      "|    time_elapsed         | 46516        |\n",
      "|    total_timesteps      | 5132288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010978577 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 149          |\n",
      "|    n_updates            | 25050        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    reward               | 0.016918652  |\n",
      "|    std                  | 32.8         |\n",
      "|    value_loss           | 347          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2507          |\n",
      "|    time_elapsed         | 46534         |\n",
      "|    total_timesteps      | 5134336       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015567534 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.362         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 461           |\n",
      "|    n_updates            | 25060         |\n",
      "|    policy_gradient_loss | -0.000884     |\n",
      "|    reward               | 3.1195095     |\n",
      "|    std                  | 32.8          |\n",
      "|    value_loss           | 657           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2508        |\n",
      "|    time_elapsed         | 46553       |\n",
      "|    total_timesteps      | 5136384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007511607 |\n",
      "|    clip_fraction        | 0.0389      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 25070       |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    reward               | 1.1616341   |\n",
      "|    std                  | 32.9        |\n",
      "|    value_loss           | 50          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2509          |\n",
      "|    time_elapsed         | 46571         |\n",
      "|    total_timesteps      | 5138432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033932758 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.782         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 138           |\n",
      "|    n_updates            | 25080         |\n",
      "|    policy_gradient_loss | -0.00214      |\n",
      "|    reward               | 2.3748624     |\n",
      "|    std                  | 32.9          |\n",
      "|    value_loss           | 428           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2510          |\n",
      "|    time_elapsed         | 46589         |\n",
      "|    total_timesteps      | 5140480       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023870077 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.487         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 157           |\n",
      "|    n_updates            | 25090         |\n",
      "|    policy_gradient_loss | -0.00148      |\n",
      "|    reward               | 28.607233     |\n",
      "|    std                  | 32.9          |\n",
      "|    value_loss           | 434           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2511         |\n",
      "|    time_elapsed         | 46608        |\n",
      "|    total_timesteps      | 5142528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056424364 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.138        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.8         |\n",
      "|    n_updates            | 25100        |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    reward               | 2.4859805    |\n",
      "|    std                  | 33           |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2512         |\n",
      "|    time_elapsed         | 46628        |\n",
      "|    total_timesteps      | 5144576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037224784 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.127        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93.3         |\n",
      "|    n_updates            | 25110        |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    reward               | -0.28348264  |\n",
      "|    std                  | 33.1         |\n",
      "|    value_loss           | 218          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2513          |\n",
      "|    time_elapsed         | 46647         |\n",
      "|    total_timesteps      | 5146624       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058540795 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.541         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 157           |\n",
      "|    n_updates            | 25120         |\n",
      "|    policy_gradient_loss | -0.00216      |\n",
      "|    reward               | 1.5192797     |\n",
      "|    std                  | 33.1          |\n",
      "|    value_loss           | 300           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9531464.70\n",
      "total_reward: 8531464.70\n",
      "total_cost: 311889.03\n",
      "total_trades: 64400\n",
      "Sharpe: 1.034\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2514         |\n",
      "|    time_elapsed         | 46666        |\n",
      "|    total_timesteps      | 5148672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009329127 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.538        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 154          |\n",
      "|    n_updates            | 25130        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    reward               | -1.2677335   |\n",
      "|    std                  | 33.2         |\n",
      "|    value_loss           | 274          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2515        |\n",
      "|    time_elapsed         | 46685       |\n",
      "|    total_timesteps      | 5150720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008413218 |\n",
      "|    clip_fraction        | 0.0449      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 25140       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -2.8747532  |\n",
      "|    std                  | 33.3        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2516          |\n",
      "|    time_elapsed         | 46704         |\n",
      "|    total_timesteps      | 5152768       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015659435 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.429         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 174           |\n",
      "|    n_updates            | 25150         |\n",
      "|    policy_gradient_loss | -0.000772     |\n",
      "|    reward               | -2.3929844    |\n",
      "|    std                  | 33.3          |\n",
      "|    value_loss           | 411           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2517         |\n",
      "|    time_elapsed         | 46722        |\n",
      "|    total_timesteps      | 5154816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003800321 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 158          |\n",
      "|    n_updates            | 25160        |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    reward               | -1.2181544   |\n",
      "|    std                  | 33.4         |\n",
      "|    value_loss           | 289          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2518        |\n",
      "|    time_elapsed         | 46741       |\n",
      "|    total_timesteps      | 5156864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008106199 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.4        |\n",
      "|    n_updates            | 25170       |\n",
      "|    policy_gradient_loss | -0.00916    |\n",
      "|    reward               | 4.9433613   |\n",
      "|    std                  | 33.4        |\n",
      "|    value_loss           | 65          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2519          |\n",
      "|    time_elapsed         | 46759         |\n",
      "|    total_timesteps      | 5158912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034175062 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.72          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 187           |\n",
      "|    n_updates            | 25180         |\n",
      "|    policy_gradient_loss | -0.00149      |\n",
      "|    reward               | -3.2753794    |\n",
      "|    std                  | 33.4          |\n",
      "|    value_loss           | 262           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2520         |\n",
      "|    time_elapsed         | 46778        |\n",
      "|    total_timesteps      | 5160960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002196785 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 211          |\n",
      "|    n_updates            | 25190        |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    reward               | -2.975346    |\n",
      "|    std                  | 33.4         |\n",
      "|    value_loss           | 361          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2521          |\n",
      "|    time_elapsed         | 46797         |\n",
      "|    total_timesteps      | 5163008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053609465 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.583         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 87.8          |\n",
      "|    n_updates            | 25200         |\n",
      "|    policy_gradient_loss | -0.00164      |\n",
      "|    reward               | 0.3143648     |\n",
      "|    std                  | 33.5          |\n",
      "|    value_loss           | 208           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2522         |\n",
      "|    time_elapsed         | 46815        |\n",
      "|    total_timesteps      | 5165056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009606248 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 129          |\n",
      "|    n_updates            | 25210        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    reward               | 2.0605297    |\n",
      "|    std                  | 33.5         |\n",
      "|    value_loss           | 151          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2523          |\n",
      "|    time_elapsed         | 46833         |\n",
      "|    total_timesteps      | 5167104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073726603 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.403         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 146           |\n",
      "|    n_updates            | 25220         |\n",
      "|    policy_gradient_loss | -0.00236      |\n",
      "|    reward               | -0.22403258   |\n",
      "|    std                  | 33.6          |\n",
      "|    value_loss           | 302           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2524          |\n",
      "|    time_elapsed         | 46851         |\n",
      "|    total_timesteps      | 5169152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042443845 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.53          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 123           |\n",
      "|    n_updates            | 25230         |\n",
      "|    policy_gradient_loss | -0.00197      |\n",
      "|    reward               | -0.9335567    |\n",
      "|    std                  | 33.6          |\n",
      "|    value_loss           | 331           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2525         |\n",
      "|    time_elapsed         | 46870        |\n",
      "|    total_timesteps      | 5171200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075934473 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.429        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.2         |\n",
      "|    n_updates            | 25240        |\n",
      "|    policy_gradient_loss | -0.00962     |\n",
      "|    reward               | 2.6449668    |\n",
      "|    std                  | 33.8         |\n",
      "|    value_loss           | 73.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2526         |\n",
      "|    time_elapsed         | 46888        |\n",
      "|    total_timesteps      | 5173248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005666688 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.763        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 514          |\n",
      "|    n_updates            | 25250        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | 0.028032102  |\n",
      "|    std                  | 33.8         |\n",
      "|    value_loss           | 355          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2527         |\n",
      "|    time_elapsed         | 46906        |\n",
      "|    total_timesteps      | 5175296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004913432 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.789        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 96.9         |\n",
      "|    n_updates            | 25260        |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    reward               | 7.262983     |\n",
      "|    std                  | 33.9         |\n",
      "|    value_loss           | 306          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9172168.23\n",
      "total_reward: 8172168.23\n",
      "total_cost: 285394.96\n",
      "total_trades: 63389\n",
      "Sharpe: 1.018\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2528         |\n",
      "|    time_elapsed         | 46924        |\n",
      "|    total_timesteps      | 5177344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010355298 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 146          |\n",
      "|    n_updates            | 25270        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | 4.7776074    |\n",
      "|    std                  | 34           |\n",
      "|    value_loss           | 171          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2529         |\n",
      "|    time_elapsed         | 46944        |\n",
      "|    total_timesteps      | 5179392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035799942 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.795        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43           |\n",
      "|    n_updates            | 25280        |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    reward               | -0.019996624 |\n",
      "|    std                  | 33.9         |\n",
      "|    value_loss           | 167          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2530          |\n",
      "|    time_elapsed         | 46962         |\n",
      "|    total_timesteps      | 5181440       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092451007 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.52          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 198           |\n",
      "|    n_updates            | 25290         |\n",
      "|    policy_gradient_loss | -0.00254      |\n",
      "|    reward               | 0.40719557    |\n",
      "|    std                  | 34            |\n",
      "|    value_loss           | 366           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2531         |\n",
      "|    time_elapsed         | 46980        |\n",
      "|    total_timesteps      | 5183488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020777609 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 483          |\n",
      "|    n_updates            | 25300        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    reward               | 2.7149017    |\n",
      "|    std                  | 34.1         |\n",
      "|    value_loss           | 613          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2532         |\n",
      "|    time_elapsed         | 46999        |\n",
      "|    total_timesteps      | 5185536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076485057 |\n",
      "|    clip_fraction        | 0.0275       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 25310        |\n",
      "|    policy_gradient_loss | -0.00757     |\n",
      "|    reward               | 1.0510284    |\n",
      "|    std                  | 34.3         |\n",
      "|    value_loss           | 54.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2533          |\n",
      "|    time_elapsed         | 47018         |\n",
      "|    total_timesteps      | 5187584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022182497 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.794         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 171           |\n",
      "|    n_updates            | 25320         |\n",
      "|    policy_gradient_loss | -0.00119      |\n",
      "|    reward               | 2.1133878     |\n",
      "|    std                  | 34.3          |\n",
      "|    value_loss           | 392           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2534         |\n",
      "|    time_elapsed         | 47037        |\n",
      "|    total_timesteps      | 5189632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019275896 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 121          |\n",
      "|    n_updates            | 25330        |\n",
      "|    policy_gradient_loss | -0.00501     |\n",
      "|    reward               | -25.570114   |\n",
      "|    std                  | 34.3         |\n",
      "|    value_loss           | 380          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2535        |\n",
      "|    time_elapsed         | 47056       |\n",
      "|    total_timesteps      | 5191680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006232745 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.3        |\n",
      "|    n_updates            | 25340       |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    reward               | -6.1942835  |\n",
      "|    std                  | 34.5        |\n",
      "|    value_loss           | 86          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2536        |\n",
      "|    time_elapsed         | 47074       |\n",
      "|    total_timesteps      | 5193728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002242846 |\n",
      "|    clip_fraction        | 0.00156     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.8        |\n",
      "|    n_updates            | 25350       |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    reward               | 0.38260755  |\n",
      "|    std                  | 34.6        |\n",
      "|    value_loss           | 258         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2537         |\n",
      "|    time_elapsed         | 47092        |\n",
      "|    total_timesteps      | 5195776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017715525 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 194          |\n",
      "|    n_updates            | 25360        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -4.117735    |\n",
      "|    std                  | 34.7         |\n",
      "|    value_loss           | 414          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2538         |\n",
      "|    time_elapsed         | 47112        |\n",
      "|    total_timesteps      | 5197824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005561142 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 86.1         |\n",
      "|    n_updates            | 25370        |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    reward               | 0.24442002   |\n",
      "|    std                  | 34.7         |\n",
      "|    value_loss           | 235          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2539        |\n",
      "|    time_elapsed         | 47130       |\n",
      "|    total_timesteps      | 5199872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008186264 |\n",
      "|    clip_fraction        | 0.0415      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 25380       |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    reward               | 0.33346504  |\n",
      "|    std                  | 34.8        |\n",
      "|    value_loss           | 66.3        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2540          |\n",
      "|    time_elapsed         | 47148         |\n",
      "|    total_timesteps      | 5201920       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064827106 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.679         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 184           |\n",
      "|    n_updates            | 25390         |\n",
      "|    policy_gradient_loss | -0.00255      |\n",
      "|    reward               | 0.28830484    |\n",
      "|    std                  | 34.9          |\n",
      "|    value_loss           | 235           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2541        |\n",
      "|    time_elapsed         | 47166       |\n",
      "|    total_timesteps      | 5203968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000541223 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 25400       |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    reward               | 5.7773037   |\n",
      "|    std                  | 34.9        |\n",
      "|    value_loss           | 304         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9701153.05\n",
      "total_reward: 8701153.05\n",
      "total_cost: 305189.00\n",
      "total_trades: 64878\n",
      "Sharpe: 1.031\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2542         |\n",
      "|    time_elapsed         | 47185        |\n",
      "|    total_timesteps      | 5206016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025718529 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.3         |\n",
      "|    n_updates            | 25410        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    reward               | -2.7639737   |\n",
      "|    std                  | 35           |\n",
      "|    value_loss           | 73.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2543          |\n",
      "|    time_elapsed         | 47203         |\n",
      "|    total_timesteps      | 5208064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040999605 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.747         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 47.7          |\n",
      "|    n_updates            | 25420         |\n",
      "|    policy_gradient_loss | -0.000999     |\n",
      "|    reward               | 0.23884976    |\n",
      "|    std                  | 35            |\n",
      "|    value_loss           | 284           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2544          |\n",
      "|    time_elapsed         | 47221         |\n",
      "|    total_timesteps      | 5210112       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024839176 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.702         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 241           |\n",
      "|    n_updates            | 25430         |\n",
      "|    policy_gradient_loss | -0.000938     |\n",
      "|    reward               | 15.680362     |\n",
      "|    std                  | 35.1          |\n",
      "|    value_loss           | 469           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2545         |\n",
      "|    time_elapsed         | 47240        |\n",
      "|    total_timesteps      | 5212160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024284155 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 113          |\n",
      "|    n_updates            | 25440        |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | 0.008351299  |\n",
      "|    std                  | 35.2         |\n",
      "|    value_loss           | 153          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2546         |\n",
      "|    time_elapsed         | 47258        |\n",
      "|    total_timesteps      | 5214208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012061712 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 169          |\n",
      "|    n_updates            | 25450        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | -1.0804437   |\n",
      "|    std                  | 35.2         |\n",
      "|    value_loss           | 236          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2547          |\n",
      "|    time_elapsed         | 47277         |\n",
      "|    total_timesteps      | 5216256       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.6013396e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.242         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 195           |\n",
      "|    n_updates            | 25460         |\n",
      "|    policy_gradient_loss | -0.000412     |\n",
      "|    reward               | 1.866843      |\n",
      "|    std                  | 35.2          |\n",
      "|    value_loss           | 699           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2548          |\n",
      "|    time_elapsed         | 47296         |\n",
      "|    total_timesteps      | 5218304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026308236 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.381         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 176           |\n",
      "|    n_updates            | 25470         |\n",
      "|    policy_gradient_loss | -0.00125      |\n",
      "|    reward               | 1.3089153     |\n",
      "|    std                  | 35.3          |\n",
      "|    value_loss           | 408           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2549        |\n",
      "|    time_elapsed         | 47315       |\n",
      "|    total_timesteps      | 5220352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008757342 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 25480       |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    reward               | 1.5083812   |\n",
      "|    std                  | 35.4        |\n",
      "|    value_loss           | 46          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2550         |\n",
      "|    time_elapsed         | 47334        |\n",
      "|    total_timesteps      | 5222400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004652188 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.5         |\n",
      "|    n_updates            | 25490        |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | 0.9825481    |\n",
      "|    std                  | 35.5         |\n",
      "|    value_loss           | 221          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2551         |\n",
      "|    time_elapsed         | 47353        |\n",
      "|    total_timesteps      | 5224448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006154188 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 110          |\n",
      "|    n_updates            | 25500        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | -4.2703524   |\n",
      "|    std                  | 35.5         |\n",
      "|    value_loss           | 249          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2552         |\n",
      "|    time_elapsed         | 47371        |\n",
      "|    total_timesteps      | 5226496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064506717 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.186        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 140          |\n",
      "|    n_updates            | 25510        |\n",
      "|    policy_gradient_loss | -0.00923     |\n",
      "|    reward               | -0.1833002   |\n",
      "|    std                  | 35.6         |\n",
      "|    value_loss           | 183          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2553        |\n",
      "|    time_elapsed         | 47390       |\n",
      "|    total_timesteps      | 5228544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004004535 |\n",
      "|    clip_fraction        | 0.00684     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 255         |\n",
      "|    n_updates            | 25520       |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | 0.7916222   |\n",
      "|    std                  | 35.7        |\n",
      "|    value_loss           | 398         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2554         |\n",
      "|    time_elapsed         | 47409        |\n",
      "|    total_timesteps      | 5230592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018784528 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 126          |\n",
      "|    n_updates            | 25530        |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    reward               | 0.38015124   |\n",
      "|    std                  | 35.8         |\n",
      "|    value_loss           | 441          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2555          |\n",
      "|    time_elapsed         | 47427         |\n",
      "|    total_timesteps      | 5232640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033939426 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.735         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 122           |\n",
      "|    n_updates            | 25540         |\n",
      "|    policy_gradient_loss | -0.00152      |\n",
      "|    reward               | 1.9074655     |\n",
      "|    std                  | 35.8          |\n",
      "|    value_loss           | 312           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7981069.47\n",
      "total_reward: 6981069.47\n",
      "total_cost: 310002.51\n",
      "total_trades: 64635\n",
      "Sharpe: 0.933\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2556         |\n",
      "|    time_elapsed         | 47446        |\n",
      "|    total_timesteps      | 5234688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101231765 |\n",
      "|    clip_fraction        | 0.0504       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.716        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 25550        |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    reward               | 0.9871441    |\n",
      "|    std                  | 35.9         |\n",
      "|    value_loss           | 39.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2557          |\n",
      "|    time_elapsed         | 47465         |\n",
      "|    total_timesteps      | 5236736       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00085422467 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.723         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 90.7          |\n",
      "|    n_updates            | 25560         |\n",
      "|    policy_gradient_loss | -0.00261      |\n",
      "|    reward               | -0.7381848    |\n",
      "|    std                  | 35.9          |\n",
      "|    value_loss           | 209           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2558         |\n",
      "|    time_elapsed         | 47483        |\n",
      "|    total_timesteps      | 5238784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006814661 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 203          |\n",
      "|    n_updates            | 25570        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | 2.8720603    |\n",
      "|    std                  | 36           |\n",
      "|    value_loss           | 406          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2559         |\n",
      "|    time_elapsed         | 47501        |\n",
      "|    total_timesteps      | 5240832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027207718 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27           |\n",
      "|    n_updates            | 25580        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    reward               | 3.667752     |\n",
      "|    std                  | 36.1         |\n",
      "|    value_loss           | 69.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2560        |\n",
      "|    time_elapsed         | 47519       |\n",
      "|    total_timesteps      | 5242880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001323024 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 25590       |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    reward               | -1.294248   |\n",
      "|    std                  | 36.1        |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2561          |\n",
      "|    time_elapsed         | 47538         |\n",
      "|    total_timesteps      | 5244928       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011839002 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.47          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 203           |\n",
      "|    n_updates            | 25600         |\n",
      "|    policy_gradient_loss | -0.000931     |\n",
      "|    reward               | -11.494833    |\n",
      "|    std                  | 36.1          |\n",
      "|    value_loss           | 398           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2562         |\n",
      "|    time_elapsed         | 47557        |\n",
      "|    total_timesteps      | 5246976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008142375 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 137          |\n",
      "|    n_updates            | 25610        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | -1.5006247   |\n",
      "|    std                  | 36.2         |\n",
      "|    value_loss           | 171          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2563         |\n",
      "|    time_elapsed         | 47575        |\n",
      "|    total_timesteps      | 5249024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031949067 |\n",
      "|    clip_fraction        | 0.004        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.6         |\n",
      "|    n_updates            | 25620        |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    reward               | -3.4580965   |\n",
      "|    std                  | 36.3         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2564         |\n",
      "|    time_elapsed         | 47593        |\n",
      "|    total_timesteps      | 5251072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001498657 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 87.1         |\n",
      "|    n_updates            | 25630        |\n",
      "|    policy_gradient_loss | -0.000674    |\n",
      "|    reward               | 2.0314171    |\n",
      "|    std                  | 36.4         |\n",
      "|    value_loss           | 252          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2565         |\n",
      "|    time_elapsed         | 47611        |\n",
      "|    total_timesteps      | 5253120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015896133 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 148          |\n",
      "|    n_updates            | 25640        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | 6.3415003    |\n",
      "|    std                  | 36.5         |\n",
      "|    value_loss           | 307          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2566         |\n",
      "|    time_elapsed         | 47630        |\n",
      "|    total_timesteps      | 5255168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076271268 |\n",
      "|    clip_fraction        | 0.0388       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.206        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 25650        |\n",
      "|    policy_gradient_loss | -0.00905     |\n",
      "|    reward               | 0.10009547   |\n",
      "|    std                  | 36.5         |\n",
      "|    value_loss           | 58.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2567          |\n",
      "|    time_elapsed         | 47648         |\n",
      "|    total_timesteps      | 5257216       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067043566 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.118         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 104           |\n",
      "|    n_updates            | 25660         |\n",
      "|    policy_gradient_loss | -0.0021       |\n",
      "|    reward               | -0.9902753    |\n",
      "|    std                  | 36.5          |\n",
      "|    value_loss           | 362           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2568          |\n",
      "|    time_elapsed         | 47667         |\n",
      "|    total_timesteps      | 5259264       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014561761 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.811         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 168           |\n",
      "|    n_updates            | 25670         |\n",
      "|    policy_gradient_loss | -0.000715     |\n",
      "|    reward               | -0.1209441    |\n",
      "|    std                  | 36.6          |\n",
      "|    value_loss           | 360           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2569         |\n",
      "|    time_elapsed         | 47686        |\n",
      "|    total_timesteps      | 5261312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030665288 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.4         |\n",
      "|    n_updates            | 25680        |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    reward               | 0.6104777    |\n",
      "|    std                  | 36.7         |\n",
      "|    value_loss           | 128          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8198933.89\n",
      "total_reward: 7198933.89\n",
      "total_cost: 342848.90\n",
      "total_trades: 66198\n",
      "Sharpe: 0.975\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2570         |\n",
      "|    time_elapsed         | 47704        |\n",
      "|    total_timesteps      | 5263360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036322246 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 130          |\n",
      "|    n_updates            | 25690        |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    reward               | -0.44870788  |\n",
      "|    std                  | 36.8         |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2571          |\n",
      "|    time_elapsed         | 47722         |\n",
      "|    total_timesteps      | 5265408       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023307078 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.581         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 85.9          |\n",
      "|    n_updates            | 25700         |\n",
      "|    policy_gradient_loss | -0.000967     |\n",
      "|    reward               | -0.3461779    |\n",
      "|    std                  | 36.8          |\n",
      "|    value_loss           | 201           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2572          |\n",
      "|    time_elapsed         | 47740         |\n",
      "|    total_timesteps      | 5267456       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048791943 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.656         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 80.6          |\n",
      "|    n_updates            | 25710         |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    reward               | -1.4803481    |\n",
      "|    std                  | 36.8          |\n",
      "|    value_loss           | 190           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2573        |\n",
      "|    time_elapsed         | 47759       |\n",
      "|    total_timesteps      | 5269504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009860888 |\n",
      "|    clip_fraction        | 0.0699      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -145        |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 25720       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 1.8952694   |\n",
      "|    std                  | 36.9        |\n",
      "|    value_loss           | 36.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2574          |\n",
      "|    time_elapsed         | 47777         |\n",
      "|    total_timesteps      | 5271552       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033368703 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.708         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 74.1          |\n",
      "|    n_updates            | 25730         |\n",
      "|    policy_gradient_loss | -0.00186      |\n",
      "|    reward               | 0.40702504    |\n",
      "|    std                  | 36.9          |\n",
      "|    value_loss           | 220           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2575          |\n",
      "|    time_elapsed         | 47795         |\n",
      "|    total_timesteps      | 5273600       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012246412 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.276         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 140           |\n",
      "|    n_updates            | 25740         |\n",
      "|    policy_gradient_loss | -0.000911     |\n",
      "|    reward               | 0.7956466     |\n",
      "|    std                  | 36.9          |\n",
      "|    value_loss           | 259           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2576        |\n",
      "|    time_elapsed         | 47813       |\n",
      "|    total_timesteps      | 5275648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000765708 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -145        |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.8        |\n",
      "|    n_updates            | 25750       |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    reward               | -0.4539734  |\n",
      "|    std                  | 37          |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2577         |\n",
      "|    time_elapsed         | 47832        |\n",
      "|    total_timesteps      | 5277696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018400485 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.856        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42           |\n",
      "|    n_updates            | 25760        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | 0.18258639   |\n",
      "|    std                  | 37           |\n",
      "|    value_loss           | 91.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2578          |\n",
      "|    time_elapsed         | 47850         |\n",
      "|    total_timesteps      | 5279744       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063508097 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.797         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 66            |\n",
      "|    n_updates            | 25770         |\n",
      "|    policy_gradient_loss | -0.00181      |\n",
      "|    reward               | -0.38745973   |\n",
      "|    std                  | 37.1          |\n",
      "|    value_loss           | 178           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2579          |\n",
      "|    time_elapsed         | 47868         |\n",
      "|    total_timesteps      | 5281792       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067597255 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.642         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 87.4          |\n",
      "|    n_updates            | 25780         |\n",
      "|    policy_gradient_loss | -0.00247      |\n",
      "|    reward               | -5.428004     |\n",
      "|    std                  | 37.1          |\n",
      "|    value_loss           | 166           |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2580       |\n",
      "|    time_elapsed         | 47887      |\n",
      "|    total_timesteps      | 5283840    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01041452 |\n",
      "|    clip_fraction        | 0.0675     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -145       |\n",
      "|    explained_variance   | 0.42       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.9       |\n",
      "|    n_updates            | 25790      |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    reward               | 2.5315049  |\n",
      "|    std                  | 37.3       |\n",
      "|    value_loss           | 30.6       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2581          |\n",
      "|    time_elapsed         | 47905         |\n",
      "|    total_timesteps      | 5285888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016358326 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.527         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 35.4          |\n",
      "|    n_updates            | 25800         |\n",
      "|    policy_gradient_loss | -0.00102      |\n",
      "|    reward               | -0.2282214    |\n",
      "|    std                  | 37.3          |\n",
      "|    value_loss           | 142           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2582          |\n",
      "|    time_elapsed         | 47924         |\n",
      "|    total_timesteps      | 5287936       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033114114 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.334         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 85.7          |\n",
      "|    n_updates            | 25810         |\n",
      "|    policy_gradient_loss | -0.00141      |\n",
      "|    reward               | -0.087395     |\n",
      "|    std                  | 37.4          |\n",
      "|    value_loss           | 194           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2583        |\n",
      "|    time_elapsed         | 47942       |\n",
      "|    total_timesteps      | 5289984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001296495 |\n",
      "|    clip_fraction        | 0.000146    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -145        |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 25820       |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    reward               | 1.1955961   |\n",
      "|    std                  | 37.5        |\n",
      "|    value_loss           | 41.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7403346.64\n",
      "total_reward: 6403346.64\n",
      "total_cost: 346197.94\n",
      "total_trades: 66531\n",
      "Sharpe: 0.917\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2584         |\n",
      "|    time_elapsed         | 47960        |\n",
      "|    total_timesteps      | 5292032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009357772 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.315        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.3         |\n",
      "|    n_updates            | 25830        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | 0.046299845  |\n",
      "|    std                  | 37.5         |\n",
      "|    value_loss           | 137          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2585          |\n",
      "|    time_elapsed         | 47978         |\n",
      "|    total_timesteps      | 5294080       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040527552 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.562         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 70.3          |\n",
      "|    n_updates            | 25840         |\n",
      "|    policy_gradient_loss | -0.00181      |\n",
      "|    reward               | -2.2924237    |\n",
      "|    std                  | 37.6          |\n",
      "|    value_loss           | 156           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2586          |\n",
      "|    time_elapsed         | 47998         |\n",
      "|    total_timesteps      | 5296128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013585531 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.484         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 133           |\n",
      "|    n_updates            | 25850         |\n",
      "|    policy_gradient_loss | -0.000546     |\n",
      "|    reward               | 4.970971      |\n",
      "|    std                  | 37.6          |\n",
      "|    value_loss           | 196           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2587         |\n",
      "|    time_elapsed         | 48016        |\n",
      "|    total_timesteps      | 5298176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032484625 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.763        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.6         |\n",
      "|    n_updates            | 25860        |\n",
      "|    policy_gradient_loss | -0.00534     |\n",
      "|    reward               | 0.97941273   |\n",
      "|    std                  | 37.6         |\n",
      "|    value_loss           | 79.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2588         |\n",
      "|    time_elapsed         | 48035        |\n",
      "|    total_timesteps      | 5300224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009801356 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.1         |\n",
      "|    n_updates            | 25870        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | -0.05272968  |\n",
      "|    std                  | 37.7         |\n",
      "|    value_loss           | 139          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2589         |\n",
      "|    time_elapsed         | 48054        |\n",
      "|    total_timesteps      | 5302272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007501752 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.232        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.5         |\n",
      "|    n_updates            | 25880        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | 8.604266     |\n",
      "|    std                  | 37.7         |\n",
      "|    value_loss           | 192          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2590        |\n",
      "|    time_elapsed         | 48073       |\n",
      "|    total_timesteps      | 5304320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007521143 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -145        |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 25890       |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    reward               | 3.4088411   |\n",
      "|    std                  | 37.9        |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2591          |\n",
      "|    time_elapsed         | 48091         |\n",
      "|    total_timesteps      | 5306368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047303885 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.751         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 49.6          |\n",
      "|    n_updates            | 25900         |\n",
      "|    policy_gradient_loss | -0.0013       |\n",
      "|    reward               | 1.6880362     |\n",
      "|    std                  | 37.9          |\n",
      "|    value_loss           | 115           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2592         |\n",
      "|    time_elapsed         | 48111        |\n",
      "|    total_timesteps      | 5308416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005886267 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.4         |\n",
      "|    n_updates            | 25910        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | 6.804624     |\n",
      "|    std                  | 37.9         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2593        |\n",
      "|    time_elapsed         | 48130       |\n",
      "|    total_timesteps      | 5310464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002090674 |\n",
      "|    clip_fraction        | 0.00137     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -145        |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 25920       |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    reward               | 2.6424453   |\n",
      "|    std                  | 38.1        |\n",
      "|    value_loss           | 70.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2594         |\n",
      "|    time_elapsed         | 48150        |\n",
      "|    total_timesteps      | 5312512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019791154 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.805        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 25930        |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    reward               | 1.0997233    |\n",
      "|    std                  | 38.2         |\n",
      "|    value_loss           | 80.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2595         |\n",
      "|    time_elapsed         | 48169        |\n",
      "|    total_timesteps      | 5314560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005858886 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.3         |\n",
      "|    n_updates            | 25940        |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    reward               | 0.0944846    |\n",
      "|    std                  | 38.1         |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2596         |\n",
      "|    time_elapsed         | 48188        |\n",
      "|    total_timesteps      | 5316608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015576315 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.9         |\n",
      "|    n_updates            | 25950        |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    reward               | 2.0886683    |\n",
      "|    std                  | 38.2         |\n",
      "|    value_loss           | 179          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2597         |\n",
      "|    time_elapsed         | 48206        |\n",
      "|    total_timesteps      | 5318656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067404946 |\n",
      "|    clip_fraction        | 0.0316       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.368        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 25960        |\n",
      "|    policy_gradient_loss | -0.00961     |\n",
      "|    reward               | -1.837891    |\n",
      "|    std                  | 38.3         |\n",
      "|    value_loss           | 30.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5213574.32\n",
      "total_reward: 4213574.32\n",
      "total_cost: 298847.99\n",
      "total_trades: 63704\n",
      "Sharpe: 0.716\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2598          |\n",
      "|    time_elapsed         | 48225         |\n",
      "|    total_timesteps      | 5320704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045391847 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.794         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 47.1          |\n",
      "|    n_updates            | 25970         |\n",
      "|    policy_gradient_loss | -0.00181      |\n",
      "|    reward               | -2.0487497    |\n",
      "|    std                  | 38.3          |\n",
      "|    value_loss           | 125           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2599          |\n",
      "|    time_elapsed         | 48244         |\n",
      "|    total_timesteps      | 5322752       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011040358 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.299         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 88.8          |\n",
      "|    n_updates            | 25980         |\n",
      "|    policy_gradient_loss | -0.000629     |\n",
      "|    reward               | 4.2961483     |\n",
      "|    std                  | 38.3          |\n",
      "|    value_loss           | 211           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2600         |\n",
      "|    time_elapsed         | 48263        |\n",
      "|    total_timesteps      | 5324800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060116267 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.259        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.4         |\n",
      "|    n_updates            | 25990        |\n",
      "|    policy_gradient_loss | -0.0085      |\n",
      "|    reward               | -4.181729    |\n",
      "|    std                  | 38.3         |\n",
      "|    value_loss           | 53.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2601          |\n",
      "|    time_elapsed         | 48281         |\n",
      "|    total_timesteps      | 5326848       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00076147204 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.71          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 43.1          |\n",
      "|    n_updates            | 26000         |\n",
      "|    policy_gradient_loss | -0.00214      |\n",
      "|    reward               | 0.4438988     |\n",
      "|    std                  | 38.4          |\n",
      "|    value_loss           | 89.8          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2602         |\n",
      "|    time_elapsed         | 48300        |\n",
      "|    total_timesteps      | 5328896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010763353 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.2         |\n",
      "|    n_updates            | 26010        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | -1.0430709   |\n",
      "|    std                  | 38.5         |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2603         |\n",
      "|    time_elapsed         | 48319        |\n",
      "|    total_timesteps      | 5330944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001797507 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90.3         |\n",
      "|    n_updates            | 26020        |\n",
      "|    policy_gradient_loss | -0.000628    |\n",
      "|    reward               | 1.8532627    |\n",
      "|    std                  | 38.5         |\n",
      "|    value_loss           | 196          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2604        |\n",
      "|    time_elapsed         | 48338       |\n",
      "|    total_timesteps      | 5332992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006387729 |\n",
      "|    clip_fraction        | 0.0232      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -146        |\n",
      "|    explained_variance   | -0.199      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 26030       |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    reward               | -1.540129   |\n",
      "|    std                  | 38.6        |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2605          |\n",
      "|    time_elapsed         | 48357         |\n",
      "|    total_timesteps      | 5335040       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039426264 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.519         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 54.3          |\n",
      "|    n_updates            | 26040         |\n",
      "|    policy_gradient_loss | -0.00147      |\n",
      "|    reward               | 2.244384      |\n",
      "|    std                  | 38.6          |\n",
      "|    value_loss           | 175           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2606          |\n",
      "|    time_elapsed         | 48376         |\n",
      "|    total_timesteps      | 5337088       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025775167 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.497         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 71.6          |\n",
      "|    n_updates            | 26050         |\n",
      "|    policy_gradient_loss | -0.00107      |\n",
      "|    reward               | -4.3736115    |\n",
      "|    std                  | 38.6          |\n",
      "|    value_loss           | 212           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2607         |\n",
      "|    time_elapsed         | 48394        |\n",
      "|    total_timesteps      | 5339136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021475838 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.186        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.1         |\n",
      "|    n_updates            | 26060        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    reward               | -2.4074414   |\n",
      "|    std                  | 38.6         |\n",
      "|    value_loss           | 81.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2608         |\n",
      "|    time_elapsed         | 48413        |\n",
      "|    total_timesteps      | 5341184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007235446 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.5         |\n",
      "|    n_updates            | 26070        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | 0.07535929   |\n",
      "|    std                  | 38.7         |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2609        |\n",
      "|    time_elapsed         | 48431       |\n",
      "|    total_timesteps      | 5343232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001344302 |\n",
      "|    clip_fraction        | 0.000537    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -146        |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.2        |\n",
      "|    n_updates            | 26080       |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    reward               | 3.2205248   |\n",
      "|    std                  | 38.7        |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2610        |\n",
      "|    time_elapsed         | 48449       |\n",
      "|    total_timesteps      | 5345280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000832648 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -146        |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 26090       |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    reward               | 1.7660928   |\n",
      "|    std                  | 38.7        |\n",
      "|    value_loss           | 99.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2611         |\n",
      "|    time_elapsed         | 48468        |\n",
      "|    total_timesteps      | 5347328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046601994 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.0557       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.1         |\n",
      "|    n_updates            | 26100        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    reward               | -0.3482177   |\n",
      "|    std                  | 38.8         |\n",
      "|    value_loss           | 92.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5965314.72\n",
      "total_reward: 4965314.72\n",
      "total_cost: 290892.21\n",
      "total_trades: 64180\n",
      "Sharpe: 0.781\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2612          |\n",
      "|    time_elapsed         | 48486         |\n",
      "|    total_timesteps      | 5349376       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031183835 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.652         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 56.6          |\n",
      "|    n_updates            | 26110         |\n",
      "|    policy_gradient_loss | -0.00121      |\n",
      "|    reward               | 0.36440578    |\n",
      "|    std                  | 38.9          |\n",
      "|    value_loss           | 140           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2613          |\n",
      "|    time_elapsed         | 48505         |\n",
      "|    total_timesteps      | 5351424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030134464 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.432         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 151           |\n",
      "|    n_updates            | 26120         |\n",
      "|    policy_gradient_loss | -0.00109      |\n",
      "|    reward               | 1.4479138     |\n",
      "|    std                  | 38.9          |\n",
      "|    value_loss           | 217           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2614         |\n",
      "|    time_elapsed         | 48525        |\n",
      "|    total_timesteps      | 5353472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062489286 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.337        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 26130        |\n",
      "|    policy_gradient_loss | -0.00719     |\n",
      "|    reward               | 1.4378005    |\n",
      "|    std                  | 38.9         |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2615         |\n",
      "|    time_elapsed         | 48545        |\n",
      "|    total_timesteps      | 5355520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006976753 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.9         |\n",
      "|    n_updates            | 26140        |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    reward               | -0.8723414   |\n",
      "|    std                  | 38.9         |\n",
      "|    value_loss           | 88.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2616         |\n",
      "|    time_elapsed         | 48564        |\n",
      "|    total_timesteps      | 5357568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007980499 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.287        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 175          |\n",
      "|    n_updates            | 26150        |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    reward               | 4.1281705    |\n",
      "|    std                  | 38.9         |\n",
      "|    value_loss           | 279          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2617         |\n",
      "|    time_elapsed         | 48584        |\n",
      "|    total_timesteps      | 5359616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002982204 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.267        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.6         |\n",
      "|    n_updates            | 26160        |\n",
      "|    policy_gradient_loss | -0.000942    |\n",
      "|    reward               | 5.8393135    |\n",
      "|    std                  | 39           |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2618         |\n",
      "|    time_elapsed         | 48603        |\n",
      "|    total_timesteps      | 5361664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018820518 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.8         |\n",
      "|    n_updates            | 26170        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    reward               | 0.23000902   |\n",
      "|    std                  | 39           |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2619          |\n",
      "|    time_elapsed         | 48622         |\n",
      "|    total_timesteps      | 5363712       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047140702 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.541         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 69.8          |\n",
      "|    n_updates            | 26180         |\n",
      "|    policy_gradient_loss | -0.00203      |\n",
      "|    reward               | -1.9643844    |\n",
      "|    std                  | 39            |\n",
      "|    value_loss           | 144           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2620          |\n",
      "|    time_elapsed         | 48641         |\n",
      "|    total_timesteps      | 5365760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024054904 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.497         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 98.9          |\n",
      "|    n_updates            | 26190         |\n",
      "|    policy_gradient_loss | -0.00117      |\n",
      "|    reward               | -0.22225726   |\n",
      "|    std                  | 39            |\n",
      "|    value_loss           | 208           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2621         |\n",
      "|    time_elapsed         | 48660        |\n",
      "|    total_timesteps      | 5367808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074791964 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 26200        |\n",
      "|    policy_gradient_loss | -0.00828     |\n",
      "|    reward               | 0.9504884    |\n",
      "|    std                  | 39.3         |\n",
      "|    value_loss           | 28.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2622         |\n",
      "|    time_elapsed         | 48679        |\n",
      "|    total_timesteps      | 5369856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008535856 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.8         |\n",
      "|    n_updates            | 26210        |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    reward               | -0.008851528 |\n",
      "|    std                  | 39.4         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2623          |\n",
      "|    time_elapsed         | 48697         |\n",
      "|    total_timesteps      | 5371904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066797825 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.739         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 53            |\n",
      "|    n_updates            | 26220         |\n",
      "|    policy_gradient_loss | -0.00275      |\n",
      "|    reward               | -0.66399777   |\n",
      "|    std                  | 39.5          |\n",
      "|    value_loss           | 129           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2624         |\n",
      "|    time_elapsed         | 48715        |\n",
      "|    total_timesteps      | 5373952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021757367 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.3         |\n",
      "|    n_updates            | 26230        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | -3.258769    |\n",
      "|    std                  | 39.6         |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2625         |\n",
      "|    time_elapsed         | 48734        |\n",
      "|    total_timesteps      | 5376000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022214148 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.5         |\n",
      "|    n_updates            | 26240        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | 0.27352777   |\n",
      "|    std                  | 39.7         |\n",
      "|    value_loss           | 95.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2626         |\n",
      "|    time_elapsed         | 48753        |\n",
      "|    total_timesteps      | 5378048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015002398 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.5         |\n",
      "|    n_updates            | 26250        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | 5.053488     |\n",
      "|    std                  | 39.8         |\n",
      "|    value_loss           | 122          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6818424.90\n",
      "total_reward: 5818424.90\n",
      "total_cost: 353306.97\n",
      "total_trades: 66608\n",
      "Sharpe: 0.871\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2627          |\n",
      "|    time_elapsed         | 48771         |\n",
      "|    total_timesteps      | 5380096       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053923647 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.61          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 68.2          |\n",
      "|    n_updates            | 26260         |\n",
      "|    policy_gradient_loss | -0.00151      |\n",
      "|    reward               | 0.36953598    |\n",
      "|    std                  | 39.8          |\n",
      "|    value_loss           | 149           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2628        |\n",
      "|    time_elapsed         | 48790       |\n",
      "|    total_timesteps      | 5382144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005797467 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -147        |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 26270       |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    reward               | -0.66252774 |\n",
      "|    std                  | 39.9        |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2629          |\n",
      "|    time_elapsed         | 48809         |\n",
      "|    total_timesteps      | 5384192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034492655 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.475         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 147           |\n",
      "|    n_updates            | 26280         |\n",
      "|    policy_gradient_loss | -0.00117      |\n",
      "|    reward               | 0.1273777     |\n",
      "|    std                  | 39.9          |\n",
      "|    value_loss           | 185           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2630        |\n",
      "|    time_elapsed         | 48827       |\n",
      "|    total_timesteps      | 5386240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001792989 |\n",
      "|    clip_fraction        | 0.000195    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -147        |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.6        |\n",
      "|    n_updates            | 26290       |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    reward               | 0.6526967   |\n",
      "|    std                  | 40          |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2631         |\n",
      "|    time_elapsed         | 48846        |\n",
      "|    total_timesteps      | 5388288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024017403 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.3         |\n",
      "|    n_updates            | 26300        |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    reward               | 1.4483925    |\n",
      "|    std                  | 40.2         |\n",
      "|    value_loss           | 88.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2632         |\n",
      "|    time_elapsed         | 48865        |\n",
      "|    total_timesteps      | 5390336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009418755 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.6         |\n",
      "|    n_updates            | 26310        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | -2.2626865   |\n",
      "|    std                  | 40.3         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2633         |\n",
      "|    time_elapsed         | 48883        |\n",
      "|    total_timesteps      | 5392384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005136617 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64           |\n",
      "|    n_updates            | 26320        |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    reward               | -0.06536663  |\n",
      "|    std                  | 40.4         |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2634          |\n",
      "|    time_elapsed         | 48902         |\n",
      "|    total_timesteps      | 5394432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019138498 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.379         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 42.4          |\n",
      "|    n_updates            | 26330         |\n",
      "|    policy_gradient_loss | -0.000797     |\n",
      "|    reward               | -0.5879021    |\n",
      "|    std                  | 40.4          |\n",
      "|    value_loss           | 163           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2635         |\n",
      "|    time_elapsed         | 48921        |\n",
      "|    total_timesteps      | 5396480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026858211 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 26340        |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    reward               | 0.029214855  |\n",
      "|    std                  | 40.5         |\n",
      "|    value_loss           | 65.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2636         |\n",
      "|    time_elapsed         | 48940        |\n",
      "|    total_timesteps      | 5398528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005650135 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.7         |\n",
      "|    n_updates            | 26350        |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    reward               | 2.5573251    |\n",
      "|    std                  | 40.6         |\n",
      "|    value_loss           | 159          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2637         |\n",
      "|    time_elapsed         | 48958        |\n",
      "|    total_timesteps      | 5400576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014384332 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.647        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42           |\n",
      "|    n_updates            | 26360        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | 4.5526       |\n",
      "|    std                  | 40.7         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2638        |\n",
      "|    time_elapsed         | 48976       |\n",
      "|    total_timesteps      | 5402624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009111205 |\n",
      "|    clip_fraction        | 0.0541      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -147        |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 26370       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -1.9305454  |\n",
      "|    std                  | 41          |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2639         |\n",
      "|    time_elapsed         | 48995        |\n",
      "|    total_timesteps      | 5404672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004893601 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.1         |\n",
      "|    n_updates            | 26380        |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    reward               | 1.1902319    |\n",
      "|    std                  | 41           |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2640         |\n",
      "|    time_elapsed         | 49013        |\n",
      "|    total_timesteps      | 5406720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010067737 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.7         |\n",
      "|    n_updates            | 26390        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | 0.45153996   |\n",
      "|    std                  | 41           |\n",
      "|    value_loss           | 145          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5424219.26\n",
      "total_reward: 4424219.26\n",
      "total_cost: 257571.18\n",
      "total_trades: 62230\n",
      "Sharpe: 0.722\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2641         |\n",
      "|    time_elapsed         | 49031        |\n",
      "|    total_timesteps      | 5408768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006100538 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.233        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.3         |\n",
      "|    n_updates            | 26400        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    reward               | 3.2737002    |\n",
      "|    std                  | 41.1         |\n",
      "|    value_loss           | 159          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2642         |\n",
      "|    time_elapsed         | 49050        |\n",
      "|    total_timesteps      | 5410816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017396274 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.152        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.6         |\n",
      "|    n_updates            | 26410        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | 0.6408912    |\n",
      "|    std                  | 41.2         |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2643         |\n",
      "|    time_elapsed         | 49069        |\n",
      "|    total_timesteps      | 5412864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038430174 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 94.7         |\n",
      "|    n_updates            | 26420        |\n",
      "|    policy_gradient_loss | -0.00622     |\n",
      "|    reward               | 0.9791823    |\n",
      "|    std                  | 41.2         |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2644         |\n",
      "|    time_elapsed         | 49088        |\n",
      "|    total_timesteps      | 5414912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008226171 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.328        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.6         |\n",
      "|    n_updates            | 26430        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    reward               | 0.69185984   |\n",
      "|    std                  | 41.3         |\n",
      "|    value_loss           | 181          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2645       |\n",
      "|    time_elapsed         | 49107      |\n",
      "|    total_timesteps      | 5416960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00811452 |\n",
      "|    clip_fraction        | 0.0415     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -148       |\n",
      "|    explained_variance   | 0.552      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.9       |\n",
      "|    n_updates            | 26440      |\n",
      "|    policy_gradient_loss | -0.00981   |\n",
      "|    reward               | 0.28059402 |\n",
      "|    std                  | 41.4       |\n",
      "|    value_loss           | 25.4       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2646          |\n",
      "|    time_elapsed         | 49126         |\n",
      "|    total_timesteps      | 5419008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070828723 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.599         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 48.9          |\n",
      "|    n_updates            | 26450         |\n",
      "|    policy_gradient_loss | -0.00249      |\n",
      "|    reward               | 2.692315      |\n",
      "|    std                  | 41.5          |\n",
      "|    value_loss           | 96            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2647         |\n",
      "|    time_elapsed         | 49145        |\n",
      "|    total_timesteps      | 5421056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024007224 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.18         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93.3         |\n",
      "|    n_updates            | 26460        |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    reward               | 4.7194557    |\n",
      "|    std                  | 41.6         |\n",
      "|    value_loss           | 205          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2648        |\n",
      "|    time_elapsed         | 49163       |\n",
      "|    total_timesteps      | 5423104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008915593 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 26470       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -0.95509195 |\n",
      "|    std                  | 41.7        |\n",
      "|    value_loss           | 47.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2649         |\n",
      "|    time_elapsed         | 49181        |\n",
      "|    total_timesteps      | 5425152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003789741 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93.6         |\n",
      "|    n_updates            | 26480        |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    reward               | -0.14505696  |\n",
      "|    std                  | 41.7         |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2650        |\n",
      "|    time_elapsed         | 49200       |\n",
      "|    total_timesteps      | 5427200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000882281 |\n",
      "|    clip_fraction        | 9.77e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 159         |\n",
      "|    n_updates            | 26490       |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    reward               | -2.4593346  |\n",
      "|    std                  | 41.7        |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2651         |\n",
      "|    time_elapsed         | 49220        |\n",
      "|    total_timesteps      | 5429248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015731833 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.2         |\n",
      "|    n_updates            | 26500        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | 0.930721     |\n",
      "|    std                  | 41.8         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2652         |\n",
      "|    time_elapsed         | 49239        |\n",
      "|    total_timesteps      | 5431296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029795917 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.755        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.5         |\n",
      "|    n_updates            | 26510        |\n",
      "|    policy_gradient_loss | -0.00504     |\n",
      "|    reward               | 1.3699881    |\n",
      "|    std                  | 41.8         |\n",
      "|    value_loss           | 57.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2653         |\n",
      "|    time_elapsed         | 49258        |\n",
      "|    total_timesteps      | 5433344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003357565 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.8         |\n",
      "|    n_updates            | 26520        |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    reward               | 1.0873679    |\n",
      "|    std                  | 41.9         |\n",
      "|    value_loss           | 169          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2654         |\n",
      "|    time_elapsed         | 49277        |\n",
      "|    total_timesteps      | 5435392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002004902 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.5         |\n",
      "|    n_updates            | 26530        |\n",
      "|    policy_gradient_loss | -0.000886    |\n",
      "|    reward               | -0.20829971  |\n",
      "|    std                  | 41.9         |\n",
      "|    value_loss           | 203          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7346606.92\n",
      "total_reward: 6346606.92\n",
      "total_cost: 331643.37\n",
      "total_trades: 65604\n",
      "Sharpe: 0.873\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2655        |\n",
      "|    time_elapsed         | 49295       |\n",
      "|    total_timesteps      | 5437440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008931354 |\n",
      "|    clip_fraction        | 0.0487      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 26540       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -2.9090755  |\n",
      "|    std                  | 41.8        |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2656          |\n",
      "|    time_elapsed         | 49313         |\n",
      "|    total_timesteps      | 5439488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035610973 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.669         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 139           |\n",
      "|    n_updates            | 26550         |\n",
      "|    policy_gradient_loss | -0.00194      |\n",
      "|    reward               | -0.71589625   |\n",
      "|    std                  | 41.8          |\n",
      "|    value_loss           | 237           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2657         |\n",
      "|    time_elapsed         | 49331        |\n",
      "|    total_timesteps      | 5441536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.847887e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.9         |\n",
      "|    n_updates            | 26560        |\n",
      "|    policy_gradient_loss | -0.000567    |\n",
      "|    reward               | -3.5419183   |\n",
      "|    std                  | 41.9         |\n",
      "|    value_loss           | 238          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2658         |\n",
      "|    time_elapsed         | 49349        |\n",
      "|    total_timesteps      | 5443584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008030019 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.4         |\n",
      "|    n_updates            | 26570        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | -1.8813024   |\n",
      "|    std                  | 41.9         |\n",
      "|    value_loss           | 86           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2659          |\n",
      "|    time_elapsed         | 49366         |\n",
      "|    total_timesteps      | 5445632       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00097606686 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.759         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.4          |\n",
      "|    n_updates            | 26580         |\n",
      "|    policy_gradient_loss | -0.00268      |\n",
      "|    reward               | 4.205332      |\n",
      "|    std                  | 42            |\n",
      "|    value_loss           | 102           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2660         |\n",
      "|    time_elapsed         | 49385        |\n",
      "|    total_timesteps      | 5447680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.329836e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 106          |\n",
      "|    n_updates            | 26590        |\n",
      "|    policy_gradient_loss | -0.000567    |\n",
      "|    reward               | -0.06167116  |\n",
      "|    std                  | 42           |\n",
      "|    value_loss           | 242          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2661         |\n",
      "|    time_elapsed         | 49405        |\n",
      "|    total_timesteps      | 5449728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009440606 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.3         |\n",
      "|    n_updates            | 26600        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    reward               | 0.7560194    |\n",
      "|    std                  | 42.1         |\n",
      "|    value_loss           | 177          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2662         |\n",
      "|    time_elapsed         | 49424        |\n",
      "|    total_timesteps      | 5451776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064311987 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 26610        |\n",
      "|    policy_gradient_loss | -0.00847     |\n",
      "|    reward               | 0.7466008    |\n",
      "|    std                  | 42.1         |\n",
      "|    value_loss           | 36.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2663          |\n",
      "|    time_elapsed         | 49443         |\n",
      "|    total_timesteps      | 5453824       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037317252 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.745         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 84            |\n",
      "|    n_updates            | 26620         |\n",
      "|    policy_gradient_loss | -0.00166      |\n",
      "|    reward               | -1.1962408    |\n",
      "|    std                  | 42.1          |\n",
      "|    value_loss           | 178           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2664          |\n",
      "|    time_elapsed         | 49462         |\n",
      "|    total_timesteps      | 5455872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6064383e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.145         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 199           |\n",
      "|    n_updates            | 26630         |\n",
      "|    policy_gradient_loss | -0.000278     |\n",
      "|    reward               | 3.8286493     |\n",
      "|    std                  | 42.1          |\n",
      "|    value_loss           | 463           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2665         |\n",
      "|    time_elapsed         | 49480        |\n",
      "|    total_timesteps      | 5457920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010882677 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.3          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 26640        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | -0.50680155  |\n",
      "|    std                  | 42.2         |\n",
      "|    value_loss           | 92.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2666         |\n",
      "|    time_elapsed         | 49499        |\n",
      "|    total_timesteps      | 5459968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007377275 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.7         |\n",
      "|    n_updates            | 26650        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | 0.050416578  |\n",
      "|    std                  | 42.2         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2667          |\n",
      "|    time_elapsed         | 49518         |\n",
      "|    total_timesteps      | 5462016       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046093942 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.741         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 70.8          |\n",
      "|    n_updates            | 26660         |\n",
      "|    policy_gradient_loss | -0.00177      |\n",
      "|    reward               | 0.026832307   |\n",
      "|    std                  | 42.2          |\n",
      "|    value_loss           | 163           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2668          |\n",
      "|    time_elapsed         | 49537         |\n",
      "|    total_timesteps      | 5464064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046936038 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.613         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 69.7          |\n",
      "|    n_updates            | 26670         |\n",
      "|    policy_gradient_loss | -0.00226      |\n",
      "|    reward               | -0.5900458    |\n",
      "|    std                  | 42.3          |\n",
      "|    value_loss           | 185           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6572997.48\n",
      "total_reward: 5572997.48\n",
      "total_cost: 257553.00\n",
      "total_trades: 62756\n",
      "Sharpe: 0.804\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2669        |\n",
      "|    time_elapsed         | 49556       |\n",
      "|    total_timesteps      | 5466112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009550762 |\n",
      "|    clip_fraction        | 0.0446      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 26680       |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    reward               | 2.0925188   |\n",
      "|    std                  | 42.3        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2670          |\n",
      "|    time_elapsed         | 49575         |\n",
      "|    total_timesteps      | 5468160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014034589 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.745         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 87.4          |\n",
      "|    n_updates            | 26690         |\n",
      "|    policy_gradient_loss | -0.000772     |\n",
      "|    reward               | 0.90388197    |\n",
      "|    std                  | 42.4          |\n",
      "|    value_loss           | 131           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2671          |\n",
      "|    time_elapsed         | 49594         |\n",
      "|    total_timesteps      | 5470208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031073016 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.756         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 46.3          |\n",
      "|    n_updates            | 26700         |\n",
      "|    policy_gradient_loss | -0.00165      |\n",
      "|    reward               | -4.947995     |\n",
      "|    std                  | 42.4          |\n",
      "|    value_loss           | 179           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2672         |\n",
      "|    time_elapsed         | 49613        |\n",
      "|    total_timesteps      | 5472256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004837351  |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.387        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 26710        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    reward               | -0.025342528 |\n",
      "|    std                  | 42.4         |\n",
      "|    value_loss           | 54.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2673         |\n",
      "|    time_elapsed         | 49632        |\n",
      "|    total_timesteps      | 5474304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006030614 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62           |\n",
      "|    n_updates            | 26720        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | 3.8278317    |\n",
      "|    std                  | 42.4         |\n",
      "|    value_loss           | 128          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2674          |\n",
      "|    time_elapsed         | 49651         |\n",
      "|    total_timesteps      | 5476352       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019864386 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.721         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 78.8          |\n",
      "|    n_updates            | 26730         |\n",
      "|    policy_gradient_loss | -0.00137      |\n",
      "|    reward               | 14.873491     |\n",
      "|    std                  | 42.5          |\n",
      "|    value_loss           | 181           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2675         |\n",
      "|    time_elapsed         | 49670        |\n",
      "|    total_timesteps      | 5478400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013747879 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.8         |\n",
      "|    n_updates            | 26740        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    reward               | -0.8989241   |\n",
      "|    std                  | 42.6         |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2676         |\n",
      "|    time_elapsed         | 49689        |\n",
      "|    total_timesteps      | 5480448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024057594 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.1         |\n",
      "|    n_updates            | 26750        |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    reward               | 0.03968043   |\n",
      "|    std                  | 42.6         |\n",
      "|    value_loss           | 94.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2677         |\n",
      "|    time_elapsed         | 49708        |\n",
      "|    total_timesteps      | 5482496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007584366 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 146          |\n",
      "|    n_updates            | 26760        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    reward               | -1.9159658   |\n",
      "|    std                  | 42.7         |\n",
      "|    value_loss           | 228          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2678          |\n",
      "|    time_elapsed         | 49727         |\n",
      "|    total_timesteps      | 5484544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028480627 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.515         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 127           |\n",
      "|    n_updates            | 26770         |\n",
      "|    policy_gradient_loss | -0.00114      |\n",
      "|    reward               | -2.284077     |\n",
      "|    std                  | 42.7          |\n",
      "|    value_loss           | 167           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2679        |\n",
      "|    time_elapsed         | 49746       |\n",
      "|    total_timesteps      | 5486592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006843219 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -149        |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 26780       |\n",
      "|    policy_gradient_loss | -0.00732    |\n",
      "|    reward               | 0.045536812 |\n",
      "|    std                  | 42.8        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2680         |\n",
      "|    time_elapsed         | 49764        |\n",
      "|    total_timesteps      | 5488640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005232936 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.515        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.2         |\n",
      "|    n_updates            | 26790        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    reward               | 0.22057964   |\n",
      "|    std                  | 42.8         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2681          |\n",
      "|    time_elapsed         | 49783         |\n",
      "|    total_timesteps      | 5490688       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047647077 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.703         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 36.2          |\n",
      "|    n_updates            | 26800         |\n",
      "|    policy_gradient_loss | -0.00178      |\n",
      "|    reward               | 8.062522      |\n",
      "|    std                  | 42.8          |\n",
      "|    value_loss           | 116           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2682         |\n",
      "|    time_elapsed         | 49801        |\n",
      "|    total_timesteps      | 5492736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014027264 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.6         |\n",
      "|    n_updates            | 26810        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    reward               | -0.5596194   |\n",
      "|    std                  | 42.8         |\n",
      "|    value_loss           | 92.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5675776.68\n",
      "total_reward: 4675776.68\n",
      "total_cost: 237248.97\n",
      "total_trades: 61368\n",
      "Sharpe: 0.736\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2683         |\n",
      "|    time_elapsed         | 49820        |\n",
      "|    total_timesteps      | 5494784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020223693 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.7         |\n",
      "|    n_updates            | 26820        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | 4.9409614    |\n",
      "|    std                  | 42.9         |\n",
      "|    value_loss           | 94.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2684          |\n",
      "|    time_elapsed         | 49839         |\n",
      "|    total_timesteps      | 5496832       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014789565 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.448         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 113           |\n",
      "|    n_updates            | 26830         |\n",
      "|    policy_gradient_loss | -0.000891     |\n",
      "|    reward               | 0.11335836    |\n",
      "|    std                  | 42.9          |\n",
      "|    value_loss           | 191           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2685          |\n",
      "|    time_elapsed         | 49858         |\n",
      "|    total_timesteps      | 5498880       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042719848 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.712         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 65.9          |\n",
      "|    n_updates            | 26840         |\n",
      "|    policy_gradient_loss | -0.00145      |\n",
      "|    reward               | 0.7919116     |\n",
      "|    std                  | 42.9          |\n",
      "|    value_loss           | 141           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2686         |\n",
      "|    time_elapsed         | 49877        |\n",
      "|    total_timesteps      | 5500928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037055737 |\n",
      "|    clip_fraction        | 0.00908      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 26850        |\n",
      "|    policy_gradient_loss | -0.00558     |\n",
      "|    reward               | 5.7614484    |\n",
      "|    std                  | 43           |\n",
      "|    value_loss           | 57.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2687          |\n",
      "|    time_elapsed         | 49895         |\n",
      "|    total_timesteps      | 5502976       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030854682 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.591         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 64.9          |\n",
      "|    n_updates            | 26860         |\n",
      "|    policy_gradient_loss | -0.00144      |\n",
      "|    reward               | 0.4660851     |\n",
      "|    std                  | 43.1          |\n",
      "|    value_loss           | 119           |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2688       |\n",
      "|    time_elapsed         | 49914      |\n",
      "|    total_timesteps      | 5505024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00072546 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -149       |\n",
      "|    explained_variance   | 0.649      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 49.4       |\n",
      "|    n_updates            | 26870      |\n",
      "|    policy_gradient_loss | -0.00243   |\n",
      "|    reward               | 7.6686473  |\n",
      "|    std                  | 43.1       |\n",
      "|    value_loss           | 133        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2689         |\n",
      "|    time_elapsed         | 49932        |\n",
      "|    total_timesteps      | 5507072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011059924 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.3         |\n",
      "|    n_updates            | 26880        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    reward               | -0.13481149  |\n",
      "|    std                  | 43.1         |\n",
      "|    value_loss           | 84.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2690         |\n",
      "|    time_elapsed         | 49950        |\n",
      "|    total_timesteps      | 5509120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009884728 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.9         |\n",
      "|    n_updates            | 26890        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | -0.5780626   |\n",
      "|    std                  | 43.2         |\n",
      "|    value_loss           | 77.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2691         |\n",
      "|    time_elapsed         | 49969        |\n",
      "|    total_timesteps      | 5511168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002294787 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57           |\n",
      "|    n_updates            | 26900        |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    reward               | -0.20883365  |\n",
      "|    std                  | 43.3         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2692        |\n",
      "|    time_elapsed         | 49988       |\n",
      "|    total_timesteps      | 5513216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001433986 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -149        |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.1        |\n",
      "|    n_updates            | 26910       |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | 0.5101969   |\n",
      "|    std                  | 43.3        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2693        |\n",
      "|    time_elapsed         | 50007       |\n",
      "|    total_timesteps      | 5515264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005263268 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -149        |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 26920       |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    reward               | -1.1016744  |\n",
      "|    std                  | 43.4        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2694         |\n",
      "|    time_elapsed         | 50025        |\n",
      "|    total_timesteps      | 5517312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011102398 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.1         |\n",
      "|    n_updates            | 26930        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    reward               | 1.0459368    |\n",
      "|    std                  | 43.5         |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2695          |\n",
      "|    time_elapsed         | 50044         |\n",
      "|    total_timesteps      | 5519360       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040531514 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.463         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 68.8          |\n",
      "|    n_updates            | 26940         |\n",
      "|    policy_gradient_loss | -0.00185      |\n",
      "|    reward               | -2.0903056    |\n",
      "|    std                  | 43.5          |\n",
      "|    value_loss           | 193           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2696         |\n",
      "|    time_elapsed         | 50062        |\n",
      "|    total_timesteps      | 5521408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016808348 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 26950        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    reward               | 0.95867264   |\n",
      "|    std                  | 43.5         |\n",
      "|    value_loss           | 58.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5973278.45\n",
      "total_reward: 4973278.45\n",
      "total_cost: 204224.15\n",
      "total_trades: 59535\n",
      "Sharpe: 0.743\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2697        |\n",
      "|    time_elapsed         | 50080       |\n",
      "|    total_timesteps      | 5523456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001124123 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -149        |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.9        |\n",
      "|    n_updates            | 26960       |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    reward               | 2.272371    |\n",
      "|    std                  | 43.5        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2698          |\n",
      "|    time_elapsed         | 50099         |\n",
      "|    total_timesteps      | 5525504       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.4432923e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.188         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 66.5          |\n",
      "|    n_updates            | 26970         |\n",
      "|    policy_gradient_loss | -0.000361     |\n",
      "|    reward               | 3.9665365     |\n",
      "|    std                  | 43.6          |\n",
      "|    value_loss           | 236           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2699         |\n",
      "|    time_elapsed         | 50117        |\n",
      "|    total_timesteps      | 5527552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018637896 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.4         |\n",
      "|    n_updates            | 26980        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | -1.2556807   |\n",
      "|    std                  | 43.7         |\n",
      "|    value_loss           | 89.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2700         |\n",
      "|    time_elapsed         | 50135        |\n",
      "|    total_timesteps      | 5529600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020120866 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.8         |\n",
      "|    n_updates            | 26990        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | -0.15268198  |\n",
      "|    std                  | 43.9         |\n",
      "|    value_loss           | 96.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2701         |\n",
      "|    time_elapsed         | 50153        |\n",
      "|    total_timesteps      | 5531648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003734387 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 116          |\n",
      "|    n_updates            | 27000        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | -1.4920169   |\n",
      "|    std                  | 44           |\n",
      "|    value_loss           | 238          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2702         |\n",
      "|    time_elapsed         | 50172        |\n",
      "|    total_timesteps      | 5533696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010105136 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 124          |\n",
      "|    n_updates            | 27010        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | -4.4318194   |\n",
      "|    std                  | 44.1         |\n",
      "|    value_loss           | 187          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2703        |\n",
      "|    time_elapsed         | 50191       |\n",
      "|    total_timesteps      | 5535744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004744298 |\n",
      "|    clip_fraction        | 0.00576     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -150        |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 27020       |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | -0.70556813 |\n",
      "|    std                  | 44.3        |\n",
      "|    value_loss           | 70.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2704        |\n",
      "|    time_elapsed         | 50209       |\n",
      "|    total_timesteps      | 5537792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001624712 |\n",
      "|    clip_fraction        | 0.00083     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -150        |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 27030       |\n",
      "|    policy_gradient_loss | -0.00298    |\n",
      "|    reward               | 0.038362395 |\n",
      "|    std                  | 44.4        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2705         |\n",
      "|    time_elapsed         | 50228        |\n",
      "|    total_timesteps      | 5539840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013500492 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39           |\n",
      "|    n_updates            | 27040        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | -0.090451024 |\n",
      "|    std                  | 44.5         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2706         |\n",
      "|    time_elapsed         | 50247        |\n",
      "|    total_timesteps      | 5541888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024877458 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41           |\n",
      "|    n_updates            | 27050        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    reward               | -3.1154778   |\n",
      "|    std                  | 44.6         |\n",
      "|    value_loss           | 85.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2707         |\n",
      "|    time_elapsed         | 50265        |\n",
      "|    total_timesteps      | 5543936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036442154 |\n",
      "|    clip_fraction        | 0.00728      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.6         |\n",
      "|    n_updates            | 27060        |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    reward               | -1.6381805   |\n",
      "|    std                  | 44.9         |\n",
      "|    value_loss           | 88.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2708          |\n",
      "|    time_elapsed         | 50284         |\n",
      "|    total_timesteps      | 5545984       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075980456 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.732         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 119           |\n",
      "|    n_updates            | 27070         |\n",
      "|    policy_gradient_loss | -0.00246      |\n",
      "|    reward               | -0.14866197   |\n",
      "|    std                  | 45            |\n",
      "|    value_loss           | 185           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2709          |\n",
      "|    time_elapsed         | 50302         |\n",
      "|    total_timesteps      | 5548032       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017155497 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.279         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 73.9          |\n",
      "|    n_updates            | 27080         |\n",
      "|    policy_gradient_loss | -0.000845     |\n",
      "|    reward               | -1.2036034    |\n",
      "|    std                  | 45            |\n",
      "|    value_loss           | 242           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2710         |\n",
      "|    time_elapsed         | 50321        |\n",
      "|    total_timesteps      | 5550080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077830786 |\n",
      "|    clip_fraction        | 0.0397       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 27090        |\n",
      "|    policy_gradient_loss | -0.00951     |\n",
      "|    reward               | -2.4472458   |\n",
      "|    std                  | 45           |\n",
      "|    value_loss           | 33.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6531234.62\n",
      "total_reward: 5531234.62\n",
      "total_cost: 237209.49\n",
      "total_trades: 61009\n",
      "Sharpe: 0.789\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2711          |\n",
      "|    time_elapsed         | 50340         |\n",
      "|    total_timesteps      | 5552128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062516576 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.508         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 62.4          |\n",
      "|    n_updates            | 27100         |\n",
      "|    policy_gradient_loss | -0.00243      |\n",
      "|    reward               | 0.503685      |\n",
      "|    std                  | 45.1          |\n",
      "|    value_loss           | 143           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2712         |\n",
      "|    time_elapsed         | 50358        |\n",
      "|    total_timesteps      | 5554176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004979306 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.3         |\n",
      "|    n_updates            | 27110        |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    reward               | -6.6986575   |\n",
      "|    std                  | 45.2         |\n",
      "|    value_loss           | 171          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2713         |\n",
      "|    time_elapsed         | 50412        |\n",
      "|    total_timesteps      | 5556224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027203183 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.1         |\n",
      "|    n_updates            | 27120        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | -0.2973752   |\n",
      "|    std                  | 45.3         |\n",
      "|    value_loss           | 83.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2714         |\n",
      "|    time_elapsed         | 50431        |\n",
      "|    total_timesteps      | 5558272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015911587 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.8         |\n",
      "|    n_updates            | 27130        |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    reward               | -0.101383395 |\n",
      "|    std                  | 45.5         |\n",
      "|    value_loss           | 84.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2715         |\n",
      "|    time_elapsed         | 50449        |\n",
      "|    total_timesteps      | 5560320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015235863 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 120          |\n",
      "|    n_updates            | 27140        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | -4.002304    |\n",
      "|    std                  | 45.5         |\n",
      "|    value_loss           | 255          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2716         |\n",
      "|    time_elapsed         | 50467        |\n",
      "|    total_timesteps      | 5562368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021325992 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.276        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 88           |\n",
      "|    n_updates            | 27150        |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    reward               | -0.18687993  |\n",
      "|    std                  | 45.6         |\n",
      "|    value_loss           | 159          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2717         |\n",
      "|    time_elapsed         | 50485        |\n",
      "|    total_timesteps      | 5564416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067356466 |\n",
      "|    clip_fraction        | 0.0286       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 27160        |\n",
      "|    policy_gradient_loss | -0.00953     |\n",
      "|    reward               | 0.36034903   |\n",
      "|    std                  | 45.6         |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2718          |\n",
      "|    time_elapsed         | 50503         |\n",
      "|    total_timesteps      | 5566464       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068907125 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.66          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 50.8          |\n",
      "|    n_updates            | 27170         |\n",
      "|    policy_gradient_loss | -0.0023       |\n",
      "|    reward               | 2.278447      |\n",
      "|    std                  | 45.6          |\n",
      "|    value_loss           | 120           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2719         |\n",
      "|    time_elapsed         | 50521        |\n",
      "|    total_timesteps      | 5568512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005171583 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.7         |\n",
      "|    n_updates            | 27180        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    reward               | -0.26692778  |\n",
      "|    std                  | 45.7         |\n",
      "|    value_loss           | 147          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2720        |\n",
      "|    time_elapsed         | 50539       |\n",
      "|    total_timesteps      | 5570560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008657791 |\n",
      "|    clip_fraction        | 0.0329      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 27190       |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    reward               | 0.30676845  |\n",
      "|    std                  | 45.8        |\n",
      "|    value_loss           | 59.4        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2721          |\n",
      "|    time_elapsed         | 50557         |\n",
      "|    total_timesteps      | 5572608       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081082043 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.656         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 47.9          |\n",
      "|    n_updates            | 27200         |\n",
      "|    policy_gradient_loss | -0.00276      |\n",
      "|    reward               | -2.0077875    |\n",
      "|    std                  | 45.9          |\n",
      "|    value_loss           | 106           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2722         |\n",
      "|    time_elapsed         | 50576        |\n",
      "|    total_timesteps      | 5574656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007098877 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 96.4         |\n",
      "|    n_updates            | 27210        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | 2.0332508    |\n",
      "|    std                  | 45.9         |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2723          |\n",
      "|    time_elapsed         | 50594         |\n",
      "|    total_timesteps      | 5576704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022775432 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.312         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 73.5          |\n",
      "|    n_updates            | 27220         |\n",
      "|    policy_gradient_loss | -0.000895     |\n",
      "|    reward               | 1.3205962     |\n",
      "|    std                  | 46            |\n",
      "|    value_loss           | 127           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2724         |\n",
      "|    time_elapsed         | 50612        |\n",
      "|    total_timesteps      | 5578752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014725365 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.6         |\n",
      "|    n_updates            | 27230        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    reward               | 1.393039     |\n",
      "|    std                  | 46           |\n",
      "|    value_loss           | 55           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5701026.45\n",
      "total_reward: 4701026.45\n",
      "total_cost: 231494.84\n",
      "total_trades: 60070\n",
      "Sharpe: 0.732\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2725          |\n",
      "|    time_elapsed         | 50630         |\n",
      "|    total_timesteps      | 5580800       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00093967083 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.71          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 61.3          |\n",
      "|    n_updates            | 27240         |\n",
      "|    policy_gradient_loss | -0.00232      |\n",
      "|    reward               | 1.858619      |\n",
      "|    std                  | 46            |\n",
      "|    value_loss           | 101           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2726         |\n",
      "|    time_elapsed         | 50648        |\n",
      "|    total_timesteps      | 5582848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014492455 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.7         |\n",
      "|    n_updates            | 27250        |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    reward               | 4.6707015    |\n",
      "|    std                  | 46           |\n",
      "|    value_loss           | 139          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2727         |\n",
      "|    time_elapsed         | 50667        |\n",
      "|    total_timesteps      | 5584896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008132156 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 27260        |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    reward               | -1.8507342   |\n",
      "|    std                  | 46.2         |\n",
      "|    value_loss           | 63.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2728        |\n",
      "|    time_elapsed         | 50686       |\n",
      "|    total_timesteps      | 5586944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002055509 |\n",
      "|    clip_fraction        | 0.00103     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.6        |\n",
      "|    n_updates            | 27270       |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    reward               | -0.7622492  |\n",
      "|    std                  | 46.2        |\n",
      "|    value_loss           | 98.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2729         |\n",
      "|    time_elapsed         | 50706        |\n",
      "|    total_timesteps      | 5588992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006742078 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.464        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 113          |\n",
      "|    n_updates            | 27280        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    reward               | -1.4588085   |\n",
      "|    std                  | 46.3         |\n",
      "|    value_loss           | 235          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2730         |\n",
      "|    time_elapsed         | 50724        |\n",
      "|    total_timesteps      | 5591040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027349833 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.9         |\n",
      "|    n_updates            | 27290        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | -3.7807434   |\n",
      "|    std                  | 46.4         |\n",
      "|    value_loss           | 86.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2731         |\n",
      "|    time_elapsed         | 50743        |\n",
      "|    total_timesteps      | 5593088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023179145 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.7         |\n",
      "|    n_updates            | 27300        |\n",
      "|    policy_gradient_loss | -0.00431     |\n",
      "|    reward               | 0.5564018    |\n",
      "|    std                  | 46.5         |\n",
      "|    value_loss           | 128          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2732        |\n",
      "|    time_elapsed         | 50762       |\n",
      "|    total_timesteps      | 5595136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001377159 |\n",
      "|    clip_fraction        | 0.000439    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 27310       |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    reward               | 0.73613137  |\n",
      "|    std                  | 46.6        |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2733          |\n",
      "|    time_elapsed         | 50780         |\n",
      "|    total_timesteps      | 5597184       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00052106247 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.55          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 80            |\n",
      "|    n_updates            | 27320         |\n",
      "|    policy_gradient_loss | -0.00169      |\n",
      "|    reward               | -0.20053908   |\n",
      "|    std                  | 46.6          |\n",
      "|    value_loss           | 120           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2734        |\n",
      "|    time_elapsed         | 50798       |\n",
      "|    total_timesteps      | 5599232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007643052 |\n",
      "|    clip_fraction        | 0.025       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 27330       |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    reward               | 0.8158273   |\n",
      "|    std                  | 46.7        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2735          |\n",
      "|    time_elapsed         | 50817         |\n",
      "|    total_timesteps      | 5601280       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033660483 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.669         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 43.6          |\n",
      "|    n_updates            | 27340         |\n",
      "|    policy_gradient_loss | -0.00165      |\n",
      "|    reward               | -0.41038927   |\n",
      "|    std                  | 46.8          |\n",
      "|    value_loss           | 144           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2736          |\n",
      "|    time_elapsed         | 50836         |\n",
      "|    total_timesteps      | 5603328       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067095575 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.534         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 48.6          |\n",
      "|    n_updates            | 27350         |\n",
      "|    policy_gradient_loss | -0.00241      |\n",
      "|    reward               | 8.769568      |\n",
      "|    std                  | 46.9          |\n",
      "|    value_loss           | 124           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2737         |\n",
      "|    time_elapsed         | 50854        |\n",
      "|    total_timesteps      | 5605376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032774727 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 27360        |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    reward               | -0.5375415   |\n",
      "|    std                  | 47           |\n",
      "|    value_loss           | 40.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2738         |\n",
      "|    time_elapsed         | 50872        |\n",
      "|    total_timesteps      | 5607424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010212661 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.681        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37           |\n",
      "|    n_updates            | 27370        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    reward               | -1.490087    |\n",
      "|    std                  | 47           |\n",
      "|    value_loss           | 81.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2739         |\n",
      "|    time_elapsed         | 50891        |\n",
      "|    total_timesteps      | 5609472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011252272 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.4         |\n",
      "|    n_updates            | 27380        |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    reward               | 22.256369    |\n",
      "|    std                  | 47.1         |\n",
      "|    value_loss           | 180          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5898281.48\n",
      "total_reward: 4898281.48\n",
      "total_cost: 252846.80\n",
      "total_trades: 61571\n",
      "Sharpe: 0.755\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2740          |\n",
      "|    time_elapsed         | 50909         |\n",
      "|    total_timesteps      | 5611520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024443722 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.538         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 82.1          |\n",
      "|    n_updates            | 27390         |\n",
      "|    policy_gradient_loss | -0.00155      |\n",
      "|    reward               | 2.077681      |\n",
      "|    std                  | 47.1          |\n",
      "|    value_loss           | 181           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2741         |\n",
      "|    time_elapsed         | 50926        |\n",
      "|    total_timesteps      | 5613568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037043788 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.2         |\n",
      "|    n_updates            | 27400        |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    reward               | -0.04663386  |\n",
      "|    std                  | 47.3         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2742         |\n",
      "|    time_elapsed         | 50945        |\n",
      "|    total_timesteps      | 5615616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019227926 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.7         |\n",
      "|    n_updates            | 27410        |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    reward               | 0.76077163   |\n",
      "|    std                  | 47.5         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2743          |\n",
      "|    time_elapsed         | 50963         |\n",
      "|    total_timesteps      | 5617664       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035840514 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.721         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 150           |\n",
      "|    n_updates            | 27420         |\n",
      "|    policy_gradient_loss | -0.00204      |\n",
      "|    reward               | 2.1488245     |\n",
      "|    std                  | 47.5          |\n",
      "|    value_loss           | 252           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2744         |\n",
      "|    time_elapsed         | 50981        |\n",
      "|    total_timesteps      | 5619712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012912883 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 27430        |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    reward               | 1.4186352    |\n",
      "|    std                  | 47.6         |\n",
      "|    value_loss           | 48.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2745         |\n",
      "|    time_elapsed         | 51000        |\n",
      "|    total_timesteps      | 5621760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009442379 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 27440        |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    reward               | -0.17648868  |\n",
      "|    std                  | 47.7         |\n",
      "|    value_loss           | 86.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2746          |\n",
      "|    time_elapsed         | 51018         |\n",
      "|    total_timesteps      | 5623808       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077588396 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.749         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 59.8          |\n",
      "|    n_updates            | 27450         |\n",
      "|    policy_gradient_loss | -0.00254      |\n",
      "|    reward               | -4.546916     |\n",
      "|    std                  | 47.8          |\n",
      "|    value_loss           | 144           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2747        |\n",
      "|    time_elapsed         | 51037       |\n",
      "|    total_timesteps      | 5625856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004158325 |\n",
      "|    clip_fraction        | 0.00732     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -152        |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.4        |\n",
      "|    n_updates            | 27460       |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    reward               | -0.6871173  |\n",
      "|    std                  | 47.9        |\n",
      "|    value_loss           | 71.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2748         |\n",
      "|    time_elapsed         | 51056        |\n",
      "|    total_timesteps      | 5627904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019949088 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.707        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.8         |\n",
      "|    n_updates            | 27470        |\n",
      "|    policy_gradient_loss | -0.00503     |\n",
      "|    reward               | 1.0371705    |\n",
      "|    std                  | 48.1         |\n",
      "|    value_loss           | 63.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2749         |\n",
      "|    time_elapsed         | 51075        |\n",
      "|    total_timesteps      | 5629952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007943943 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.6         |\n",
      "|    n_updates            | 27480        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    reward               | -0.27695414  |\n",
      "|    std                  | 48.1         |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2750          |\n",
      "|    time_elapsed         | 51094         |\n",
      "|    total_timesteps      | 5632000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017378025 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.623         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 97.5          |\n",
      "|    n_updates            | 27490         |\n",
      "|    policy_gradient_loss | -0.000968     |\n",
      "|    reward               | 4.6283545     |\n",
      "|    std                  | 48.2          |\n",
      "|    value_loss           | 214           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2751        |\n",
      "|    time_elapsed         | 51112       |\n",
      "|    total_timesteps      | 5634048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006935233 |\n",
      "|    clip_fraction        | 0.032       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -152        |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 27500       |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | -1.4255955  |\n",
      "|    std                  | 48.4        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2752          |\n",
      "|    time_elapsed         | 51131         |\n",
      "|    total_timesteps      | 5636096       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042576974 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.741         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 89.9          |\n",
      "|    n_updates            | 27510         |\n",
      "|    policy_gradient_loss | -0.00171      |\n",
      "|    reward               | 0.5831242     |\n",
      "|    std                  | 48.4          |\n",
      "|    value_loss           | 126           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2753         |\n",
      "|    time_elapsed         | 51150        |\n",
      "|    total_timesteps      | 5638144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010172459 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.8         |\n",
      "|    n_updates            | 27520        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    reward               | 0.42888153   |\n",
      "|    std                  | 48.5         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5372901.06\n",
      "total_reward: 4372901.06\n",
      "total_cost: 297093.93\n",
      "total_trades: 63606\n",
      "Sharpe: 0.748\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2754        |\n",
      "|    time_elapsed         | 51169       |\n",
      "|    total_timesteps      | 5640192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003947294 |\n",
      "|    clip_fraction        | 0.00654     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -153        |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.2        |\n",
      "|    n_updates            | 27530       |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    reward               | -2.092687   |\n",
      "|    std                  | 48.6        |\n",
      "|    value_loss           | 61.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2755         |\n",
      "|    time_elapsed         | 51187        |\n",
      "|    total_timesteps      | 5642240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016955428 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.2         |\n",
      "|    n_updates            | 27540        |\n",
      "|    policy_gradient_loss | -0.00501     |\n",
      "|    reward               | 0.2109153    |\n",
      "|    std                  | 48.6         |\n",
      "|    value_loss           | 65           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2756         |\n",
      "|    time_elapsed         | 51206        |\n",
      "|    total_timesteps      | 5644288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006756898 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.1         |\n",
      "|    n_updates            | 27550        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | 3.465015     |\n",
      "|    std                  | 48.7         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2757         |\n",
      "|    time_elapsed         | 51225        |\n",
      "|    total_timesteps      | 5646336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014737097 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.4         |\n",
      "|    n_updates            | 27560        |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    reward               | -0.08018147  |\n",
      "|    std                  | 48.7         |\n",
      "|    value_loss           | 95.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2758         |\n",
      "|    time_elapsed         | 51244        |\n",
      "|    total_timesteps      | 5648384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070504267 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 27570        |\n",
      "|    policy_gradient_loss | -0.00877     |\n",
      "|    reward               | -0.6710351   |\n",
      "|    std                  | 48.8         |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2759         |\n",
      "|    time_elapsed         | 51263        |\n",
      "|    total_timesteps      | 5650432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011094183 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.6         |\n",
      "|    n_updates            | 27580        |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    reward               | -1.0831858   |\n",
      "|    std                  | 48.9         |\n",
      "|    value_loss           | 97.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2760          |\n",
      "|    time_elapsed         | 51282         |\n",
      "|    total_timesteps      | 5652480       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090976537 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.708         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 63.6          |\n",
      "|    n_updates            | 27590         |\n",
      "|    policy_gradient_loss | -0.0031       |\n",
      "|    reward               | 6.400978      |\n",
      "|    std                  | 49            |\n",
      "|    value_loss           | 124           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2761        |\n",
      "|    time_elapsed         | 51301       |\n",
      "|    total_timesteps      | 5654528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004071981 |\n",
      "|    clip_fraction        | 0.00591     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -153        |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 27600       |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    reward               | 1.4002804   |\n",
      "|    std                  | 49          |\n",
      "|    value_loss           | 44.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2762          |\n",
      "|    time_elapsed         | 51320         |\n",
      "|    total_timesteps      | 5656576       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033625402 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.751         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 151           |\n",
      "|    n_updates            | 27610         |\n",
      "|    policy_gradient_loss | -0.00138      |\n",
      "|    reward               | 1.8569736     |\n",
      "|    std                  | 49.1          |\n",
      "|    value_loss           | 165           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2763          |\n",
      "|    time_elapsed         | 51339         |\n",
      "|    total_timesteps      | 5658624       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014449874 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.311         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 63.5          |\n",
      "|    n_updates            | 27620         |\n",
      "|    policy_gradient_loss | -0.000882     |\n",
      "|    reward               | -15.663745    |\n",
      "|    std                  | 49.1          |\n",
      "|    value_loss           | 192           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2764          |\n",
      "|    time_elapsed         | 51358         |\n",
      "|    total_timesteps      | 5660672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050979713 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.32          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 67.8          |\n",
      "|    n_updates            | 27630         |\n",
      "|    policy_gradient_loss | -0.00131      |\n",
      "|    reward               | -0.017409341  |\n",
      "|    std                  | 49.1          |\n",
      "|    value_loss           | 129           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2765        |\n",
      "|    time_elapsed         | 51376       |\n",
      "|    total_timesteps      | 5662720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003191001 |\n",
      "|    clip_fraction        | 0.00439     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -153        |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 27640       |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    reward               | -1.845507   |\n",
      "|    std                  | 49.3        |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2766          |\n",
      "|    time_elapsed         | 51394         |\n",
      "|    total_timesteps      | 5664768       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018699002 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.659         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 41.7          |\n",
      "|    n_updates            | 27650         |\n",
      "|    policy_gradient_loss | -0.000975     |\n",
      "|    reward               | -4.2083516    |\n",
      "|    std                  | 49.4          |\n",
      "|    value_loss           | 155           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2767         |\n",
      "|    time_elapsed         | 51413        |\n",
      "|    total_timesteps      | 5666816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.318278e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93.1         |\n",
      "|    n_updates            | 27660        |\n",
      "|    policy_gradient_loss | -0.000594    |\n",
      "|    reward               | 11.827921    |\n",
      "|    std                  | 49.4         |\n",
      "|    value_loss           | 216          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5744094.17\n",
      "total_reward: 4744094.17\n",
      "total_cost: 285819.13\n",
      "total_trades: 63026\n",
      "Sharpe: 0.764\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2768        |\n",
      "|    time_elapsed         | 51431       |\n",
      "|    total_timesteps      | 5668864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008273839 |\n",
      "|    clip_fraction        | 0.0439      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -153        |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 27670       |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | 1.4435294   |\n",
      "|    std                  | 49.7        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2769         |\n",
      "|    time_elapsed         | 51450        |\n",
      "|    total_timesteps      | 5670912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002582417 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.3         |\n",
      "|    n_updates            | 27680        |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    reward               | 1.1441435    |\n",
      "|    std                  | 49.7         |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2770          |\n",
      "|    time_elapsed         | 51468         |\n",
      "|    total_timesteps      | 5672960       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020060435 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.659         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 68.9          |\n",
      "|    n_updates            | 27690         |\n",
      "|    policy_gradient_loss | -0.00116      |\n",
      "|    reward               | -3.780007     |\n",
      "|    std                  | 49.8          |\n",
      "|    value_loss           | 172           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2771         |\n",
      "|    time_elapsed         | 51487        |\n",
      "|    total_timesteps      | 5675008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011349027 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 27700        |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    reward               | -0.012540227 |\n",
      "|    std                  | 49.8         |\n",
      "|    value_loss           | 65.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2772         |\n",
      "|    time_elapsed         | 51506        |\n",
      "|    total_timesteps      | 5677056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006944399 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.4         |\n",
      "|    n_updates            | 27710        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | -1.4551694   |\n",
      "|    std                  | 49.9         |\n",
      "|    value_loss           | 76.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2773         |\n",
      "|    time_elapsed         | 51525        |\n",
      "|    total_timesteps      | 5679104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007939857 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.5         |\n",
      "|    n_updates            | 27720        |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    reward               | 0.13654521   |\n",
      "|    std                  | 50           |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2774          |\n",
      "|    time_elapsed         | 51544         |\n",
      "|    total_timesteps      | 5681152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020266007 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.601         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 109           |\n",
      "|    n_updates            | 27730         |\n",
      "|    policy_gradient_loss | -0.00117      |\n",
      "|    reward               | 0.13252209    |\n",
      "|    std                  | 50            |\n",
      "|    value_loss           | 166           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2775         |\n",
      "|    time_elapsed         | 51563        |\n",
      "|    total_timesteps      | 5683200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042376565 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 27740        |\n",
      "|    policy_gradient_loss | -0.00545     |\n",
      "|    reward               | 0.2611894    |\n",
      "|    std                  | 50.1         |\n",
      "|    value_loss           | 29.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2776          |\n",
      "|    time_elapsed         | 51583         |\n",
      "|    total_timesteps      | 5685248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044823636 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.641         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 36.7          |\n",
      "|    n_updates            | 27750         |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    reward               | 0.097463585   |\n",
      "|    std                  | 50.1          |\n",
      "|    value_loss           | 129           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2777        |\n",
      "|    time_elapsed         | 51601       |\n",
      "|    total_timesteps      | 5687296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000559966 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -153        |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 27760       |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    reward               | 3.1518707   |\n",
      "|    std                  | 50.1        |\n",
      "|    value_loss           | 286         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2778        |\n",
      "|    time_elapsed         | 51621       |\n",
      "|    total_timesteps      | 5689344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003039534 |\n",
      "|    clip_fraction        | 0.00396     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -153        |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 27770       |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    reward               | -0.43155718 |\n",
      "|    std                  | 50.3        |\n",
      "|    value_loss           | 59.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2779         |\n",
      "|    time_elapsed         | 51639        |\n",
      "|    total_timesteps      | 5691392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013330067 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.5         |\n",
      "|    n_updates            | 27780        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | -0.5651982   |\n",
      "|    std                  | 50.4         |\n",
      "|    value_loss           | 92.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2780          |\n",
      "|    time_elapsed         | 51658         |\n",
      "|    total_timesteps      | 5693440       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027281855 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.631         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 87.4          |\n",
      "|    n_updates            | 27790         |\n",
      "|    policy_gradient_loss | -0.000982     |\n",
      "|    reward               | 0.16876991    |\n",
      "|    std                  | 50.4          |\n",
      "|    value_loss           | 188           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2781          |\n",
      "|    time_elapsed         | 51676         |\n",
      "|    total_timesteps      | 5695488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018250966 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.429         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 77.1          |\n",
      "|    n_updates            | 27800         |\n",
      "|    policy_gradient_loss | -0.00111      |\n",
      "|    reward               | 0.23217198    |\n",
      "|    std                  | 50.4          |\n",
      "|    value_loss           | 196           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6161469.66\n",
      "total_reward: 5161469.66\n",
      "total_cost: 233611.69\n",
      "total_trades: 60538\n",
      "Sharpe: 0.773\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2782         |\n",
      "|    time_elapsed         | 51695        |\n",
      "|    total_timesteps      | 5697536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046455488 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.02         |\n",
      "|    n_updates            | 27810        |\n",
      "|    policy_gradient_loss | -0.00746     |\n",
      "|    reward               | -0.7808952   |\n",
      "|    std                  | 50.4         |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2783         |\n",
      "|    time_elapsed         | 51713        |\n",
      "|    total_timesteps      | 5699584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002842693 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.4         |\n",
      "|    n_updates            | 27820        |\n",
      "|    policy_gradient_loss | -0.00128     |\n",
      "|    reward               | -4.0337405   |\n",
      "|    std                  | 50.4         |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2784         |\n",
      "|    time_elapsed         | 51731        |\n",
      "|    total_timesteps      | 5701632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005680687 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.9         |\n",
      "|    n_updates            | 27830        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | 6.123232     |\n",
      "|    std                  | 50.5         |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2785        |\n",
      "|    time_elapsed         | 51749       |\n",
      "|    total_timesteps      | 5703680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007572441 |\n",
      "|    clip_fraction        | 0.0324      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -154        |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 27840       |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    reward               | 0.8618167   |\n",
      "|    std                  | 50.7        |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2786          |\n",
      "|    time_elapsed         | 51767         |\n",
      "|    total_timesteps      | 5705728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028949862 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.627         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 52.5          |\n",
      "|    n_updates            | 27850         |\n",
      "|    policy_gradient_loss | -0.00131      |\n",
      "|    reward               | 2.6669285     |\n",
      "|    std                  | 50.7          |\n",
      "|    value_loss           | 126           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2787         |\n",
      "|    time_elapsed         | 51786        |\n",
      "|    total_timesteps      | 5707776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004539795 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.3         |\n",
      "|    n_updates            | 27860        |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    reward               | -3.8974648   |\n",
      "|    std                  | 50.8         |\n",
      "|    value_loss           | 158          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2788          |\n",
      "|    time_elapsed         | 51805         |\n",
      "|    total_timesteps      | 5709824       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025639177 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.655         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 65.5          |\n",
      "|    n_updates            | 27870         |\n",
      "|    policy_gradient_loss | -0.00134      |\n",
      "|    reward               | -4.1276293    |\n",
      "|    std                  | 50.9          |\n",
      "|    value_loss           | 124           |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2789       |\n",
      "|    time_elapsed         | 51823      |\n",
      "|    total_timesteps      | 5711872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00216694 |\n",
      "|    clip_fraction        | 0.00103    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -154       |\n",
      "|    explained_variance   | 0.71       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 39.6       |\n",
      "|    n_updates            | 27880      |\n",
      "|    policy_gradient_loss | -0.00484   |\n",
      "|    reward               | 1.2788239  |\n",
      "|    std                  | 50.9       |\n",
      "|    value_loss           | 76.5       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2790          |\n",
      "|    time_elapsed         | 51841         |\n",
      "|    total_timesteps      | 5713920       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048262154 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.798         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 55.8          |\n",
      "|    n_updates            | 27890         |\n",
      "|    policy_gradient_loss | -0.00135      |\n",
      "|    reward               | -0.1532138    |\n",
      "|    std                  | 50.9          |\n",
      "|    value_loss           | 160           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2791         |\n",
      "|    time_elapsed         | 51859        |\n",
      "|    total_timesteps      | 5715968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002913632 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 138          |\n",
      "|    n_updates            | 27900        |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    reward               | 9.461424     |\n",
      "|    std                  | 51           |\n",
      "|    value_loss           | 195          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2792        |\n",
      "|    time_elapsed         | 51878       |\n",
      "|    total_timesteps      | 5718016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006692289 |\n",
      "|    clip_fraction        | 0.0309      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -154        |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 27910       |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | 1.7180116   |\n",
      "|    std                  | 51.3        |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2793          |\n",
      "|    time_elapsed         | 51896         |\n",
      "|    total_timesteps      | 5720064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038693272 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.727         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 43            |\n",
      "|    n_updates            | 27920         |\n",
      "|    policy_gradient_loss | -0.00173      |\n",
      "|    reward               | 0.2582214     |\n",
      "|    std                  | 51.4          |\n",
      "|    value_loss           | 113           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2794          |\n",
      "|    time_elapsed         | 51915         |\n",
      "|    total_timesteps      | 5722112       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050469744 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.757         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 105           |\n",
      "|    n_updates            | 27930         |\n",
      "|    policy_gradient_loss | -0.00186      |\n",
      "|    reward               | -1.9511957    |\n",
      "|    std                  | 51.4          |\n",
      "|    value_loss           | 157           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2795         |\n",
      "|    time_elapsed         | 51932        |\n",
      "|    total_timesteps      | 5724160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017726137 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.611        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.2         |\n",
      "|    n_updates            | 27940        |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    reward               | -2.5333192   |\n",
      "|    std                  | 51.6         |\n",
      "|    value_loss           | 88           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6480913.98\n",
      "total_reward: 5480913.98\n",
      "total_cost: 276027.07\n",
      "total_trades: 63032\n",
      "Sharpe: 0.801\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2796         |\n",
      "|    time_elapsed         | 51951        |\n",
      "|    total_timesteps      | 5726208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009324073 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.4         |\n",
      "|    n_updates            | 27950        |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    reward               | 0.54158306   |\n",
      "|    std                  | 51.7         |\n",
      "|    value_loss           | 77.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2797          |\n",
      "|    time_elapsed         | 51969         |\n",
      "|    total_timesteps      | 5728256       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036181306 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.782         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 73.1          |\n",
      "|    n_updates            | 27960         |\n",
      "|    policy_gradient_loss | -0.00151      |\n",
      "|    reward               | 0.010635243   |\n",
      "|    std                  | 51.7          |\n",
      "|    value_loss           | 187           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2798          |\n",
      "|    time_elapsed         | 51987         |\n",
      "|    total_timesteps      | 5730304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014807394 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.375         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 138           |\n",
      "|    n_updates            | 27970         |\n",
      "|    policy_gradient_loss | -0.000605     |\n",
      "|    reward               | 1.3797692     |\n",
      "|    std                  | 51.8          |\n",
      "|    value_loss           | 209           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2799         |\n",
      "|    time_elapsed         | 52006        |\n",
      "|    total_timesteps      | 5732352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070875296 |\n",
      "|    clip_fraction        | 0.0316       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.9         |\n",
      "|    n_updates            | 27980        |\n",
      "|    policy_gradient_loss | -0.00935     |\n",
      "|    reward               | 1.3225586    |\n",
      "|    std                  | 52.1         |\n",
      "|    value_loss           | 39.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2800         |\n",
      "|    time_elapsed         | 52025        |\n",
      "|    total_timesteps      | 5734400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010381287 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.5         |\n",
      "|    n_updates            | 27990        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | 2.3361506    |\n",
      "|    std                  | 52.1         |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2801          |\n",
      "|    time_elapsed         | 52044         |\n",
      "|    total_timesteps      | 5736448       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3353502e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.141         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 83.3          |\n",
      "|    n_updates            | 28000         |\n",
      "|    policy_gradient_loss | -0.000543     |\n",
      "|    reward               | 0.89665174    |\n",
      "|    std                  | 52.1          |\n",
      "|    value_loss           | 285           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2802        |\n",
      "|    time_elapsed         | 52062       |\n",
      "|    total_timesteps      | 5738496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001218176 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -155        |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 28010       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    reward               | -8.0907135  |\n",
      "|    std                  | 52.2        |\n",
      "|    value_loss           | 63.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2803         |\n",
      "|    time_elapsed         | 52082        |\n",
      "|    total_timesteps      | 5740544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011037795 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 28020        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -0.72023374  |\n",
      "|    std                  | 52.3         |\n",
      "|    value_loss           | 92.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2804          |\n",
      "|    time_elapsed         | 52100         |\n",
      "|    total_timesteps      | 5742592       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040869668 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.715         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 107           |\n",
      "|    n_updates            | 28030         |\n",
      "|    policy_gradient_loss | -0.00156      |\n",
      "|    reward               | 5.474081      |\n",
      "|    std                  | 52.3          |\n",
      "|    value_loss           | 147           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2805         |\n",
      "|    time_elapsed         | 52119        |\n",
      "|    total_timesteps      | 5744640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003022937 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82.2         |\n",
      "|    n_updates            | 28040        |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    reward               | -0.4899834   |\n",
      "|    std                  | 52.4         |\n",
      "|    value_loss           | 235          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2806         |\n",
      "|    time_elapsed         | 52137        |\n",
      "|    total_timesteps      | 5746688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028962237 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 28050        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | -1.219259    |\n",
      "|    std                  | 52.5         |\n",
      "|    value_loss           | 42.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2807         |\n",
      "|    time_elapsed         | 52155        |\n",
      "|    total_timesteps      | 5748736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008410492 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 28060        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    reward               | -2.6337116   |\n",
      "|    std                  | 52.6         |\n",
      "|    value_loss           | 178          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2808        |\n",
      "|    time_elapsed         | 52173       |\n",
      "|    total_timesteps      | 5750784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000984407 |\n",
      "|    clip_fraction        | 9.77e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -155        |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.7        |\n",
      "|    n_updates            | 28070       |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    reward               | 4.1858954   |\n",
      "|    std                  | 52.8        |\n",
      "|    value_loss           | 225         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2809        |\n",
      "|    time_elapsed         | 52191       |\n",
      "|    total_timesteps      | 5752832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005615296 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -155        |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 28080       |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    reward               | -2.7253861  |\n",
      "|    std                  | 53          |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6007881.99\n",
      "total_reward: 5007881.99\n",
      "total_cost: 303369.16\n",
      "total_trades: 64038\n",
      "Sharpe: 0.787\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2810         |\n",
      "|    time_elapsed         | 52210        |\n",
      "|    total_timesteps      | 5754880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006434116 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.7         |\n",
      "|    n_updates            | 28090        |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    reward               | -0.35511628  |\n",
      "|    std                  | 53.2         |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2811          |\n",
      "|    time_elapsed         | 52228         |\n",
      "|    total_timesteps      | 5756928       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016718509 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.37          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 122           |\n",
      "|    n_updates            | 28100         |\n",
      "|    policy_gradient_loss | -0.00099      |\n",
      "|    reward               | 8.136134      |\n",
      "|    std                  | 53.2          |\n",
      "|    value_loss           | 281           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2812         |\n",
      "|    time_elapsed         | 52247        |\n",
      "|    total_timesteps      | 5758976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011574869 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.393        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.7         |\n",
      "|    n_updates            | 28110        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | -0.779127    |\n",
      "|    std                  | 53.4         |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2813         |\n",
      "|    time_elapsed         | 52266        |\n",
      "|    total_timesteps      | 5761024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016889372 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.477        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.7         |\n",
      "|    n_updates            | 28120        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | 1.858964     |\n",
      "|    std                  | 53.5         |\n",
      "|    value_loss           | 83.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2814         |\n",
      "|    time_elapsed         | 52284        |\n",
      "|    total_timesteps      | 5763072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011455619 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.9         |\n",
      "|    n_updates            | 28130        |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    reward               | -0.120594256 |\n",
      "|    std                  | 53.6         |\n",
      "|    value_loss           | 147          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2815         |\n",
      "|    time_elapsed         | 52303        |\n",
      "|    total_timesteps      | 5765120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005662561 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 96.6         |\n",
      "|    n_updates            | 28140        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | -2.6834528   |\n",
      "|    std                  | 53.7         |\n",
      "|    value_loss           | 213          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2816         |\n",
      "|    time_elapsed         | 52321        |\n",
      "|    total_timesteps      | 5767168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016971978 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.369        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 28150        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    reward               | 0.8955052    |\n",
      "|    std                  | 53.8         |\n",
      "|    value_loss           | 72.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2817         |\n",
      "|    time_elapsed         | 52340        |\n",
      "|    total_timesteps      | 5769216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016171417 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.5         |\n",
      "|    n_updates            | 28160        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | 0.21404223   |\n",
      "|    std                  | 53.9         |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2818         |\n",
      "|    time_elapsed         | 52358        |\n",
      "|    total_timesteps      | 5771264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004193864 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.6         |\n",
      "|    n_updates            | 28170        |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    reward               | 4.547789     |\n",
      "|    std                  | 54           |\n",
      "|    value_loss           | 153          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2819         |\n",
      "|    time_elapsed         | 52377        |\n",
      "|    total_timesteps      | 5773312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036960472 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 28180        |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    reward               | 1.5130848    |\n",
      "|    std                  | 54.3         |\n",
      "|    value_loss           | 64.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2820         |\n",
      "|    time_elapsed         | 52395        |\n",
      "|    total_timesteps      | 5775360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012379345 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.5         |\n",
      "|    n_updates            | 28190        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    reward               | 2.2127633    |\n",
      "|    std                  | 54.4         |\n",
      "|    value_loss           | 83.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2821         |\n",
      "|    time_elapsed         | 52414        |\n",
      "|    total_timesteps      | 5777408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010418727 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.779        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.2         |\n",
      "|    n_updates            | 28200        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | 2.487115     |\n",
      "|    std                  | 54.5         |\n",
      "|    value_loss           | 160          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2822         |\n",
      "|    time_elapsed         | 52433        |\n",
      "|    total_timesteps      | 5779456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007163923 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.362        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.9         |\n",
      "|    n_updates            | 28210        |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    reward               | -2.9425764   |\n",
      "|    std                  | 54.5         |\n",
      "|    value_loss           | 219          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2823         |\n",
      "|    time_elapsed         | 52451        |\n",
      "|    total_timesteps      | 5781504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062429607 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.68         |\n",
      "|    n_updates            | 28220        |\n",
      "|    policy_gradient_loss | -0.00653     |\n",
      "|    reward               | -1.8126003   |\n",
      "|    std                  | 54.5         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5560270.07\n",
      "total_reward: 4560270.07\n",
      "total_cost: 197149.16\n",
      "total_trades: 59418\n",
      "Sharpe: 0.730\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2824         |\n",
      "|    time_elapsed         | 52470        |\n",
      "|    total_timesteps      | 5783552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017876935 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.1         |\n",
      "|    n_updates            | 28230        |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    reward               | 1.231125     |\n",
      "|    std                  | 54.6         |\n",
      "|    value_loss           | 122          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2825         |\n",
      "|    time_elapsed         | 52488        |\n",
      "|    total_timesteps      | 5785600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016034814 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.4         |\n",
      "|    n_updates            | 28240        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | -0.527294    |\n",
      "|    std                  | 54.6         |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2826        |\n",
      "|    time_elapsed         | 52506       |\n",
      "|    total_timesteps      | 5787648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003538082 |\n",
      "|    clip_fraction        | 0.00522     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -156        |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 28250       |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    reward               | -6.190721   |\n",
      "|    std                  | 54.9        |\n",
      "|    value_loss           | 64          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2827         |\n",
      "|    time_elapsed         | 52524        |\n",
      "|    total_timesteps      | 5789696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016328294 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.8         |\n",
      "|    n_updates            | 28260        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | 0.41130543   |\n",
      "|    std                  | 55           |\n",
      "|    value_loss           | 158          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2828        |\n",
      "|    time_elapsed         | 52542       |\n",
      "|    total_timesteps      | 5791744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001957232 |\n",
      "|    clip_fraction        | 0.000537    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -156        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 28270       |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    reward               | -9.132014   |\n",
      "|    std                  | 55.1        |\n",
      "|    value_loss           | 246         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2829         |\n",
      "|    time_elapsed         | 52562        |\n",
      "|    total_timesteps      | 5793792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008335026 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.322        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.9         |\n",
      "|    n_updates            | 28280        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | 1.4176873    |\n",
      "|    std                  | 55.2         |\n",
      "|    value_loss           | 166          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2830         |\n",
      "|    time_elapsed         | 52581        |\n",
      "|    total_timesteps      | 5795840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029760534 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 28290        |\n",
      "|    policy_gradient_loss | -0.00713     |\n",
      "|    reward               | 0.49013916   |\n",
      "|    std                  | 55.3         |\n",
      "|    value_loss           | 42.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2831          |\n",
      "|    time_elapsed         | 52600         |\n",
      "|    total_timesteps      | 5797888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00055094715 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -156          |\n",
      "|    explained_variance   | 0.599         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 62.5          |\n",
      "|    n_updates            | 28300         |\n",
      "|    policy_gradient_loss | -0.00254      |\n",
      "|    reward               | 1.730273      |\n",
      "|    std                  | 55.4          |\n",
      "|    value_loss           | 115           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2832          |\n",
      "|    time_elapsed         | 52618         |\n",
      "|    total_timesteps      | 5799936       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039487806 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -156          |\n",
      "|    explained_variance   | 0.676         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 92            |\n",
      "|    n_updates            | 28310         |\n",
      "|    policy_gradient_loss | -0.00212      |\n",
      "|    reward               | -0.856919     |\n",
      "|    std                  | 55.4          |\n",
      "|    value_loss           | 160           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2833         |\n",
      "|    time_elapsed         | 52638        |\n",
      "|    total_timesteps      | 5801984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012335649 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.5         |\n",
      "|    n_updates            | 28320        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    reward               | -3.8255653   |\n",
      "|    std                  | 55.5         |\n",
      "|    value_loss           | 48.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2834         |\n",
      "|    time_elapsed         | 52657        |\n",
      "|    total_timesteps      | 5804032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006949912 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.45         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.9         |\n",
      "|    n_updates            | 28330        |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    reward               | -1.0680344   |\n",
      "|    std                  | 55.6         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2835         |\n",
      "|    time_elapsed         | 52675        |\n",
      "|    total_timesteps      | 5806080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005732686 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67           |\n",
      "|    n_updates            | 28340        |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    reward               | 5.6442785    |\n",
      "|    std                  | 55.8         |\n",
      "|    value_loss           | 174          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2836         |\n",
      "|    time_elapsed         | 52695        |\n",
      "|    total_timesteps      | 5808128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011660021 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 87.5         |\n",
      "|    n_updates            | 28350        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | -2.825383    |\n",
      "|    std                  | 55.8         |\n",
      "|    value_loss           | 155          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2837         |\n",
      "|    time_elapsed         | 52713        |\n",
      "|    total_timesteps      | 5810176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014409733 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.3         |\n",
      "|    n_updates            | 28360        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | 1.1773059    |\n",
      "|    std                  | 55.9         |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5202506.70\n",
      "total_reward: 4202506.70\n",
      "total_cost: 277476.04\n",
      "total_trades: 62656\n",
      "Sharpe: 0.710\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2838          |\n",
      "|    time_elapsed         | 52732         |\n",
      "|    total_timesteps      | 5812224       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062154286 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -156          |\n",
      "|    explained_variance   | 0.736         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 70.1          |\n",
      "|    n_updates            | 28370         |\n",
      "|    policy_gradient_loss | -0.00188      |\n",
      "|    reward               | -0.042105366  |\n",
      "|    std                  | 56            |\n",
      "|    value_loss           | 132           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2839          |\n",
      "|    time_elapsed         | 52751         |\n",
      "|    total_timesteps      | 5814272       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034585752 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -157          |\n",
      "|    explained_variance   | 0.393         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 61.5          |\n",
      "|    n_updates            | 28380         |\n",
      "|    policy_gradient_loss | -0.00131      |\n",
      "|    reward               | 3.609911      |\n",
      "|    std                  | 56            |\n",
      "|    value_loss           | 166           |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 2840      |\n",
      "|    time_elapsed         | 52769     |\n",
      "|    total_timesteps      | 5816320   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0033921 |\n",
      "|    clip_fraction        | 0.00396   |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -157      |\n",
      "|    explained_variance   | 0.415     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 19.8      |\n",
      "|    n_updates            | 28390     |\n",
      "|    policy_gradient_loss | -0.00439  |\n",
      "|    reward               | 1.9142612 |\n",
      "|    std                  | 56.1      |\n",
      "|    value_loss           | 42.7      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2841         |\n",
      "|    time_elapsed         | 52789        |\n",
      "|    total_timesteps      | 5818368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011674319 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 145          |\n",
      "|    n_updates            | 28400        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | 2.2429326    |\n",
      "|    std                  | 56.1         |\n",
      "|    value_loss           | 197          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2842        |\n",
      "|    time_elapsed         | 52809       |\n",
      "|    total_timesteps      | 5820416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001189002 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -157        |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.3        |\n",
      "|    n_updates            | 28410       |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    reward               | -0.66749865 |\n",
      "|    std                  | 56.2        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2843         |\n",
      "|    time_elapsed         | 52828        |\n",
      "|    total_timesteps      | 5822464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026893981 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.394        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 92.1         |\n",
      "|    n_updates            | 28420        |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    reward               | -5.6271324   |\n",
      "|    std                  | 56.3         |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2844         |\n",
      "|    time_elapsed         | 52847        |\n",
      "|    total_timesteps      | 5824512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022473042 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.2         |\n",
      "|    n_updates            | 28430        |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    reward               | -1.1035919   |\n",
      "|    std                  | 56.5         |\n",
      "|    value_loss           | 90.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2845          |\n",
      "|    time_elapsed         | 52866         |\n",
      "|    total_timesteps      | 5826560       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041645742 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -157          |\n",
      "|    explained_variance   | 0.707         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 92.6          |\n",
      "|    n_updates            | 28440         |\n",
      "|    policy_gradient_loss | -0.00226      |\n",
      "|    reward               | -1.5459565    |\n",
      "|    std                  | 56.6          |\n",
      "|    value_loss           | 198           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2846          |\n",
      "|    time_elapsed         | 52885         |\n",
      "|    total_timesteps      | 5828608       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081615755 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -157          |\n",
      "|    explained_variance   | 0.508         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 75.5          |\n",
      "|    n_updates            | 28450         |\n",
      "|    policy_gradient_loss | -0.00263      |\n",
      "|    reward               | -0.24667959   |\n",
      "|    std                  | 56.7          |\n",
      "|    value_loss           | 194           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2847         |\n",
      "|    time_elapsed         | 52904        |\n",
      "|    total_timesteps      | 5830656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044098003 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.8          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 28460        |\n",
      "|    policy_gradient_loss | -0.00513     |\n",
      "|    reward               | -0.48597658  |\n",
      "|    std                  | 57           |\n",
      "|    value_loss           | 35.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2848         |\n",
      "|    time_elapsed         | 52923        |\n",
      "|    total_timesteps      | 5832704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005486628 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 101          |\n",
      "|    n_updates            | 28470        |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    reward               | -0.4914425   |\n",
      "|    std                  | 57.1         |\n",
      "|    value_loss           | 176          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2849         |\n",
      "|    time_elapsed         | 52941        |\n",
      "|    total_timesteps      | 5834752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010153414 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.5         |\n",
      "|    n_updates            | 28480        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    reward               | 8.015863     |\n",
      "|    std                  | 57.2         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2850        |\n",
      "|    time_elapsed         | 52961       |\n",
      "|    total_timesteps      | 5836800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004025748 |\n",
      "|    clip_fraction        | 0.00967     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -157        |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 28490       |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    reward               | 2.7364337   |\n",
      "|    std                  | 57.5        |\n",
      "|    value_loss           | 47          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2851          |\n",
      "|    time_elapsed         | 52980         |\n",
      "|    total_timesteps      | 5838848       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025983728 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -157          |\n",
      "|    explained_variance   | 0.757         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 30.1          |\n",
      "|    n_updates            | 28500         |\n",
      "|    policy_gradient_loss | -0.00106      |\n",
      "|    reward               | -0.8060723    |\n",
      "|    std                  | 57.5          |\n",
      "|    value_loss           | 136           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2852         |\n",
      "|    time_elapsed         | 52999        |\n",
      "|    total_timesteps      | 5840896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008886803 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.821        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.8         |\n",
      "|    n_updates            | 28510        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | -24.518042   |\n",
      "|    std                  | 57.7         |\n",
      "|    value_loss           | 137          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5467180.96\n",
      "total_reward: 4467180.96\n",
      "total_cost: 324240.92\n",
      "total_trades: 64392\n",
      "Sharpe: 0.733\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2853         |\n",
      "|    time_elapsed         | 53017        |\n",
      "|    total_timesteps      | 5842944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006032589 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.8         |\n",
      "|    n_updates            | 28520        |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    reward               | 1.028164     |\n",
      "|    std                  | 57.7         |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2854         |\n",
      "|    time_elapsed         | 53035        |\n",
      "|    total_timesteps      | 5844992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017696565 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 28530        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | 0.08775486   |\n",
      "|    std                  | 58           |\n",
      "|    value_loss           | 76.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2855         |\n",
      "|    time_elapsed         | 53053        |\n",
      "|    total_timesteps      | 5847040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005370276 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.5         |\n",
      "|    n_updates            | 28540        |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    reward               | 1.1375968    |\n",
      "|    std                  | 58.1         |\n",
      "|    value_loss           | 125          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2856         |\n",
      "|    time_elapsed         | 53071        |\n",
      "|    total_timesteps      | 5849088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021878788 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.3         |\n",
      "|    n_updates            | 28550        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    reward               | -0.19412614  |\n",
      "|    std                  | 58.4         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2857        |\n",
      "|    time_elapsed         | 53089       |\n",
      "|    total_timesteps      | 5851136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006267093 |\n",
      "|    clip_fraction        | 0.0191      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -158        |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 28560       |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    reward               | 1.3268005   |\n",
      "|    std                  | 58.4        |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2858          |\n",
      "|    time_elapsed         | 53108         |\n",
      "|    total_timesteps      | 5853184       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069206883 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.523         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 147           |\n",
      "|    n_updates            | 28570         |\n",
      "|    policy_gradient_loss | -0.00211      |\n",
      "|    reward               | 0.58348125    |\n",
      "|    std                  | 58.5          |\n",
      "|    value_loss           | 227           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2859          |\n",
      "|    time_elapsed         | 53127         |\n",
      "|    total_timesteps      | 5855232       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042780125 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.728         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 118           |\n",
      "|    n_updates            | 28580         |\n",
      "|    policy_gradient_loss | -0.00127      |\n",
      "|    reward               | 1.8855398     |\n",
      "|    std                  | 58.6          |\n",
      "|    value_loss           | 173           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2860         |\n",
      "|    time_elapsed         | 53145        |\n",
      "|    total_timesteps      | 5857280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010456294 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70           |\n",
      "|    n_updates            | 28590        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | -0.7743976   |\n",
      "|    std                  | 58.7         |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2861         |\n",
      "|    time_elapsed         | 53164        |\n",
      "|    total_timesteps      | 5859328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017246681 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40           |\n",
      "|    n_updates            | 28600        |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    reward               | -0.06789639  |\n",
      "|    std                  | 58.9         |\n",
      "|    value_loss           | 76.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2862         |\n",
      "|    time_elapsed         | 53183        |\n",
      "|    total_timesteps      | 5861376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008086894 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.1         |\n",
      "|    n_updates            | 28610        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | 0.06448016   |\n",
      "|    std                  | 59           |\n",
      "|    value_loss           | 155          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2863         |\n",
      "|    time_elapsed         | 53202        |\n",
      "|    total_timesteps      | 5863424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003077812 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 88.8         |\n",
      "|    n_updates            | 28620        |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    reward               | -0.105015956 |\n",
      "|    std                  | 59           |\n",
      "|    value_loss           | 195          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2864        |\n",
      "|    time_elapsed         | 53221       |\n",
      "|    total_timesteps      | 5865472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004825902 |\n",
      "|    clip_fraction        | 0.0144      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -158        |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 28630       |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    reward               | -0.3763639  |\n",
      "|    std                  | 59.2        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2865        |\n",
      "|    time_elapsed         | 53239       |\n",
      "|    total_timesteps      | 5867520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000239391 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -158        |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.9        |\n",
      "|    n_updates            | 28640       |\n",
      "|    policy_gradient_loss | -0.000998   |\n",
      "|    reward               | -1.7681932  |\n",
      "|    std                  | 59.2        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2866          |\n",
      "|    time_elapsed         | 53257         |\n",
      "|    total_timesteps      | 5869568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027859412 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.403         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 106           |\n",
      "|    n_updates            | 28650         |\n",
      "|    policy_gradient_loss | -0.0011       |\n",
      "|    reward               | 1.6499676     |\n",
      "|    std                  | 59.3          |\n",
      "|    value_loss           | 200           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6394610.44\n",
      "total_reward: 5394610.44\n",
      "total_cost: 301961.25\n",
      "total_trades: 64192\n",
      "Sharpe: 0.802\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2867         |\n",
      "|    time_elapsed         | 53276        |\n",
      "|    total_timesteps      | 5871616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028370281 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.4         |\n",
      "|    n_updates            | 28660        |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    reward               | -1.8767042   |\n",
      "|    std                  | 59.5         |\n",
      "|    value_loss           | 64.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2868         |\n",
      "|    time_elapsed         | 53295        |\n",
      "|    total_timesteps      | 5873664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008259632 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.7         |\n",
      "|    n_updates            | 28670        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    reward               | -2.5116835   |\n",
      "|    std                  | 59.6         |\n",
      "|    value_loss           | 87.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2869        |\n",
      "|    time_elapsed         | 53313       |\n",
      "|    total_timesteps      | 5875712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001119487 |\n",
      "|    clip_fraction        | 0.000195    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -158        |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.5        |\n",
      "|    n_updates            | 28680       |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    reward               | -0.17457213 |\n",
      "|    std                  | 59.8        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2870         |\n",
      "|    time_elapsed         | 53331        |\n",
      "|    total_timesteps      | 5877760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005158904 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.2         |\n",
      "|    n_updates            | 28690        |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    reward               | 1.5574309    |\n",
      "|    std                  | 59.8         |\n",
      "|    value_loss           | 147          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2871         |\n",
      "|    time_elapsed         | 53350        |\n",
      "|    total_timesteps      | 5879808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075022792 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 28700        |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    reward               | 0.25583228   |\n",
      "|    std                  | 59.9         |\n",
      "|    value_loss           | 28.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2872         |\n",
      "|    time_elapsed         | 53368        |\n",
      "|    total_timesteps      | 5881856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005795295 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.9         |\n",
      "|    n_updates            | 28710        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    reward               | -0.30457598  |\n",
      "|    std                  | 60           |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2873          |\n",
      "|    time_elapsed         | 53387         |\n",
      "|    total_timesteps      | 5883904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031848703 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.447         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 67.1          |\n",
      "|    n_updates            | 28720         |\n",
      "|    policy_gradient_loss | -0.00135      |\n",
      "|    reward               | -2.580261     |\n",
      "|    std                  | 60            |\n",
      "|    value_loss           | 159           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2874         |\n",
      "|    time_elapsed         | 53406        |\n",
      "|    total_timesteps      | 5885952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033826071 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 28730        |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    reward               | -1.1497989   |\n",
      "|    std                  | 60.1         |\n",
      "|    value_loss           | 41.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2875         |\n",
      "|    time_elapsed         | 53425        |\n",
      "|    total_timesteps      | 5888000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008114431 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35           |\n",
      "|    n_updates            | 28740        |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    reward               | -0.42872828  |\n",
      "|    std                  | 60.1         |\n",
      "|    value_loss           | 123          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2876          |\n",
      "|    time_elapsed         | 53443         |\n",
      "|    total_timesteps      | 5890048       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023690576 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.729         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 122           |\n",
      "|    n_updates            | 28750         |\n",
      "|    policy_gradient_loss | -0.00122      |\n",
      "|    reward               | -10.113043    |\n",
      "|    std                  | 60.2          |\n",
      "|    value_loss           | 168           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2877        |\n",
      "|    time_elapsed         | 53462       |\n",
      "|    total_timesteps      | 5892096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000487179 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -159        |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 99.6        |\n",
      "|    n_updates            | 28760       |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    reward               | 1.4560434   |\n",
      "|    std                  | 60.2        |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2878         |\n",
      "|    time_elapsed         | 53480        |\n",
      "|    total_timesteps      | 5894144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018507624 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 94.7         |\n",
      "|    n_updates            | 28770        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    reward               | -0.5269778   |\n",
      "|    std                  | 60.3         |\n",
      "|    value_loss           | 139          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2879          |\n",
      "|    time_elapsed         | 53499         |\n",
      "|    total_timesteps      | 5896192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033397772 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.675         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 78.6          |\n",
      "|    n_updates            | 28780         |\n",
      "|    policy_gradient_loss | -0.00172      |\n",
      "|    reward               | -2.246167     |\n",
      "|    std                  | 60.4          |\n",
      "|    value_loss           | 164           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2880         |\n",
      "|    time_elapsed         | 53516        |\n",
      "|    total_timesteps      | 5898240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007318675 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.5         |\n",
      "|    n_updates            | 28790        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    reward               | 2.0904875    |\n",
      "|    std                  | 60.5         |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6503149.02\n",
      "total_reward: 5503149.02\n",
      "total_cost: 241012.11\n",
      "total_trades: 62488\n",
      "Sharpe: 0.789\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2881          |\n",
      "|    time_elapsed         | 53534         |\n",
      "|    total_timesteps      | 5900288       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029552967 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.498         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 31.8          |\n",
      "|    n_updates            | 28800         |\n",
      "|    policy_gradient_loss | -0.00154      |\n",
      "|    reward               | -0.5036283    |\n",
      "|    std                  | 60.6          |\n",
      "|    value_loss           | 111           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2882        |\n",
      "|    time_elapsed         | 53552       |\n",
      "|    total_timesteps      | 5902336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000773521 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -159        |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96.2        |\n",
      "|    n_updates            | 28810       |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    reward               | 1.0695312   |\n",
      "|    std                  | 60.7        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2883          |\n",
      "|    time_elapsed         | 53570         |\n",
      "|    total_timesteps      | 5904384       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073678925 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.581         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 49.4          |\n",
      "|    n_updates            | 28820         |\n",
      "|    policy_gradient_loss | -0.00257      |\n",
      "|    reward               | -20.395819    |\n",
      "|    std                  | 60.8          |\n",
      "|    value_loss           | 144           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2884         |\n",
      "|    time_elapsed         | 53588        |\n",
      "|    total_timesteps      | 5906432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018065302 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.8         |\n",
      "|    n_updates            | 28830        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | -0.6596894   |\n",
      "|    std                  | 61           |\n",
      "|    value_loss           | 80.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2885         |\n",
      "|    time_elapsed         | 53607        |\n",
      "|    total_timesteps      | 5908480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024794305 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.3         |\n",
      "|    n_updates            | 28840        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | -1.9156669   |\n",
      "|    std                  | 61.2         |\n",
      "|    value_loss           | 99.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2886         |\n",
      "|    time_elapsed         | 53625        |\n",
      "|    total_timesteps      | 5910528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007058813 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.785        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 106          |\n",
      "|    n_updates            | 28850        |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    reward               | 1.228471     |\n",
      "|    std                  | 61.2         |\n",
      "|    value_loss           | 211          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2887          |\n",
      "|    time_elapsed         | 53642         |\n",
      "|    total_timesteps      | 5912576       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034261902 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.462         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 102           |\n",
      "|    n_updates            | 28860         |\n",
      "|    policy_gradient_loss | -0.0016       |\n",
      "|    reward               | 0.73922133    |\n",
      "|    std                  | 61.3          |\n",
      "|    value_loss           | 250           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2888        |\n",
      "|    time_elapsed         | 53659       |\n",
      "|    total_timesteps      | 5914624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004425699 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -159        |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 28870       |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | 1.0520945   |\n",
      "|    std                  | 61.5        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2889         |\n",
      "|    time_elapsed         | 53676        |\n",
      "|    total_timesteps      | 5916672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004611042 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.757        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.8         |\n",
      "|    n_updates            | 28880        |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    reward               | 1.622811     |\n",
      "|    std                  | 61.5         |\n",
      "|    value_loss           | 138          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2890          |\n",
      "|    time_elapsed         | 53694         |\n",
      "|    total_timesteps      | 5918720       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00055115414 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.618         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 108           |\n",
      "|    n_updates            | 28890         |\n",
      "|    policy_gradient_loss | -0.00191      |\n",
      "|    reward               | 18.200825     |\n",
      "|    std                  | 61.5          |\n",
      "|    value_loss           | 226           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2891        |\n",
      "|    time_elapsed         | 53711       |\n",
      "|    total_timesteps      | 5920768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004126341 |\n",
      "|    clip_fraction        | 0.00732     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -159        |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 28900       |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    reward               | 2.8592439   |\n",
      "|    std                  | 61.8        |\n",
      "|    value_loss           | 85.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2892         |\n",
      "|    time_elapsed         | 53728        |\n",
      "|    total_timesteps      | 5922816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012067008 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.4         |\n",
      "|    n_updates            | 28910        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | -0.4312644   |\n",
      "|    std                  | 61.8         |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2893          |\n",
      "|    time_elapsed         | 53745         |\n",
      "|    total_timesteps      | 5924864       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095242134 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.716         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 69.1          |\n",
      "|    n_updates            | 28920         |\n",
      "|    policy_gradient_loss | -0.00248      |\n",
      "|    reward               | 4.932365      |\n",
      "|    std                  | 61.9          |\n",
      "|    value_loss           | 199           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2894          |\n",
      "|    time_elapsed         | 53763         |\n",
      "|    total_timesteps      | 5926912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039289834 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.666         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 81.1          |\n",
      "|    n_updates            | 28930         |\n",
      "|    policy_gradient_loss | -0.00195      |\n",
      "|    reward               | 0.5522979     |\n",
      "|    std                  | 62            |\n",
      "|    value_loss           | 141           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6551856.75\n",
      "total_reward: 5551856.75\n",
      "total_cost: 252209.42\n",
      "total_trades: 62295\n",
      "Sharpe: 0.785\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2895         |\n",
      "|    time_elapsed         | 53780        |\n",
      "|    total_timesteps      | 5928960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033860407 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 28940        |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    reward               | 0.2426983    |\n",
      "|    std                  | 62.3         |\n",
      "|    value_loss           | 38.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2896         |\n",
      "|    time_elapsed         | 53798        |\n",
      "|    total_timesteps      | 5931008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012949902 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.1         |\n",
      "|    n_updates            | 28950        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | -2.3252604   |\n",
      "|    std                  | 62.3         |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2897         |\n",
      "|    time_elapsed         | 53816        |\n",
      "|    total_timesteps      | 5933056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005491212 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.7         |\n",
      "|    n_updates            | 28960        |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    reward               | 3.8683696    |\n",
      "|    std                  | 62.4         |\n",
      "|    value_loss           | 181          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2898         |\n",
      "|    time_elapsed         | 53833        |\n",
      "|    total_timesteps      | 5935104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038687035 |\n",
      "|    clip_fraction        | 0.00591      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 28970        |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    reward               | 2.738659     |\n",
      "|    std                  | 62.6         |\n",
      "|    value_loss           | 58.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2899         |\n",
      "|    time_elapsed         | 53851        |\n",
      "|    total_timesteps      | 5937152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005660672 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.646        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.3         |\n",
      "|    n_updates            | 28980        |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    reward               | 1.7433501    |\n",
      "|    std                  | 62.7         |\n",
      "|    value_loss           | 194          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2900         |\n",
      "|    time_elapsed         | 53868        |\n",
      "|    total_timesteps      | 5939200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004343465 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.681        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.7         |\n",
      "|    n_updates            | 28990        |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    reward               | 10.26489     |\n",
      "|    std                  | 62.7         |\n",
      "|    value_loss           | 157          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2901         |\n",
      "|    time_elapsed         | 53886        |\n",
      "|    total_timesteps      | 5941248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009085508 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.7         |\n",
      "|    n_updates            | 29000        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | -0.7116177   |\n",
      "|    std                  | 62.8         |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2902         |\n",
      "|    time_elapsed         | 53903        |\n",
      "|    total_timesteps      | 5943296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026239583 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.5         |\n",
      "|    n_updates            | 29010        |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    reward               | -0.4835405   |\n",
      "|    std                  | 63           |\n",
      "|    value_loss           | 91.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2903          |\n",
      "|    time_elapsed         | 53920         |\n",
      "|    total_timesteps      | 5945344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048936147 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.751         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 104           |\n",
      "|    n_updates            | 29020         |\n",
      "|    policy_gradient_loss | -0.00244      |\n",
      "|    reward               | 1.3352728     |\n",
      "|    std                  | 63.1          |\n",
      "|    value_loss           | 232           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2904          |\n",
      "|    time_elapsed         | 53938         |\n",
      "|    total_timesteps      | 5947392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034509483 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.745         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 93.9          |\n",
      "|    n_updates            | 29030         |\n",
      "|    policy_gradient_loss | -0.00195      |\n",
      "|    reward               | -0.99872696   |\n",
      "|    std                  | 63.2          |\n",
      "|    value_loss           | 240           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2905         |\n",
      "|    time_elapsed         | 53955        |\n",
      "|    total_timesteps      | 5949440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057797097 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 29040        |\n",
      "|    policy_gradient_loss | -0.00796     |\n",
      "|    reward               | 0.7182708    |\n",
      "|    std                  | 63.4         |\n",
      "|    value_loss           | 52.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2906         |\n",
      "|    time_elapsed         | 53972        |\n",
      "|    total_timesteps      | 5951488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001561084 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.805        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 149          |\n",
      "|    n_updates            | 29050        |\n",
      "|    policy_gradient_loss | -0.000514    |\n",
      "|    reward               | 0.010296155  |\n",
      "|    std                  | 63.5         |\n",
      "|    value_loss           | 240          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2907         |\n",
      "|    time_elapsed         | 53990        |\n",
      "|    total_timesteps      | 5953536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005682432 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.296        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.7         |\n",
      "|    n_updates            | 29060        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    reward               | -0.41152188  |\n",
      "|    std                  | 63.5         |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2908          |\n",
      "|    time_elapsed         | 54007         |\n",
      "|    total_timesteps      | 5955584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047361196 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.202         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 33.9          |\n",
      "|    n_updates            | 29070         |\n",
      "|    policy_gradient_loss | -0.00187      |\n",
      "|    reward               | 2.1029255     |\n",
      "|    std                  | 63.7          |\n",
      "|    value_loss           | 99.1          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6786789.31\n",
      "total_reward: 5786789.31\n",
      "total_cost: 306542.17\n",
      "total_trades: 64947\n",
      "Sharpe: 0.819\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2909         |\n",
      "|    time_elapsed         | 54024        |\n",
      "|    total_timesteps      | 5957632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014233453 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.4         |\n",
      "|    n_updates            | 29080        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    reward               | 0.47103837   |\n",
      "|    std                  | 63.7         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2910          |\n",
      "|    time_elapsed         | 54041         |\n",
      "|    total_timesteps      | 5959680       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.7131735e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.566         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 113           |\n",
      "|    n_updates            | 29090         |\n",
      "|    policy_gradient_loss | -0.000806     |\n",
      "|    reward               | 1.0970222     |\n",
      "|    std                  | 63.7          |\n",
      "|    value_loss           | 212           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2911          |\n",
      "|    time_elapsed         | 54058         |\n",
      "|    total_timesteps      | 5961728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035188257 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.723         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 75.1          |\n",
      "|    n_updates            | 29100         |\n",
      "|    policy_gradient_loss | -0.00112      |\n",
      "|    reward               | 0.851284      |\n",
      "|    std                  | 63.8          |\n",
      "|    value_loss           | 180           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2912         |\n",
      "|    time_elapsed         | 54076        |\n",
      "|    total_timesteps      | 5963776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066116666 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.218        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 29110        |\n",
      "|    policy_gradient_loss | -0.0073      |\n",
      "|    reward               | -1.0368093   |\n",
      "|    std                  | 63.9         |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2913          |\n",
      "|    time_elapsed         | 54093         |\n",
      "|    total_timesteps      | 5965824       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030637774 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.648         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 30.7          |\n",
      "|    n_updates            | 29120         |\n",
      "|    policy_gradient_loss | -0.0014       |\n",
      "|    reward               | 0.6633088     |\n",
      "|    std                  | 64            |\n",
      "|    value_loss           | 115           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2914          |\n",
      "|    time_elapsed         | 54110         |\n",
      "|    total_timesteps      | 5967872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036834442 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.406         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 75.8          |\n",
      "|    n_updates            | 29130         |\n",
      "|    policy_gradient_loss | -0.00154      |\n",
      "|    reward               | -2.6414196    |\n",
      "|    std                  | 64.1          |\n",
      "|    value_loss           | 192           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2915          |\n",
      "|    time_elapsed         | 54127         |\n",
      "|    total_timesteps      | 5969920       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043695123 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.525         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 47.9          |\n",
      "|    n_updates            | 29140         |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    reward               | 5.3888483     |\n",
      "|    std                  | 64.2          |\n",
      "|    value_loss           | 110           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2916          |\n",
      "|    time_elapsed         | 54145         |\n",
      "|    total_timesteps      | 5971968       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00059479143 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.119         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 87.1          |\n",
      "|    n_updates            | 29150         |\n",
      "|    policy_gradient_loss | -0.00169      |\n",
      "|    reward               | -1.5351295    |\n",
      "|    std                  | 64.3          |\n",
      "|    value_loss           | 143           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2917          |\n",
      "|    time_elapsed         | 54162         |\n",
      "|    total_timesteps      | 5974016       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023932249 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.427         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 131           |\n",
      "|    n_updates            | 29160         |\n",
      "|    policy_gradient_loss | -0.00161      |\n",
      "|    reward               | 12.573723     |\n",
      "|    std                  | 64.4          |\n",
      "|    value_loss           | 218           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2918          |\n",
      "|    time_elapsed         | 54180         |\n",
      "|    total_timesteps      | 5976064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028695268 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.519         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 119           |\n",
      "|    n_updates            | 29170         |\n",
      "|    policy_gradient_loss | -0.00126      |\n",
      "|    reward               | 0.2671525     |\n",
      "|    std                  | 64.5          |\n",
      "|    value_loss           | 233           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2919        |\n",
      "|    time_elapsed         | 54197       |\n",
      "|    total_timesteps      | 5978112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005716388 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -160        |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.8        |\n",
      "|    n_updates            | 29180       |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    reward               | 1.5935493   |\n",
      "|    std                  | 64.9        |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2920          |\n",
      "|    time_elapsed         | 54214         |\n",
      "|    total_timesteps      | 5980160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028931515 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.527         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 59.1          |\n",
      "|    n_updates            | 29190         |\n",
      "|    policy_gradient_loss | -0.00118      |\n",
      "|    reward               | -2.1875503    |\n",
      "|    std                  | 64.9          |\n",
      "|    value_loss           | 141           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2921          |\n",
      "|    time_elapsed         | 54232         |\n",
      "|    total_timesteps      | 5982208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067856815 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.207         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 63.4          |\n",
      "|    n_updates            | 29200         |\n",
      "|    policy_gradient_loss | -0.00218      |\n",
      "|    reward               | -2.278037     |\n",
      "|    std                  | 65            |\n",
      "|    value_loss           | 279           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2922         |\n",
      "|    time_elapsed         | 54249        |\n",
      "|    total_timesteps      | 5984256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026393107 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.383        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 29210        |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    reward               | 0.62554795   |\n",
      "|    std                  | 65           |\n",
      "|    value_loss           | 65.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5953287.74\n",
      "total_reward: 4953287.74\n",
      "total_cost: 265413.38\n",
      "total_trades: 62516\n",
      "Sharpe: 0.749\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2923          |\n",
      "|    time_elapsed         | 54266         |\n",
      "|    total_timesteps      | 5986304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054609915 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.209         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 120           |\n",
      "|    n_updates            | 29220         |\n",
      "|    policy_gradient_loss | -0.00162      |\n",
      "|    reward               | 0.90818644    |\n",
      "|    std                  | 65.1          |\n",
      "|    value_loss           | 183           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2924          |\n",
      "|    time_elapsed         | 54283         |\n",
      "|    total_timesteps      | 5988352       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021248104 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.448         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 61.2          |\n",
      "|    n_updates            | 29230         |\n",
      "|    policy_gradient_loss | -0.00103      |\n",
      "|    reward               | 4.13049       |\n",
      "|    std                  | 65.1          |\n",
      "|    value_loss           | 189           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2925          |\n",
      "|    time_elapsed         | 54301         |\n",
      "|    total_timesteps      | 5990400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031816008 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.334         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 60.4          |\n",
      "|    n_updates            | 29240         |\n",
      "|    policy_gradient_loss | -0.00114      |\n",
      "|    reward               | 0.67881453    |\n",
      "|    std                  | 65.2          |\n",
      "|    value_loss           | 110           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2926         |\n",
      "|    time_elapsed         | 54318        |\n",
      "|    total_timesteps      | 5992448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020584427 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 29250        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    reward               | -0.67841166  |\n",
      "|    std                  | 65.3         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2927        |\n",
      "|    time_elapsed         | 54335       |\n",
      "|    total_timesteps      | 5994496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000521429 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -161        |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 29260       |\n",
      "|    policy_gradient_loss | -0.00192    |\n",
      "|    reward               | 0.77004665  |\n",
      "|    std                  | 65.4        |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2928         |\n",
      "|    time_elapsed         | 54353        |\n",
      "|    total_timesteps      | 5996544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002398447 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.515        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.5         |\n",
      "|    n_updates            | 29270        |\n",
      "|    policy_gradient_loss | -0.000922    |\n",
      "|    reward               | -0.953974    |\n",
      "|    std                  | 65.5         |\n",
      "|    value_loss           | 216          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2929        |\n",
      "|    time_elapsed         | 54369       |\n",
      "|    total_timesteps      | 5998592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003046695 |\n",
      "|    clip_fraction        | 0.00371     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -161        |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 29280       |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    reward               | -6.536346   |\n",
      "|    std                  | 65.8        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2930         |\n",
      "|    time_elapsed         | 54387        |\n",
      "|    total_timesteps      | 6000640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007339814 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.5         |\n",
      "|    n_updates            | 29290        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | -0.24564207  |\n",
      "|    std                  | 66           |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# model_ppo2.load('42')\n",
    "print('load')\n",
    "trained_ppo2 = agent_con.train_model(model=model_ppo2, \n",
    "                             tb_log_name=\"9\",\n",
    "                             total_timesteps=6000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Model 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xwOhVjqRkCdM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "K8RSdKCckJyH"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23766/4244563930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_sac = agent.train_model(model=model_sac, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sac'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              total_timesteps=60000)\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         )\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;31m# Special case when the user passes `gradient_steps=0`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgradient_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# Select action according to policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                 \u001b[0mnext_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# Compute the next Q values: min over all critics targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mnext_q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/policies.py\u001b[0m in \u001b[0;36maction_log_prob\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_dist_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# return action and associated log prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mlog_prob_from_params\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mactions_from_params\u001b[0;34m(self, mean_actions, log_std, deterministic)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Update the proba distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"SquashedDiagGaussianDistribution\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSquashedDiagGaussianDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m    151\u001b[0m         \u001b[0maction_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     raise ValueError(\n\u001b[1;32m     56\u001b[0m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at 2020-07-01. We use the DDPG model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEv5KGC8h1jE"
   },
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be greater than the maximum of insample turbulence data, if current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "efwBi84ch1jE"
   },
   "outputs": [],
   "source": [
    "data_risk_indicator = processed_full[(processed_full.date<'2020-07-01') & (processed_full.date>='2009-01-01')]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n",
    "\n",
    "trained_ppo2.save('92')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VHZMBpSqh1jG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       18.824245\n",
       "std         8.489311\n",
       "min         9.140000\n",
       "25%        13.330000\n",
       "50%        16.139999\n",
       "75%        21.309999\n",
       "max        82.690002\n",
       "Name: vix, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "BDkszkMloRWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.40400183105453"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.quantile(0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "AL7hs7svnNWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       34.574233\n",
       "std        43.787150\n",
       "min         0.000000\n",
       "25%        14.966105\n",
       "50%        24.124290\n",
       "75%        39.162080\n",
       "max       652.505555\n",
       "Name: turbulence, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "N78hfHckoqJ9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276.45132359815483"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.quantile(0.996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trade\n",
    "\n",
    "DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "cIqoV0GSI52v"
   },
   "outputs": [],
   "source": [
    "#trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "W_XNgGsBMeVw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "eLOnL5eYh1jR"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trained_ppo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_74364/536458364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     environment = e_trade_gym)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m df_account_value, df_actions = DRLAgent.DRL_prediction(\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_ppo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     environment = e_trade_gym)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trained_ppo' is not defined"
     ]
    }
   ],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERxw3KqLkcP4"
   },
   "outputs": [],
   "source": [
    "df_account_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yRkNguY5yvp"
   },
   "outputs": [],
   "source": [
    "df_account_value.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFlK5hNbWVFk"
   },
   "outputs": [],
   "source": [
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nzkr9yv-AdV_"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkV-LB66iwhD"
   },
   "outputs": [],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "qg1kvfemrrQH"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50697/2351900042.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value.loc[0,'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "tt1bzL5OrsTa"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50697/1309470278.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_account_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value.loc[len(df_account_value)-1,'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "lKRGftSS7pNM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to DJIA===========\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50697/2064601725.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Dow Jones Index: ^DJI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# NASDAQ 100: ^NDX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m backtest_plot(df_account_value, \n\u001b[0m\u001b[1;32m      7\u001b[0m              \u001b[0mbaseline_ticker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'^DJI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m              \u001b[0mbaseline_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "BzBaE63H3RLc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>1.392028e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>1.396311e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>1.397991e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>1.382603e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>1.388971e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  account_value\n",
       "331  2021-10-22   1.392028e+06\n",
       "332  2021-10-25   1.396311e+06\n",
       "333  2021-10-26   1.397991e+06\n",
       "334  2021-10-27   1.382603e+06\n",
       "335  2021-10-28   1.388971e+06"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value2, df_actions2 = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo2, \n",
    "    environment = e_trade_gym)\n",
    "df_account_value2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ZYeOjax-7H_5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.279440\n",
      "Cumulative returns     0.388971\n",
      "Annual volatility      0.150276\n",
      "Sharpe ratio           1.720515\n",
      "Calmar ratio           2.572170\n",
      "Stability              0.935587\n",
      "Max drawdown          -0.108640\n",
      "Omega ratio            1.338568\n",
      "Sortino ratio          2.534959\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.073039\n",
      "Daily value at risk   -0.017907\n",
      "dtype: float64\n",
      "==============Get Baseline Stats===========\n",
      "Annual return          0.269722\n",
      "Cumulative returns     0.374922\n",
      "Annual volatility      0.139083\n",
      "Sharpe ratio           1.792302\n",
      "Calmar ratio           3.020136\n",
      "Stability              0.919220\n",
      "Max drawdown          -0.089308\n",
      "Omega ratio            1.347571\n",
      "Sortino ratio          2.655481\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.052781\n",
      "Daily value at risk   -0.016534\n",
      "dtype: float64\n",
      "==============Compare to DJIA===========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2020-07-01</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2021-10-28</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>16</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>27.944%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>38.897%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>15.028%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-10.864%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-1.791%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.86</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>2020-11-11</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.78</td>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.01</td>\n",
       "      <td>2021-05-07</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.82</td>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.57</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>2021-02-26</td>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stress Events</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Normal</th>\n",
       "      <td>0.10%</td>\n",
       "      <td>-3.47%</td>\n",
       "      <td>3.15%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x5184 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value2)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'2.csv')\n",
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value2.loc[0,'date'],\n",
    "        end = df_account_value2.loc[len(df_account_value2)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n",
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value2, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value2.loc[0,'date'],\n",
    "             baseline_end = df_account_value2.loc[len(df_account_value2)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Uy5_PTmOh1hj",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_StockTrading_NeurIPS_2018.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
