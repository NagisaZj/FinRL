{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/FinRL_StockTrading_NeurIPS_2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
    "\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)   \n",
    "* [RLlib Section](#7)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "ef0ba8d0-f57a-4c74-bb0b-46737762677d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
      "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to /tmp/pip-req-build-8i1_yu6g\n",
      "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-8i1_yu6g\n",
      "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
      "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
      "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "  Running command git clone -q https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.19.5)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.1.5)\n",
      "Collecting stockstats\n",
      "  Downloading stockstats-0.3.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.1.67-py2.py3-none-any.whl (25 kB)\n",
      "Collecting elegantrl\n",
      "  Downloading elegantrl-0.3.2-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 2.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.17.3)\n",
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-1.3.0-py3-none-any.whl (174 kB)\n",
      "\u001b[K     |████████████████████████████████| 174 kB 65.2 MB/s \n",
      "\u001b[?25hCollecting ray[default]\n",
      "  Downloading ray-1.9.1-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 57.6 MB 1.4 MB/s \n",
      "\u001b[?25hCollecting lz4\n",
      "  Downloading lz4-3.1.10-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 42.9 MB/s \n",
      "\u001b[?25hCollecting tensorboardX\n",
      "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 71.5 MB/s \n",
      "\u001b[?25hCollecting gputil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "Collecting exchange_calendars\n",
      "  Downloading exchange_calendars-3.5.tar.gz (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 35.6 MB/s \n",
      "\u001b[?25hCollecting alpaca_trade_api\n",
      "  Downloading alpaca_trade_api-1.4.3-py3-none-any.whl (36 kB)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting jqdatasdk\n",
      "  Downloading jqdatasdk-1.8.10-py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 57.3 MB/s \n",
      "\u001b[?25hCollecting wrds\n",
      "  Downloading wrds-3.1.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.6.4)\n",
      "Requirement already satisfied: setuptools>=41.4.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (57.4.0)\n",
      "Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.37.0)\n",
      "Collecting pre-commit\n",
      "  Downloading pre_commit-2.16.0-py2.py3-none-any.whl (191 kB)\n",
      "\u001b[K     |████████████████████████████████| 191 kB 55.1 MB/s \n",
      "\u001b[?25hCollecting pybullet\n",
      "  Downloading pybullet-3.2.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (90.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 90.8 MB 244 bytes/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (1.10.0+cu111)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (4.1.2.30)\n",
      "Collecting box2d-py\n",
      "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 50.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.5.0)\n",
      "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2018.9)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.4.1)\n",
      "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.11.2)\n",
      "Collecting empyrical>=0.5.0\n",
      "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.9.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.0.18)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.4.2)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.6.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (0.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.23.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.2.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.2.5)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.3.3) (0.16.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (1.1.0)\n",
      "Collecting websocket-client<2,>=0.56.0\n",
      "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
      "\u001b[?25hCollecting PyYAML==5.4.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 52.7 MB/s \n",
      "\u001b[?25hCollecting msgpack==1.0.2\n",
      "  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
      "\u001b[K     |████████████████████████████████| 273 kB 60.4 MB/s \n",
      "\u001b[?25hCollecting aiohttp==3.7.4\n",
      "  Downloading aiohttp-3.7.4-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 55.5 MB/s \n",
      "\u001b[?25hCollecting websockets<10,>=8.0\n",
      "  Downloading websockets-9.1-cp37-cp37m-manylinux2010_x86_64.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 48.7 MB/s \n",
      "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (3.10.0.2)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 56.6 MB/s \n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 57.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (21.2.0)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 68.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 28.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 21.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 11.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 70.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 24.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 14.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 65.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.85-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 59.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.84-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.83-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.82-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.81-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.80-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 35.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.79-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.78-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 20.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.77-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.76-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.75-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.74-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 34.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.73-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.72-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.71-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.70-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.69-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.68-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 60.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.67-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.66-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.65-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.64-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.63-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.62-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.61-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.60-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 57.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.59-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.58-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.57-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.56-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.55-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.54-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.53-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.52-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.51-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.6 MB/s \n",
      "\u001b[?25hCollecting aiodns>=1.1.1\n",
      "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 60.7 MB/s \n",
      "\u001b[?25hCollecting cryptography>=2.6.1\n",
      "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 42.6 MB/s \n",
      "\u001b[?25hCollecting pycares>=4.0.0\n",
      "  Downloading pycares-4.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (291 kB)\n",
      "\u001b[K     |████████████████████████████████| 291 kB 44.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt->finrl==0.3.3) (2.21)\n",
      "Collecting pyluach\n",
      "  Downloading pyluach-1.3.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.11.2)\n",
      "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.2.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.3) (1.4.27)\n",
      "Collecting thriftpy2>=0.3.9\n",
      "  Downloading thriftpy2-0.4.14.tar.gz (361 kB)\n",
      "\u001b[K     |████████████████████████████████| 361 kB 50.4 MB/s \n",
      "\u001b[?25hCollecting pymysql>=0.7.6\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (1.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (4.8.2)\n",
      "Collecting ply<4.0,>=3.4\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (3.6.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.0)\n",
      "Collecting cfgv>=2.0.0\n",
      "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (0.10.2)\n",
      "Collecting identify>=1.0.0\n",
      "  Downloading identify-2.4.1-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 7.2 MB/s \n",
      "\u001b[?25hCollecting virtualenv>=20.0.8\n",
      "  Downloading virtualenv-20.11.0-py2.py3-none-any.whl (6.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5 MB 39.6 MB/s \n",
      "\u001b[?25hCollecting nodeenv>=0.11.1\n",
      "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (3.4.0)\n",
      "Collecting distlib<1,>=0.3.1\n",
      "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
      "\u001b[K     |████████████████████████████████| 461 kB 32.3 MB/s \n",
      "\u001b[?25hCollecting platformdirs<3,>=2\n",
      "  Downloading platformdirs-2.4.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (0.7.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.11.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (8.12.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.42.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (3.17.3)\n",
      "Collecting redis>=3.5.0\n",
      "  Downloading redis-4.1.0-py3-none-any.whl (171 kB)\n",
      "\u001b[K     |████████████████████████████████| 171 kB 57.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (2.6.0)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.12.0)\n",
      "Collecting aioredis<2\n",
      "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.6 MB/s \n",
      "\u001b[?25hCollecting py-spy>=0.2.0\n",
      "  Downloading py_spy-0.3.11-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 50.8 MB/s \n",
      "\u001b[?25hCollecting colorful\n",
      "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[K     |████████████████████████████████| 201 kB 70.8 MB/s \n",
      "\u001b[?25hCollecting aiohttp-cors\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (5.2.1)\n",
      "Collecting aiosignal\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist\n",
      "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
      "\u001b[K     |████████████████████████████████| 192 kB 7.1 MB/s \n",
      "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
      "  Downloading gpustat-1.0.0b1.tar.gz (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 213 kB/s \n",
      "\u001b[?25hCollecting opencensus\n",
      "  Downloading opencensus-0.8.0-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 53.5 MB/s \n",
      "\u001b[?25hCollecting hiredis\n",
      "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 2.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (7.352.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (5.4.8)\n",
      "Collecting blessed>=1.17.1\n",
      "  Downloading blessed-1.19.0-py2.py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 4.8 MB/s \n",
      "\u001b[?25hCollecting deprecated>=1.2.3\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]->finrl==0.3.3) (21.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[default]->finrl==0.3.3) (1.13.3)\n",
      "Collecting opencensus-context==0.1.2\n",
      "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.3) (1.26.3)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.35.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.53.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.4.8)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.8.9)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (2.7.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (0.2.9)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.1.1)\n",
      "Collecting int-date>=0.1.7\n",
      "  Downloading int_date-0.1.8-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting mock\n",
      "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.4 MB 45.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.3) (0.0.10)\n",
      "Building wheels for collected packages: finrl, elegantrl, pyfolio, empyrical, exchange-calendars, gputil, thriftpy2, gpustat\n",
      "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for finrl: filename=finrl-0.3.3-py3-none-any.whl size=3885640 sha256=1667a85b9c8c0a7a8efbf04d5ebf154d5d1ea119a32e922d094820030ce0e7e4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/17/ff/bd/1bc602a0352762b0b24041b88536d803ae343ed0a711fcf55e\n",
      "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for elegantrl: filename=elegantrl-0.3.2-py3-none-any.whl size=168744 sha256=7773813204e1a2954730bd149444640d5155458fc82b6910ec4e661879797016\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/99/85/5e/86cb3a9f47adfca5e248295e93113e1b298d60883126d62c84\n",
      "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75775 sha256=e3753b24d032afc5ef0b133c50557002ca9fed8416e2205e1547fc81af5c124a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/ef/09/e5/2c1bf37c050d22557c080deb1be986d06424627c04aeca19b9\n",
      "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39777 sha256=6cc78a6b3f88187e2798221487acba0361bb1d094b6c82496348fb4c85f7686b\n",
      "  Stored in directory: /root/.cache/pip/wheels/d9/91/4b/654fcff57477efcf149eaca236da2fce991526cbab431bf312\n",
      "  Building wheel for exchange-calendars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for exchange-calendars: filename=exchange_calendars-3.5-py3-none-any.whl size=179487 sha256=3d877d78e29a28c4b098f4a0b1d0106458d7f73b52f6c7a43d0757d55c11d44b\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/21/43/b6ae2605dd767f6cd5a5b0b70c93a9a75823e44b3ccb92bce7\n",
      "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=33dcd980f1b32f0582d029fcef126ae53327fb90724eee8c33bc3b4dbebda4b1\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
      "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for thriftpy2: filename=thriftpy2-0.4.14-cp37-cp37m-linux_x86_64.whl size=940507 sha256=429244bf5fd89014c79f01bf0e4a59477258cd2b88978e3125b54f4bd62a88f5\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/f5/49/9c0d851aa64b58db72883cf9393cc824d536bdf13f5c83cff4\n",
      "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gpustat: filename=gpustat-1.0.0b1-py3-none-any.whl size=15979 sha256=b831a9dba6682b3e0a7ae05d7c2ba465918426c72474917e56e0850ac8c73263\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/16/e2/3e2437fba4c4b6a97a97bd96fce5d14e66cff5c4966fb1cc8c\n",
      "Successfully built finrl elegantrl pyfolio empyrical exchange-calendars gputil thriftpy2 gpustat\n",
      "Installing collected packages: multidict, yarl, lxml, deprecated, async-timeout, redis, PyYAML, pycares, ply, platformdirs, opencensus-context, msgpack, hiredis, frozenlist, distlib, blessed, aiohttp, websockets, websocket-client, virtualenv, thriftpy2, tensorboardX, stable-baselines3, ray, pymysql, pyluach, pybullet, py-spy, psycopg2-binary, opencensus, nodeenv, mock, int-date, identify, gpustat, empyrical, cryptography, colorful, cfgv, box2d-py, aiosignal, aioredis, aiohttp-cors, aiodns, yfinance, wrds, stockstats, pyfolio, pre-commit, lz4, jqdatasdk, gputil, exchange-calendars, elegantrl, ccxt, alpaca-trade-api, finrl\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.2.6\n",
      "    Uninstalling lxml-4.2.6:\n",
      "      Successfully uninstalled lxml-4.2.6\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.3\n",
      "    Uninstalling msgpack-1.0.3:\n",
      "      Successfully uninstalled msgpack-1.0.3\n",
      "Successfully installed PyYAML-5.4.1 aiodns-3.0.0 aiohttp-3.7.4 aiohttp-cors-0.7.0 aioredis-1.3.1 aiosignal-1.2.0 alpaca-trade-api-1.4.3 async-timeout-3.0.1 blessed-1.19.0 box2d-py-2.3.8 ccxt-1.61.51 cfgv-3.3.1 colorful-0.5.4 cryptography-36.0.1 deprecated-1.2.13 distlib-0.3.4 elegantrl-0.3.2 empyrical-0.5.5 exchange-calendars-3.5 finrl-0.3.3 frozenlist-1.2.0 gpustat-1.0.0b1 gputil-1.4.0 hiredis-2.0.0 identify-2.4.1 int-date-0.1.8 jqdatasdk-1.8.10 lxml-4.7.1 lz4-3.1.10 mock-4.0.3 msgpack-1.0.2 multidict-5.2.0 nodeenv-1.6.0 opencensus-0.8.0 opencensus-context-0.1.2 platformdirs-2.4.1 ply-3.11 pre-commit-2.16.0 psycopg2-binary-2.9.2 py-spy-0.3.11 pybullet-3.2.1 pycares-4.1.2 pyfolio-0.9.2+75.g4b901f6 pyluach-1.3.0 pymysql-1.0.2 ray-1.9.1 redis-4.1.0 stable-baselines3-1.3.0 stockstats-0.3.2 tensorboardX-2.4.1 thriftpy2-0.4.14 virtualenv-20.11.0 websocket-client-1.2.3 websockets-9.1 wrds-3.1.1 yarl-1.6.3 yfinance-0.1.67\n"
     ]
    }
   ],
   "source": [
    "## install finrl library\n",
    "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "10b08480-3a0c-4826-8e51-f94ce97ab84a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zj/anaconda3/envs/finrl/lib/python3.7/site-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.finrl_meta.preprocessor.tusharedownloader import TushareDownloader\n",
    "from finrl.finrl_meta.data_processors.processor_alpaca import AlpacaProcessor\n",
    "from finrl.finrl_meta.data_processors.processor_wrds import WrdsProcessor\n",
    "from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading_conservative import StockTradingEnvCon\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.finrl_meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot2 import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "5302d7c0-1c68-4c6e-b30e-b1395bdc109e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-01-01'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py TRAIN_START_DATE is a string\n",
    "config.TRAIN_START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FUnY8WEfLq3C",
    "outputId": "35dd8c5b-d58f-49b8-e4df-ae7e122448cd"
   },
   "outputs": [],
   "source": [
    "# from config.py TRAIN_END_DATE is a string\n",
    "# config.TRAIN_END_DATE\n",
    "# df2=TushareDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "83c7f894-3757-473b-8afb-a904e6caabda",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = YahooDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "7a991dfe-f39c-40db-ec44-7c416cdce7dc"
   },
   "outputs": [],
   "source": [
    "# print(config_tickers.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "5267773c-399c-4ec9-d4d5-13ab1e4cced0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94360, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./1.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "210fade5-e912-40df-be99-4ad00bdb9d2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600</td>\n",
       "      <td>AXP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100</td>\n",
       "      <td>BA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400</td>\n",
       "      <td>CAT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date       open       high        low      close  \\\n",
       "0           0  2008-12-31   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31  43.700001  45.099998  43.700001  30.628819   \n",
       "\n",
       "      volume   tic  day  \n",
       "0  607541200  AAPL    2  \n",
       "1    6287200  AMGN    2  \n",
       "2    9625600   AXP    2  \n",
       "3    5443100    BA    2  \n",
       "4    6277400   CAT    2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmKP-1ii3RLS",
    "outputId": "0708badb-77ef-4c86-f77c-6525f0e8934d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fe = FeatureEngineer(\n",
    "#                     use_technical_indicator=True,\n",
    "#                     tech_indicator_list = config.INDICATORS,\n",
    "#                     use_vix=True,\n",
    "#                     use_turbulence=True,\n",
    "#                     user_defined_feature = False)\n",
    "\n",
    "# processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Kixon2tR3RLT"
   },
   "outputs": [],
   "source": [
    "# list_ticker = processed[\"tic\"].unique().tolist()\n",
    "# list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "# combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "# processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "# processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "# processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "# processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "grvhGJJII3Xn",
    "outputId": "733758c3-3552-4aa5-e1f9-789bd4ce0c92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AXP</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>BA</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CAT</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CRM</td>\n",
       "      <td>7.712500</td>\n",
       "      <td>8.130000</td>\n",
       "      <td>7.707500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>5367600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>16.180000</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.120001</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>37513700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CVX</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>74.629997</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>9964300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>DIS</td>\n",
       "      <td>22.570000</td>\n",
       "      <td>22.950001</td>\n",
       "      <td>22.520000</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>9012100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>GS</td>\n",
       "      <td>82.239998</td>\n",
       "      <td>86.150002</td>\n",
       "      <td>81.120003</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>14894100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic       open       high        low      close  \\\n",
       "0           0  2008-12-31  AAPL   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  AMGN  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31   AXP  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31    BA  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31   CAT  43.700001  45.099998  43.700001  30.628819   \n",
       "5           5  2008-12-31   CRM   7.712500   8.130000   7.707500   8.002500   \n",
       "6           6  2008-12-31  CSCO  16.180000  16.549999  16.120001  11.787783   \n",
       "7           7  2008-12-31   CVX  72.900002  74.629997  72.900002  43.314438   \n",
       "8           8  2008-12-31   DIS  22.570000  22.950001  22.520000  19.538342   \n",
       "9           9  2008-12-31    GS  82.239998  86.150002  81.120003  69.224182   \n",
       "\n",
       "        volume  day  macd   boll_ub   boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0  607541200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "1    6287200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "2    9625600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "3    5443100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "4    6277400.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "5    5367600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "6   37513700.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "7    9964300.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "8    9012100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "9   14894100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma   vix  turbulence  \n",
       "0      2.606277      2.606277  40.0         0.0  \n",
       "1     43.924454     43.924454  40.0         0.0  \n",
       "2     14.908465     14.908465  40.0         0.0  \n",
       "3     32.005894     32.005894  40.0         0.0  \n",
       "4     30.628819     30.628819  40.0         0.0  \n",
       "5      8.002500      8.002500  40.0         0.0  \n",
       "6     11.787783     11.787783  40.0         0.0  \n",
       "7     43.314438     43.314438  40.0         0.0  \n",
       "8     19.538342     19.538342  40.0         0.0  \n",
       "9     69.224182     69.224182  40.0         0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full=pd.read_csv('./2.csv')\n",
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TOhcryx44bb"
   },
   "source": [
    "## Training data split: 2009-01-01 to 2020-07-01\n",
    "## Trade data split: 2020-07-01 to 2021-10-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "ca8d1a43-ffc3-4fc3-efa9-4de9a9065842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83897\n",
      "9744\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, '2009-01-01','2020-07-01')\n",
    "trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "p52zNCOhTtLR",
    "outputId": "b3ad3e10-376f-4186-f875-0331708c5e14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121795</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>UNH</td>\n",
       "      <td>288.570007</td>\n",
       "      <td>296.450012</td>\n",
       "      <td>287.660004</td>\n",
       "      <td>287.776794</td>\n",
       "      <td>2932900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>303.925869</td>\n",
       "      <td>271.251255</td>\n",
       "      <td>52.413046</td>\n",
       "      <td>-25.838431</td>\n",
       "      <td>1.846804</td>\n",
       "      <td>288.020689</td>\n",
       "      <td>281.001438</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121796</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>V</td>\n",
       "      <td>191.490005</td>\n",
       "      <td>193.750000</td>\n",
       "      <td>190.160004</td>\n",
       "      <td>190.737244</td>\n",
       "      <td>9040100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.048786</td>\n",
       "      <td>198.750528</td>\n",
       "      <td>185.041391</td>\n",
       "      <td>53.021033</td>\n",
       "      <td>-51.550760</td>\n",
       "      <td>2.013358</td>\n",
       "      <td>191.485037</td>\n",
       "      <td>181.677683</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121797</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>VZ</td>\n",
       "      <td>54.919998</td>\n",
       "      <td>55.290001</td>\n",
       "      <td>54.360001</td>\n",
       "      <td>50.376743</td>\n",
       "      <td>17414800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.437111</td>\n",
       "      <td>53.918425</td>\n",
       "      <td>48.729324</td>\n",
       "      <td>48.097044</td>\n",
       "      <td>-51.018262</td>\n",
       "      <td>8.508886</td>\n",
       "      <td>51.012123</td>\n",
       "      <td>51.464679</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121798</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WBA</td>\n",
       "      <td>42.119999</td>\n",
       "      <td>42.580002</td>\n",
       "      <td>41.759998</td>\n",
       "      <td>39.035732</td>\n",
       "      <td>4782100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.083986</td>\n",
       "      <td>42.609305</td>\n",
       "      <td>36.487095</td>\n",
       "      <td>48.830181</td>\n",
       "      <td>-14.508130</td>\n",
       "      <td>1.500723</td>\n",
       "      <td>39.135190</td>\n",
       "      <td>38.935129</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121799</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WMT</td>\n",
       "      <td>119.220001</td>\n",
       "      <td>120.129997</td>\n",
       "      <td>118.540001</td>\n",
       "      <td>116.121765</td>\n",
       "      <td>6836400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.886569</td>\n",
       "      <td>119.473758</td>\n",
       "      <td>113.510454</td>\n",
       "      <td>48.159665</td>\n",
       "      <td>-69.938795</td>\n",
       "      <td>3.847271</td>\n",
       "      <td>117.787627</td>\n",
       "      <td>119.723273</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        date  tic        open        high         low  \\\n",
       "2892      121795  2020-06-30  UNH  288.570007  296.450012  287.660004   \n",
       "2892      121796  2020-06-30    V  191.490005  193.750000  190.160004   \n",
       "2892      121797  2020-06-30   VZ   54.919998   55.290001   54.360001   \n",
       "2892      121798  2020-06-30  WBA   42.119999   42.580002   41.759998   \n",
       "2892      121799  2020-06-30  WMT  119.220001  120.129997  118.540001   \n",
       "\n",
       "           close      volume  day      macd     boll_ub     boll_lb  \\\n",
       "2892  287.776794   2932900.0  1.0 -0.019475  303.925869  271.251255   \n",
       "2892  190.737244   9040100.0  1.0  1.048786  198.750528  185.041391   \n",
       "2892   50.376743  17414800.0  1.0 -0.437111   53.918425   48.729324   \n",
       "2892   39.035732   4782100.0  1.0 -0.083986   42.609305   36.487095   \n",
       "2892  116.121765   6836400.0  1.0 -0.886569  119.473758  113.510454   \n",
       "\n",
       "         rsi_30     cci_30     dx_30  close_30_sma  close_60_sma    vix  \\\n",
       "2892  52.413046 -25.838431  1.846804    288.020689    281.001438  30.43   \n",
       "2892  53.021033 -51.550760  2.013358    191.485037    181.677683  30.43   \n",
       "2892  48.097044 -51.018262  8.508886     51.012123     51.464679  30.43   \n",
       "2892  48.830181 -14.508130  1.500723     39.135190     38.935129  30.43   \n",
       "2892  48.159665 -69.938795  3.847271    117.787627    119.723273  30.43   \n",
       "\n",
       "      turbulence  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "k9zU9YaTTvFq",
    "outputId": "72213585-39a3-4bff-c031-874ec0ca06f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "7f228183-abe3-4477-f574-3c9b25c62cd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "1f54d044-e2d3-4a34-c041-e913d686654e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "e_train_gym_conservative = StockTradingEnvCon(df = train, **env_kwargs)\n",
    "e_train_gym_conservative.value_history.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64EoqOrQjiVf"
   },
   "source": [
    "## Environment for Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "deeaef07-afda-4ca1-fea8-99384224c7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))\n",
    "env_train_con, _ = e_train_gym_conservative.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "364PsqckttcQ"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "agent_con = DRLAgent(env = env_train_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Model 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "a90a7a60-21a5-47e1-b683-1f7cbb4b8bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0GVpkWGqH4-D",
    "outputId": "570d540f-abe9-402b-e0cc-f9b007228e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 67         |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | -1.41      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -72.8      |\n",
      "|    reward             | 0.19451597 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.68       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 68         |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | -0.115     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -70.2      |\n",
      "|    reward             | -1.4624771 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.55       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0.198    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -167     |\n",
      "|    reward             | 5.02583  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 21.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -30.9    |\n",
      "|    reward             | 5.606354 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 368       |\n",
      "|    reward             | -7.546301 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 164       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0.0793    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 145       |\n",
      "|    reward             | 0.4507672 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 15        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | -0.0998    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -78.4      |\n",
      "|    reward             | -2.1521304 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 5.52       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0.00557     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 10.6        |\n",
      "|    reward             | -0.80710465 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 2.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 70.3        |\n",
      "|    reward             | -0.11950674 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 3.94        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -35.7      |\n",
      "|    reward             | -4.1389766 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.35       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -245     |\n",
      "|    reward             | 6.363784 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 38.5     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -63.1      |\n",
      "|    reward             | 0.07753525 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.93       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | -0.000831 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 48.9      |\n",
      "|    reward             | -4.088032 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 8         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 179       |\n",
      "|    reward             | 2.0626597 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 40.8      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 169       |\n",
      "|    reward             | 4.8591986 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 21.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 85.1       |\n",
      "|    reward             | 0.85958314 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 6.29       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -141     |\n",
      "|    reward             | 5.65319  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 51.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -41       |\n",
      "|    reward             | 1.1973313 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.57      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -26.6      |\n",
      "|    reward             | 0.36287376 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.68       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40         |\n",
      "|    explained_variance | -0.0091     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -83.6       |\n",
      "|    reward             | -0.30971453 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 13.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 204       |\n",
      "|    reward             | 1.7650424 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 30.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 158        |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | -153       |\n",
      "|    reward             | -7.5710273 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 23.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | -2.04e+03  |\n",
      "|    reward             | -14.886115 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3e+03      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 51        |\n",
      "|    reward             | 0.0559524 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.94      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -46.7     |\n",
      "|    reward             | -0.434364 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 5.71      |\n",
      "|    reward             | 4.8586307 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.131     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 194        |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -13.8      |\n",
      "|    reward             | -0.4118847 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.392      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 201       |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 328       |\n",
      "|    reward             | 1.0554261 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 66.3      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 209       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0.88      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -116      |\n",
      "|    reward             | 2.3091433 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 9.5       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 216        |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | -20.7      |\n",
      "|    reward             | 0.38583377 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.509      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 223        |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | 43.7       |\n",
      "|    reward             | -0.3664559 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 230        |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -38.8      |\n",
      "|    reward             | -0.4616701 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 11.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 237        |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | 96.4       |\n",
      "|    reward             | 0.11014476 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.58       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 245       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -3.93     |\n",
      "|    reward             | 2.1390972 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 30.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | 76.4       |\n",
      "|    reward             | 0.16336557 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.35       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 259       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -85.2     |\n",
      "|    reward             | 1.0221922 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.59      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 266       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 225       |\n",
      "|    reward             | 1.1701288 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 38.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 273       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 33.2      |\n",
      "|    reward             | 2.4472284 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.27      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 281        |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 41.3       |\n",
      "|    reward             | -1.2081411 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.04       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 288       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | -0.481    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -5.13     |\n",
      "|    reward             | 1.3224076 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2         |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | 1.15        |\n",
      "|    reward             | -0.25540048 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.837       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 302       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0.000881  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -119      |\n",
      "|    reward             | 1.3826902 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 10.9      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 309       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -64       |\n",
      "|    reward             | 3.9822705 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.59      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 63.9       |\n",
      "|    reward             | 0.95108056 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 4.87       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 324        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | 86.2       |\n",
      "|    reward             | -2.1539907 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 331       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 102       |\n",
      "|    reward             | 4.8509326 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0.00948     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | -105        |\n",
      "|    reward             | -0.22313617 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 8.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 346         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | -104        |\n",
      "|    reward             | -0.99914765 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 7.87        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 353        |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -33.2      |\n",
      "|    reward             | 0.20132123 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.946      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 360        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | -7.57e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 46.2       |\n",
      "|    reward             | 0.26696855 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.03       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 367        |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | -83.4      |\n",
      "|    reward             | -1.8360271 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 374       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -359      |\n",
      "|    reward             | 3.2874866 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 92.2      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3161472.69\n",
      "total_reward: 2161472.69\n",
      "total_cost: 19221.41\n",
      "total_trades: 41334\n",
      "Sharpe: 0.663\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 382       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -7.54     |\n",
      "|    reward             | 0.2828299 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.173     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 389         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | 26.5        |\n",
      "|    reward             | -0.19252001 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.14        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 396       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -15       |\n",
      "|    reward             | 2.0577734 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.6       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 403         |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -46.9       |\n",
      "|    reward             | -0.06746031 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.12        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 411        |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0.00117    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | -37.6      |\n",
      "|    reward             | 0.18157594 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.34       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 418       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0.0166    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -31.3     |\n",
      "|    reward             | 0.6473793 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.72      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 425        |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | 7.13       |\n",
      "|    reward             | 0.22656512 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.251      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 432        |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | 59.9       |\n",
      "|    reward             | -0.8028962 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.88       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 439        |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | -10.2      |\n",
      "|    reward             | -1.7693416 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.89       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 446         |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 20.2        |\n",
      "|    reward             | -0.10761352 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 454      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 203      |\n",
      "|    reward             | 3.869458 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 34.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 461       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -0.0428   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 110       |\n",
      "|    reward             | 1.2343621 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.67      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 468       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    reward             | -2.028344 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.83      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 475        |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | -66.8      |\n",
      "|    reward             | 0.33169752 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.98       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 483      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | 0.00675  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -869     |\n",
      "|    reward             | -8.09732 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 536      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 490        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 28.9       |\n",
      "|    reward             | 0.56556416 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 13         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 497        |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -176       |\n",
      "|    reward             | -2.9329143 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 88.1       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 504        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 72.3       |\n",
      "|    reward             | 0.22214015 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 3.11       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 511        |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 105        |\n",
      "|    reward             | -0.6425189 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 12         |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 519         |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | -360        |\n",
      "|    reward             | -0.22756429 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 80.8        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 526         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | -430        |\n",
      "|    reward             | -0.44158605 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 131         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 533        |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | 404        |\n",
      "|    reward             | -5.8487034 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 111        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 540       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 1.07e+03  |\n",
      "|    reward             | -14.82644 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 832       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 548       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -141      |\n",
      "|    reward             | 1.4826734 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 555        |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | -0.0473    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | -184       |\n",
      "|    reward             | 0.34629944 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 25.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 562       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -42       |\n",
      "|    reward             | -2.415951 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 6         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 569       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 55.1      |\n",
      "|    reward             | 5.0485888 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 42.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 576        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | -207       |\n",
      "|    reward             | -3.2154734 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 56.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 584       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | 257       |\n",
      "|    reward             | 5.370093  |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 56.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 591        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -160       |\n",
      "|    reward             | 0.03019213 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 16.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 598        |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 118        |\n",
      "|    reward             | -1.1561224 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 12.6       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 605         |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -214        |\n",
      "|    reward             | -0.94865924 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 30.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 613       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -250      |\n",
      "|    reward             | 1.1797212 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 41.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 620        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 411        |\n",
      "|    reward             | -22.785406 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 144        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 627       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 72.4      |\n",
      "|    reward             | 3.2164123 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.27      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 634         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | 87          |\n",
      "|    reward             | -0.17441794 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 6.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 642         |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | 262         |\n",
      "|    reward             | -0.85795397 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 48.9        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 649        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | 72.7       |\n",
      "|    reward             | -2.2230675 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 22.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 656       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -49.2     |\n",
      "|    reward             | 2.6728501 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.66      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 663      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -238     |\n",
      "|    reward             | 8.656925 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 86.3     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 670         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0.000219    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | -187        |\n",
      "|    reward             | -0.62001467 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 27.3        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 678       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 55.6      |\n",
      "|    reward             | 1.1713017 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.79      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 685       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 139       |\n",
      "|    reward             | 1.3898315 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 14.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 692       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -52.5     |\n",
      "|    reward             | -6.044222 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.49      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 699       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 67.7      |\n",
      "|    reward             | 1.8213228 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 9.97      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 706      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 177      |\n",
      "|    reward             | 8.957433 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 58.6     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 714         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 14.2        |\n",
      "|    reward             | -0.26523116 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.559       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 721        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | -0.00926   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | 1.12       |\n",
      "|    reward             | -0.6623605 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.953      |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2YadjfnLwgt"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCDa78rqfO_a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "y5D5PFUhMzSV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Gt8eIQKYM4G3",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ppo/1_1\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 124       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 0.5073655 |\n",
      "----------------------------------\n",
      "day: 2892, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3946387.70\n",
      "total_reward: 2946387.70\n",
      "total_cost: 357438.48\n",
      "total_trades: 81024\n",
      "Sharpe: 0.793\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015788507 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.00723     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.41        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    reward               | 0.3435485   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012375185 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.7        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | -1.1157341  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 65.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016662188 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.00193    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 2.2809894   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017038994 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00886    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    reward               | 3.2505164   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 105        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01701039 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.4      |\n",
      "|    explained_variance   | 0.0063     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17         |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    reward               | 1.8685282  |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 32.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02486872 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.5      |\n",
      "|    explained_variance   | -0.0142    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.5       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    reward               | 0.39857626 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 46.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020911664 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | -0.0215     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | 1.3883617   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7870/2360990771.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_ppo = agent.train_model(model=model_ppo, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              total_timesteps=3000000)\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             )\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/zj/FinRL/finrl/finrl_meta/env_stock_trading/env_stocktrading.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    321\u001b[0m             )\n\u001b[1;32m    322\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_total_asset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_total_asset\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbegin_total_asset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/zj/FinRL/finrl/finrl_meta/env_stock_trading/env_stocktrading.py\u001b[0m in \u001b[0;36m_get_date\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2037\u001b[0m         \u001b[0mCategories\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'b'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2038\u001b[0m         \"\"\"\n\u001b[0;32m-> 2039\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0mhtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_hashtable_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_get_hashtable_algo\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mndtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_object_for_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0mhtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_hashtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mndtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_check_object_for_strings\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# including nulls because that is the only difference between\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# StringHashTable and ObjectHashtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0mndtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mndtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name=\"1\",\n",
    "                             total_timesteps=3000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "JSAHhV4Xc-bh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent_con = DRLAgent(env = env_train_con)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo2 = agent_con.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "OSRxNYAxdKpU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load\n",
      "Logging to ppo/8_3\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 117       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 17        |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 0.2954527 |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0139981955 |\n",
      "|    clip_fraction        | 0.178        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.2        |\n",
      "|    explained_variance   | -0.0106      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.97         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0227      |\n",
      "|    reward               | 0.50004077   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 10.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013899902 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.0107     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    reward               | -1.2012023  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 109       |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.011043  |\n",
      "|    clip_fraction        | 0.0688    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.3     |\n",
      "|    explained_variance   | -0.000883 |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 11.8      |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | -0.0143   |\n",
      "|    reward               | 3.0586877 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 49.6      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012586994 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.0137     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.63        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    reward               | 2.896432    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012635764 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | 0.00603     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    reward               | 1.6648384   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015180964 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00397    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    reward               | 1.762582    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 50.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015979383 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | 0.00628     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    reward               | 0.34289297  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017755287 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | -0.00618    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.7        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    reward               | 0.31520438  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 81.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017658316 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | -0.00839    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    reward               | 1.0853715   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012580872 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | 0.0221      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.8        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 2.5376236   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017950803 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | 0.00618     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.6         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    reward               | -0.14442861 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5673966.50\n",
      "total_reward: 4673966.50\n",
      "total_cost: 329987.39\n",
      "total_trades: 78769\n",
      "Sharpe: 0.936\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017202176 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | 0.00462     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    reward               | 0.5119066   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 256        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02346272 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.5      |\n",
      "|    explained_variance   | 0.00622    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34         |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    reward               | -1.1041186 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 115        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 273        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02129434 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.5      |\n",
      "|    explained_variance   | -0.0298    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.9       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    reward               | 4.7134023  |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 22.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023392877 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | 0.018       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.3        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    reward               | -0.5770558  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 53.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024697777 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.00657     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.3        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    reward               | 0.6372559   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 95.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 328         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014407504 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.0215      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.2        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | 0.3479067   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 91.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 346         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029754903 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.0278      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.3         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | 0.17728704  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023183068 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.018       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | -0.48324066 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 73.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 382         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024984993 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.0102      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.7        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | -9.63396    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 82.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 400         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029196676 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | -0.00835    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    reward               | 2.1931765   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 418         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030962288 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.0119      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    reward               | 0.5239948   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 437         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028155822 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.0217      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.1        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | 6.9981203   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 455         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02462938  |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.00514     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.1        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | -0.94137394 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 81.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 473         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034217656 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.0398      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.07        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    reward               | -0.31879595 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5113839.79\n",
      "total_reward: 4113839.79\n",
      "total_cost: 320673.17\n",
      "total_trades: 77328\n",
      "Sharpe: 0.892\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 491         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028233755 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0.00959     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    reward               | 0.25378832  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 54          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 509         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033148848 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | 0.00333     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | -0.42292613 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 85.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 528         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022043392 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | -0.00473    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.73        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    reward               | -0.32011712 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 546         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028838554 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.038       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    reward               | 0.5673191   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 67.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 564         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018457264 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.5       |\n",
      "|    explained_variance   | 0.00797     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.8        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -0.37763873 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 59.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 582         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020606091 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.5       |\n",
      "|    explained_variance   | -0.0353     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | -0.71887743 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 601         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027071    |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0743      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | -0.80382866 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 619         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026655925 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0604      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.1        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    reward               | 0.5898994   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 94.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 637         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019607559 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0193      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    reward               | -1.3339138  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 88.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 655        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07027431 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | 0.0443     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.1       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.000824  |\n",
      "|    reward               | -3.3791013 |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 29.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 673         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020131271 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0365      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 162         |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.21855599 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 248         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 691         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021279342 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0892      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -11.834559  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 709         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025244918 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    reward               | -2.6708727  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 43.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 728         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027274475 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0919      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.3        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    reward               | -0.7140996  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6790498.57\n",
      "total_reward: 5790498.57\n",
      "total_cost: 247318.59\n",
      "total_trades: 72473\n",
      "Sharpe: 1.034\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 745         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023963021 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0249      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 0.3286716   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 93.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 764         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037621442 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0146      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.8        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00052    |\n",
      "|    reward               | 0.21551542  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 782        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04165061 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | -0.0766    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.88       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.01      |\n",
      "|    reward               | 1.1158478  |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 14.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 800         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021835417 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0309      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | 0.032064676 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 53.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 818         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02440767  |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0554      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.3        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    reward               | -0.45532167 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 837         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040007304 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    reward               | -5.2431736  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 855         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020190002 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.3        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 1.2591662   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 873        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03788153 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | -0.0199    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.7       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.00665   |\n",
      "|    reward               | 9.915262   |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 50.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 891         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023470415 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0213      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    reward               | -1.2734942  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 198         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 909          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.027519695  |\n",
      "|    clip_fraction        | 0.264        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.4        |\n",
      "|    explained_variance   | 0.17         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.5         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0136      |\n",
      "|    reward               | -0.062822476 |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 927          |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0318885    |\n",
      "|    clip_fraction        | 0.27         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.5        |\n",
      "|    explained_variance   | 0.121        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 96.9         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00902     |\n",
      "|    reward               | -0.009275025 |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 173          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 946         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028594052 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0124      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -4.4708323  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 964         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025628284 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | 0.4038918   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 982         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035490915 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 0.98194265  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 64.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 1000       |\n",
      "|    total_timesteps      | 112640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02584539 |\n",
      "|    clip_fraction        | 0.233      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | -0.0695    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.6       |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | -0.0201    |\n",
      "|    reward               | 3.3464172  |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 56.5       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5167999.75\n",
      "total_reward: 4167999.75\n",
      "total_cost: 330222.97\n",
      "total_trades: 77665\n",
      "Sharpe: 0.952\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1018        |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031146862 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.00239     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 1.3226465   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 1036         |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.034744766  |\n",
      "|    clip_fraction        | 0.308        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.8        |\n",
      "|    explained_variance   | 0.14         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0155      |\n",
      "|    reward               | -0.089648485 |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 81.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 1055       |\n",
      "|    total_timesteps      | 118784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03515335 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.137      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.3       |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | -0.00858   |\n",
      "|    reward               | 0.9325766  |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 131        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 1073       |\n",
      "|    total_timesteps      | 120832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03963577 |\n",
      "|    clip_fraction        | 0.429      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0413     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.2       |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | 0.00701    |\n",
      "|    reward               | -0.1879884 |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 168        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1091        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026372854 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -0.5558971  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 61         |\n",
      "|    time_elapsed         | 1109       |\n",
      "|    total_timesteps      | 124928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02305083 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.12       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 80.2       |\n",
      "|    n_updates            | 600        |\n",
      "|    policy_gradient_loss | -0.00602   |\n",
      "|    reward               | 0.9315422  |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 138        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1127        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021918297 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.2        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    reward               | 2.1089096   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1146        |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022668153 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.000836    |\n",
      "|    reward               | 3.9591465   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 36.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 1164        |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028403038 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -0.55835146 |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 81.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1182        |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018559285 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.7        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    reward               | -1.1362568  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1200        |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009909157 |\n",
      "|    clip_fraction        | 0.0823      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0806      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96.5        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    reward               | 4.5732336   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 1218        |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034471605 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | -1.9457221  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1236        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03214822  |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.3        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    reward               | -0.35956755 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1254        |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035728864 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0484      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 235         |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | 0.000619    |\n",
      "|    reward               | -5.3499675  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 323         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7250857.76\n",
      "total_reward: 6250857.76\n",
      "total_cost: 212853.67\n",
      "total_trades: 68375\n",
      "Sharpe: 1.065\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1272        |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036457777 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00198    |\n",
      "|    reward               | 1.7339044   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1291        |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017182514 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0943      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    reward               | 0.8139784   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1309        |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019403497 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.058       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 225         |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.000607   |\n",
      "|    reward               | -40.342552  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 410         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1327        |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035111815 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0219      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.4        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | 0.0063      |\n",
      "|    reward               | -1.970908   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1346        |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027363654 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | -1.8584591  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 75         |\n",
      "|    time_elapsed         | 1364       |\n",
      "|    total_timesteps      | 153600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04030798 |\n",
      "|    clip_fraction        | 0.306      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.211      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 218        |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | -0.00263   |\n",
      "|    reward               | 1.036521   |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 209        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1381        |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034860495 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.054       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | 0.00466     |\n",
      "|    reward               | -1.2258592  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 353         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1399        |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034137852 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | 0.00658     |\n",
      "|    reward               | 2.7423098   |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 55.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1417        |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039696753 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.00174    |\n",
      "|    reward               | 1.5978193   |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 241         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1436        |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034536123 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    reward               | 0.6341668   |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 269         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1454        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034770284 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.000537    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.8        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | 0.000936    |\n",
      "|    reward               | 1.2190436   |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1473        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023339596 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0829      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.6        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | -0.9662784  |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1490        |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023343388 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.0679      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 190         |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    reward               | -1.2681714  |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 262         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 83         |\n",
      "|    time_elapsed         | 1509       |\n",
      "|    total_timesteps      | 169984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0188924  |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | 0.00222    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 113        |\n",
      "|    n_updates            | 820        |\n",
      "|    policy_gradient_loss | -0.00702   |\n",
      "|    reward               | -0.4951392 |\n",
      "|    std                  | 1.14       |\n",
      "|    value_loss           | 223        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8146698.84\n",
      "total_reward: 7146698.84\n",
      "total_cost: 189158.62\n",
      "total_trades: 66568\n",
      "Sharpe: 1.057\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1527        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023021234 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    reward               | 0.012566893 |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1545        |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03507964  |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.0766      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 216         |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | 0.00228     |\n",
      "|    reward               | -0.27235782 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 291         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1563        |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03964562  |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.7        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | 0.00185     |\n",
      "|    reward               | -0.93986976 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1581        |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028897498 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | 0.00578     |\n",
      "|    reward               | 2.6196947   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 60.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 88         |\n",
      "|    time_elapsed         | 1599       |\n",
      "|    total_timesteps      | 180224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03306818 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.2      |\n",
      "|    explained_variance   | 0.248      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 49.7       |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | -0.00615   |\n",
      "|    reward               | -0.7535859 |\n",
      "|    std                  | 1.15       |\n",
      "|    value_loss           | 146        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1617        |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023777109 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.5        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    reward               | -0.07015394 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1635        |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035549853 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.0018      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | 0.000841    |\n",
      "|    reward               | 1.1387851   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1653        |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030757172 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.04        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | 0.0026      |\n",
      "|    reward               | -0.7310507  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 1671        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016506543 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.5        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    reward               | -1.403747   |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 93.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1689        |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024655424 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.8        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | 0.0075      |\n",
      "|    reward               | -3.582374   |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 84.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1707        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021572322 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    reward               | -0.3787093  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1725        |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018636247 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    reward               | 0.12279202  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 96         |\n",
      "|    time_elapsed         | 1743       |\n",
      "|    total_timesteps      | 196608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01369971 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.4      |\n",
      "|    explained_variance   | 0.237      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 47.2       |\n",
      "|    n_updates            | 950        |\n",
      "|    policy_gradient_loss | -0.00986   |\n",
      "|    reward               | 3.026407   |\n",
      "|    std                  | 1.16       |\n",
      "|    value_loss           | 167        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1762        |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027314246 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.0668      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | -1.0035616  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 47.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6163796.69\n",
      "total_reward: 5163796.69\n",
      "total_cost: 166819.70\n",
      "total_trades: 64504\n",
      "Sharpe: 1.023\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 1780        |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030226484 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45          |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    reward               | -1.5915722  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 61.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1798        |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024322007 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72          |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    reward               | -1.513133   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1816        |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037674204 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.0513      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | 0.0067      |\n",
      "|    reward               | -3.0899537  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 1834        |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022645328 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    reward               | -1.5248104  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 1852        |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031460457 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | -1.1433287  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 85          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 1870        |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015908837 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.9        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    reward               | -4.472      |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 1889        |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020239979 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | 0.0717      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    reward               | 0.61979     |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 1907        |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022368118 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.9        |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    reward               | -1.6031868  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 95          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 1925        |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018402115 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.4        |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    reward               | -0.45757386 |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 1943        |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021360844 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 99.9        |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.00133    |\n",
      "|    reward               | 1.192493    |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 1961        |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039040767 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.91        |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | 0.0116      |\n",
      "|    reward               | -0.53542954 |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 1979         |\n",
      "|    total_timesteps      | 223232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.023219252  |\n",
      "|    clip_fraction        | 0.236        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -46          |\n",
      "|    explained_variance   | 0.298        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | -0.095511235 |\n",
      "|    std                  | 1.18         |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 1997        |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043962877 |\n",
      "|    clip_fraction        | 0.402       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    reward               | -1.7030718  |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 2015        |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015943777 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.9        |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    reward               | 4.29042     |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5693718.68\n",
      "total_reward: 4693718.68\n",
      "total_cost: 165441.74\n",
      "total_trades: 63542\n",
      "Sharpe: 1.008\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 2033        |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016711101 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    reward               | -0.5758315  |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 59.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 2051        |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025849493 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | 0.7275882   |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 91.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 2069        |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012261982 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.2       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.4        |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    reward               | -0.89616495 |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 95.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 115        |\n",
      "|    time_elapsed         | 2087       |\n",
      "|    total_timesteps      | 235520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02409564 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.2      |\n",
      "|    explained_variance   | 0.572      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.7        |\n",
      "|    n_updates            | 1140       |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    reward               | -3.4028168 |\n",
      "|    std                  | 1.19       |\n",
      "|    value_loss           | 16.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 2105        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027862785 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.3       |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    reward               | -1.3726007  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 96.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 117        |\n",
      "|    time_elapsed         | 2123       |\n",
      "|    total_timesteps      | 239616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02204775 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.3      |\n",
      "|    explained_variance   | 0.149      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 39.3       |\n",
      "|    n_updates            | 1160       |\n",
      "|    policy_gradient_loss | -0.00699   |\n",
      "|    reward               | 0.23180407 |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 162        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 118        |\n",
      "|    time_elapsed         | 2142       |\n",
      "|    total_timesteps      | 241664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03408967 |\n",
      "|    clip_fraction        | 0.336      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.4      |\n",
      "|    explained_variance   | 0.328      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.5       |\n",
      "|    n_updates            | 1170       |\n",
      "|    policy_gradient_loss | -0.00581   |\n",
      "|    reward               | 2.5860925  |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 38.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 2160        |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020892244 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.4       |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.5        |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | -0.4371263  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 92.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 120        |\n",
      "|    time_elapsed         | 2179       |\n",
      "|    total_timesteps      | 245760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02107229 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.5      |\n",
      "|    explained_variance   | 0.174      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 48.1       |\n",
      "|    n_updates            | 1190       |\n",
      "|    policy_gradient_loss | -0.00533   |\n",
      "|    reward               | -1.6927819 |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 72.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 2197        |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026830586 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.5       |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.00015    |\n",
      "|    reward               | 0.534687    |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 54.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 122        |\n",
      "|    time_elapsed         | 2215       |\n",
      "|    total_timesteps      | 249856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02594518 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.5      |\n",
      "|    explained_variance   | 0.294      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.5       |\n",
      "|    n_updates            | 1210       |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    reward               | 0.57216096 |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 48.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 2234        |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042645626 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.5       |\n",
      "|    explained_variance   | 0.0835      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | 0.00864     |\n",
      "|    reward               | 2.592759    |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 71.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 2252        |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012126176 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.6       |\n",
      "|    explained_variance   | 0.0345      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.2        |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | 0.21172473  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 125        |\n",
      "|    time_elapsed         | 2270       |\n",
      "|    total_timesteps      | 256000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02271069 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.6      |\n",
      "|    explained_variance   | 0.286      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.1       |\n",
      "|    n_updates            | 1240       |\n",
      "|    policy_gradient_loss | -0.00442   |\n",
      "|    reward               | 1.6402568  |\n",
      "|    std                  | 1.21       |\n",
      "|    value_loss           | 22.4       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3953877.46\n",
      "total_reward: 2953877.46\n",
      "total_cost: 150806.13\n",
      "total_trades: 63583\n",
      "Sharpe: 0.806\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 2288        |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022728547 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.6       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.2        |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.00873    |\n",
      "|    reward               | -0.6322216  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 79.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 2306        |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041511066 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | 0.0184      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.6        |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | 0.00302     |\n",
      "|    reward               | -3.0246065  |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 74          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 2324        |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018236846 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.8       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | 0.000144    |\n",
      "|    reward               | 0.37571147  |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 2343        |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026751684 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.8       |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    reward               | 0.12932168  |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 2361        |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024900043 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.8       |\n",
      "|    explained_variance   | 0.0853      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    reward               | -0.4779202  |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 79          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 2379        |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019406233 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.9       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | 2.3351064   |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 132        |\n",
      "|    time_elapsed         | 2397       |\n",
      "|    total_timesteps      | 270336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02483565 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47        |\n",
      "|    explained_variance   | 0.306      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.34       |\n",
      "|    n_updates            | 1310       |\n",
      "|    policy_gradient_loss | -0.00623   |\n",
      "|    reward               | 0.4931649  |\n",
      "|    std                  | 1.23       |\n",
      "|    value_loss           | 19.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 2415        |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023004707 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00818    |\n",
      "|    reward               | 1.6542565   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 68.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 2433         |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146680605 |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.1        |\n",
      "|    explained_variance   | 0.0501       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.4         |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | -0.00487     |\n",
      "|    reward               | -8.861007    |\n",
      "|    std                  | 1.23         |\n",
      "|    value_loss           | 79.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 2451        |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021899711 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.18        |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    reward               | -2.126474   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 2469        |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015504629 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 0.8464402   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 2487        |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028093945 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.0837      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    reward               | -10.283192  |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 71.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 2505        |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028097209 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.067       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.7        |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    reward               | 2.1325805   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 2523        |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025509167 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.27        |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    reward               | -1.9122814  |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4024736.51\n",
      "total_reward: 3024736.51\n",
      "total_cost: 108121.62\n",
      "total_trades: 58699\n",
      "Sharpe: 0.783\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 2541        |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019991314 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | 0.0669      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38          |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 0.482866    |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 81.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 2559        |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025489483 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | 0.09        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.00049    |\n",
      "|    reward               | 0.03592245  |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 76.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 2577        |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026124366 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | 0.000171    |\n",
      "|    reward               | -1.6401266  |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 2595        |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012415782 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | 0.0871      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    reward               | 0.5559621   |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 85.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 2614        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019657163 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | 0.0803      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.9        |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    reward               | 3.5821056   |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 83.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 2633        |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019071408 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    reward               | 0.41161734  |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 55.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 2650       |\n",
      "|    total_timesteps      | 299008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02751444 |\n",
      "|    clip_fraction        | 0.272      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.5      |\n",
      "|    explained_variance   | 0.131      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.4       |\n",
      "|    n_updates            | 1450       |\n",
      "|    policy_gradient_loss | -0.00705   |\n",
      "|    reward               | 1.0715953  |\n",
      "|    std                  | 1.25       |\n",
      "|    value_loss           | 52.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 2668        |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032330524 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.08        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45          |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    reward               | -0.76844037 |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 85.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 148        |\n",
      "|    time_elapsed         | 2686       |\n",
      "|    total_timesteps      | 303104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02302296 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.6      |\n",
      "|    explained_variance   | 0.156      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.8       |\n",
      "|    n_updates            | 1470       |\n",
      "|    policy_gradient_loss | 0.00196    |\n",
      "|    reward               | 0.48076624 |\n",
      "|    std                  | 1.25       |\n",
      "|    value_loss           | 81.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 2704        |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026241425 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.44        |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | 0.000455    |\n",
      "|    reward               | 0.40597308  |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 2722        |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020460624 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    reward               | 1.5332084   |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 58.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 2740        |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018198922 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.2        |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    reward               | -3.0056956  |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 83.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 2759        |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014853658 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    reward               | -2.1919699  |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 2777        |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022177745 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.1        |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    reward               | -0.84536844 |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4357043.90\n",
      "total_reward: 3357043.90\n",
      "total_cost: 102568.18\n",
      "total_trades: 58950\n",
      "Sharpe: 0.823\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 2795        |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018437032 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.7        |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    reward               | -0.767211   |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 79.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 2813        |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022780403 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.8       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    reward               | 1.0229471   |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 83.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 2831        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028008336 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.8       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.92        |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    reward               | -1.4548249  |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 2849        |\n",
      "|    total_timesteps      | 321536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035597064 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.8       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | 0.000749    |\n",
      "|    reward               | -1.1330857  |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 68.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 2867        |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020542815 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.9       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.4        |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.00198    |\n",
      "|    reward               | -10.501992  |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 159        |\n",
      "|    time_elapsed         | 2885       |\n",
      "|    total_timesteps      | 325632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02787919 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.9      |\n",
      "|    explained_variance   | 0.158      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.3       |\n",
      "|    n_updates            | 1580       |\n",
      "|    policy_gradient_loss | -0.00697   |\n",
      "|    reward               | -1.7671038 |\n",
      "|    std                  | 1.26       |\n",
      "|    value_loss           | 36.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 2903        |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029173665 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.9       |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | -0.00896    |\n",
      "|    reward               | 1.9838018   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 53.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 2922        |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027476786 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    reward               | 32.788273   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 95.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 2940        |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022277728 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    reward               | 0.4329366   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 79.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 163        |\n",
      "|    time_elapsed         | 2957       |\n",
      "|    total_timesteps      | 333824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03565497 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.1      |\n",
      "|    explained_variance   | 0.214      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.5       |\n",
      "|    n_updates            | 1620       |\n",
      "|    policy_gradient_loss | -0.00598   |\n",
      "|    reward               | -1.5297059 |\n",
      "|    std                  | 1.27       |\n",
      "|    value_loss           | 40.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 2976        |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016669314 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.9        |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    reward               | 0.120173655 |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 73          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 2995        |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038283907 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.00156    |\n",
      "|    reward               | 2.3208706   |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 66.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 3013        |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041752215 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | 0.00225     |\n",
      "|    reward               | 2.3563364   |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 112       |\n",
      "|    iterations           | 167       |\n",
      "|    time_elapsed         | 3031      |\n",
      "|    total_timesteps      | 342016    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0327148 |\n",
      "|    clip_fraction        | 0.271     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -48.3     |\n",
      "|    explained_variance   | 0.0819    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 35.5      |\n",
      "|    n_updates            | 1660      |\n",
      "|    policy_gradient_loss | -0.00306  |\n",
      "|    reward               | 0.855254  |\n",
      "|    std                  | 1.28      |\n",
      "|    value_loss           | 72.1      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 3049        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009265106 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    reward               | 4.6200275   |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 67.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4099905.76\n",
      "total_reward: 3099905.76\n",
      "total_cost: 90162.97\n",
      "total_trades: 57626\n",
      "Sharpe: 0.801\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 3067        |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015898596 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    reward               | -0.5635234  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 52.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 3085        |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030278817 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.4       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -1.7233568  |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 3103        |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010921771 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.5       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    reward               | -0.550567   |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 76.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 172        |\n",
      "|    time_elapsed         | 3121       |\n",
      "|    total_timesteps      | 352256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03087277 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.5      |\n",
      "|    explained_variance   | 0.112      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 35.5       |\n",
      "|    n_updates            | 1710       |\n",
      "|    policy_gradient_loss | -0.00106   |\n",
      "|    reward               | 2.2196202  |\n",
      "|    std                  | 1.29       |\n",
      "|    value_loss           | 78.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 3139        |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039944503 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.6       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.49        |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | 0.00381     |\n",
      "|    reward               | -0.98735845 |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 3157        |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020166347 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.6        |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    reward               | 0.275026    |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 69.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 3175        |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022707345 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    reward               | -0.4899947  |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 63.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 3194        |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025720628 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.0596      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    reward               | 0.23118626  |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 56.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 3212        |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038107708 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.8       |\n",
      "|    explained_variance   | 0.031       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    reward               | 0.6640229   |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 58.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 3231        |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015837055 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.8       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | 0.000205    |\n",
      "|    reward               | -0.9268787  |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 54.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 179          |\n",
      "|    time_elapsed         | 3248         |\n",
      "|    total_timesteps      | 366592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.03235536   |\n",
      "|    clip_fraction        | 0.274        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.8        |\n",
      "|    explained_variance   | 0.104        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45           |\n",
      "|    n_updates            | 1780         |\n",
      "|    policy_gradient_loss | -0.00607     |\n",
      "|    reward               | 0.0021684219 |\n",
      "|    std                  | 1.31         |\n",
      "|    value_loss           | 92.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 3266        |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046261758 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | 0.00218     |\n",
      "|    reward               | 0.52154833  |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 3284        |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030378046 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49         |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    reward               | 0.05971093  |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 78.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 182        |\n",
      "|    time_elapsed         | 3302       |\n",
      "|    total_timesteps      | 372736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01958453 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49        |\n",
      "|    explained_variance   | 0.119      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 54.3       |\n",
      "|    n_updates            | 1810       |\n",
      "|    policy_gradient_loss | 0.000857   |\n",
      "|    reward               | 0.395524   |\n",
      "|    std                  | 1.32       |\n",
      "|    value_loss           | 88.4       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5278352.47\n",
      "total_reward: 4278352.47\n",
      "total_cost: 160212.97\n",
      "total_trades: 62940\n",
      "Sharpe: 0.913\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 3322        |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029091652 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    reward               | 2.1572003   |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 3340        |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031555336 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.00873    |\n",
      "|    reward               | -1.4695151  |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 70.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 3358        |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026568562 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.0633      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    reward               | 6.1239524   |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 78.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 3376        |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031780206 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.0762      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | -0.00991    |\n",
      "|    reward               | -1.7526149  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 61.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 3394        |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026025644 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.37        |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | 1.3618797   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 47.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 3412        |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019933078 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.0486      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.6        |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.2570789   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 75.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 3430        |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015237817 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    reward               | -2.235444   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 65.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 3447        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033911742 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    reward               | 5.540939    |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 3465        |\n",
      "|    total_timesteps      | 391168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023770535 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    reward               | 0.5076957   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 70.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 3483        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010219789 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    reward               | -5.8649826  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 193        |\n",
      "|    time_elapsed         | 3501       |\n",
      "|    total_timesteps      | 395264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02505302 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.4      |\n",
      "|    explained_variance   | 0.205      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.5       |\n",
      "|    n_updates            | 1920       |\n",
      "|    policy_gradient_loss | -0.00483   |\n",
      "|    reward               | 0.26074496 |\n",
      "|    std                  | 1.33       |\n",
      "|    value_loss           | 53.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 3520        |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020927649 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    reward               | 0.4697299   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 3538        |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014261354 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    reward               | 0.92212164  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 62.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 196          |\n",
      "|    time_elapsed         | 3556         |\n",
      "|    total_timesteps      | 401408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067822584 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.5        |\n",
      "|    explained_variance   | 0.322        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47           |\n",
      "|    n_updates            | 1950         |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    reward               | 4.0247464    |\n",
      "|    std                  | 1.34         |\n",
      "|    value_loss           | 80.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4942077.22\n",
      "total_reward: 3942077.22\n",
      "total_cost: 112767.76\n",
      "total_trades: 60252\n",
      "Sharpe: 0.884\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 3574        |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029657919 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 1960        |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    reward               | 4.5432844   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 198        |\n",
      "|    time_elapsed         | 3592       |\n",
      "|    total_timesteps      | 405504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01898916 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.5      |\n",
      "|    explained_variance   | 0.15       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 45.7       |\n",
      "|    n_updates            | 1970       |\n",
      "|    policy_gradient_loss | -0.00264   |\n",
      "|    reward               | 0.12631038 |\n",
      "|    std                  | 1.34       |\n",
      "|    value_loss           | 81.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 3610        |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024337143 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | 0.0511      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.8        |\n",
      "|    n_updates            | 1980        |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    reward               | 3.5082214   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 96.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 3628        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024822302 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | 0.0981      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    reward               | 0.7510146   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 3646        |\n",
      "|    total_timesteps      | 411648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030825967 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    reward               | -0.45201728 |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 49.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 3664        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017473046 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.8        |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    reward               | -6.666996   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 75.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 203        |\n",
      "|    time_elapsed         | 3682       |\n",
      "|    total_timesteps      | 415744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01334068 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.7      |\n",
      "|    explained_variance   | 0.152      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.4       |\n",
      "|    n_updates            | 2020       |\n",
      "|    policy_gradient_loss | -0.000456  |\n",
      "|    reward               | 2.0606613  |\n",
      "|    std                  | 1.34       |\n",
      "|    value_loss           | 89.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 3700        |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029162848 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.7       |\n",
      "|    explained_variance   | -0.115      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.17        |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | -0.00109    |\n",
      "|    reward               | -0.2013736  |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 205        |\n",
      "|    time_elapsed         | 3717       |\n",
      "|    total_timesteps      | 419840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01221326 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.7      |\n",
      "|    explained_variance   | 0.288      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.4       |\n",
      "|    n_updates            | 2040       |\n",
      "|    policy_gradient_loss | 0.00469    |\n",
      "|    reward               | 3.6596146  |\n",
      "|    std                  | 1.35       |\n",
      "|    value_loss           | 54.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 3736        |\n",
      "|    total_timesteps      | 421888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003726396 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.7       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.8        |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    reward               | -0.13281617 |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 66.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 3754        |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030059272 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.7       |\n",
      "|    explained_variance   | 0.0817      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 2060        |\n",
      "|    policy_gradient_loss | 0.00727     |\n",
      "|    reward               | -1.3836025  |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 3772        |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022862801 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.7       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 2070        |\n",
      "|    policy_gradient_loss | 0.00263     |\n",
      "|    reward               | -1.576679   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 58.9        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 112       |\n",
      "|    iterations           | 209       |\n",
      "|    time_elapsed         | 3789      |\n",
      "|    total_timesteps      | 428032    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0245687 |\n",
      "|    clip_fraction        | 0.214     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -49.7     |\n",
      "|    explained_variance   | 0.267     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 32.1      |\n",
      "|    n_updates            | 2080      |\n",
      "|    policy_gradient_loss | 0.000996  |\n",
      "|    reward               | 2.1187317 |\n",
      "|    std                  | 1.35      |\n",
      "|    value_loss           | 54.1      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 3807        |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051063128 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.8       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | 0.0116      |\n",
      "|    reward               | -1.407612   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 58.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4149656.50\n",
      "total_reward: 3149656.50\n",
      "total_cost: 82219.35\n",
      "total_trades: 57042\n",
      "Sharpe: 0.798\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 211        |\n",
      "|    time_elapsed         | 3825       |\n",
      "|    total_timesteps      | 432128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03919382 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.8      |\n",
      "|    explained_variance   | 0.242      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.2       |\n",
      "|    n_updates            | 2100       |\n",
      "|    policy_gradient_loss | -0.00503   |\n",
      "|    reward               | -1.4316144 |\n",
      "|    std                  | 1.35       |\n",
      "|    value_loss           | 38         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 3843        |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022662744 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.8       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | 0.00161     |\n",
      "|    reward               | -0.1465563  |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 3861        |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013916715 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | 0.00295     |\n",
      "|    reward               | 2.1995893   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 68.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 214        |\n",
      "|    time_elapsed         | 3879       |\n",
      "|    total_timesteps      | 438272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05377433 |\n",
      "|    clip_fraction        | 0.416      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.9      |\n",
      "|    explained_variance   | 0.122      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.6       |\n",
      "|    n_updates            | 2130       |\n",
      "|    policy_gradient_loss | 0.00291    |\n",
      "|    reward               | 0.13148335 |\n",
      "|    std                  | 1.36       |\n",
      "|    value_loss           | 25.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 215         |\n",
      "|    time_elapsed         | 3897        |\n",
      "|    total_timesteps      | 440320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034379162 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50         |\n",
      "|    explained_variance   | 0.0517      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.2        |\n",
      "|    n_updates            | 2140        |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    reward               | 0.4097999   |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 77.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 216        |\n",
      "|    time_elapsed         | 3915       |\n",
      "|    total_timesteps      | 442368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02603357 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50        |\n",
      "|    explained_variance   | 0.0463     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 53.7       |\n",
      "|    n_updates            | 2150       |\n",
      "|    policy_gradient_loss | -0.00197   |\n",
      "|    reward               | 0.98186153 |\n",
      "|    std                  | 1.36       |\n",
      "|    value_loss           | 101        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 3932        |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.05500079  |\n",
      "|    clip_fraction        | 0.393       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.1       |\n",
      "|    explained_variance   | 0.0176      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | 0.00776     |\n",
      "|    reward               | -0.17824508 |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 57          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 3951        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039451465 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.1       |\n",
      "|    explained_variance   | 0.0599      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.4        |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.000943   |\n",
      "|    reward               | 0.99763936  |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 64.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 219          |\n",
      "|    time_elapsed         | 3970         |\n",
      "|    total_timesteps      | 448512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016415972  |\n",
      "|    clip_fraction        | 0.171        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.2        |\n",
      "|    explained_variance   | 0.068        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.2         |\n",
      "|    n_updates            | 2180         |\n",
      "|    policy_gradient_loss | -0.00814     |\n",
      "|    reward               | -0.037475858 |\n",
      "|    std                  | 1.37         |\n",
      "|    value_loss           | 81.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 220         |\n",
      "|    time_elapsed         | 3988        |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022118174 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.2       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | 0.00594     |\n",
      "|    reward               | 3.3461626   |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 97.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 221        |\n",
      "|    time_elapsed         | 4006       |\n",
      "|    total_timesteps      | 452608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02183413 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.2      |\n",
      "|    explained_variance   | 0.149      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.4       |\n",
      "|    n_updates            | 2200       |\n",
      "|    policy_gradient_loss | -0.00881   |\n",
      "|    reward               | -1.8252585 |\n",
      "|    std                  | 1.37       |\n",
      "|    value_loss           | 23.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 4024        |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026666982 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.3       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 2210        |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    reward               | 0.08668327  |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 75.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 4042        |\n",
      "|    total_timesteps      | 456704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011779399 |\n",
      "|    clip_fraction        | 0.0452      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.3       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 2220        |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    reward               | -2.1037366  |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 75.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 4060        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057205055 |\n",
      "|    clip_fraction        | 0.446       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.3       |\n",
      "|    explained_variance   | 0.0448      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 2230        |\n",
      "|    policy_gradient_loss | 0.0148      |\n",
      "|    reward               | -1.3976567  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4047687.17\n",
      "total_reward: 3047687.17\n",
      "total_cost: 226593.98\n",
      "total_trades: 69762\n",
      "Sharpe: 0.845\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 225         |\n",
      "|    time_elapsed         | 4078        |\n",
      "|    total_timesteps      | 460800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033969246 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.4       |\n",
      "|    explained_variance   | 0.0686      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 2240        |\n",
      "|    policy_gradient_loss | -0.000258   |\n",
      "|    reward               | 2.2529519   |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 4096        |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027353179 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.4       |\n",
      "|    explained_variance   | 0.0879      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | 0.000615    |\n",
      "|    reward               | 5.19798     |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 42.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 4115        |\n",
      "|    total_timesteps      | 464896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027436238 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | 0.0206      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | 0.00391     |\n",
      "|    reward               | 2.2334113   |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 84.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 4133        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030899858 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.98        |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    reward               | -0.3245028  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 4151        |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022683496 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    reward               | -0.4274515  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 60.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 4169        |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024250498 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43          |\n",
      "|    n_updates            | 2290        |\n",
      "|    policy_gradient_loss | 0.00513     |\n",
      "|    reward               | 2.0529528   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 67.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 231        |\n",
      "|    time_elapsed         | 4187       |\n",
      "|    total_timesteps      | 473088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04053952 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.6      |\n",
      "|    explained_variance   | 0.393      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.6       |\n",
      "|    n_updates            | 2300       |\n",
      "|    policy_gradient_loss | 0.00247    |\n",
      "|    reward               | -5.669707  |\n",
      "|    std                  | 1.39       |\n",
      "|    value_loss           | 29.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 4205        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021174336 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | 0.00526     |\n",
      "|    reward               | 0.13427773  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 59.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 4223        |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018941278 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.6        |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | -0.000869   |\n",
      "|    reward               | 1.7787749   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 59.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 4241        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019273508 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | 0.0106      |\n",
      "|    reward               | -0.2991953  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 235        |\n",
      "|    time_elapsed         | 4259       |\n",
      "|    total_timesteps      | 481280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03210757 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.7      |\n",
      "|    explained_variance   | 0.273      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.1       |\n",
      "|    n_updates            | 2340       |\n",
      "|    policy_gradient_loss | -0.00764   |\n",
      "|    reward               | -0.7143956 |\n",
      "|    std                  | 1.39       |\n",
      "|    value_loss           | 22.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 4278        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029185466 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | 0.0103      |\n",
      "|    reward               | 2.047792    |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 39.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 4296        |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008449152 |\n",
      "|    clip_fraction        | 0.0478      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    reward               | 1.2886668   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 47.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 4314        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018416764 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.0237      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.52        |\n",
      "|    n_updates            | 2370        |\n",
      "|    policy_gradient_loss | 0.00245     |\n",
      "|    reward               | -1.1881369  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4376419.66\n",
      "total_reward: 3376419.66\n",
      "total_cost: 131643.69\n",
      "total_trades: 62232\n",
      "Sharpe: 0.864\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 4332        |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026934797 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 2380        |\n",
      "|    policy_gradient_loss | 0.000443    |\n",
      "|    reward               | 1.1897501   |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 4350        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018232659 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.8       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 2390        |\n",
      "|    policy_gradient_loss | -0.001      |\n",
      "|    reward               | -2.510046   |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 4368        |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012600994 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.8       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 2400        |\n",
      "|    policy_gradient_loss | -0.0025     |\n",
      "|    reward               | -0.35886082 |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 4386        |\n",
      "|    total_timesteps      | 495616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020806137 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.9       |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.99        |\n",
      "|    n_updates            | 2410        |\n",
      "|    policy_gradient_loss | 0.00077     |\n",
      "|    reward               | -1.0287873  |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 4404        |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023757972 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.9       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 2420        |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    reward               | 0.6973435   |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 244        |\n",
      "|    time_elapsed         | 4422       |\n",
      "|    total_timesteps      | 499712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02192055 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.9      |\n",
      "|    explained_variance   | 0.157      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38.4       |\n",
      "|    n_updates            | 2430       |\n",
      "|    policy_gradient_loss | -0.00515   |\n",
      "|    reward               | 1.6527488  |\n",
      "|    std                  | 1.41       |\n",
      "|    value_loss           | 66.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 4439        |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030939925 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.62        |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | 0.00172     |\n",
      "|    reward               | -0.326231   |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 246        |\n",
      "|    time_elapsed         | 4457       |\n",
      "|    total_timesteps      | 503808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02327265 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51        |\n",
      "|    explained_variance   | 0.23       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.7       |\n",
      "|    n_updates            | 2450       |\n",
      "|    policy_gradient_loss | -0.00627   |\n",
      "|    reward               | 1.2210824  |\n",
      "|    std                  | 1.41       |\n",
      "|    value_loss           | 36.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 247         |\n",
      "|    time_elapsed         | 4475        |\n",
      "|    total_timesteps      | 505856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019510416 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    reward               | 7.5575724   |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 4493        |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029150508 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.0544      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 2470        |\n",
      "|    policy_gradient_loss | 0.00434     |\n",
      "|    reward               | -1.3644904  |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 249         |\n",
      "|    time_elapsed         | 4511        |\n",
      "|    total_timesteps      | 509952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038277775 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.1       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.9         |\n",
      "|    n_updates            | 2480        |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    reward               | 0.8520082   |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 250         |\n",
      "|    time_elapsed         | 4530        |\n",
      "|    total_timesteps      | 512000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016605124 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | 0.0021      |\n",
      "|    reward               | 2.7738495   |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 42.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 4548        |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022512432 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    reward               | 0.24159504  |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 252         |\n",
      "|    time_elapsed         | 4565        |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036457777 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.01        |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | -0.00154    |\n",
      "|    reward               | 0.19666597  |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3778910.68\n",
      "total_reward: 2778910.68\n",
      "total_cost: 73912.44\n",
      "total_trades: 57257\n",
      "Sharpe: 0.759\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 4583        |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020541795 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.000194   |\n",
      "|    reward               | -0.05028585 |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 254         |\n",
      "|    time_elapsed         | 4601        |\n",
      "|    total_timesteps      | 520192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014912609 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 2530        |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    reward               | -0.32314    |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 46.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 4619        |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027390247 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.85        |\n",
      "|    n_updates            | 2540        |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    reward               | 3.080809    |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 4637        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040204532 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.02        |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.00158    |\n",
      "|    reward               | 3.096917    |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 257        |\n",
      "|    time_elapsed         | 4655       |\n",
      "|    total_timesteps      | 526336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02122124 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.4      |\n",
      "|    explained_variance   | 0.125      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 54.5       |\n",
      "|    n_updates            | 2560       |\n",
      "|    policy_gradient_loss | 0.00531    |\n",
      "|    reward               | 2.1231008  |\n",
      "|    std                  | 1.43       |\n",
      "|    value_loss           | 57.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 4673        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015485274 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    reward               | 1.6489805   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 52.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 4691        |\n",
      "|    total_timesteps      | 530432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034251016 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    reward               | 0.22609735  |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 260         |\n",
      "|    time_elapsed         | 4709        |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039842516 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.0831      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 2590        |\n",
      "|    policy_gradient_loss | 0.00488     |\n",
      "|    reward               | -0.39650202 |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 62.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 261        |\n",
      "|    time_elapsed         | 4730       |\n",
      "|    total_timesteps      | 534528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02322445 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.4      |\n",
      "|    explained_variance   | 0.14       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22         |\n",
      "|    n_updates            | 2600       |\n",
      "|    policy_gradient_loss | 0.00289    |\n",
      "|    reward               | 2.0030575  |\n",
      "|    std                  | 1.43       |\n",
      "|    value_loss           | 49.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 262         |\n",
      "|    time_elapsed         | 4748        |\n",
      "|    total_timesteps      | 536576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039121494 |\n",
      "|    clip_fraction        | 0.402       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.61        |\n",
      "|    n_updates            | 2610        |\n",
      "|    policy_gradient_loss | 0.00617     |\n",
      "|    reward               | 0.1569369   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 263         |\n",
      "|    time_elapsed         | 4765        |\n",
      "|    total_timesteps      | 538624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027895188 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 2620        |\n",
      "|    policy_gradient_loss | -0.000774   |\n",
      "|    reward               | -0.16442376 |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 264        |\n",
      "|    time_elapsed         | 4783       |\n",
      "|    total_timesteps      | 540672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03754063 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.6      |\n",
      "|    explained_variance   | 0.0626     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.4       |\n",
      "|    n_updates            | 2630       |\n",
      "|    policy_gradient_loss | 0.00397    |\n",
      "|    reward               | -2.6566708 |\n",
      "|    std                  | 1.44       |\n",
      "|    value_loss           | 41.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 265         |\n",
      "|    time_elapsed         | 4802        |\n",
      "|    total_timesteps      | 542720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029016934 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.7       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 2640        |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    reward               | -1.2116207  |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 4820        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032529727 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.7       |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.97        |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    reward               | -0.8172242  |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3968568.68\n",
      "total_reward: 2968568.68\n",
      "total_cost: 119723.92\n",
      "total_trades: 60827\n",
      "Sharpe: 0.768\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 267         |\n",
      "|    time_elapsed         | 4838        |\n",
      "|    total_timesteps      | 546816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049900874 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.8       |\n",
      "|    explained_variance   | 0.0918      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 2660        |\n",
      "|    policy_gradient_loss | 0.0101      |\n",
      "|    reward               | -0.74882025 |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 46          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 268         |\n",
      "|    time_elapsed         | 4856        |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015984915 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.9       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 2670        |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | -0.62489456 |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 58.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 269         |\n",
      "|    time_elapsed         | 4874        |\n",
      "|    total_timesteps      | 550912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037034865 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.9       |\n",
      "|    explained_variance   | 0.0907      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.2         |\n",
      "|    n_updates            | 2680        |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    reward               | 0.19680017  |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 270        |\n",
      "|    time_elapsed         | 4892       |\n",
      "|    total_timesteps      | 552960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01554488 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52        |\n",
      "|    explained_variance   | 0.424      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.5       |\n",
      "|    n_updates            | 2690       |\n",
      "|    policy_gradient_loss | 0.00553    |\n",
      "|    reward               | 1.6404941  |\n",
      "|    std                  | 1.46       |\n",
      "|    value_loss           | 38.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 271         |\n",
      "|    time_elapsed         | 4910        |\n",
      "|    total_timesteps      | 555008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012400694 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52         |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 2700        |\n",
      "|    policy_gradient_loss | -0.000752   |\n",
      "|    reward               | -0.3316283  |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 49          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 4928        |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02725041  |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52         |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 2710        |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    reward               | -0.22757834 |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 273        |\n",
      "|    time_elapsed         | 4947       |\n",
      "|    total_timesteps      | 559104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01928339 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.1      |\n",
      "|    explained_variance   | 0.239      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.1       |\n",
      "|    n_updates            | 2720       |\n",
      "|    policy_gradient_loss | -0.00537   |\n",
      "|    reward               | -0.6139324 |\n",
      "|    std                  | 1.46       |\n",
      "|    value_loss           | 44.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 274         |\n",
      "|    time_elapsed         | 4965        |\n",
      "|    total_timesteps      | 561152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010214163 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.1       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | -8.134008   |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 67.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 4983        |\n",
      "|    total_timesteps      | 563200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010655483 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.2       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 2740        |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    reward               | 0.58368844  |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 5002        |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027832476 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.2       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.06        |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    reward               | 2.4722338   |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 5020        |\n",
      "|    total_timesteps      | 567296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011056557 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 2760        |\n",
      "|    policy_gradient_loss | -0.00912    |\n",
      "|    reward               | 0.25016508  |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 53.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 278         |\n",
      "|    time_elapsed         | 5038        |\n",
      "|    total_timesteps      | 569344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018966474 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 2770        |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    reward               | 1.3844572   |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 61.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 279         |\n",
      "|    time_elapsed         | 5057        |\n",
      "|    total_timesteps      | 571392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031167429 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.23        |\n",
      "|    n_updates            | 2780        |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    reward               | 0.33583498  |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 5075        |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018798446 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.4       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 2790        |\n",
      "|    policy_gradient_loss | -0.00606    |\n",
      "|    reward               | 0.96286774  |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 5093        |\n",
      "|    total_timesteps      | 575488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016943684 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.4       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 2800        |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    reward               | 2.7849436   |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 55          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4159270.79\n",
      "total_reward: 3159270.79\n",
      "total_cost: 112515.23\n",
      "total_trades: 59075\n",
      "Sharpe: 0.830\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 282        |\n",
      "|    time_elapsed         | 5112       |\n",
      "|    total_timesteps      | 577536     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02518321 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.4      |\n",
      "|    explained_variance   | 0.346      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.7       |\n",
      "|    n_updates            | 2810       |\n",
      "|    policy_gradient_loss | -0.00524   |\n",
      "|    reward               | -0.3131008 |\n",
      "|    std                  | 1.48       |\n",
      "|    value_loss           | 39.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 283        |\n",
      "|    time_elapsed         | 5130       |\n",
      "|    total_timesteps      | 579584     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02318525 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.5      |\n",
      "|    explained_variance   | 0.285      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.1       |\n",
      "|    n_updates            | 2820       |\n",
      "|    policy_gradient_loss | -0.00663   |\n",
      "|    reward               | 0.23967703 |\n",
      "|    std                  | 1.48       |\n",
      "|    value_loss           | 36.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 284         |\n",
      "|    time_elapsed         | 5148        |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018980546 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.5       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 2830        |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    reward               | 2.05915     |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 46.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 5166        |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012235425 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.5       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 2840        |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    reward               | 5.749501    |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 57.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 5185        |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026516784 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    reward               | 1.3343599   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 5203        |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01678914  |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    reward               | -0.45062116 |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 5221        |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024720198 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | 0.00154     |\n",
      "|    reward               | 0.63718146  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 54.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 289         |\n",
      "|    time_elapsed         | 5239        |\n",
      "|    total_timesteps      | 591872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022463085 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 2880        |\n",
      "|    policy_gradient_loss | 0.000137    |\n",
      "|    reward               | 1.1558348   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 5257        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021319414 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    reward               | 0.8162174   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 291         |\n",
      "|    time_elapsed         | 5276        |\n",
      "|    total_timesteps      | 595968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010337336 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 2900        |\n",
      "|    policy_gradient_loss | -0.00192    |\n",
      "|    reward               | 0.08441368  |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 5294        |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021131188 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.8       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 2910        |\n",
      "|    policy_gradient_loss | 0.00335     |\n",
      "|    reward               | 0.597854    |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 293         |\n",
      "|    time_elapsed         | 5312        |\n",
      "|    total_timesteps      | 600064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022790581 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.8       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.07        |\n",
      "|    n_updates            | 2920        |\n",
      "|    policy_gradient_loss | -0.00134    |\n",
      "|    reward               | 0.50546485  |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 5330        |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027037911 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.8       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 2930        |\n",
      "|    policy_gradient_loss | -0.00246    |\n",
      "|    reward               | -0.50884944 |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 5349        |\n",
      "|    total_timesteps      | 604160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014107164 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.8       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | 0.000674    |\n",
      "|    reward               | -0.7780363  |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3983089.18\n",
      "total_reward: 2983089.18\n",
      "total_cost: 72701.27\n",
      "total_trades: 54354\n",
      "Sharpe: 0.804\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 5367        |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013514317 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.8       |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    reward               | -2.9034595  |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 5385        |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012341192 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.8       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 2960        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -1.0839479  |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 298          |\n",
      "|    time_elapsed         | 5403         |\n",
      "|    total_timesteps      | 610304       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0150485635 |\n",
      "|    clip_fraction        | 0.197        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -52.9        |\n",
      "|    explained_variance   | 0.402        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 2970         |\n",
      "|    policy_gradient_loss | 0.00164      |\n",
      "|    reward               | -0.82660294  |\n",
      "|    std                  | 1.5          |\n",
      "|    value_loss           | 48.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 5422        |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011512598 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 2980        |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    reward               | -0.29993093 |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 5440        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032770872 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.22        |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | 1.5775249   |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 301         |\n",
      "|    time_elapsed         | 5459        |\n",
      "|    total_timesteps      | 616448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017446758 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    reward               | 0.5637549   |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 302          |\n",
      "|    time_elapsed         | 5477         |\n",
      "|    total_timesteps      | 618496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042209574 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -52.9        |\n",
      "|    explained_variance   | 0.266        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 3010         |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    reward               | -7.008957    |\n",
      "|    std                  | 1.5          |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 303         |\n",
      "|    time_elapsed         | 5495        |\n",
      "|    total_timesteps      | 620544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033790797 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.2         |\n",
      "|    n_updates            | 3020        |\n",
      "|    policy_gradient_loss | 0.00676     |\n",
      "|    reward               | -3.3885562  |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 5514        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025968764 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53         |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 3030        |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    reward               | 0.3967289   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 54.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 5532        |\n",
      "|    total_timesteps      | 624640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009284115 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53         |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 3040        |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    reward               | 0.7496331   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 42.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 5550        |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013068847 |\n",
      "|    clip_fraction        | 0.0597      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53         |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 3050        |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    reward               | -2.7122936  |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 5568        |\n",
      "|    total_timesteps      | 628736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030805882 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 3060        |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    reward               | 1.4729437   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 308         |\n",
      "|    time_elapsed         | 5586        |\n",
      "|    total_timesteps      | 630784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013560178 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 3070        |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    reward               | 0.099536225 |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 309          |\n",
      "|    time_elapsed         | 5604         |\n",
      "|    total_timesteps      | 632832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054508015 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -53.1        |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.1         |\n",
      "|    n_updates            | 3080         |\n",
      "|    policy_gradient_loss | -0.0064      |\n",
      "|    reward               | 1.5958387    |\n",
      "|    std                  | 1.52         |\n",
      "|    value_loss           | 52.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3737105.68\n",
      "total_reward: 2737105.68\n",
      "total_cost: 74210.86\n",
      "total_trades: 53217\n",
      "Sharpe: 0.775\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 310        |\n",
      "|    time_elapsed         | 5623       |\n",
      "|    total_timesteps      | 634880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03218322 |\n",
      "|    clip_fraction        | 0.398      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.2      |\n",
      "|    explained_variance   | 0.448      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.33       |\n",
      "|    n_updates            | 3090       |\n",
      "|    policy_gradient_loss | 0.00551    |\n",
      "|    reward               | -1.1043484 |\n",
      "|    std                  | 1.52       |\n",
      "|    value_loss           | 13.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 5641        |\n",
      "|    total_timesteps      | 636928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00796522  |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.2       |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 3100        |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    reward               | -0.42251426 |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 5659        |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008354375 |\n",
      "|    clip_fraction        | 0.0458      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.2       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 3110        |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    reward               | -2.8553479  |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 313         |\n",
      "|    time_elapsed         | 5677        |\n",
      "|    total_timesteps      | 641024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018976627 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.2       |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | 0.00938     |\n",
      "|    reward               | -5.914389   |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 5695        |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031974673 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.2       |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 3130        |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    reward               | -1.0983602  |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 5713        |\n",
      "|    total_timesteps      | 645120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009666693 |\n",
      "|    clip_fraction        | 0.0552      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.2       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 3140        |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    reward               | -5.211121   |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 40.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 316        |\n",
      "|    time_elapsed         | 5731       |\n",
      "|    total_timesteps      | 647168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00995291 |\n",
      "|    clip_fraction        | 0.0608     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.2      |\n",
      "|    explained_variance   | 0.342      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.1       |\n",
      "|    n_updates            | 3150       |\n",
      "|    policy_gradient_loss | -0.00552   |\n",
      "|    reward               | 2.071377   |\n",
      "|    std                  | 1.52       |\n",
      "|    value_loss           | 46.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 317        |\n",
      "|    time_elapsed         | 5749       |\n",
      "|    total_timesteps      | 649216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03087666 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.2      |\n",
      "|    explained_variance   | 0.386      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.39       |\n",
      "|    n_updates            | 3160       |\n",
      "|    policy_gradient_loss | 0.00589    |\n",
      "|    reward               | 0.15430973 |\n",
      "|    std                  | 1.52       |\n",
      "|    value_loss           | 13         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 318         |\n",
      "|    time_elapsed         | 5767        |\n",
      "|    total_timesteps      | 651264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021948129 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.3       |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 3170        |\n",
      "|    policy_gradient_loss | -0.00489    |\n",
      "|    reward               | 3.5086882   |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 5786        |\n",
      "|    total_timesteps      | 653312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006442732 |\n",
      "|    clip_fraction        | 0.0581      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.3       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 3180        |\n",
      "|    policy_gradient_loss | -0.000314   |\n",
      "|    reward               | -1.740086   |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 320         |\n",
      "|    time_elapsed         | 5804        |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022299869 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.3       |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | 1.2387868   |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 321         |\n",
      "|    time_elapsed         | 5822        |\n",
      "|    total_timesteps      | 657408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021589966 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.4       |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 3200        |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    reward               | 0.37448823  |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 322         |\n",
      "|    time_elapsed         | 5840        |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024289947 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.4       |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 3210        |\n",
      "|    policy_gradient_loss | 0.00121     |\n",
      "|    reward               | 1.4914418   |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 323         |\n",
      "|    time_elapsed         | 5858        |\n",
      "|    total_timesteps      | 661504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009064123 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.4       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | -0.34010586 |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 35.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3176981.45\n",
      "total_reward: 2176981.45\n",
      "total_cost: 55746.78\n",
      "total_trades: 51535\n",
      "Sharpe: 0.684\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 5876        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019929592 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.5       |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 3230        |\n",
      "|    policy_gradient_loss | -0.000391   |\n",
      "|    reward               | 1.0477873   |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 5895        |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034453012 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.5       |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    reward               | 0.6045447   |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 326          |\n",
      "|    time_elapsed         | 5915         |\n",
      "|    total_timesteps      | 667648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0152690895 |\n",
      "|    clip_fraction        | 0.0745       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -53.6        |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 3250         |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | -1.3710706   |\n",
      "|    std                  | 1.54         |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 327        |\n",
      "|    time_elapsed         | 5934       |\n",
      "|    total_timesteps      | 669696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02179474 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.6      |\n",
      "|    explained_variance   | 0.296      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.59       |\n",
      "|    n_updates            | 3260       |\n",
      "|    policy_gradient_loss | 0.000351   |\n",
      "|    reward               | 0.54957217 |\n",
      "|    std                  | 1.54       |\n",
      "|    value_loss           | 16.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 328         |\n",
      "|    time_elapsed         | 5953        |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012129314 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.7       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 3270        |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    reward               | -0.32855842 |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 5971        |\n",
      "|    total_timesteps      | 673792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027098754 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.7       |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 3280        |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    reward               | -4.032499   |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 330          |\n",
      "|    time_elapsed         | 5989         |\n",
      "|    total_timesteps      | 675840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117739495 |\n",
      "|    clip_fraction        | 0.0615       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -53.7        |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 3290         |\n",
      "|    policy_gradient_loss | -0.00599     |\n",
      "|    reward               | -4.0487757   |\n",
      "|    std                  | 1.55         |\n",
      "|    value_loss           | 27.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 6007        |\n",
      "|    total_timesteps      | 677888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022891197 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.7       |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.4         |\n",
      "|    n_updates            | 3300        |\n",
      "|    policy_gradient_loss | -0.00489    |\n",
      "|    reward               | 0.013717865 |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 332         |\n",
      "|    time_elapsed         | 6025        |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019301396 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.8       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 3310        |\n",
      "|    policy_gradient_loss | 0.00298     |\n",
      "|    reward               | 0.2681369   |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 333          |\n",
      "|    time_elapsed         | 6043         |\n",
      "|    total_timesteps      | 681984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059470935 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -53.8        |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.91         |\n",
      "|    n_updates            | 3320         |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    reward               | -0.58173513  |\n",
      "|    std                  | 1.55         |\n",
      "|    value_loss           | 41           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 6061        |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015555237 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.8       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.41        |\n",
      "|    n_updates            | 3330        |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    reward               | 2.1060703   |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 335         |\n",
      "|    time_elapsed         | 6080        |\n",
      "|    total_timesteps      | 686080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013520369 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.44        |\n",
      "|    n_updates            | 3340        |\n",
      "|    policy_gradient_loss | 0.000197    |\n",
      "|    reward               | -0.38644898 |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 336        |\n",
      "|    time_elapsed         | 6098       |\n",
      "|    total_timesteps      | 688128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01627051 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.9      |\n",
      "|    explained_variance   | 0.23       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 55.1       |\n",
      "|    n_updates            | 3350       |\n",
      "|    policy_gradient_loss | -0.000852  |\n",
      "|    reward               | 3.5558698  |\n",
      "|    std                  | 1.56       |\n",
      "|    value_loss           | 53.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 337         |\n",
      "|    time_elapsed         | 6117        |\n",
      "|    total_timesteps      | 690176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018130712 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.69        |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | -0.00178    |\n",
      "|    reward               | -0.8734867  |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3522318.78\n",
      "total_reward: 2522318.78\n",
      "total_cost: 54930.10\n",
      "total_trades: 50297\n",
      "Sharpe: 0.739\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 6136        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019665487 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54         |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 3370        |\n",
      "|    policy_gradient_loss | 0.00861     |\n",
      "|    reward               | -0.25375855 |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 6155        |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017937947 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54         |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 3380        |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    reward               | 6.095624    |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 36.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 340        |\n",
      "|    time_elapsed         | 6174       |\n",
      "|    total_timesteps      | 696320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02181457 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.1      |\n",
      "|    explained_variance   | 0.482      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.5       |\n",
      "|    n_updates            | 3390       |\n",
      "|    policy_gradient_loss | -0.000671  |\n",
      "|    reward               | 4.8645973  |\n",
      "|    std                  | 1.57       |\n",
      "|    value_loss           | 40.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 6194        |\n",
      "|    total_timesteps      | 698368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.04305496  |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.49        |\n",
      "|    n_updates            | 3400        |\n",
      "|    policy_gradient_loss | 0.0056      |\n",
      "|    reward               | -0.06404619 |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 342         |\n",
      "|    time_elapsed         | 6213        |\n",
      "|    total_timesteps      | 700416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019044612 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.2       |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 3410        |\n",
      "|    policy_gradient_loss | 0.00694     |\n",
      "|    reward               | 0.29019874  |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 6231        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015107766 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.2       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    reward               | 0.5329738   |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 43.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 6250        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012613909 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 3430        |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    reward               | 4.3930397   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 345         |\n",
      "|    time_elapsed         | 6268        |\n",
      "|    total_timesteps      | 706560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015451788 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 3440        |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    reward               | 0.7755898   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 6286        |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015867677 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 3450        |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    reward               | 2.05698     |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 347         |\n",
      "|    time_elapsed         | 6304        |\n",
      "|    total_timesteps      | 710656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015859904 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 3460        |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    reward               | 2.4426184   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 348         |\n",
      "|    time_elapsed         | 6323        |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013273697 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.5         |\n",
      "|    n_updates            | 3470        |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    reward               | -0.4619251  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 6342        |\n",
      "|    total_timesteps      | 714752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015934983 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 3480        |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    reward               | 0.40090793  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 350        |\n",
      "|    time_elapsed         | 6360       |\n",
      "|    total_timesteps      | 716800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01097736 |\n",
      "|    clip_fraction        | 0.0706     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.3      |\n",
      "|    explained_variance   | 0.557      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.7       |\n",
      "|    n_updates            | 3490       |\n",
      "|    policy_gradient_loss | -0.00181   |\n",
      "|    reward               | 2.8731422  |\n",
      "|    std                  | 1.58       |\n",
      "|    value_loss           | 35.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 6378        |\n",
      "|    total_timesteps      | 718848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029073723 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.96        |\n",
      "|    n_updates            | 3500        |\n",
      "|    policy_gradient_loss | 0.00239     |\n",
      "|    reward               | -0.8973274  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3442930.03\n",
      "total_reward: 2442930.03\n",
      "total_cost: 51598.26\n",
      "total_trades: 49520\n",
      "Sharpe: 0.739\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 352         |\n",
      "|    time_elapsed         | 6396        |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024444573 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.06        |\n",
      "|    n_updates            | 3510        |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    reward               | -0.462099   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 353          |\n",
      "|    time_elapsed         | 6415         |\n",
      "|    total_timesteps      | 722944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065916236 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -54.4        |\n",
      "|    explained_variance   | 0.213        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 3520         |\n",
      "|    policy_gradient_loss | -0.00603     |\n",
      "|    reward               | 1.2616616    |\n",
      "|    std                  | 1.58         |\n",
      "|    value_loss           | 43.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 354         |\n",
      "|    time_elapsed         | 6433        |\n",
      "|    total_timesteps      | 724992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013603637 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 3530        |\n",
      "|    policy_gradient_loss | 7.19e-05    |\n",
      "|    reward               | -2.8059633  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 355         |\n",
      "|    time_elapsed         | 6451        |\n",
      "|    total_timesteps      | 727040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025071353 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.91        |\n",
      "|    n_updates            | 3540        |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    reward               | 0.13696396  |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 23.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 356         |\n",
      "|    time_elapsed         | 6473        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010273773 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 3550        |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    reward               | -0.44879168 |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 357         |\n",
      "|    time_elapsed         | 6492        |\n",
      "|    total_timesteps      | 731136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009371679 |\n",
      "|    clip_fraction        | 0.0332      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 3560        |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    reward               | -1.4414172  |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 6510        |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.05541248  |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.62        |\n",
      "|    n_updates            | 3570        |\n",
      "|    policy_gradient_loss | 0.00354     |\n",
      "|    reward               | -0.39679533 |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 359        |\n",
      "|    time_elapsed         | 6528       |\n",
      "|    total_timesteps      | 735232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03314446 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.5      |\n",
      "|    explained_variance   | 0.558      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.6       |\n",
      "|    n_updates            | 3580       |\n",
      "|    policy_gradient_loss | 0.00339    |\n",
      "|    reward               | -1.4585274 |\n",
      "|    std                  | 1.59       |\n",
      "|    value_loss           | 28.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 6546        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013264251 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 3590        |\n",
      "|    policy_gradient_loss | 0.00222     |\n",
      "|    reward               | 0.59756637  |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 6565        |\n",
      "|    total_timesteps      | 739328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008498258 |\n",
      "|    clip_fraction        | 0.0287      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    reward               | -0.19170469 |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 362         |\n",
      "|    time_elapsed         | 6583        |\n",
      "|    total_timesteps      | 741376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021171154 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 3610        |\n",
      "|    policy_gradient_loss | 0.000644    |\n",
      "|    reward               | 0.9160641   |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 363        |\n",
      "|    time_elapsed         | 6601       |\n",
      "|    total_timesteps      | 743424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01642248 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.5      |\n",
      "|    explained_variance   | 0.567      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.9       |\n",
      "|    n_updates            | 3620       |\n",
      "|    policy_gradient_loss | -0.000196  |\n",
      "|    reward               | -16.024069 |\n",
      "|    std                  | 1.59       |\n",
      "|    value_loss           | 34.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 364         |\n",
      "|    time_elapsed         | 6620        |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009527577 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.6       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 3630        |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | 1.4325345   |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 6638        |\n",
      "|    total_timesteps      | 747520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026460538 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.6       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.88        |\n",
      "|    n_updates            | 3640        |\n",
      "|    policy_gradient_loss | 0.000472    |\n",
      "|    reward               | 1.2510865   |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3105898.43\n",
      "total_reward: 2105898.43\n",
      "total_cost: 36359.11\n",
      "total_trades: 47341\n",
      "Sharpe: 0.667\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 366        |\n",
      "|    time_elapsed         | 6656       |\n",
      "|    total_timesteps      | 749568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04707443 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.6      |\n",
      "|    explained_variance   | 0.594      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.3       |\n",
      "|    n_updates            | 3650       |\n",
      "|    policy_gradient_loss | 0.00554    |\n",
      "|    reward               | 1.4869189  |\n",
      "|    std                  | 1.6        |\n",
      "|    value_loss           | 34.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 367        |\n",
      "|    time_elapsed         | 6674       |\n",
      "|    total_timesteps      | 751616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02155518 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.7      |\n",
      "|    explained_variance   | 0.493      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.7       |\n",
      "|    n_updates            | 3660       |\n",
      "|    policy_gradient_loss | 0.000593   |\n",
      "|    reward               | 0.6342506  |\n",
      "|    std                  | 1.6        |\n",
      "|    value_loss           | 33.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 368        |\n",
      "|    time_elapsed         | 6692       |\n",
      "|    total_timesteps      | 753664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03125522 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.7      |\n",
      "|    explained_variance   | 0.462      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.4        |\n",
      "|    n_updates            | 3670       |\n",
      "|    policy_gradient_loss | -0.002     |\n",
      "|    reward               | -1.8622599 |\n",
      "|    std                  | 1.61       |\n",
      "|    value_loss           | 18.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 6711        |\n",
      "|    total_timesteps      | 755712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023608608 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.8       |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 3680        |\n",
      "|    policy_gradient_loss | 0.00159     |\n",
      "|    reward               | -0.6326273  |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 6729        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01458383  |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.9       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | 0.00488     |\n",
      "|    reward               | -0.80040413 |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 371         |\n",
      "|    time_elapsed         | 6747        |\n",
      "|    total_timesteps      | 759808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012061327 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.9       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 3700        |\n",
      "|    policy_gradient_loss | -0.00144    |\n",
      "|    reward               | -0.76133597 |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 372         |\n",
      "|    time_elapsed         | 6765        |\n",
      "|    total_timesteps      | 761856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018303534 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.9       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.55        |\n",
      "|    n_updates            | 3710        |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    reward               | 0.15980823  |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 6783        |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027108252 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.9       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | -0.000393   |\n",
      "|    reward               | -0.71306884 |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 374        |\n",
      "|    time_elapsed         | 6801       |\n",
      "|    total_timesteps      | 765952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01351941 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55        |\n",
      "|    explained_variance   | 0.607      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.3       |\n",
      "|    n_updates            | 3730       |\n",
      "|    policy_gradient_loss | 0.00337    |\n",
      "|    reward               | -1.9299725 |\n",
      "|    std                  | 1.62       |\n",
      "|    value_loss           | 36.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 6819        |\n",
      "|    total_timesteps      | 768000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054768983 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55         |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.2         |\n",
      "|    n_updates            | 3740        |\n",
      "|    policy_gradient_loss | 0.00509     |\n",
      "|    reward               | 0.7474833   |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 376          |\n",
      "|    time_elapsed         | 6837         |\n",
      "|    total_timesteps      | 770048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.020024084  |\n",
      "|    clip_fraction        | 0.219        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -55.1        |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 3750         |\n",
      "|    policy_gradient_loss | 0.00166      |\n",
      "|    reward               | -0.015882134 |\n",
      "|    std                  | 1.62         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 6855        |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019002479 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 3760        |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    reward               | 0.44316635  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 6873        |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028363107 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 3770        |\n",
      "|    policy_gradient_loss | 0.00703     |\n",
      "|    reward               | 4.212468    |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 379        |\n",
      "|    time_elapsed         | 6891       |\n",
      "|    total_timesteps      | 776192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04521824 |\n",
      "|    clip_fraction        | 0.299      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.2      |\n",
      "|    explained_variance   | 0.526      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.86       |\n",
      "|    n_updates            | 3780       |\n",
      "|    policy_gradient_loss | 0.00574    |\n",
      "|    reward               | 2.1586611  |\n",
      "|    std                  | 1.63       |\n",
      "|    value_loss           | 24.6       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4040386.06\n",
      "total_reward: 3040386.06\n",
      "total_cost: 35630.30\n",
      "total_trades: 46896\n",
      "Sharpe: 0.827\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 6909        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012218922 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 3790        |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    reward               | 0.098923646 |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 48.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 381        |\n",
      "|    time_elapsed         | 6927       |\n",
      "|    total_timesteps      | 780288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02631224 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.3      |\n",
      "|    explained_variance   | 0.436      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.9       |\n",
      "|    n_updates            | 3800       |\n",
      "|    policy_gradient_loss | 0.00254    |\n",
      "|    reward               | 0.6699934  |\n",
      "|    std                  | 1.63       |\n",
      "|    value_loss           | 43.5       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 382         |\n",
      "|    time_elapsed         | 6945        |\n",
      "|    total_timesteps      | 782336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031807408 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.3       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.5         |\n",
      "|    n_updates            | 3810        |\n",
      "|    policy_gradient_loss | 0.00985     |\n",
      "|    reward               | 0.8383769   |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 6963        |\n",
      "|    total_timesteps      | 784384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012077339 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.4       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    reward               | -0.38498998 |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 42.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 384          |\n",
      "|    time_elapsed         | 6981         |\n",
      "|    total_timesteps      | 786432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077653932 |\n",
      "|    clip_fraction        | 0.0844       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -55.4        |\n",
      "|    explained_variance   | 0.468        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 3830         |\n",
      "|    policy_gradient_loss | -0.0095      |\n",
      "|    reward               | 0.31868002   |\n",
      "|    std                  | 1.64         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 385           |\n",
      "|    time_elapsed         | 6999          |\n",
      "|    total_timesteps      | 788480        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.019321792   |\n",
      "|    clip_fraction        | 0.118         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -55.4         |\n",
      "|    explained_variance   | 0.488         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.7          |\n",
      "|    n_updates            | 3840          |\n",
      "|    policy_gradient_loss | -0.00206      |\n",
      "|    reward               | -0.0058048693 |\n",
      "|    std                  | 1.64          |\n",
      "|    value_loss           | 24.6          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 386         |\n",
      "|    time_elapsed         | 7017        |\n",
      "|    total_timesteps      | 790528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025094822 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.5       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    reward               | 1.5887134   |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 387         |\n",
      "|    time_elapsed         | 7034        |\n",
      "|    total_timesteps      | 792576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024521733 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.5       |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 3860        |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    reward               | -0.3176408  |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 388        |\n",
      "|    time_elapsed         | 7052       |\n",
      "|    total_timesteps      | 794624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02072092 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.6      |\n",
      "|    explained_variance   | 0.598      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.7       |\n",
      "|    n_updates            | 3870       |\n",
      "|    policy_gradient_loss | -0.000684  |\n",
      "|    reward               | 0.53061265 |\n",
      "|    std                  | 1.65       |\n",
      "|    value_loss           | 34.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 389         |\n",
      "|    time_elapsed         | 7070        |\n",
      "|    total_timesteps      | 796672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015296371 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.6       |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.19        |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    reward               | 2.2853053   |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 7088        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019593451 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.7       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | -0.00165    |\n",
      "|    reward               | 0.9670204   |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 391         |\n",
      "|    time_elapsed         | 7106        |\n",
      "|    total_timesteps      | 800768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018800918 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.7       |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | 0.00141     |\n",
      "|    reward               | -4.663887   |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 7124        |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022088459 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.7       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.34        |\n",
      "|    n_updates            | 3910        |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | -3.84745    |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 7142        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024734491 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.8       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | 0.00443     |\n",
      "|    reward               | -0.17027327 |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 7160        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018574007 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.8       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | -0.85842067 |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3451040.55\n",
      "total_reward: 2451040.55\n",
      "total_cost: 43438.76\n",
      "total_trades: 48054\n",
      "Sharpe: 0.734\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 7178        |\n",
      "|    total_timesteps      | 808960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016563736 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.9       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | -7.17e-05   |\n",
      "|    reward               | -1.2714313  |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 396         |\n",
      "|    time_elapsed         | 7196        |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016730413 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.9       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.52        |\n",
      "|    n_updates            | 3950        |\n",
      "|    policy_gradient_loss | 0.000782    |\n",
      "|    reward               | 0.478678    |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 7214        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01379896  |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.9       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 3960        |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    reward               | -0.39282677 |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 398         |\n",
      "|    time_elapsed         | 7232        |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019025162 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.9       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    reward               | -2.433943   |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 7250        |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025512213 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56         |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.11        |\n",
      "|    n_updates            | 3980        |\n",
      "|    policy_gradient_loss | 0.00179     |\n",
      "|    reward               | -4.8359356  |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 7268        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022303164 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56         |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 3990        |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    reward               | -0.42485154 |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 401         |\n",
      "|    time_elapsed         | 7287        |\n",
      "|    total_timesteps      | 821248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017880835 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56         |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 4000        |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    reward               | -4.803026   |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 40.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 402        |\n",
      "|    time_elapsed         | 7306       |\n",
      "|    total_timesteps      | 823296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02426809 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.1      |\n",
      "|    explained_variance   | 0.452      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.4       |\n",
      "|    n_updates            | 4010       |\n",
      "|    policy_gradient_loss | 0.000271   |\n",
      "|    reward               | 0.48053554 |\n",
      "|    std                  | 1.68       |\n",
      "|    value_loss           | 30.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 403         |\n",
      "|    time_elapsed         | 7324        |\n",
      "|    total_timesteps      | 825344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019820586 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.1       |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.93        |\n",
      "|    n_updates            | 4020        |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    reward               | 0.086901605 |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 7342        |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018275764 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | -1.2815174  |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 405         |\n",
      "|    time_elapsed         | 7361        |\n",
      "|    total_timesteps      | 829440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010171837 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 4040        |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    reward               | 1.3697106   |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 42.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 406        |\n",
      "|    time_elapsed         | 7379       |\n",
      "|    total_timesteps      | 831488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02094993 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.2      |\n",
      "|    explained_variance   | 0.641      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.01       |\n",
      "|    n_updates            | 4050       |\n",
      "|    policy_gradient_loss | -0.00907   |\n",
      "|    reward               | 1.2139273  |\n",
      "|    std                  | 1.69       |\n",
      "|    value_loss           | 12.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 407        |\n",
      "|    time_elapsed         | 7397       |\n",
      "|    total_timesteps      | 833536     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01689539 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.2      |\n",
      "|    explained_variance   | 0.584      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.4       |\n",
      "|    n_updates            | 4060       |\n",
      "|    policy_gradient_loss | -0.00264   |\n",
      "|    reward               | 1.3249987  |\n",
      "|    std                  | 1.69       |\n",
      "|    value_loss           | 32.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 408         |\n",
      "|    time_elapsed         | 7415        |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029667411 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 4070        |\n",
      "|    policy_gradient_loss | 0.0123      |\n",
      "|    reward               | 9.011445    |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 63.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3905089.66\n",
      "total_reward: 2905089.66\n",
      "total_cost: 35774.00\n",
      "total_trades: 47309\n",
      "Sharpe: 0.808\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 409         |\n",
      "|    time_elapsed         | 7433        |\n",
      "|    total_timesteps      | 837632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010336243 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 4080        |\n",
      "|    policy_gradient_loss | -0.000737   |\n",
      "|    reward               | -2.4515042  |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 7452        |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011110719 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.37        |\n",
      "|    n_updates            | 4090        |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | 1.067096    |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 411         |\n",
      "|    time_elapsed         | 7471        |\n",
      "|    total_timesteps      | 841728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022428546 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 4100        |\n",
      "|    policy_gradient_loss | 0.00573     |\n",
      "|    reward               | 3.976171    |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 7489        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014272404 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    reward               | -0.3720411  |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 413         |\n",
      "|    time_elapsed         | 7507        |\n",
      "|    total_timesteps      | 845824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017565735 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 4120        |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    reward               | -1.1458957  |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 7525        |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020882193 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 4130        |\n",
      "|    policy_gradient_loss | -0.0021     |\n",
      "|    reward               | -0.6135289  |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 415        |\n",
      "|    time_elapsed         | 7544       |\n",
      "|    total_timesteps      | 849920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01156582 |\n",
      "|    clip_fraction        | 0.0682     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.4      |\n",
      "|    explained_variance   | 0.49       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.2       |\n",
      "|    n_updates            | 4140       |\n",
      "|    policy_gradient_loss | -0.00117   |\n",
      "|    reward               | -0.5674653 |\n",
      "|    std                  | 1.7        |\n",
      "|    value_loss           | 42         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 416         |\n",
      "|    time_elapsed         | 7562        |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027559604 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.13        |\n",
      "|    n_updates            | 4150        |\n",
      "|    policy_gradient_loss | -0.00109    |\n",
      "|    reward               | 0.61364526  |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 417          |\n",
      "|    time_elapsed         | 7580         |\n",
      "|    total_timesteps      | 854016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0154877305 |\n",
      "|    clip_fraction        | 0.253        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -56.5        |\n",
      "|    explained_variance   | 0.393        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.77         |\n",
      "|    n_updates            | 4160         |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    reward               | 0.4400476    |\n",
      "|    std                  | 1.7          |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 418          |\n",
      "|    time_elapsed         | 7599         |\n",
      "|    total_timesteps      | 856064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062877843 |\n",
      "|    clip_fraction        | 0.06         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -56.5        |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.7         |\n",
      "|    n_updates            | 4170         |\n",
      "|    policy_gradient_loss | -0.00599     |\n",
      "|    reward               | -1.5321299   |\n",
      "|    std                  | 1.71         |\n",
      "|    value_loss           | 42.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 7617        |\n",
      "|    total_timesteps      | 858112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016935315 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 4180        |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    reward               | -0.53997636 |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 420         |\n",
      "|    time_elapsed         | 7635        |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022367092 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.72        |\n",
      "|    n_updates            | 4190        |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    reward               | -0.32284334 |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 7653        |\n",
      "|    total_timesteps      | 862208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017937873 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | -0.58255845 |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 39.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 422         |\n",
      "|    time_elapsed         | 7672        |\n",
      "|    total_timesteps      | 864256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012447743 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 4210        |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    reward               | 0.5156419   |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3970916.82\n",
      "total_reward: 2970916.82\n",
      "total_cost: 33709.37\n",
      "total_trades: 48148\n",
      "Sharpe: 0.802\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 423         |\n",
      "|    time_elapsed         | 7690        |\n",
      "|    total_timesteps      | 866304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026739987 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.06        |\n",
      "|    n_updates            | 4220        |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    reward               | 1.5542262   |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 424         |\n",
      "|    time_elapsed         | 7708        |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021089962 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 4230        |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    reward               | -1.4214112  |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 425         |\n",
      "|    time_elapsed         | 7726        |\n",
      "|    total_timesteps      | 870400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015528353 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    reward               | -3.9960926  |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 7744        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015052701 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 4250        |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    reward               | 0.48157278  |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 7762        |\n",
      "|    total_timesteps      | 874496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021242857 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 4260        |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    reward               | -0.39175704 |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 428         |\n",
      "|    time_elapsed         | 7780        |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013187656 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 4270        |\n",
      "|    policy_gradient_loss | 2.13e-07    |\n",
      "|    reward               | -7.3263106  |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 7798        |\n",
      "|    total_timesteps      | 878592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011574057 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    reward               | -0.91027826 |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 56.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 430         |\n",
      "|    time_elapsed         | 7816        |\n",
      "|    total_timesteps      | 880640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020406324 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.85        |\n",
      "|    n_updates            | 4290        |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    reward               | 3.1823142   |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 431         |\n",
      "|    time_elapsed         | 7834        |\n",
      "|    total_timesteps      | 882688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019095764 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 4300        |\n",
      "|    policy_gradient_loss | -0.000904   |\n",
      "|    reward               | -1.7674657  |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 7852        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009624921 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 4310        |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    reward               | -0.32501984 |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 46.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 433         |\n",
      "|    time_elapsed         | 7871        |\n",
      "|    total_timesteps      | 886784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026835125 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 4320        |\n",
      "|    policy_gradient_loss | 0.00159     |\n",
      "|    reward               | -4.628446   |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 434         |\n",
      "|    time_elapsed         | 7889        |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022835137 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 4330        |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | 1.5794734   |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 63.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 435         |\n",
      "|    time_elapsed         | 7907        |\n",
      "|    total_timesteps      | 890880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011922512 |\n",
      "|    clip_fraction        | 0.0944      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.4        |\n",
      "|    n_updates            | 4340        |\n",
      "|    policy_gradient_loss | -0.00203    |\n",
      "|    reward               | 0.32219324  |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 7926        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015824724 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | 0.000445    |\n",
      "|    reward               | 4.0146165   |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4509846.26\n",
      "total_reward: 3509846.26\n",
      "total_cost: 43245.52\n",
      "total_trades: 50251\n",
      "Sharpe: 0.862\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 7944        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02001305  |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.1       |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.00804    |\n",
      "|    reward               | -0.66965324 |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 7962        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018340563 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.1       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | 0.75422853  |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 7981        |\n",
      "|    total_timesteps      | 899072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024340566 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.1       |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 4380        |\n",
      "|    policy_gradient_loss | -0.00164    |\n",
      "|    reward               | 4.3153577   |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 440         |\n",
      "|    time_elapsed         | 7999        |\n",
      "|    total_timesteps      | 901120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020204158 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.2       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.29        |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | 0.00233     |\n",
      "|    reward               | -0.4652867  |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 441         |\n",
      "|    time_elapsed         | 8017        |\n",
      "|    total_timesteps      | 903168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012508113 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.3       |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 4400        |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    reward               | -0.83416945 |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 442         |\n",
      "|    time_elapsed         | 8036        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011769244 |\n",
      "|    clip_fraction        | 0.0993      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.3       |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    reward               | 1.9061214   |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 443          |\n",
      "|    time_elapsed         | 8055         |\n",
      "|    total_timesteps      | 907264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108263455 |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -57.4        |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 4420         |\n",
      "|    policy_gradient_loss | 0.00351      |\n",
      "|    reward               | 2.4514654    |\n",
      "|    std                  | 1.76         |\n",
      "|    value_loss           | 26.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 8074        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02126455  |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.4       |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | -0.00263    |\n",
      "|    reward               | -0.29322332 |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 445         |\n",
      "|    time_elapsed         | 8092        |\n",
      "|    total_timesteps      | 911360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014111045 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.4       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    reward               | -0.72152793 |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 446         |\n",
      "|    time_elapsed         | 8110        |\n",
      "|    total_timesteps      | 913408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017318713 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.5       |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 4450        |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    reward               | 2.179161    |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 39.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 447         |\n",
      "|    time_elapsed         | 8128        |\n",
      "|    total_timesteps      | 915456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024162468 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.5       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.75        |\n",
      "|    n_updates            | 4460        |\n",
      "|    policy_gradient_loss | 0.00472     |\n",
      "|    reward               | -0.2645044  |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 8146        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016536724 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.6       |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 4470        |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    reward               | 0.4945646   |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 42          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 449         |\n",
      "|    time_elapsed         | 8164        |\n",
      "|    total_timesteps      | 919552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013884405 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.6       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 4480        |\n",
      "|    policy_gradient_loss | -0.00191    |\n",
      "|    reward               | 2.361255    |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 450         |\n",
      "|    time_elapsed         | 8181        |\n",
      "|    total_timesteps      | 921600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015046036 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 4490        |\n",
      "|    policy_gradient_loss | -0.00191    |\n",
      "|    reward               | -1.0699234  |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3362296.69\n",
      "total_reward: 2362296.69\n",
      "total_cost: 30717.84\n",
      "total_trades: 49294\n",
      "Sharpe: 0.706\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 8199        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016151726 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    reward               | 0.030508412 |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 8218        |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018325571 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 4510        |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | -4.311954   |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 453         |\n",
      "|    time_elapsed         | 8236        |\n",
      "|    total_timesteps      | 927744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015670363 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.8       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 4520        |\n",
      "|    policy_gradient_loss | 0.0073      |\n",
      "|    reward               | 0.45194733  |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 454         |\n",
      "|    time_elapsed         | 8254        |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017707186 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.8       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.54        |\n",
      "|    n_updates            | 4530        |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    reward               | 0.93211347  |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 455         |\n",
      "|    time_elapsed         | 8272        |\n",
      "|    total_timesteps      | 931840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015966743 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.9       |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 4540        |\n",
      "|    policy_gradient_loss | -0.00917    |\n",
      "|    reward               | 1.1627398   |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 8290        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008644608 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.9       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 4550        |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    reward               | -1.461038   |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 8308        |\n",
      "|    total_timesteps      | 935936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016688112 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.9       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    reward               | -5.0893884  |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 8326        |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014879417 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58         |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 4570        |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    reward               | -3.194526   |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 459         |\n",
      "|    time_elapsed         | 8344        |\n",
      "|    total_timesteps      | 940032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036846288 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58         |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 4580        |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    reward               | -1.7774228  |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 460         |\n",
      "|    time_elapsed         | 8362        |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008896615 |\n",
      "|    clip_fraction        | 0.0752      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58         |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 4590        |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    reward               | -1.5615435  |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 461          |\n",
      "|    time_elapsed         | 8381         |\n",
      "|    total_timesteps      | 944128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.022282243  |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -58.1        |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.76         |\n",
      "|    n_updates            | 4600         |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    reward               | -0.057283163 |\n",
      "|    std                  | 1.8          |\n",
      "|    value_loss           | 20.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 462         |\n",
      "|    time_elapsed         | 8399        |\n",
      "|    total_timesteps      | 946176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017423071 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 4610        |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    reward               | -0.23978184 |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 8417        |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016714094 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    reward               | 9.599675    |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 464         |\n",
      "|    time_elapsed         | 8435        |\n",
      "|    total_timesteps      | 950272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023881003 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.76        |\n",
      "|    n_updates            | 4630        |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    reward               | -1.5438608  |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3445256.06\n",
      "total_reward: 2445256.06\n",
      "total_cost: 47912.43\n",
      "total_trades: 51259\n",
      "Sharpe: 0.725\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 8453        |\n",
      "|    total_timesteps      | 952320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017382188 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.2       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 4640        |\n",
      "|    policy_gradient_loss | -0.00256    |\n",
      "|    reward               | 0.060909446 |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 466         |\n",
      "|    time_elapsed         | 8473        |\n",
      "|    total_timesteps      | 954368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015490325 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.2       |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 4650        |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    reward               | -5.0493655  |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 467         |\n",
      "|    time_elapsed         | 8491        |\n",
      "|    total_timesteps      | 956416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020303449 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 4660        |\n",
      "|    policy_gradient_loss | -0.00222    |\n",
      "|    reward               | 0.5935059   |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 468         |\n",
      "|    time_elapsed         | 8509        |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023010843 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.8         |\n",
      "|    n_updates            | 4670        |\n",
      "|    policy_gradient_loss | -9.6e-05    |\n",
      "|    reward               | 0.9650313   |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 469         |\n",
      "|    time_elapsed         | 8527        |\n",
      "|    total_timesteps      | 960512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01483134  |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    reward               | -0.24728997 |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 470         |\n",
      "|    time_elapsed         | 8545        |\n",
      "|    total_timesteps      | 962560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014558829 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 4690        |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    reward               | -0.86594325 |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 8564        |\n",
      "|    total_timesteps      | 964608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035421852 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.8         |\n",
      "|    n_updates            | 4700        |\n",
      "|    policy_gradient_loss | 0.00292     |\n",
      "|    reward               | -0.357529   |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 472         |\n",
      "|    time_elapsed         | 8583        |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01670131  |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.85        |\n",
      "|    n_updates            | 4710        |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    reward               | -0.62850404 |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 473         |\n",
      "|    time_elapsed         | 8602        |\n",
      "|    total_timesteps      | 968704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012179628 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 4720        |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | -0.8921543  |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 35.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 474         |\n",
      "|    time_elapsed         | 8620        |\n",
      "|    total_timesteps      | 970752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026830211 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.63        |\n",
      "|    n_updates            | 4730        |\n",
      "|    policy_gradient_loss | -0.000282   |\n",
      "|    reward               | 3.5987506   |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 8639        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013793385 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | 0.01653666  |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 23.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 8658        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016827205 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 4750        |\n",
      "|    policy_gradient_loss | -0.00178    |\n",
      "|    reward               | -1.640016   |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 477         |\n",
      "|    time_elapsed         | 8682        |\n",
      "|    total_timesteps      | 976896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030657882 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 4760        |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    reward               | 0.9592314   |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 8701        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019193009 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.13        |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    reward               | 1.2125814   |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3294161.44\n",
      "total_reward: 2294161.44\n",
      "total_cost: 31163.11\n",
      "total_trades: 50254\n",
      "Sharpe: 0.709\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 479         |\n",
      "|    time_elapsed         | 8719        |\n",
      "|    total_timesteps      | 980992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014467383 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 4780        |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    reward               | -1.4890566  |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 8737        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008781185 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 4790        |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    reward               | 3.7793708   |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 481         |\n",
      "|    time_elapsed         | 8756        |\n",
      "|    total_timesteps      | 985088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023538195 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 4800        |\n",
      "|    policy_gradient_loss | -0.000881   |\n",
      "|    reward               | 1.5775287   |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 8774        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016791098 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 4810        |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    reward               | -0.56557643 |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 483          |\n",
      "|    time_elapsed         | 8792         |\n",
      "|    total_timesteps      | 989184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0141694015 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -58.6        |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 4820         |\n",
      "|    policy_gradient_loss | -0.0062      |\n",
      "|    reward               | -6.626096    |\n",
      "|    std                  | 1.83         |\n",
      "|    value_loss           | 37           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 484         |\n",
      "|    time_elapsed         | 8810        |\n",
      "|    total_timesteps      | 991232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015660685 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 4830        |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    reward               | 1.0322157   |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 8828        |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020594072 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.26        |\n",
      "|    n_updates            | 4840        |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | -0.99392843 |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 16.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 486        |\n",
      "|    time_elapsed         | 8847       |\n",
      "|    total_timesteps      | 995328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01889142 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.8      |\n",
      "|    explained_variance   | 0.344      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.3       |\n",
      "|    n_updates            | 4850       |\n",
      "|    policy_gradient_loss | -0.00401   |\n",
      "|    reward               | 0.43737158 |\n",
      "|    std                  | 1.85       |\n",
      "|    value_loss           | 37.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 487        |\n",
      "|    time_elapsed         | 8865       |\n",
      "|    total_timesteps      | 997376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06394068 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.8      |\n",
      "|    explained_variance   | 0.64       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.2       |\n",
      "|    n_updates            | 4860       |\n",
      "|    policy_gradient_loss | 0.000153   |\n",
      "|    reward               | 1.6106318  |\n",
      "|    std                  | 1.85       |\n",
      "|    value_loss           | 39.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 8883        |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024839412 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.9       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.29        |\n",
      "|    n_updates            | 4870        |\n",
      "|    policy_gradient_loss | -0.000907   |\n",
      "|    reward               | 0.49098122  |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 489         |\n",
      "|    time_elapsed         | 8901        |\n",
      "|    total_timesteps      | 1001472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017640494 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.9       |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 4880        |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    reward               | -0.13100065 |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 490        |\n",
      "|    time_elapsed         | 8920       |\n",
      "|    total_timesteps      | 1003520    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01680337 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59        |\n",
      "|    explained_variance   | 0.65       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.3       |\n",
      "|    n_updates            | 4890       |\n",
      "|    policy_gradient_loss | -0.0035    |\n",
      "|    reward               | 0.88061243 |\n",
      "|    std                  | 1.86       |\n",
      "|    value_loss           | 34.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 491         |\n",
      "|    time_elapsed         | 8938        |\n",
      "|    total_timesteps      | 1005568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019543763 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 4900        |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    reward               | 0.6816301   |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 492        |\n",
      "|    time_elapsed         | 8956       |\n",
      "|    total_timesteps      | 1007616    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02734438 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59        |\n",
      "|    explained_variance   | 0.518      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.9       |\n",
      "|    n_updates            | 4910       |\n",
      "|    policy_gradient_loss | -0.00324   |\n",
      "|    reward               | 0.36396274 |\n",
      "|    std                  | 1.86       |\n",
      "|    value_loss           | 26.3       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3272835.93\n",
      "total_reward: 2272835.93\n",
      "total_cost: 28144.76\n",
      "total_trades: 49799\n",
      "Sharpe: 0.691\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 493          |\n",
      "|    time_elapsed         | 8974         |\n",
      "|    total_timesteps      | 1009664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.020988803  |\n",
      "|    clip_fraction        | 0.232        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -59.1        |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 4920         |\n",
      "|    policy_gradient_loss | -0.000695    |\n",
      "|    reward               | -0.036451764 |\n",
      "|    std                  | 1.87         |\n",
      "|    value_loss           | 36.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 494         |\n",
      "|    time_elapsed         | 8992        |\n",
      "|    total_timesteps      | 1011712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009487016 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 4930        |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    reward               | 0.36894056  |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 9011        |\n",
      "|    total_timesteps      | 1013760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021375064 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.68        |\n",
      "|    n_updates            | 4940        |\n",
      "|    policy_gradient_loss | -0.0025     |\n",
      "|    reward               | -0.7942674  |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 496         |\n",
      "|    time_elapsed         | 9029        |\n",
      "|    total_timesteps      | 1015808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018555993 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.2       |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 4950        |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    reward               | 0.21772689  |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 497         |\n",
      "|    time_elapsed         | 9047        |\n",
      "|    total_timesteps      | 1017856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014797686 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.2       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 4960        |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    reward               | 1.6596413   |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 498        |\n",
      "|    time_elapsed         | 9065       |\n",
      "|    total_timesteps      | 1019904    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02102806 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.3      |\n",
      "|    explained_variance   | 0.514      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.57       |\n",
      "|    n_updates            | 4970       |\n",
      "|    policy_gradient_loss | -0.00121   |\n",
      "|    reward               | 0.38481626 |\n",
      "|    std                  | 1.88       |\n",
      "|    value_loss           | 22.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 499         |\n",
      "|    time_elapsed         | 9084        |\n",
      "|    total_timesteps      | 1021952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015195862 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.3       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 4980        |\n",
      "|    policy_gradient_loss | 3.26e-06    |\n",
      "|    reward               | -0.7274122  |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 500         |\n",
      "|    time_elapsed         | 9102        |\n",
      "|    total_timesteps      | 1024000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014518121 |\n",
      "|    clip_fraction        | 0.0698      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.3       |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 4990        |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    reward               | 2.208772    |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 501         |\n",
      "|    time_elapsed         | 9120        |\n",
      "|    total_timesteps      | 1026048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016312078 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.3       |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 5000        |\n",
      "|    policy_gradient_loss | -0.000106   |\n",
      "|    reward               | 0.9287008   |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 502         |\n",
      "|    time_elapsed         | 9139        |\n",
      "|    total_timesteps      | 1028096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016299382 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.3       |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 5010        |\n",
      "|    policy_gradient_loss | -0.0051     |\n",
      "|    reward               | 1.1297214   |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 503          |\n",
      "|    time_elapsed         | 9157         |\n",
      "|    total_timesteps      | 1030144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0128453225 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -59.4        |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.5         |\n",
      "|    n_updates            | 5020         |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    reward               | 0.102361046  |\n",
      "|    std                  | 1.88         |\n",
      "|    value_loss           | 37.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 504         |\n",
      "|    time_elapsed         | 9176        |\n",
      "|    total_timesteps      | 1032192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015043851 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.4       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 5030        |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    reward               | -3.1342168  |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 505         |\n",
      "|    time_elapsed         | 9194        |\n",
      "|    total_timesteps      | 1034240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023653602 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.5       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.82        |\n",
      "|    n_updates            | 5040        |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | -0.26551768 |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 506         |\n",
      "|    time_elapsed         | 9213        |\n",
      "|    total_timesteps      | 1036288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015587103 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.5       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 5050        |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    reward               | 0.7444011   |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 507         |\n",
      "|    time_elapsed         | 9231        |\n",
      "|    total_timesteps      | 1038336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020373188 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 5060        |\n",
      "|    policy_gradient_loss | -0.00387    |\n",
      "|    reward               | 6.2960806   |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4415397.92\n",
      "total_reward: 3415397.92\n",
      "total_cost: 41132.29\n",
      "total_trades: 50959\n",
      "Sharpe: 0.850\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 508         |\n",
      "|    time_elapsed         | 9249        |\n",
      "|    total_timesteps      | 1040384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024777692 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 5070        |\n",
      "|    policy_gradient_loss | 0.00117     |\n",
      "|    reward               | 1.9860632   |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 52.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 509         |\n",
      "|    time_elapsed         | 9267        |\n",
      "|    total_timesteps      | 1042432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017780177 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 5080        |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | -0.40873274 |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 9286        |\n",
      "|    total_timesteps      | 1044480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025069471 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 5090        |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    reward               | 0.03956184  |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 511        |\n",
      "|    time_elapsed         | 9304       |\n",
      "|    total_timesteps      | 1046528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02011041 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.7      |\n",
      "|    explained_variance   | 0.519      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.6       |\n",
      "|    n_updates            | 5100       |\n",
      "|    policy_gradient_loss | -0.000996  |\n",
      "|    reward               | -2.0885575 |\n",
      "|    std                  | 1.9        |\n",
      "|    value_loss           | 40.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 512         |\n",
      "|    time_elapsed         | 9323        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03783478  |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.83        |\n",
      "|    n_updates            | 5110        |\n",
      "|    policy_gradient_loss | 0.007       |\n",
      "|    reward               | -0.87268263 |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 513         |\n",
      "|    time_elapsed         | 9341        |\n",
      "|    total_timesteps      | 1050624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013737513 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 5120        |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    reward               | 0.21790755  |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 514          |\n",
      "|    time_elapsed         | 9359         |\n",
      "|    total_timesteps      | 1052672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0137375165 |\n",
      "|    clip_fraction        | 0.155        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -59.8        |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 5130         |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    reward               | 1.7936159    |\n",
      "|    std                  | 1.91         |\n",
      "|    value_loss           | 44.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 515         |\n",
      "|    time_elapsed         | 9377        |\n",
      "|    total_timesteps      | 1054720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017625805 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.13        |\n",
      "|    n_updates            | 5140        |\n",
      "|    policy_gradient_loss | 0.0043      |\n",
      "|    reward               | -0.25961164 |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 516         |\n",
      "|    time_elapsed         | 9395        |\n",
      "|    total_timesteps      | 1056768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015801642 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.43        |\n",
      "|    n_updates            | 5150        |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    reward               | -1.8550215  |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 517         |\n",
      "|    time_elapsed         | 9414        |\n",
      "|    total_timesteps      | 1058816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020280255 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 5160        |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    reward               | -4.185877   |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 44.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 518          |\n",
      "|    time_elapsed         | 9433         |\n",
      "|    total_timesteps      | 1060864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041871355 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -59.8        |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 5170         |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    reward               | -0.11867462  |\n",
      "|    std                  | 1.91         |\n",
      "|    value_loss           | 48.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 519         |\n",
      "|    time_elapsed         | 9451        |\n",
      "|    total_timesteps      | 1062912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022575697 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.38        |\n",
      "|    n_updates            | 5180        |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    reward               | -0.4063069  |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 520         |\n",
      "|    time_elapsed         | 9470        |\n",
      "|    total_timesteps      | 1064960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01093282  |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.9       |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 5190        |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | -0.07968179 |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 36.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 521        |\n",
      "|    time_elapsed         | 9488       |\n",
      "|    total_timesteps      | 1067008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01007715 |\n",
      "|    clip_fraction        | 0.0602     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.9      |\n",
      "|    explained_variance   | 0.619      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.1       |\n",
      "|    n_updates            | 5200       |\n",
      "|    policy_gradient_loss | -0.00492   |\n",
      "|    reward               | 3.2748487  |\n",
      "|    std                  | 1.92       |\n",
      "|    value_loss           | 41.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3481768.21\n",
      "total_reward: 2481768.21\n",
      "total_cost: 32423.87\n",
      "total_trades: 48856\n",
      "Sharpe: 0.720\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 522        |\n",
      "|    time_elapsed         | 9507       |\n",
      "|    total_timesteps      | 1069056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02528783 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.9      |\n",
      "|    explained_variance   | 0.667      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.4       |\n",
      "|    n_updates            | 5210       |\n",
      "|    policy_gradient_loss | 0.00127    |\n",
      "|    reward               | 2.6017146  |\n",
      "|    std                  | 1.92       |\n",
      "|    value_loss           | 23.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 523         |\n",
      "|    time_elapsed         | 9525        |\n",
      "|    total_timesteps      | 1071104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020714113 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.9       |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.24        |\n",
      "|    n_updates            | 5220        |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    reward               | 1.5334079   |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 524         |\n",
      "|    time_elapsed         | 9543        |\n",
      "|    total_timesteps      | 1073152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016138654 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60         |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 5230        |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    reward               | 4.9354467   |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 525         |\n",
      "|    time_elapsed         | 9562        |\n",
      "|    total_timesteps      | 1075200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020352485 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60         |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 5240        |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    reward               | 0.3454733   |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 61.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 526         |\n",
      "|    time_elapsed         | 9580        |\n",
      "|    total_timesteps      | 1077248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020508448 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.39        |\n",
      "|    n_updates            | 5250        |\n",
      "|    policy_gradient_loss | 0.000737    |\n",
      "|    reward               | 0.47428182  |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 9598        |\n",
      "|    total_timesteps      | 1079296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016586922 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 5260        |\n",
      "|    policy_gradient_loss | -0.00117    |\n",
      "|    reward               | -1.5622653  |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 528        |\n",
      "|    time_elapsed         | 9616       |\n",
      "|    total_timesteps      | 1081344    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00766961 |\n",
      "|    clip_fraction        | 0.0482     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.1      |\n",
      "|    explained_variance   | 0.638      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.9       |\n",
      "|    n_updates            | 5270       |\n",
      "|    policy_gradient_loss | -0.00464   |\n",
      "|    reward               | 1.9043481  |\n",
      "|    std                  | 1.93       |\n",
      "|    value_loss           | 48.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 529         |\n",
      "|    time_elapsed         | 9634        |\n",
      "|    total_timesteps      | 1083392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018110596 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.97        |\n",
      "|    n_updates            | 5280        |\n",
      "|    policy_gradient_loss | -0.000882   |\n",
      "|    reward               | 0.18059951  |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 530         |\n",
      "|    time_elapsed         | 9652        |\n",
      "|    total_timesteps      | 1085440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023978718 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 5290        |\n",
      "|    policy_gradient_loss | -0.00171    |\n",
      "|    reward               | -0.42134103 |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 9670        |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016898617 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.2       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 5300        |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    reward               | 1.4933785   |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 46.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 9689        |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016356321 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.2       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 5310        |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    reward               | 1.7897853   |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 112       |\n",
      "|    iterations           | 533       |\n",
      "|    time_elapsed         | 9707      |\n",
      "|    total_timesteps      | 1091584   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0347723 |\n",
      "|    clip_fraction        | 0.321     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -60.2     |\n",
      "|    explained_variance   | 0.609     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 10.7      |\n",
      "|    n_updates            | 5320      |\n",
      "|    policy_gradient_loss | -0.00567  |\n",
      "|    reward               | -0.495763 |\n",
      "|    std                  | 1.94      |\n",
      "|    value_loss           | 25.7      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 534          |\n",
      "|    time_elapsed         | 9725         |\n",
      "|    total_timesteps      | 1093632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012492682  |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -60.2        |\n",
      "|    explained_variance   | 0.285        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29           |\n",
      "|    n_updates            | 5330         |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    reward               | -0.121211216 |\n",
      "|    std                  | 1.94         |\n",
      "|    value_loss           | 64.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 535         |\n",
      "|    time_elapsed         | 9743        |\n",
      "|    total_timesteps      | 1095680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017838776 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.2       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 5340        |\n",
      "|    policy_gradient_loss | -0.00081    |\n",
      "|    reward               | 2.1085534   |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 51.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4435962.25\n",
      "total_reward: 3435962.25\n",
      "total_cost: 54005.16\n",
      "total_trades: 52046\n",
      "Sharpe: 0.827\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 536         |\n",
      "|    time_elapsed         | 9761        |\n",
      "|    total_timesteps      | 1097728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040928796 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.99        |\n",
      "|    n_updates            | 5350        |\n",
      "|    policy_gradient_loss | 0.00814     |\n",
      "|    reward               | 1.0185145   |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 537        |\n",
      "|    time_elapsed         | 9780       |\n",
      "|    total_timesteps      | 1099776    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02388497 |\n",
      "|    clip_fraction        | 0.306      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.3      |\n",
      "|    explained_variance   | 0.214      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.8       |\n",
      "|    n_updates            | 5360       |\n",
      "|    policy_gradient_loss | 0.00925    |\n",
      "|    reward               | -0.8140748 |\n",
      "|    std                  | 1.95       |\n",
      "|    value_loss           | 64.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 538         |\n",
      "|    time_elapsed         | 9797        |\n",
      "|    total_timesteps      | 1101824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009686619 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.4       |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 5370        |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    reward               | -2.6231773  |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 57.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 539        |\n",
      "|    time_elapsed         | 9815       |\n",
      "|    total_timesteps      | 1103872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02222891 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.5      |\n",
      "|    explained_variance   | 0.544      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.4       |\n",
      "|    n_updates            | 5380       |\n",
      "|    policy_gradient_loss | -0.000122  |\n",
      "|    reward               | 1.5378344  |\n",
      "|    std                  | 1.96       |\n",
      "|    value_loss           | 37.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 540        |\n",
      "|    time_elapsed         | 9833       |\n",
      "|    total_timesteps      | 1105920    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01661993 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.5      |\n",
      "|    explained_variance   | 0.432      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.1       |\n",
      "|    n_updates            | 5390       |\n",
      "|    policy_gradient_loss | -0.00291   |\n",
      "|    reward               | 1.4657408  |\n",
      "|    std                  | 1.96       |\n",
      "|    value_loss           | 41.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 541        |\n",
      "|    time_elapsed         | 9850       |\n",
      "|    total_timesteps      | 1107968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01592036 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.5      |\n",
      "|    explained_variance   | 0.563      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.2       |\n",
      "|    n_updates            | 5400       |\n",
      "|    policy_gradient_loss | -0.00275   |\n",
      "|    reward               | -1.1582887 |\n",
      "|    std                  | 1.96       |\n",
      "|    value_loss           | 59.9       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 542        |\n",
      "|    time_elapsed         | 9868       |\n",
      "|    total_timesteps      | 1110016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02203552 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.6      |\n",
      "|    explained_variance   | 0.305      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.4       |\n",
      "|    n_updates            | 5410       |\n",
      "|    policy_gradient_loss | -0.00589   |\n",
      "|    reward               | -2.5213192 |\n",
      "|    std                  | 1.96       |\n",
      "|    value_loss           | 78         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 9886        |\n",
      "|    total_timesteps      | 1112064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028892424 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.6       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 5420        |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    reward               | 1.5067567   |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 544         |\n",
      "|    time_elapsed         | 9904        |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017918717 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 5430        |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    reward               | -0.5931431  |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 545          |\n",
      "|    time_elapsed         | 9922         |\n",
      "|    total_timesteps      | 1116160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047774813 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -60.7        |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 5440         |\n",
      "|    policy_gradient_loss | -0.00622     |\n",
      "|    reward               | 5.0993357    |\n",
      "|    std                  | 1.97         |\n",
      "|    value_loss           | 57.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 546         |\n",
      "|    time_elapsed         | 9940        |\n",
      "|    total_timesteps      | 1118208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01222914  |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 5450        |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    reward               | -0.10511807 |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 547         |\n",
      "|    time_elapsed         | 9958        |\n",
      "|    total_timesteps      | 1120256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018711928 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 5460        |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    reward               | 4.4737573   |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 548         |\n",
      "|    time_elapsed         | 9976        |\n",
      "|    total_timesteps      | 1122304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005315368 |\n",
      "|    clip_fraction        | 0.0228      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.8       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 5470        |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    reward               | -1.7024747  |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 59.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 9995        |\n",
      "|    total_timesteps      | 1124352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007432595 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.8       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 5480        |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    reward               | 2.7198486   |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4190293.05\n",
      "total_reward: 3190293.05\n",
      "total_cost: 50580.85\n",
      "total_trades: 51817\n",
      "Sharpe: 0.787\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 550         |\n",
      "|    time_elapsed         | 10013       |\n",
      "|    total_timesteps      | 1126400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014930783 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.8       |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.95        |\n",
      "|    n_updates            | 5490        |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | -0.94666743 |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 551          |\n",
      "|    time_elapsed         | 10031        |\n",
      "|    total_timesteps      | 1128448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117147565 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -60.8        |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 5500         |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | 0.41314656   |\n",
      "|    std                  | 1.98         |\n",
      "|    value_loss           | 50.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 552          |\n",
      "|    time_elapsed         | 10049        |\n",
      "|    total_timesteps      | 1130496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043621566 |\n",
      "|    clip_fraction        | 0.0602       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -60.8        |\n",
      "|    explained_variance   | 0.606        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23           |\n",
      "|    n_updates            | 5510         |\n",
      "|    policy_gradient_loss | 0.00414      |\n",
      "|    reward               | 0.44424504   |\n",
      "|    std                  | 1.98         |\n",
      "|    value_loss           | 59           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 10067       |\n",
      "|    total_timesteps      | 1132544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027784806 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.8       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 5520        |\n",
      "|    policy_gradient_loss | -0.000963   |\n",
      "|    reward               | -0.8846992  |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 554         |\n",
      "|    time_elapsed         | 10085       |\n",
      "|    total_timesteps      | 1134592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029868653 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.8       |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 5530        |\n",
      "|    policy_gradient_loss | 0.00067     |\n",
      "|    reward               | 0.28206012  |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 555         |\n",
      "|    time_elapsed         | 10103       |\n",
      "|    total_timesteps      | 1136640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018712398 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.8       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 5540        |\n",
      "|    policy_gradient_loss | 0.00268     |\n",
      "|    reward               | 0.013965604 |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 68.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 556         |\n",
      "|    time_elapsed         | 10121       |\n",
      "|    total_timesteps      | 1138688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011857082 |\n",
      "|    clip_fraction        | 0.0754      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.8       |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 5550        |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    reward               | -3.3564947  |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 557         |\n",
      "|    time_elapsed         | 10139       |\n",
      "|    total_timesteps      | 1140736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016392417 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.8       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 5560        |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    reward               | -2.6846201  |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 558         |\n",
      "|    time_elapsed         | 10157       |\n",
      "|    total_timesteps      | 1142784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020195542 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 5570        |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    reward               | -0.10689295 |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 57.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 10176       |\n",
      "|    total_timesteps      | 1144832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015331825 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 5580        |\n",
      "|    policy_gradient_loss | 0.0019      |\n",
      "|    reward               | -1.0882441  |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 51.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 560         |\n",
      "|    time_elapsed         | 10194       |\n",
      "|    total_timesteps      | 1146880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021270366 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.0665      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 5590        |\n",
      "|    policy_gradient_loss | 0.000716    |\n",
      "|    reward               | -0.24755163 |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 561         |\n",
      "|    time_elapsed         | 10212       |\n",
      "|    total_timesteps      | 1148928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017151553 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 5600        |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | 0.27138215  |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 51.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 562         |\n",
      "|    time_elapsed         | 10230       |\n",
      "|    total_timesteps      | 1150976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011077948 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 5610        |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | -4.1844006  |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 60.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 563          |\n",
      "|    time_elapsed         | 10248        |\n",
      "|    total_timesteps      | 1153024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.021665365  |\n",
      "|    clip_fraction        | 0.299        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -61          |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 5620         |\n",
      "|    policy_gradient_loss | 0.00167      |\n",
      "|    reward               | -0.043984253 |\n",
      "|    std                  | 1.99         |\n",
      "|    value_loss           | 36           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4638420.67\n",
      "total_reward: 3638420.67\n",
      "total_cost: 57384.34\n",
      "total_trades: 53374\n",
      "Sharpe: 0.853\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 564         |\n",
      "|    time_elapsed         | 10266       |\n",
      "|    total_timesteps      | 1155072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014291329 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 5630        |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | 0.003934602 |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 43          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 565         |\n",
      "|    time_elapsed         | 10284       |\n",
      "|    total_timesteps      | 1157120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014248493 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 5640        |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    reward               | -16.250069  |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 69.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 566        |\n",
      "|    time_elapsed         | 10302      |\n",
      "|    total_timesteps      | 1159168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01225108 |\n",
      "|    clip_fraction        | 0.0584     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.1      |\n",
      "|    explained_variance   | 0.554      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.4       |\n",
      "|    n_updates            | 5650       |\n",
      "|    policy_gradient_loss | -0.00503   |\n",
      "|    reward               | 1.5462172  |\n",
      "|    std                  | 2          |\n",
      "|    value_loss           | 49.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 567         |\n",
      "|    time_elapsed         | 10320       |\n",
      "|    total_timesteps      | 1161216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024051659 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 5660        |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    reward               | -4.713748   |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 568         |\n",
      "|    time_elapsed         | 10339       |\n",
      "|    total_timesteps      | 1163264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016765002 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 5670        |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | -0.2521982  |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 43.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 569          |\n",
      "|    time_elapsed         | 10359        |\n",
      "|    total_timesteps      | 1165312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0155531205 |\n",
      "|    clip_fraction        | 0.0819       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -61.2        |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.1         |\n",
      "|    n_updates            | 5680         |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    reward               | -9.437891    |\n",
      "|    std                  | 2            |\n",
      "|    value_loss           | 49.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 570         |\n",
      "|    time_elapsed         | 10377       |\n",
      "|    total_timesteps      | 1167360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021022515 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 5690        |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    reward               | -0.28001383 |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 571        |\n",
      "|    time_elapsed         | 10395      |\n",
      "|    total_timesteps      | 1169408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04094518 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.2      |\n",
      "|    explained_variance   | 0.65       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.1       |\n",
      "|    n_updates            | 5700       |\n",
      "|    policy_gradient_loss | -0.000458  |\n",
      "|    reward               | 1.3928274  |\n",
      "|    std                  | 2.01       |\n",
      "|    value_loss           | 35.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 572          |\n",
      "|    time_elapsed         | 10413        |\n",
      "|    total_timesteps      | 1171456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052324384 |\n",
      "|    clip_fraction        | 0.0418       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -61.2        |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.8         |\n",
      "|    n_updates            | 5710         |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    reward               | 1.0439649    |\n",
      "|    std                  | 2.01         |\n",
      "|    value_loss           | 52.9         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 573        |\n",
      "|    time_elapsed         | 10431      |\n",
      "|    total_timesteps      | 1173504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02926936 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.3      |\n",
      "|    explained_variance   | 0.683      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.9       |\n",
      "|    n_updates            | 5720       |\n",
      "|    policy_gradient_loss | 0.00767    |\n",
      "|    reward               | 0.45349368 |\n",
      "|    std                  | 2.01       |\n",
      "|    value_loss           | 39.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 574         |\n",
      "|    time_elapsed         | 10449       |\n",
      "|    total_timesteps      | 1175552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024368282 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 5730        |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    reward               | -0.6257018  |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 575         |\n",
      "|    time_elapsed         | 10467       |\n",
      "|    total_timesteps      | 1177600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011878239 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 5740        |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    reward               | -0.46497568 |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 46.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 576         |\n",
      "|    time_elapsed         | 10485       |\n",
      "|    total_timesteps      | 1179648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006521545 |\n",
      "|    clip_fraction        | 0.0222      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 5750        |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    reward               | -0.5451075  |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 55.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 577         |\n",
      "|    time_elapsed         | 10503       |\n",
      "|    total_timesteps      | 1181696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029626645 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 5760        |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    reward               | 0.13398647  |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3621347.78\n",
      "total_reward: 2621347.78\n",
      "total_cost: 32502.61\n",
      "total_trades: 50661\n",
      "Sharpe: 0.743\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 578         |\n",
      "|    time_elapsed         | 10521       |\n",
      "|    total_timesteps      | 1183744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010701779 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.4       |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 5770        |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | -0.3441069  |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 35.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 579        |\n",
      "|    time_elapsed         | 10540      |\n",
      "|    total_timesteps      | 1185792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01896949 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.4      |\n",
      "|    explained_variance   | 0.638      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.5       |\n",
      "|    n_updates            | 5780       |\n",
      "|    policy_gradient_loss | -0.0038    |\n",
      "|    reward               | 1.8396492  |\n",
      "|    std                  | 2.02       |\n",
      "|    value_loss           | 42.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 580        |\n",
      "|    time_elapsed         | 10559      |\n",
      "|    total_timesteps      | 1187840    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01167212 |\n",
      "|    clip_fraction        | 0.0986     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.4      |\n",
      "|    explained_variance   | 0.705      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.5       |\n",
      "|    n_updates            | 5790       |\n",
      "|    policy_gradient_loss | -0.00366   |\n",
      "|    reward               | -0.7001205 |\n",
      "|    std                  | 2.02       |\n",
      "|    value_loss           | 28.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 581         |\n",
      "|    time_elapsed         | 10579       |\n",
      "|    total_timesteps      | 1189888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017375544 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.4       |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 5800        |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | 0.5030284   |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 582         |\n",
      "|    time_elapsed         | 10598       |\n",
      "|    total_timesteps      | 1191936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011464846 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.4       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 5810        |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    reward               | -1.5056777  |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 583        |\n",
      "|    time_elapsed         | 10617      |\n",
      "|    total_timesteps      | 1193984    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01570866 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.4      |\n",
      "|    explained_variance   | 0.656      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.9       |\n",
      "|    n_updates            | 5820       |\n",
      "|    policy_gradient_loss | -0.00155   |\n",
      "|    reward               | -2.1906383 |\n",
      "|    std                  | 2.02       |\n",
      "|    value_loss           | 44.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 584         |\n",
      "|    time_elapsed         | 10635       |\n",
      "|    total_timesteps      | 1196032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017380701 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.4       |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.43        |\n",
      "|    n_updates            | 5830        |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | 0.46034554  |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 585         |\n",
      "|    time_elapsed         | 10653       |\n",
      "|    total_timesteps      | 1198080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020870626 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.5       |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 5840        |\n",
      "|    policy_gradient_loss | 0.00185     |\n",
      "|    reward               | 0.31777108  |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 31.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 586         |\n",
      "|    time_elapsed         | 10671       |\n",
      "|    total_timesteps      | 1200128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010627021 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.5       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 5850        |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    reward               | -1.7980919  |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 587         |\n",
      "|    time_elapsed         | 10689       |\n",
      "|    total_timesteps      | 1202176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013107602 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.6       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 5860        |\n",
      "|    policy_gradient_loss | 0.00052     |\n",
      "|    reward               | -1.9280317  |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 588         |\n",
      "|    time_elapsed         | 10708       |\n",
      "|    total_timesteps      | 1204224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019201754 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.6       |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.86        |\n",
      "|    n_updates            | 5870        |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    reward               | -1.8254125  |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 589         |\n",
      "|    time_elapsed         | 10726       |\n",
      "|    total_timesteps      | 1206272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019319069 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.6       |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 5880        |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | 1.0970474   |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 590         |\n",
      "|    time_elapsed         | 10744       |\n",
      "|    total_timesteps      | 1208320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012752343 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.6       |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 5890        |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    reward               | 1.6985614   |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 591         |\n",
      "|    time_elapsed         | 10762       |\n",
      "|    total_timesteps      | 1210368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020818483 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.7       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 5900        |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    reward               | -0.6581852  |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3643214.32\n",
      "total_reward: 2643214.32\n",
      "total_cost: 38502.03\n",
      "total_trades: 52087\n",
      "Sharpe: 0.733\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 592         |\n",
      "|    time_elapsed         | 10780       |\n",
      "|    total_timesteps      | 1212416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013394    |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.7       |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 5910        |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    reward               | 0.068589225 |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 593         |\n",
      "|    time_elapsed         | 10798       |\n",
      "|    total_timesteps      | 1214464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016206004 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.7       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 5920        |\n",
      "|    policy_gradient_loss | -0.00088    |\n",
      "|    reward               | 4.5421896   |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 594         |\n",
      "|    time_elapsed         | 10817       |\n",
      "|    total_timesteps      | 1216512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026632788 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.8       |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 5930        |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    reward               | -6.72476    |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 595         |\n",
      "|    time_elapsed         | 10835       |\n",
      "|    total_timesteps      | 1218560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035475068 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.8       |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 5940        |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    reward               | -2.2873342  |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 596        |\n",
      "|    time_elapsed         | 10853      |\n",
      "|    total_timesteps      | 1220608    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01231969 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.9      |\n",
      "|    explained_variance   | 0.411      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.6       |\n",
      "|    n_updates            | 5950       |\n",
      "|    policy_gradient_loss | -0.00706   |\n",
      "|    reward               | 0.50757134 |\n",
      "|    std                  | 2.06       |\n",
      "|    value_loss           | 51.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 10871       |\n",
      "|    total_timesteps      | 1222656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012953848 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.9       |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 5960        |\n",
      "|    policy_gradient_loss | -0.000839   |\n",
      "|    reward               | -0.12573911 |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 598         |\n",
      "|    time_elapsed         | 10891       |\n",
      "|    total_timesteps      | 1224704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022471704 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.9       |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.03        |\n",
      "|    n_updates            | 5970        |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    reward               | 1.9003745   |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 599         |\n",
      "|    time_elapsed         | 10910       |\n",
      "|    total_timesteps      | 1226752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030844264 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62         |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 5980        |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    reward               | 0.54389256  |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 600         |\n",
      "|    time_elapsed         | 10929       |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010511124 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62         |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 5990        |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    reward               | 0.9062073   |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 44.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 601         |\n",
      "|    time_elapsed         | 10948       |\n",
      "|    total_timesteps      | 1230848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017187487 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.1       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.61        |\n",
      "|    n_updates            | 6000        |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | -1.0390487  |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 602         |\n",
      "|    time_elapsed         | 10967       |\n",
      "|    total_timesteps      | 1232896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020456659 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.1       |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 6010        |\n",
      "|    policy_gradient_loss | -0.00171    |\n",
      "|    reward               | 1.0390877   |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 10986       |\n",
      "|    total_timesteps      | 1234944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010210778 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 6020        |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    reward               | -2.9245129  |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 604         |\n",
      "|    time_elapsed         | 11004       |\n",
      "|    total_timesteps      | 1236992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015393002 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.79        |\n",
      "|    n_updates            | 6030        |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    reward               | 6.413799    |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 605         |\n",
      "|    time_elapsed         | 11023       |\n",
      "|    total_timesteps      | 1239040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018690147 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.7         |\n",
      "|    n_updates            | 6040        |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    reward               | 0.122870654 |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 606         |\n",
      "|    time_elapsed         | 11041       |\n",
      "|    total_timesteps      | 1241088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016875736 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 6050        |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    reward               | -1.6018671  |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 59.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3685658.61\n",
      "total_reward: 2685658.61\n",
      "total_cost: 43998.60\n",
      "total_trades: 52680\n",
      "Sharpe: 0.751\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 11060       |\n",
      "|    total_timesteps      | 1243136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00986385  |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 6060        |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    reward               | -0.20125183 |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 51.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 608         |\n",
      "|    time_elapsed         | 11078       |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015527349 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.14        |\n",
      "|    n_updates            | 6070        |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    reward               | 1.4258915   |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 609        |\n",
      "|    time_elapsed         | 11096      |\n",
      "|    total_timesteps      | 1247232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01269341 |\n",
      "|    clip_fraction        | 0.088      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.3      |\n",
      "|    explained_variance   | 0.587      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.9       |\n",
      "|    n_updates            | 6080       |\n",
      "|    policy_gradient_loss | -0.00533   |\n",
      "|    reward               | -1.3329914 |\n",
      "|    std                  | 2.09       |\n",
      "|    value_loss           | 36.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 610          |\n",
      "|    time_elapsed         | 11114        |\n",
      "|    total_timesteps      | 1249280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076928986 |\n",
      "|    clip_fraction        | 0.0752       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -62.4        |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 6090         |\n",
      "|    policy_gradient_loss | -0.00708     |\n",
      "|    reward               | 3.8450313    |\n",
      "|    std                  | 2.09         |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 611        |\n",
      "|    time_elapsed         | 11132      |\n",
      "|    total_timesteps      | 1251328    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01772386 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.4      |\n",
      "|    explained_variance   | 0.271      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.5       |\n",
      "|    n_updates            | 6100       |\n",
      "|    policy_gradient_loss | -0.00169   |\n",
      "|    reward               | 1.6601166  |\n",
      "|    std                  | 2.09       |\n",
      "|    value_loss           | 24.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 612         |\n",
      "|    time_elapsed         | 11151       |\n",
      "|    total_timesteps      | 1253376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017518988 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 6110        |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    reward               | 2.065487    |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 613        |\n",
      "|    time_elapsed         | 11170      |\n",
      "|    total_timesteps      | 1255424    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01063811 |\n",
      "|    clip_fraction        | 0.089      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.5      |\n",
      "|    explained_variance   | 0.492      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13         |\n",
      "|    n_updates            | 6120       |\n",
      "|    policy_gradient_loss | -0.00773   |\n",
      "|    reward               | 0.9483976  |\n",
      "|    std                  | 2.1        |\n",
      "|    value_loss           | 33         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 614          |\n",
      "|    time_elapsed         | 11188        |\n",
      "|    total_timesteps      | 1257472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01348756   |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -62.5        |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.9         |\n",
      "|    n_updates            | 6130         |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    reward               | -0.094117165 |\n",
      "|    std                  | 2.1          |\n",
      "|    value_loss           | 33.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 11207       |\n",
      "|    total_timesteps      | 1259520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019643977 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.6       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.67        |\n",
      "|    n_updates            | 6140        |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | 0.5331559   |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 616         |\n",
      "|    time_elapsed         | 11225       |\n",
      "|    total_timesteps      | 1261568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013378195 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.6       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 6150        |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    reward               | 0.60389566  |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 11244       |\n",
      "|    total_timesteps      | 1263616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009870474 |\n",
      "|    clip_fraction        | 0.073       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.6       |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 6160        |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    reward               | 2.5300698   |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 618         |\n",
      "|    time_elapsed         | 11263       |\n",
      "|    total_timesteps      | 1265664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03392034  |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.7       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.1         |\n",
      "|    n_updates            | 6170        |\n",
      "|    policy_gradient_loss | 0.00106     |\n",
      "|    reward               | -0.56197727 |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 619         |\n",
      "|    time_elapsed         | 11282       |\n",
      "|    total_timesteps      | 1267712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015852923 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.7       |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 6180        |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | 2.810527    |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 620         |\n",
      "|    time_elapsed         | 11300       |\n",
      "|    total_timesteps      | 1269760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012130231 |\n",
      "|    clip_fraction        | 0.06        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.8       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 6190        |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | 1.7246816   |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3292564.13\n",
      "total_reward: 2292564.13\n",
      "total_cost: 43305.50\n",
      "total_trades: 52012\n",
      "Sharpe: 0.697\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 621          |\n",
      "|    time_elapsed         | 11318        |\n",
      "|    total_timesteps      | 1271808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076730014 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -62.8        |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.56         |\n",
      "|    n_updates            | 6200         |\n",
      "|    policy_gradient_loss | -0.00636     |\n",
      "|    reward               | -0.1549826   |\n",
      "|    std                  | 2.12         |\n",
      "|    value_loss           | 26.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 622          |\n",
      "|    time_elapsed         | 11337        |\n",
      "|    total_timesteps      | 1273856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.02060341   |\n",
      "|    clip_fraction        | 0.305        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -62.8        |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.53         |\n",
      "|    n_updates            | 6210         |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    reward               | -0.032928083 |\n",
      "|    std                  | 2.12         |\n",
      "|    value_loss           | 20.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 623         |\n",
      "|    time_elapsed         | 11355       |\n",
      "|    total_timesteps      | 1275904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018864498 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.8       |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 6220        |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    reward               | 0.45665544  |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 35.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 624         |\n",
      "|    time_elapsed         | 11373       |\n",
      "|    total_timesteps      | 1277952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009692363 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 6230        |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    reward               | 1.3749338   |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 625          |\n",
      "|    time_elapsed         | 11391        |\n",
      "|    total_timesteps      | 1280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016392905  |\n",
      "|    clip_fraction        | 0.188        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -62.9        |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.47         |\n",
      "|    n_updates            | 6240         |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    reward               | -0.012779902 |\n",
      "|    std                  | 2.13         |\n",
      "|    value_loss           | 17           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 626         |\n",
      "|    time_elapsed         | 11410       |\n",
      "|    total_timesteps      | 1282048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016792804 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 6250        |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    reward               | -0.61955583 |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 627          |\n",
      "|    time_elapsed         | 11435        |\n",
      "|    total_timesteps      | 1284096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102480585 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -63          |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 6260         |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    reward               | -1.622597    |\n",
      "|    std                  | 2.13         |\n",
      "|    value_loss           | 39.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 628         |\n",
      "|    time_elapsed         | 11453       |\n",
      "|    total_timesteps      | 1286144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016881514 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 6270        |\n",
      "|    policy_gradient_loss | -0.000752   |\n",
      "|    reward               | 1.6794021   |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 629         |\n",
      "|    time_elapsed         | 11471       |\n",
      "|    total_timesteps      | 1288192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026061501 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 6280        |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | -0.05995784 |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 630         |\n",
      "|    time_elapsed         | 11490       |\n",
      "|    total_timesteps      | 1290240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017230485 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 6290        |\n",
      "|    policy_gradient_loss | 0.00179     |\n",
      "|    reward               | -1.2767717  |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 11508       |\n",
      "|    total_timesteps      | 1292288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011524849 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 6300        |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    reward               | -0.11061397 |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 632         |\n",
      "|    time_elapsed         | 11527       |\n",
      "|    total_timesteps      | 1294336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019479169 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.25        |\n",
      "|    n_updates            | 6310        |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    reward               | -1.4209176  |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 112       |\n",
      "|    iterations           | 633       |\n",
      "|    time_elapsed         | 11545     |\n",
      "|    total_timesteps      | 1296384   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0185072 |\n",
      "|    clip_fraction        | 0.232     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -63.1     |\n",
      "|    explained_variance   | 0.665     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 17.7      |\n",
      "|    n_updates            | 6320      |\n",
      "|    policy_gradient_loss | -0.00109  |\n",
      "|    reward               | 0.3975522 |\n",
      "|    std                  | 2.14      |\n",
      "|    value_loss           | 32.3      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 634         |\n",
      "|    time_elapsed         | 11564       |\n",
      "|    total_timesteps      | 1298432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009634446 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 6330        |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    reward               | -3.1894772  |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3491129.22\n",
      "total_reward: 2491129.22\n",
      "total_cost: 41083.43\n",
      "total_trades: 51580\n",
      "Sharpe: 0.713\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 112       |\n",
      "|    iterations           | 635       |\n",
      "|    time_elapsed         | 11583     |\n",
      "|    total_timesteps      | 1300480   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0247351 |\n",
      "|    clip_fraction        | 0.234     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -63.2     |\n",
      "|    explained_variance   | 0.706     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 14        |\n",
      "|    n_updates            | 6340      |\n",
      "|    policy_gradient_loss | -0.00182  |\n",
      "|    reward               | 4.021646  |\n",
      "|    std                  | 2.15      |\n",
      "|    value_loss           | 22.9      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 636         |\n",
      "|    time_elapsed         | 11601       |\n",
      "|    total_timesteps      | 1302528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019885734 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.2       |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 6350        |\n",
      "|    policy_gradient_loss | -0.00267    |\n",
      "|    reward               | 0.23000963  |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 637         |\n",
      "|    time_elapsed         | 11619       |\n",
      "|    total_timesteps      | 1304576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010762539 |\n",
      "|    clip_fraction        | 0.0999      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 6360        |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    reward               | -1.9637578  |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 638        |\n",
      "|    time_elapsed         | 11638      |\n",
      "|    total_timesteps      | 1306624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01857043 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.3      |\n",
      "|    explained_variance   | 0.699      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.6       |\n",
      "|    n_updates            | 6370       |\n",
      "|    policy_gradient_loss | -0.00395   |\n",
      "|    reward               | 1.9936407  |\n",
      "|    std                  | 2.16       |\n",
      "|    value_loss           | 30.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 639         |\n",
      "|    time_elapsed         | 11657       |\n",
      "|    total_timesteps      | 1308672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026874295 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.04        |\n",
      "|    n_updates            | 6380        |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    reward               | 0.26264152  |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 640         |\n",
      "|    time_elapsed         | 11675       |\n",
      "|    total_timesteps      | 1310720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018699324 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 6390        |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    reward               | 1.2065955   |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 641          |\n",
      "|    time_elapsed         | 11693        |\n",
      "|    total_timesteps      | 1312768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066042296 |\n",
      "|    clip_fraction        | 0.0667       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -63.4        |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 6400         |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | -2.4476235   |\n",
      "|    std                  | 2.17         |\n",
      "|    value_loss           | 39.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 642         |\n",
      "|    time_elapsed         | 11712       |\n",
      "|    total_timesteps      | 1314816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014968462 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.67        |\n",
      "|    n_updates            | 6410        |\n",
      "|    policy_gradient_loss | 0.000843    |\n",
      "|    reward               | 3.1064055   |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 643         |\n",
      "|    time_elapsed         | 11730       |\n",
      "|    total_timesteps      | 1316864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016132783 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 6420        |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    reward               | -0.3347115  |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 31.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 644         |\n",
      "|    time_elapsed         | 11748       |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007897589 |\n",
      "|    clip_fraction        | 0.0882      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 6430        |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    reward               | 3.3256772   |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 645         |\n",
      "|    time_elapsed         | 11766       |\n",
      "|    total_timesteps      | 1320960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011520529 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 6440        |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    reward               | -3.8056731  |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 646         |\n",
      "|    time_elapsed         | 11784       |\n",
      "|    total_timesteps      | 1323008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016736455 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 6450        |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | 0.15948421  |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 647         |\n",
      "|    time_elapsed         | 11803       |\n",
      "|    total_timesteps      | 1325056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013006315 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 6460        |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    reward               | 1.1753843   |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 648         |\n",
      "|    time_elapsed         | 11821       |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013024063 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 6470        |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    reward               | 0.6540182   |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3852013.71\n",
      "total_reward: 2852013.71\n",
      "total_cost: 39536.50\n",
      "total_trades: 52425\n",
      "Sharpe: 0.778\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 649         |\n",
      "|    time_elapsed         | 11840       |\n",
      "|    total_timesteps      | 1329152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024557296 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.54        |\n",
      "|    n_updates            | 6480        |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    reward               | -0.5228777  |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 650         |\n",
      "|    time_elapsed         | 11858       |\n",
      "|    total_timesteps      | 1331200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013539763 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 6490        |\n",
      "|    policy_gradient_loss | -0.000634   |\n",
      "|    reward               | 0.010984531 |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 651          |\n",
      "|    time_elapsed         | 11876        |\n",
      "|    total_timesteps      | 1333248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096662715 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -63.7        |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 6500         |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    reward               | -0.92552483  |\n",
      "|    std                  | 2.19         |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 652         |\n",
      "|    time_elapsed         | 11894       |\n",
      "|    total_timesteps      | 1335296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024272515 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.98        |\n",
      "|    n_updates            | 6510        |\n",
      "|    policy_gradient_loss | 0.00659     |\n",
      "|    reward               | 1.905992    |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 11913       |\n",
      "|    total_timesteps      | 1337344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017779399 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 6520        |\n",
      "|    policy_gradient_loss | -0.000643   |\n",
      "|    reward               | 0.31298643  |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 11931       |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007517183 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 6530        |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    reward               | 19.085096   |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 655         |\n",
      "|    time_elapsed         | 11950       |\n",
      "|    total_timesteps      | 1341440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012660779 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 6540        |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    reward               | -4.3874207  |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 656         |\n",
      "|    time_elapsed         | 11968       |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015379174 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.17        |\n",
      "|    n_updates            | 6550        |\n",
      "|    policy_gradient_loss | 0.000836    |\n",
      "|    reward               | 0.75770414  |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 657         |\n",
      "|    time_elapsed         | 11986       |\n",
      "|    total_timesteps      | 1345536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024265349 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 6560        |\n",
      "|    policy_gradient_loss | 0.00144     |\n",
      "|    reward               | -0.03928172 |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 658         |\n",
      "|    time_elapsed         | 12004       |\n",
      "|    total_timesteps      | 1347584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004686741 |\n",
      "|    clip_fraction        | 0.0218      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 6570        |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    reward               | -0.39034972 |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 12022       |\n",
      "|    total_timesteps      | 1349632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019315116 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.86        |\n",
      "|    n_updates            | 6580        |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    reward               | -1.0602223  |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 660         |\n",
      "|    time_elapsed         | 12041       |\n",
      "|    total_timesteps      | 1351680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014289273 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 6590        |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    reward               | -0.6710864  |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 661         |\n",
      "|    time_elapsed         | 12060       |\n",
      "|    total_timesteps      | 1353728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015737943 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 6600        |\n",
      "|    policy_gradient_loss | 0.00172     |\n",
      "|    reward               | 3.9204493   |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 662         |\n",
      "|    time_elapsed         | 12079       |\n",
      "|    total_timesteps      | 1355776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012171693 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 6610        |\n",
      "|    policy_gradient_loss | 0.00119     |\n",
      "|    reward               | -0.37390596 |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3871069.56\n",
      "total_reward: 2871069.56\n",
      "total_cost: 36901.88\n",
      "total_trades: 52073\n",
      "Sharpe: 0.776\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 663         |\n",
      "|    time_elapsed         | 12098       |\n",
      "|    total_timesteps      | 1357824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024800412 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 6620        |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    reward               | -0.20968506 |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 664         |\n",
      "|    time_elapsed         | 12117       |\n",
      "|    total_timesteps      | 1359872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012102618 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.1       |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 6630        |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    reward               | 0.26305628  |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 42.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 665          |\n",
      "|    time_elapsed         | 12136        |\n",
      "|    total_timesteps      | 1361920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073537715 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.1        |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 6640         |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | 0.42484456   |\n",
      "|    std                  | 2.22         |\n",
      "|    value_loss           | 50           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 666          |\n",
      "|    time_elapsed         | 12155        |\n",
      "|    total_timesteps      | 1363968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.020041786  |\n",
      "|    clip_fraction        | 0.298        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.1        |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.42         |\n",
      "|    n_updates            | 6650         |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | -0.026012018 |\n",
      "|    std                  | 2.22         |\n",
      "|    value_loss           | 17.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 667         |\n",
      "|    time_elapsed         | 12173       |\n",
      "|    total_timesteps      | 1366016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011862742 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.2       |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 6660        |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    reward               | -0.95536584 |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 668         |\n",
      "|    time_elapsed         | 12191       |\n",
      "|    total_timesteps      | 1368064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015668273 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.2       |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 6670        |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    reward               | 3.0419526   |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 669        |\n",
      "|    time_elapsed         | 12211      |\n",
      "|    total_timesteps      | 1370112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01627604 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.2      |\n",
      "|    explained_variance   | 0.674      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.7       |\n",
      "|    n_updates            | 6680       |\n",
      "|    policy_gradient_loss | -0.0025    |\n",
      "|    reward               | 0.8092911  |\n",
      "|    std                  | 2.23       |\n",
      "|    value_loss           | 27.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 670         |\n",
      "|    time_elapsed         | 12229       |\n",
      "|    total_timesteps      | 1372160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017375613 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.2       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 6690        |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    reward               | 0.8400904   |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 671         |\n",
      "|    time_elapsed         | 12247       |\n",
      "|    total_timesteps      | 1374208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015280415 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 6700        |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    reward               | -0.23724945 |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 672         |\n",
      "|    time_elapsed         | 12265       |\n",
      "|    total_timesteps      | 1376256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013651825 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 6710        |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    reward               | -1.2644974  |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 12283       |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038551606 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.71        |\n",
      "|    n_updates            | 6720        |\n",
      "|    policy_gradient_loss | 0.00459     |\n",
      "|    reward               | -0.6842156  |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 674         |\n",
      "|    time_elapsed         | 12302       |\n",
      "|    total_timesteps      | 1380352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011254288 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 6730        |\n",
      "|    policy_gradient_loss | -0.0022     |\n",
      "|    reward               | 1.1899184   |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 675         |\n",
      "|    time_elapsed         | 12320       |\n",
      "|    total_timesteps      | 1382400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022745633 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 6740        |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    reward               | 3.1722524   |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 676         |\n",
      "|    time_elapsed         | 12339       |\n",
      "|    total_timesteps      | 1384448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014389465 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.49        |\n",
      "|    n_updates            | 6750        |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    reward               | -1.7601283  |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3369325.40\n",
      "total_reward: 2369325.40\n",
      "total_cost: 34820.92\n",
      "total_trades: 50633\n",
      "Sharpe: 0.702\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 677        |\n",
      "|    time_elapsed         | 12357      |\n",
      "|    total_timesteps      | 1386496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03558392 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.4      |\n",
      "|    explained_variance   | 0.712      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.9       |\n",
      "|    n_updates            | 6760       |\n",
      "|    policy_gradient_loss | -0.00314   |\n",
      "|    reward               | 0.6422713  |\n",
      "|    std                  | 2.25       |\n",
      "|    value_loss           | 25.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 678        |\n",
      "|    time_elapsed         | 12375      |\n",
      "|    total_timesteps      | 1388544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01268474 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.5      |\n",
      "|    explained_variance   | 0.66       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.3       |\n",
      "|    n_updates            | 6770       |\n",
      "|    policy_gradient_loss | -0.00182   |\n",
      "|    reward               | -2.459398  |\n",
      "|    std                  | 2.25       |\n",
      "|    value_loss           | 36         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 679         |\n",
      "|    time_elapsed         | 12393       |\n",
      "|    total_timesteps      | 1390592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007115083 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 6780        |\n",
      "|    policy_gradient_loss | -0.00152    |\n",
      "|    reward               | 0.0229644   |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 680         |\n",
      "|    time_elapsed         | 12411       |\n",
      "|    total_timesteps      | 1392640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019899506 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.98        |\n",
      "|    n_updates            | 6790        |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    reward               | -3.721985   |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 681         |\n",
      "|    time_elapsed         | 12429       |\n",
      "|    total_timesteps      | 1394688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015138687 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 6800        |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    reward               | 1.0573231   |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 682         |\n",
      "|    time_elapsed         | 12448       |\n",
      "|    total_timesteps      | 1396736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012401901 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 6810        |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | 7.5576115   |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 683         |\n",
      "|    time_elapsed         | 12466       |\n",
      "|    total_timesteps      | 1398784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018258268 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.04        |\n",
      "|    n_updates            | 6820        |\n",
      "|    policy_gradient_loss | -0.00291    |\n",
      "|    reward               | 1.4627503   |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 684         |\n",
      "|    time_elapsed         | 12484       |\n",
      "|    total_timesteps      | 1400832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010579115 |\n",
      "|    clip_fraction        | 0.0353      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.98        |\n",
      "|    n_updates            | 6830        |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | 0.13305996  |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 685         |\n",
      "|    time_elapsed         | 12502       |\n",
      "|    total_timesteps      | 1402880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012452254 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 6840        |\n",
      "|    policy_gradient_loss | -0.00267    |\n",
      "|    reward               | 0.86154526  |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 686         |\n",
      "|    time_elapsed         | 12520       |\n",
      "|    total_timesteps      | 1404928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012954673 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 6850        |\n",
      "|    policy_gradient_loss | 0.000511    |\n",
      "|    reward               | 2.3187563   |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 687         |\n",
      "|    time_elapsed         | 12540       |\n",
      "|    total_timesteps      | 1406976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016596707 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.34        |\n",
      "|    n_updates            | 6860        |\n",
      "|    policy_gradient_loss | -0.000802   |\n",
      "|    reward               | 0.45665297  |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 688        |\n",
      "|    time_elapsed         | 12558      |\n",
      "|    total_timesteps      | 1409024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01877211 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.7      |\n",
      "|    explained_variance   | 0.633      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.9       |\n",
      "|    n_updates            | 6870       |\n",
      "|    policy_gradient_loss | -0.00568   |\n",
      "|    reward               | 2.71829    |\n",
      "|    std                  | 2.27       |\n",
      "|    value_loss           | 38         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 689         |\n",
      "|    time_elapsed         | 12576       |\n",
      "|    total_timesteps      | 1411072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007396277 |\n",
      "|    clip_fraction        | 0.0383      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 6880        |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    reward               | 2.6877477   |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 42.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 690         |\n",
      "|    time_elapsed         | 12595       |\n",
      "|    total_timesteps      | 1413120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020428061 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.0957      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.38        |\n",
      "|    n_updates            | 6890        |\n",
      "|    policy_gradient_loss | 0.0034      |\n",
      "|    reward               | -0.5477384  |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3574363.73\n",
      "total_reward: 2574363.73\n",
      "total_cost: 42967.14\n",
      "total_trades: 52056\n",
      "Sharpe: 0.740\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 691         |\n",
      "|    time_elapsed         | 12615       |\n",
      "|    total_timesteps      | 1415168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007250783 |\n",
      "|    clip_fraction        | 0.0408      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 6900        |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    reward               | 0.7153018   |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 692          |\n",
      "|    time_elapsed         | 12634        |\n",
      "|    total_timesteps      | 1417216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010091811  |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.8        |\n",
      "|    explained_variance   | 0.351        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 6910         |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | 0.0064132963 |\n",
      "|    std                  | 2.27         |\n",
      "|    value_loss           | 47.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 12654       |\n",
      "|    total_timesteps      | 1419264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011436803 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 6920        |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    reward               | -3.2907813  |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 694          |\n",
      "|    time_elapsed         | 12673        |\n",
      "|    total_timesteps      | 1421312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015891965  |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.8        |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 6930         |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    reward               | -0.066247165 |\n",
      "|    std                  | 2.28         |\n",
      "|    value_loss           | 29           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 695         |\n",
      "|    time_elapsed         | 12691       |\n",
      "|    total_timesteps      | 1423360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017212698 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 6940        |\n",
      "|    policy_gradient_loss | -0.00657    |\n",
      "|    reward               | -0.01881899 |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 696         |\n",
      "|    time_elapsed         | 12709       |\n",
      "|    total_timesteps      | 1425408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009792406 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 6950        |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    reward               | -0.41542247 |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 40.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 697         |\n",
      "|    time_elapsed         | 12728       |\n",
      "|    total_timesteps      | 1427456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030557534 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.94        |\n",
      "|    n_updates            | 6960        |\n",
      "|    policy_gradient_loss | 0.00305     |\n",
      "|    reward               | -0.6163156  |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 12746       |\n",
      "|    total_timesteps      | 1429504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025728632 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 6970        |\n",
      "|    policy_gradient_loss | -0.00156    |\n",
      "|    reward               | 0.81422526  |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 699         |\n",
      "|    time_elapsed         | 12765       |\n",
      "|    total_timesteps      | 1431552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013884198 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 6980        |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    reward               | 0.81627005  |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 700          |\n",
      "|    time_elapsed         | 12783        |\n",
      "|    total_timesteps      | 1433600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055237943 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.9        |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 6990         |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    reward               | -2.2563918   |\n",
      "|    std                  | 2.28         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 701         |\n",
      "|    time_elapsed         | 12802       |\n",
      "|    total_timesteps      | 1435648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022143545 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.09        |\n",
      "|    n_updates            | 7000        |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | -3.7040215  |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 702         |\n",
      "|    time_elapsed         | 12821       |\n",
      "|    total_timesteps      | 1437696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010830829 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65         |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 7010        |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    reward               | 0.28407925  |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 703         |\n",
      "|    time_elapsed         | 12839       |\n",
      "|    total_timesteps      | 1439744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006847513 |\n",
      "|    clip_fraction        | 0.0381      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65         |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 7020        |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    reward               | 0.7157408   |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 704        |\n",
      "|    time_elapsed         | 12858      |\n",
      "|    total_timesteps      | 1441792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02646422 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65        |\n",
      "|    explained_variance   | 0.733      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.17       |\n",
      "|    n_updates            | 7030       |\n",
      "|    policy_gradient_loss | 0.00193    |\n",
      "|    reward               | 0.8659136  |\n",
      "|    std                  | 2.3        |\n",
      "|    value_loss           | 19.5       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3660999.15\n",
      "total_reward: 2660999.15\n",
      "total_cost: 45244.13\n",
      "total_trades: 52688\n",
      "Sharpe: 0.731\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 705         |\n",
      "|    time_elapsed         | 12876       |\n",
      "|    total_timesteps      | 1443840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013274716 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 7040        |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | 1.1704005   |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 706         |\n",
      "|    time_elapsed         | 12894       |\n",
      "|    total_timesteps      | 1445888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012098275 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 7050        |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | 5.623509    |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 707        |\n",
      "|    time_elapsed         | 12912      |\n",
      "|    total_timesteps      | 1447936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01988495 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.1      |\n",
      "|    explained_variance   | 0.664      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.8        |\n",
      "|    n_updates            | 7060       |\n",
      "|    policy_gradient_loss | 0.000332   |\n",
      "|    reward               | 0.6781999  |\n",
      "|    std                  | 2.3        |\n",
      "|    value_loss           | 19.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 708         |\n",
      "|    time_elapsed         | 12931       |\n",
      "|    total_timesteps      | 1449984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009324164 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 7070        |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | 0.47358525  |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 709         |\n",
      "|    time_elapsed         | 12950       |\n",
      "|    total_timesteps      | 1452032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008995449 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 7080        |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    reward               | -3.3315213  |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 39.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 710          |\n",
      "|    time_elapsed         | 12968        |\n",
      "|    total_timesteps      | 1454080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063535003 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -65.1        |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.77         |\n",
      "|    n_updates            | 7090         |\n",
      "|    policy_gradient_loss | 0.000147     |\n",
      "|    reward               | 1.3410572    |\n",
      "|    std                  | 2.3          |\n",
      "|    value_loss           | 28.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 711        |\n",
      "|    time_elapsed         | 12986      |\n",
      "|    total_timesteps      | 1456128    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.017028   |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.2      |\n",
      "|    explained_variance   | 0.689      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.5       |\n",
      "|    n_updates            | 7100       |\n",
      "|    policy_gradient_loss | -0.00281   |\n",
      "|    reward               | -0.4390913 |\n",
      "|    std                  | 2.3        |\n",
      "|    value_loss           | 18.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 712         |\n",
      "|    time_elapsed         | 13005       |\n",
      "|    total_timesteps      | 1458176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022495214 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 7110        |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    reward               | -0.14044392 |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 713         |\n",
      "|    time_elapsed         | 13023       |\n",
      "|    total_timesteps      | 1460224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020045996 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 7120        |\n",
      "|    policy_gradient_loss | 0.00146     |\n",
      "|    reward               | -2.8402052  |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 41.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 13041       |\n",
      "|    total_timesteps      | 1462272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013149368 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 7130        |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    reward               | -0.37221745 |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 715        |\n",
      "|    time_elapsed         | 13060      |\n",
      "|    total_timesteps      | 1464320    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02449003 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.2      |\n",
      "|    explained_variance   | 0.682      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.5       |\n",
      "|    n_updates            | 7140       |\n",
      "|    policy_gradient_loss | -0.00663   |\n",
      "|    reward               | 0.20985477 |\n",
      "|    std                  | 2.31       |\n",
      "|    value_loss           | 28.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 716        |\n",
      "|    time_elapsed         | 13078      |\n",
      "|    total_timesteps      | 1466368    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0081781  |\n",
      "|    clip_fraction        | 0.0548     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.3      |\n",
      "|    explained_variance   | 0.63       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.5       |\n",
      "|    n_updates            | 7150       |\n",
      "|    policy_gradient_loss | -0.00576   |\n",
      "|    reward               | -0.5128818 |\n",
      "|    std                  | 2.31       |\n",
      "|    value_loss           | 30.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 717         |\n",
      "|    time_elapsed         | 13096       |\n",
      "|    total_timesteps      | 1468416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014572542 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.38        |\n",
      "|    n_updates            | 7160        |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    reward               | 0.6984033   |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 718         |\n",
      "|    time_elapsed         | 13115       |\n",
      "|    total_timesteps      | 1470464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019561848 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.44        |\n",
      "|    n_updates            | 7170        |\n",
      "|    policy_gradient_loss | -0.00523    |\n",
      "|    reward               | -1.0940392  |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 719         |\n",
      "|    time_elapsed         | 13134       |\n",
      "|    total_timesteps      | 1472512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030964883 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 7180        |\n",
      "|    policy_gradient_loss | -0.000567   |\n",
      "|    reward               | 0.79265654  |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3464472.97\n",
      "total_reward: 2464472.97\n",
      "total_cost: 44140.17\n",
      "total_trades: 52151\n",
      "Sharpe: 0.729\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 720          |\n",
      "|    time_elapsed         | 13152        |\n",
      "|    total_timesteps      | 1474560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117737595 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -65.4        |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 7190         |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | 0.60664314   |\n",
      "|    std                  | 2.32         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 721         |\n",
      "|    time_elapsed         | 13171       |\n",
      "|    total_timesteps      | 1476608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020464756 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.42        |\n",
      "|    n_updates            | 7200        |\n",
      "|    policy_gradient_loss | 0.00427     |\n",
      "|    reward               | 0.7822157   |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 722        |\n",
      "|    time_elapsed         | 13189      |\n",
      "|    total_timesteps      | 1478656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02262317 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.4      |\n",
      "|    explained_variance   | 0.43       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.5       |\n",
      "|    n_updates            | 7210       |\n",
      "|    policy_gradient_loss | 0.00209    |\n",
      "|    reward               | -1.9006238 |\n",
      "|    std                  | 2.32       |\n",
      "|    value_loss           | 35.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 723          |\n",
      "|    time_elapsed         | 13208        |\n",
      "|    total_timesteps      | 1480704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0125498865 |\n",
      "|    clip_fraction        | 0.171        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -65.4        |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 7220         |\n",
      "|    policy_gradient_loss | -0.0087      |\n",
      "|    reward               | 2.6395826    |\n",
      "|    std                  | 2.33         |\n",
      "|    value_loss           | 33.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 724         |\n",
      "|    time_elapsed         | 13226       |\n",
      "|    total_timesteps      | 1482752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020581901 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.87        |\n",
      "|    n_updates            | 7230        |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    reward               | 1.1548252   |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 725         |\n",
      "|    time_elapsed         | 13245       |\n",
      "|    total_timesteps      | 1484800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011419934 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 7240        |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | 0.93313366  |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 726          |\n",
      "|    time_elapsed         | 13263        |\n",
      "|    total_timesteps      | 1486848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016726602  |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -65.5        |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 7250         |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    reward               | -0.023488441 |\n",
      "|    std                  | 2.33         |\n",
      "|    value_loss           | 31.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 727         |\n",
      "|    time_elapsed         | 13282       |\n",
      "|    total_timesteps      | 1488896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021500682 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 7260        |\n",
      "|    policy_gradient_loss | -0.00146    |\n",
      "|    reward               | 0.17769456  |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 728         |\n",
      "|    time_elapsed         | 13301       |\n",
      "|    total_timesteps      | 1490944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014996605 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.88        |\n",
      "|    n_updates            | 7270        |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | -0.462717   |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 729         |\n",
      "|    time_elapsed         | 13319       |\n",
      "|    total_timesteps      | 1492992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021959255 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 7280        |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    reward               | -1.072085   |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 730          |\n",
      "|    time_elapsed         | 13338        |\n",
      "|    total_timesteps      | 1495040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122657865 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -65.6        |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 7290         |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    reward               | 3.377274     |\n",
      "|    std                  | 2.34         |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 731         |\n",
      "|    time_elapsed         | 13356       |\n",
      "|    total_timesteps      | 1497088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015478723 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.02        |\n",
      "|    n_updates            | 7300        |\n",
      "|    policy_gradient_loss | 0.000914    |\n",
      "|    reward               | 1.8549229   |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 732         |\n",
      "|    time_elapsed         | 13375       |\n",
      "|    total_timesteps      | 1499136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013012527 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.14        |\n",
      "|    n_updates            | 7310        |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    reward               | 0.3893509   |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 733         |\n",
      "|    time_elapsed         | 13393       |\n",
      "|    total_timesteps      | 1501184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017074332 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 7320        |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    reward               | 0.95403135  |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3450256.04\n",
      "total_reward: 2450256.04\n",
      "total_cost: 41090.61\n",
      "total_trades: 52613\n",
      "Sharpe: 0.711\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 734         |\n",
      "|    time_elapsed         | 13412       |\n",
      "|    total_timesteps      | 1503232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018806163 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 7330        |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    reward               | -2.5305543  |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 735         |\n",
      "|    time_elapsed         | 13430       |\n",
      "|    total_timesteps      | 1505280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015356371 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.73        |\n",
      "|    n_updates            | 7340        |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    reward               | -0.6160007  |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 736         |\n",
      "|    time_elapsed         | 13448       |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022608131 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 7350        |\n",
      "|    policy_gradient_loss | 0.00351     |\n",
      "|    reward               | -0.4940004  |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 737          |\n",
      "|    time_elapsed         | 13467        |\n",
      "|    total_timesteps      | 1509376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134967165 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -65.8        |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 7360         |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    reward               | 2.241931     |\n",
      "|    std                  | 2.35         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 738         |\n",
      "|    time_elapsed         | 13485       |\n",
      "|    total_timesteps      | 1511424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017308444 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.8       |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.55        |\n",
      "|    n_updates            | 7370        |\n",
      "|    policy_gradient_loss | -0.0051     |\n",
      "|    reward               | -2.0494153  |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 739         |\n",
      "|    time_elapsed         | 13504       |\n",
      "|    total_timesteps      | 1513472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011867078 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 7380        |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    reward               | -0.7655718  |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 740         |\n",
      "|    time_elapsed         | 13523       |\n",
      "|    total_timesteps      | 1515520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015912605 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 7390        |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | 1.2660614   |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 741         |\n",
      "|    time_elapsed         | 13543       |\n",
      "|    total_timesteps      | 1517568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022690695 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 7400        |\n",
      "|    policy_gradient_loss | 5.05e-05    |\n",
      "|    reward               | -0.66546947 |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 742         |\n",
      "|    time_elapsed         | 13562       |\n",
      "|    total_timesteps      | 1519616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025855295 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.77        |\n",
      "|    n_updates            | 7410        |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    reward               | 0.14127722  |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 743         |\n",
      "|    time_elapsed         | 13581       |\n",
      "|    total_timesteps      | 1521664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008021845 |\n",
      "|    clip_fraction        | 0.0296      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 7420        |\n",
      "|    policy_gradient_loss | -0.00166    |\n",
      "|    reward               | 4.0352354   |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 744         |\n",
      "|    time_elapsed         | 13599       |\n",
      "|    total_timesteps      | 1523712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011676451 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 7430        |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | 1.3141181   |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 745         |\n",
      "|    time_elapsed         | 13617       |\n",
      "|    total_timesteps      | 1525760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035012983 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.64        |\n",
      "|    n_updates            | 7440        |\n",
      "|    policy_gradient_loss | 0.00132     |\n",
      "|    reward               | 0.7330689   |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 746         |\n",
      "|    time_elapsed         | 13636       |\n",
      "|    total_timesteps      | 1527808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012293041 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 7450        |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    reward               | -0.23236834 |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 747          |\n",
      "|    time_elapsed         | 13655        |\n",
      "|    total_timesteps      | 1529856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063865855 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.2        |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 7460         |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    reward               | -2.1654172   |\n",
      "|    std                  | 2.39         |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3299592.43\n",
      "total_reward: 2299592.43\n",
      "total_cost: 33099.55\n",
      "total_trades: 50098\n",
      "Sharpe: 0.698\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 748         |\n",
      "|    time_elapsed         | 13674       |\n",
      "|    total_timesteps      | 1531904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018955784 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.5         |\n",
      "|    n_updates            | 7470        |\n",
      "|    policy_gradient_loss | 0.00119     |\n",
      "|    reward               | 0.5113944   |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 749         |\n",
      "|    time_elapsed         | 13693       |\n",
      "|    total_timesteps      | 1533952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015089746 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.61        |\n",
      "|    n_updates            | 7480        |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    reward               | -2.1788063  |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 750         |\n",
      "|    time_elapsed         | 13711       |\n",
      "|    total_timesteps      | 1536000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008927172 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.3       |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 7490        |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    reward               | -5.8007946  |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 751         |\n",
      "|    time_elapsed         | 13729       |\n",
      "|    total_timesteps      | 1538048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009876913 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.3       |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.81        |\n",
      "|    n_updates            | 7500        |\n",
      "|    policy_gradient_loss | -0.000147   |\n",
      "|    reward               | 0.20710014  |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 752         |\n",
      "|    time_elapsed         | 13749       |\n",
      "|    total_timesteps      | 1540096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026763028 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.3       |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.58        |\n",
      "|    n_updates            | 7510        |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    reward               | 0.13574588  |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 753         |\n",
      "|    time_elapsed         | 13768       |\n",
      "|    total_timesteps      | 1542144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015795056 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.3       |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 7520        |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    reward               | 0.2736964   |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 754         |\n",
      "|    time_elapsed         | 13786       |\n",
      "|    total_timesteps      | 1544192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016603213 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.4       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 7530        |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    reward               | -1.3380697  |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 755         |\n",
      "|    time_elapsed         | 13805       |\n",
      "|    total_timesteps      | 1546240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015067148 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.4       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.94        |\n",
      "|    n_updates            | 7540        |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    reward               | 2.481553    |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 756         |\n",
      "|    time_elapsed         | 13823       |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007788431 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.4       |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 7550        |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | -0.09895108 |\n",
      "|    std                  | 2.41        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 757         |\n",
      "|    time_elapsed         | 13841       |\n",
      "|    total_timesteps      | 1550336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006643364 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.4       |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 7560        |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    reward               | 1.3647761   |\n",
      "|    std                  | 2.41        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 758         |\n",
      "|    time_elapsed         | 13859       |\n",
      "|    total_timesteps      | 1552384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009157481 |\n",
      "|    clip_fraction        | 0.022       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.5       |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.87        |\n",
      "|    n_updates            | 7570        |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    reward               | -1.5194101  |\n",
      "|    std                  | 2.41        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 759        |\n",
      "|    time_elapsed         | 13879      |\n",
      "|    total_timesteps      | 1554432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01463347 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.5      |\n",
      "|    explained_variance   | 0.657      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.84       |\n",
      "|    n_updates            | 7580       |\n",
      "|    policy_gradient_loss | 4.71e-05   |\n",
      "|    reward               | 1.1350515  |\n",
      "|    std                  | 2.41       |\n",
      "|    value_loss           | 17.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 760         |\n",
      "|    time_elapsed         | 13898       |\n",
      "|    total_timesteps      | 1556480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008289631 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.5       |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 7590        |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    reward               | 0.20426913  |\n",
      "|    std                  | 2.41        |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 761          |\n",
      "|    time_elapsed         | 13917        |\n",
      "|    total_timesteps      | 1558528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027282378 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.5        |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10           |\n",
      "|    n_updates            | 7600         |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | -0.70995075  |\n",
      "|    std                  | 2.41         |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3189663.65\n",
      "total_reward: 2189663.65\n",
      "total_cost: 29459.71\n",
      "total_trades: 50187\n",
      "Sharpe: 0.668\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 762         |\n",
      "|    time_elapsed         | 13935       |\n",
      "|    total_timesteps      | 1560576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013749751 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.6       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.61        |\n",
      "|    n_updates            | 7610        |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | 4.0377336   |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 763        |\n",
      "|    time_elapsed         | 13953      |\n",
      "|    total_timesteps      | 1562624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01699175 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.7      |\n",
      "|    explained_variance   | 0.589      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.8       |\n",
      "|    n_updates            | 7620       |\n",
      "|    policy_gradient_loss | -0.00949   |\n",
      "|    reward               | -2.3744912 |\n",
      "|    std                  | 2.43       |\n",
      "|    value_loss           | 35.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 764         |\n",
      "|    time_elapsed         | 13971       |\n",
      "|    total_timesteps      | 1564672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010330718 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 7630        |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    reward               | -0.11942802 |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 765         |\n",
      "|    time_elapsed         | 13989       |\n",
      "|    total_timesteps      | 1566720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014845977 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.53        |\n",
      "|    n_updates            | 7640        |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    reward               | -2.3517418  |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 766         |\n",
      "|    time_elapsed         | 14008       |\n",
      "|    total_timesteps      | 1568768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014810664 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 7650        |\n",
      "|    policy_gradient_loss | -0.000456   |\n",
      "|    reward               | 0.03893694  |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 767          |\n",
      "|    time_elapsed         | 14026        |\n",
      "|    total_timesteps      | 1570816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028830958 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.7        |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 7660         |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    reward               | 18.962555    |\n",
      "|    std                  | 2.43         |\n",
      "|    value_loss           | 37.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 768          |\n",
      "|    time_elapsed         | 14044        |\n",
      "|    total_timesteps      | 1572864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048308717 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.7        |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 7670         |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    reward               | -3.0367975   |\n",
      "|    std                  | 2.43         |\n",
      "|    value_loss           | 28.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 769         |\n",
      "|    time_elapsed         | 14063       |\n",
      "|    total_timesteps      | 1574912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020067582 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.32        |\n",
      "|    n_updates            | 7680        |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    reward               | 0.64956933  |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 770         |\n",
      "|    time_elapsed         | 14081       |\n",
      "|    total_timesteps      | 1576960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009236141 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.8       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 7690        |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    reward               | 0.31707874  |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 771         |\n",
      "|    time_elapsed         | 14100       |\n",
      "|    total_timesteps      | 1579008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014918328 |\n",
      "|    clip_fraction        | 0.0501      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.8       |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 7700        |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    reward               | -0.39784017 |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 772         |\n",
      "|    time_elapsed         | 14119       |\n",
      "|    total_timesteps      | 1581056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016007908 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.8       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.14        |\n",
      "|    n_updates            | 7710        |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    reward               | -1.8130596  |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 773         |\n",
      "|    time_elapsed         | 14138       |\n",
      "|    total_timesteps      | 1583104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036221504 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.35        |\n",
      "|    n_updates            | 7720        |\n",
      "|    policy_gradient_loss | -0.0037     |\n",
      "|    reward               | -0.6908071  |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 774         |\n",
      "|    time_elapsed         | 14158       |\n",
      "|    total_timesteps      | 1585152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015310016 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 7730        |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    reward               | -2.2746866  |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 31.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 775         |\n",
      "|    time_elapsed         | 14176       |\n",
      "|    total_timesteps      | 1587200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016630683 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 7740        |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    reward               | 1.904512    |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3334348.47\n",
      "total_reward: 2334348.47\n",
      "total_cost: 25426.79\n",
      "total_trades: 48679\n",
      "Sharpe: 0.687\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 776         |\n",
      "|    time_elapsed         | 14195       |\n",
      "|    total_timesteps      | 1589248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014244313 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.77        |\n",
      "|    n_updates            | 7750        |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | 0.26204944  |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 777         |\n",
      "|    time_elapsed         | 14214       |\n",
      "|    total_timesteps      | 1591296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013862742 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 7760        |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    reward               | 0.4576001   |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 778         |\n",
      "|    time_elapsed         | 14232       |\n",
      "|    total_timesteps      | 1593344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015924571 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 7770        |\n",
      "|    policy_gradient_loss | 0.00177     |\n",
      "|    reward               | -4.3376884  |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 779         |\n",
      "|    time_elapsed         | 14250       |\n",
      "|    total_timesteps      | 1595392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022515705 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.82        |\n",
      "|    n_updates            | 7780        |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | -0.32931072 |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 780         |\n",
      "|    time_elapsed         | 14269       |\n",
      "|    total_timesteps      | 1597440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011262762 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 7790        |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    reward               | 1.6536988   |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 781          |\n",
      "|    time_elapsed         | 14287        |\n",
      "|    total_timesteps      | 1599488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020693627 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -67          |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 7800         |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    reward               | 1.1588672    |\n",
      "|    std                  | 2.45         |\n",
      "|    value_loss           | 33.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 782         |\n",
      "|    time_elapsed         | 14306       |\n",
      "|    total_timesteps      | 1601536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028220627 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.89        |\n",
      "|    n_updates            | 7810        |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    reward               | -1.718869   |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 783         |\n",
      "|    time_elapsed         | 14324       |\n",
      "|    total_timesteps      | 1603584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018201236 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.1       |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.76        |\n",
      "|    n_updates            | 7820        |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    reward               | -0.09148466 |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 784         |\n",
      "|    time_elapsed         | 14342       |\n",
      "|    total_timesteps      | 1605632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013555786 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.1       |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 7830        |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    reward               | 0.57648283  |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 785         |\n",
      "|    time_elapsed         | 14360       |\n",
      "|    total_timesteps      | 1607680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013112854 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.1       |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 7840        |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    reward               | -0.8680665  |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 786         |\n",
      "|    time_elapsed         | 14378       |\n",
      "|    total_timesteps      | 1609728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026030574 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.95        |\n",
      "|    n_updates            | 7850        |\n",
      "|    policy_gradient_loss | 0.00469     |\n",
      "|    reward               | 0.40424255  |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 787         |\n",
      "|    time_elapsed         | 14397       |\n",
      "|    total_timesteps      | 1611776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020643096 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 7860        |\n",
      "|    policy_gradient_loss | -0.00061    |\n",
      "|    reward               | -0.5875429  |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 788         |\n",
      "|    time_elapsed         | 14416       |\n",
      "|    total_timesteps      | 1613824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011043331 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.3       |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 7870        |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    reward               | 4.1483774   |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 789         |\n",
      "|    time_elapsed         | 14435       |\n",
      "|    total_timesteps      | 1615872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013494179 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.3       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.56        |\n",
      "|    n_updates            | 7880        |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    reward               | -2.9699364  |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3355425.80\n",
      "total_reward: 2355425.80\n",
      "total_cost: 32049.79\n",
      "total_trades: 49404\n",
      "Sharpe: 0.710\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 790         |\n",
      "|    time_elapsed         | 14455       |\n",
      "|    total_timesteps      | 1617920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017641678 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.95        |\n",
      "|    n_updates            | 7890        |\n",
      "|    policy_gradient_loss | -0.000511   |\n",
      "|    reward               | 0.64769596  |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 791         |\n",
      "|    time_elapsed         | 14474       |\n",
      "|    total_timesteps      | 1619968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012144489 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.65        |\n",
      "|    n_updates            | 7900        |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    reward               | -2.4170187  |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 792          |\n",
      "|    time_elapsed         | 14493        |\n",
      "|    total_timesteps      | 1622016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056407456 |\n",
      "|    clip_fraction        | 0.0278       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -67.4        |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 7910         |\n",
      "|    policy_gradient_loss | -0.00479     |\n",
      "|    reward               | 1.869575     |\n",
      "|    std                  | 2.49         |\n",
      "|    value_loss           | 27.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 793        |\n",
      "|    time_elapsed         | 14512      |\n",
      "|    total_timesteps      | 1624064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01341489 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.4      |\n",
      "|    explained_variance   | 0.612      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.64       |\n",
      "|    n_updates            | 7920       |\n",
      "|    policy_gradient_loss | -0.00683   |\n",
      "|    reward               | -2.0304198 |\n",
      "|    std                  | 2.49       |\n",
      "|    value_loss           | 14.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 794         |\n",
      "|    time_elapsed         | 14531       |\n",
      "|    total_timesteps      | 1626112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014744863 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.5         |\n",
      "|    n_updates            | 7930        |\n",
      "|    policy_gradient_loss | -0.00654    |\n",
      "|    reward               | 0.01155996  |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 795         |\n",
      "|    time_elapsed         | 14550       |\n",
      "|    total_timesteps      | 1628160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012058711 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 7940        |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    reward               | -0.6940727  |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 796        |\n",
      "|    time_elapsed         | 14568      |\n",
      "|    total_timesteps      | 1630208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01763559 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.4      |\n",
      "|    explained_variance   | 0.688      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.85       |\n",
      "|    n_updates            | 7950       |\n",
      "|    policy_gradient_loss | 0.00148    |\n",
      "|    reward               | -0.5035471 |\n",
      "|    std                  | 2.49       |\n",
      "|    value_loss           | 17.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 797         |\n",
      "|    time_elapsed         | 14587       |\n",
      "|    total_timesteps      | 1632256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016017957 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.5       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.16        |\n",
      "|    n_updates            | 7960        |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    reward               | -0.35055342 |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 798         |\n",
      "|    time_elapsed         | 14607       |\n",
      "|    total_timesteps      | 1634304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013725591 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.5       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 7970        |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    reward               | 0.4862584   |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 799         |\n",
      "|    time_elapsed         | 14625       |\n",
      "|    total_timesteps      | 1636352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014409434 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.5       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 7980        |\n",
      "|    policy_gradient_loss | -0.000756   |\n",
      "|    reward               | 1.249329    |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 800         |\n",
      "|    time_elapsed         | 14643       |\n",
      "|    total_timesteps      | 1638400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012030207 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 7990        |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | 0.74169034  |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 801         |\n",
      "|    time_elapsed         | 14661       |\n",
      "|    total_timesteps      | 1640448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014293073 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 8000        |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    reward               | -1.007129   |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 802       |\n",
      "|    time_elapsed         | 14679     |\n",
      "|    total_timesteps      | 1642496   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0106642 |\n",
      "|    clip_fraction        | 0.108     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -67.7     |\n",
      "|    explained_variance   | 0.737     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 11.7      |\n",
      "|    n_updates            | 8010      |\n",
      "|    policy_gradient_loss | -0.00369  |\n",
      "|    reward               | 2.1196418 |\n",
      "|    std                  | 2.51      |\n",
      "|    value_loss           | 25.2      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 803         |\n",
      "|    time_elapsed         | 14697       |\n",
      "|    total_timesteps      | 1644544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019895418 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.61        |\n",
      "|    n_updates            | 8020        |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | 0.36996868  |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3557779.62\n",
      "total_reward: 2557779.62\n",
      "total_cost: 33692.42\n",
      "total_trades: 50406\n",
      "Sharpe: 0.746\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 804         |\n",
      "|    time_elapsed         | 14715       |\n",
      "|    total_timesteps      | 1646592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027123211 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.44        |\n",
      "|    n_updates            | 8030        |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    reward               | 0.9512887   |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 805         |\n",
      "|    time_elapsed         | 14734       |\n",
      "|    total_timesteps      | 1648640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010303148 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 8040        |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | 0.08561517  |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 806         |\n",
      "|    time_elapsed         | 14752       |\n",
      "|    total_timesteps      | 1650688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005729627 |\n",
      "|    clip_fraction        | 0.0259      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.88        |\n",
      "|    n_updates            | 8050        |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    reward               | 2.6020334   |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 807         |\n",
      "|    time_elapsed         | 14771       |\n",
      "|    total_timesteps      | 1652736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019487564 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.05        |\n",
      "|    n_updates            | 8060        |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    reward               | 0.65348047  |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 808        |\n",
      "|    time_elapsed         | 14790      |\n",
      "|    total_timesteps      | 1654784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0104461  |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.8      |\n",
      "|    explained_variance   | 0.756      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.5       |\n",
      "|    n_updates            | 8070       |\n",
      "|    policy_gradient_loss | -0.00402   |\n",
      "|    reward               | -2.1276426 |\n",
      "|    std                  | 2.52       |\n",
      "|    value_loss           | 28.9       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 809          |\n",
      "|    time_elapsed         | 14808        |\n",
      "|    total_timesteps      | 1656832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066509717 |\n",
      "|    clip_fraction        | 0.061        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -67.8        |\n",
      "|    explained_variance   | 0.75         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 8080         |\n",
      "|    policy_gradient_loss | -0.00503     |\n",
      "|    reward               | 0.1610478    |\n",
      "|    std                  | 2.53         |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 810          |\n",
      "|    time_elapsed         | 14826        |\n",
      "|    total_timesteps      | 1658880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.024007592  |\n",
      "|    clip_fraction        | 0.313        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -67.9        |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.52         |\n",
      "|    n_updates            | 8090         |\n",
      "|    policy_gradient_loss | -0.000397    |\n",
      "|    reward               | -0.090579495 |\n",
      "|    std                  | 2.53         |\n",
      "|    value_loss           | 12.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 811         |\n",
      "|    time_elapsed         | 14844       |\n",
      "|    total_timesteps      | 1660928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010909269 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.03        |\n",
      "|    n_updates            | 8100        |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    reward               | -0.84045243 |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 812         |\n",
      "|    time_elapsed         | 14862       |\n",
      "|    total_timesteps      | 1662976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005259739 |\n",
      "|    clip_fraction        | 0.0122      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 8110        |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    reward               | 0.6914587   |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 813         |\n",
      "|    time_elapsed         | 14891       |\n",
      "|    total_timesteps      | 1665024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019025011 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 8120        |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    reward               | 1.4097764   |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 814         |\n",
      "|    time_elapsed         | 14909       |\n",
      "|    total_timesteps      | 1667072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019888993 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.54        |\n",
      "|    n_updates            | 8130        |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    reward               | 1.3784688   |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 815         |\n",
      "|    time_elapsed         | 14929       |\n",
      "|    total_timesteps      | 1669120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011756314 |\n",
      "|    clip_fraction        | 0.0623      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 8140        |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    reward               | 0.2749946   |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 816         |\n",
      "|    time_elapsed         | 14947       |\n",
      "|    total_timesteps      | 1671168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013171566 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 8150        |\n",
      "|    policy_gradient_loss | 0.00116     |\n",
      "|    reward               | 0.36914188  |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 817         |\n",
      "|    time_elapsed         | 14965       |\n",
      "|    total_timesteps      | 1673216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024209287 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.19        |\n",
      "|    n_updates            | 8160        |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    reward               | 0.07915814  |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3333037.32\n",
      "total_reward: 2333037.32\n",
      "total_cost: 77512.62\n",
      "total_trades: 57032\n",
      "Sharpe: 0.709\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 818         |\n",
      "|    time_elapsed         | 14984       |\n",
      "|    total_timesteps      | 1675264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015300195 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 8170        |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    reward               | 0.8675445   |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 819        |\n",
      "|    time_elapsed         | 15001      |\n",
      "|    total_timesteps      | 1677312    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01298989 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68        |\n",
      "|    explained_variance   | 0.64       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.2       |\n",
      "|    n_updates            | 8180       |\n",
      "|    policy_gradient_loss | -0.00598   |\n",
      "|    reward               | -1.023726  |\n",
      "|    std                  | 2.54       |\n",
      "|    value_loss           | 32.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 820         |\n",
      "|    time_elapsed         | 15020       |\n",
      "|    total_timesteps      | 1679360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024571905 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.86        |\n",
      "|    n_updates            | 8190        |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    reward               | -0.2502665  |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 821          |\n",
      "|    time_elapsed         | 15039        |\n",
      "|    total_timesteps      | 1681408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065226248 |\n",
      "|    clip_fraction        | 0.0514       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.1        |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 8200         |\n",
      "|    policy_gradient_loss | -0.00557     |\n",
      "|    reward               | 0.020254405  |\n",
      "|    std                  | 2.55         |\n",
      "|    value_loss           | 28.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 822          |\n",
      "|    time_elapsed         | 15058        |\n",
      "|    total_timesteps      | 1683456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039423117 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.1        |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 8210         |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    reward               | 5.1164894    |\n",
      "|    std                  | 2.55         |\n",
      "|    value_loss           | 51.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 823         |\n",
      "|    time_elapsed         | 15077       |\n",
      "|    total_timesteps      | 1685504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018668283 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 8220        |\n",
      "|    policy_gradient_loss | -0.00173    |\n",
      "|    reward               | 2.2240217   |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 824         |\n",
      "|    time_elapsed         | 15095       |\n",
      "|    total_timesteps      | 1687552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004689694 |\n",
      "|    clip_fraction        | 0.0184      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 8230        |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    reward               | -0.9745852  |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 825         |\n",
      "|    time_elapsed         | 15114       |\n",
      "|    total_timesteps      | 1689600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009791555 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 8240        |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    reward               | -0.48359862 |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 36.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 826         |\n",
      "|    time_elapsed         | 15133       |\n",
      "|    total_timesteps      | 1691648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010248788 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 8250        |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | -2.315041   |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 827         |\n",
      "|    time_elapsed         | 15152       |\n",
      "|    total_timesteps      | 1693696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022661403 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.2       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.4         |\n",
      "|    n_updates            | 8260        |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    reward               | 1.4515196   |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 828         |\n",
      "|    time_elapsed         | 15171       |\n",
      "|    total_timesteps      | 1695744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018201983 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.2       |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 8270        |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    reward               | -0.13784106 |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 829          |\n",
      "|    time_elapsed         | 15189        |\n",
      "|    total_timesteps      | 1697792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070715193 |\n",
      "|    clip_fraction        | 0.0501       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.3        |\n",
      "|    explained_variance   | 0.362        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 8280         |\n",
      "|    policy_gradient_loss | -0.000538    |\n",
      "|    reward               | 7.1945686    |\n",
      "|    std                  | 2.56         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 830         |\n",
      "|    time_elapsed         | 15207       |\n",
      "|    total_timesteps      | 1699840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017213106 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.61        |\n",
      "|    n_updates            | 8290        |\n",
      "|    policy_gradient_loss | 0.000176    |\n",
      "|    reward               | 0.034950722 |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 831        |\n",
      "|    time_elapsed         | 15226      |\n",
      "|    total_timesteps      | 1701888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02946643 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.3      |\n",
      "|    explained_variance   | 0.63       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.64       |\n",
      "|    n_updates            | 8300       |\n",
      "|    policy_gradient_loss | 0.000481   |\n",
      "|    reward               | 0.81175077 |\n",
      "|    std                  | 2.57       |\n",
      "|    value_loss           | 18.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 832         |\n",
      "|    time_elapsed         | 15244       |\n",
      "|    total_timesteps      | 1703936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01448187  |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 8310        |\n",
      "|    policy_gradient_loss | 0.00128     |\n",
      "|    reward               | -0.04850954 |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3373331.62\n",
      "total_reward: 2373331.62\n",
      "total_cost: 45755.96\n",
      "total_trades: 53687\n",
      "Sharpe: 0.718\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 833          |\n",
      "|    time_elapsed         | 15263        |\n",
      "|    total_timesteps      | 1705984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068573738 |\n",
      "|    clip_fraction        | 0.0392       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.4        |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 8320         |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | -0.78274673  |\n",
      "|    std                  | 2.57         |\n",
      "|    value_loss           | 31.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 834         |\n",
      "|    time_elapsed         | 15281       |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019560153 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.71        |\n",
      "|    n_updates            | 8330        |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    reward               | -2.5072334  |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 835        |\n",
      "|    time_elapsed         | 15299      |\n",
      "|    total_timesteps      | 1710080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01022708 |\n",
      "|    clip_fraction        | 0.0823     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.5      |\n",
      "|    explained_variance   | 0.376      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.5       |\n",
      "|    n_updates            | 8340       |\n",
      "|    policy_gradient_loss | -0.00255   |\n",
      "|    reward               | 0.40934753 |\n",
      "|    std                  | 2.58       |\n",
      "|    value_loss           | 29.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 836         |\n",
      "|    time_elapsed         | 15319       |\n",
      "|    total_timesteps      | 1712128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009021215 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.94        |\n",
      "|    n_updates            | 8350        |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | 0.25160977  |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 837         |\n",
      "|    time_elapsed         | 15337       |\n",
      "|    total_timesteps      | 1714176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017533649 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.59        |\n",
      "|    n_updates            | 8360        |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    reward               | 2.3402483   |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 838         |\n",
      "|    time_elapsed         | 15355       |\n",
      "|    total_timesteps      | 1716224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014447936 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 8370        |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    reward               | 1.6574106   |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 839          |\n",
      "|    time_elapsed         | 15373        |\n",
      "|    total_timesteps      | 1718272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076820506 |\n",
      "|    clip_fraction        | 0.0384       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.6        |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.85         |\n",
      "|    n_updates            | 8380         |\n",
      "|    policy_gradient_loss | -0.00676     |\n",
      "|    reward               | 1.6424396    |\n",
      "|    std                  | 2.59         |\n",
      "|    value_loss           | 31.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 840         |\n",
      "|    time_elapsed         | 15392       |\n",
      "|    total_timesteps      | 1720320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008774657 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 8390        |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    reward               | 2.0709012   |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 841         |\n",
      "|    time_elapsed         | 15410       |\n",
      "|    total_timesteps      | 1722368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024116572 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.57        |\n",
      "|    n_updates            | 8400        |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    reward               | -0.11389814 |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 12.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 842         |\n",
      "|    time_elapsed         | 15428       |\n",
      "|    total_timesteps      | 1724416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018011518 |\n",
      "|    clip_fraction        | 0.077       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.63        |\n",
      "|    n_updates            | 8410        |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    reward               | -1.2778202  |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 843          |\n",
      "|    time_elapsed         | 15446        |\n",
      "|    total_timesteps      | 1726464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087020565 |\n",
      "|    clip_fraction        | 0.0912       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.7        |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.5         |\n",
      "|    n_updates            | 8420         |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    reward               | -1.7407979   |\n",
      "|    std                  | 2.6          |\n",
      "|    value_loss           | 35.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 844         |\n",
      "|    time_elapsed         | 15465       |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032467045 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.7       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.25        |\n",
      "|    n_updates            | 8430        |\n",
      "|    policy_gradient_loss | -0.000109   |\n",
      "|    reward               | -2.4021344  |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 845         |\n",
      "|    time_elapsed         | 15483       |\n",
      "|    total_timesteps      | 1730560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019035317 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.08        |\n",
      "|    n_updates            | 8440        |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    reward               | -0.15334594 |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 846         |\n",
      "|    time_elapsed         | 15501       |\n",
      "|    total_timesteps      | 1732608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009486923 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 8450        |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | 0.7738113   |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3074817.97\n",
      "total_reward: 2074817.97\n",
      "total_cost: 79578.41\n",
      "total_trades: 56633\n",
      "Sharpe: 0.700\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 847         |\n",
      "|    time_elapsed         | 15521       |\n",
      "|    total_timesteps      | 1734656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005338476 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.81        |\n",
      "|    n_updates            | 8460        |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    reward               | 1.4217649   |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 19.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 848          |\n",
      "|    time_elapsed         | 15539        |\n",
      "|    total_timesteps      | 1736704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0139809325 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.8        |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.96         |\n",
      "|    n_updates            | 8470         |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | 1.363812     |\n",
      "|    std                  | 2.62         |\n",
      "|    value_loss           | 12.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 849         |\n",
      "|    time_elapsed         | 15557       |\n",
      "|    total_timesteps      | 1738752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020765934 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.34        |\n",
      "|    n_updates            | 8480        |\n",
      "|    policy_gradient_loss | 0.000119    |\n",
      "|    reward               | -1.3802913  |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 850         |\n",
      "|    time_elapsed         | 15576       |\n",
      "|    total_timesteps      | 1740800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010744886 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 8490        |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    reward               | -2.3462658  |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 851         |\n",
      "|    time_elapsed         | 15595       |\n",
      "|    total_timesteps      | 1742848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028132107 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.58        |\n",
      "|    n_updates            | 8500        |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    reward               | -0.35799548 |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 852         |\n",
      "|    time_elapsed         | 15615       |\n",
      "|    total_timesteps      | 1744896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011972169 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 8510        |\n",
      "|    policy_gradient_loss | 5.51e-05    |\n",
      "|    reward               | -0.9784681  |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 853         |\n",
      "|    time_elapsed         | 15633       |\n",
      "|    total_timesteps      | 1746944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014086835 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 8520        |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    reward               | 6.0440416   |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 854        |\n",
      "|    time_elapsed         | 15652      |\n",
      "|    total_timesteps      | 1748992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01971262 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69        |\n",
      "|    explained_variance   | 0.624      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.45       |\n",
      "|    n_updates            | 8530       |\n",
      "|    policy_gradient_loss | -0.0038    |\n",
      "|    reward               | -0.3342444 |\n",
      "|    std                  | 2.63       |\n",
      "|    value_loss           | 17.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 855         |\n",
      "|    time_elapsed         | 15670       |\n",
      "|    total_timesteps      | 1751040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014053246 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 8540        |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    reward               | 0.13563927  |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 856          |\n",
      "|    time_elapsed         | 15688        |\n",
      "|    total_timesteps      | 1753088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074930047 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.1        |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 8550         |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    reward               | -19.973665   |\n",
      "|    std                  | 2.64         |\n",
      "|    value_loss           | 27.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 857         |\n",
      "|    time_elapsed         | 15706       |\n",
      "|    total_timesteps      | 1755136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008910314 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.1       |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 8560        |\n",
      "|    policy_gradient_loss | -0.00144    |\n",
      "|    reward               | 7.0174694   |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 858        |\n",
      "|    time_elapsed         | 15724      |\n",
      "|    total_timesteps      | 1757184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02346126 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.1      |\n",
      "|    explained_variance   | 0.715      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.18       |\n",
      "|    n_updates            | 8570       |\n",
      "|    policy_gradient_loss | -0.00566   |\n",
      "|    reward               | 2.152827   |\n",
      "|    std                  | 2.64       |\n",
      "|    value_loss           | 13.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 859         |\n",
      "|    time_elapsed         | 15742       |\n",
      "|    total_timesteps      | 1759232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0215726   |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.2       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 8580        |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    reward               | -0.45149228 |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 860          |\n",
      "|    time_elapsed         | 15760        |\n",
      "|    total_timesteps      | 1761280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072906963 |\n",
      "|    clip_fraction        | 0.0785       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.2        |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 8590         |\n",
      "|    policy_gradient_loss | -0.00581     |\n",
      "|    reward               | 2.4584398    |\n",
      "|    std                  | 2.65         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3215578.10\n",
      "total_reward: 2215578.10\n",
      "total_cost: 67177.07\n",
      "total_trades: 55777\n",
      "Sharpe: 0.704\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 15779       |\n",
      "|    total_timesteps      | 1763328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00936771  |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.2       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 8600        |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    reward               | -0.32627326 |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 862         |\n",
      "|    time_elapsed         | 15797       |\n",
      "|    total_timesteps      | 1765376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011010945 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.2       |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.01        |\n",
      "|    n_updates            | 8610        |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    reward               | -1.1808372  |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 863        |\n",
      "|    time_elapsed         | 15816      |\n",
      "|    total_timesteps      | 1767424    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01190475 |\n",
      "|    clip_fraction        | 0.0799     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.2      |\n",
      "|    explained_variance   | 0.734      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.3       |\n",
      "|    n_updates            | 8620       |\n",
      "|    policy_gradient_loss | -0.00823   |\n",
      "|    reward               | 0.3017001  |\n",
      "|    std                  | 2.65       |\n",
      "|    value_loss           | 26.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 864        |\n",
      "|    time_elapsed         | 15836      |\n",
      "|    total_timesteps      | 1769472    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00888529 |\n",
      "|    clip_fraction        | 0.0507     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.2      |\n",
      "|    explained_variance   | 0.749      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.4       |\n",
      "|    n_updates            | 8630       |\n",
      "|    policy_gradient_loss | -0.0014    |\n",
      "|    reward               | 2.0938315  |\n",
      "|    std                  | 2.65       |\n",
      "|    value_loss           | 24.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 865        |\n",
      "|    time_elapsed         | 15854      |\n",
      "|    total_timesteps      | 1771520    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03355638 |\n",
      "|    clip_fraction        | 0.299      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.3      |\n",
      "|    explained_variance   | 0.779      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.95       |\n",
      "|    n_updates            | 8640       |\n",
      "|    policy_gradient_loss | 0.00176    |\n",
      "|    reward               | -1.1993244 |\n",
      "|    std                  | 2.66       |\n",
      "|    value_loss           | 14.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 866          |\n",
      "|    time_elapsed         | 15872        |\n",
      "|    total_timesteps      | 1773568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095717665 |\n",
      "|    clip_fraction        | 0.0512       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.3        |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 8650         |\n",
      "|    policy_gradient_loss | -0.00751     |\n",
      "|    reward               | 0.44448176   |\n",
      "|    std                  | 2.66         |\n",
      "|    value_loss           | 28.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 867         |\n",
      "|    time_elapsed         | 15891       |\n",
      "|    total_timesteps      | 1775616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015193508 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.4       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 8660        |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    reward               | 0.5222451   |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 868         |\n",
      "|    time_elapsed         | 15910       |\n",
      "|    total_timesteps      | 1777664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021072432 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.4       |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.49        |\n",
      "|    n_updates            | 8670        |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    reward               | 0.38902113  |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 869         |\n",
      "|    time_elapsed         | 15929       |\n",
      "|    total_timesteps      | 1779712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008681879 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.4       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.72        |\n",
      "|    n_updates            | 8680        |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    reward               | -0.37390718 |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 870          |\n",
      "|    time_elapsed         | 15947        |\n",
      "|    total_timesteps      | 1781760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058373236 |\n",
      "|    clip_fraction        | 0.065        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.5        |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 8690         |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    reward               | -3.0471146   |\n",
      "|    std                  | 2.67         |\n",
      "|    value_loss           | 25.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 871         |\n",
      "|    time_elapsed         | 15965       |\n",
      "|    total_timesteps      | 1783808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011087315 |\n",
      "|    clip_fraction        | 0.0791      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.68        |\n",
      "|    n_updates            | 8700        |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    reward               | 2.052269    |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 872         |\n",
      "|    time_elapsed         | 15983       |\n",
      "|    total_timesteps      | 1785856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021998147 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.91        |\n",
      "|    n_updates            | 8710        |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    reward               | 0.2021988   |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 873          |\n",
      "|    time_elapsed         | 16001        |\n",
      "|    total_timesteps      | 1787904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032390752 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.5        |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 8720         |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    reward               | -0.7810907   |\n",
      "|    std                  | 2.67         |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 874         |\n",
      "|    time_elapsed         | 16019       |\n",
      "|    total_timesteps      | 1789952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010727573 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.58        |\n",
      "|    n_updates            | 8730        |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    reward               | 0.23070973  |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3475265.54\n",
      "total_reward: 2475265.54\n",
      "total_cost: 57326.06\n",
      "total_trades: 54220\n",
      "Sharpe: 0.748\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 875         |\n",
      "|    time_elapsed         | 16037       |\n",
      "|    total_timesteps      | 1792000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022732073 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.3         |\n",
      "|    n_updates            | 8740        |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    reward               | 0.6864139   |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 12.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 876          |\n",
      "|    time_elapsed         | 16055        |\n",
      "|    total_timesteps      | 1794048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099596465 |\n",
      "|    clip_fraction        | 0.0865       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.5        |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 8750         |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    reward               | -0.21527348  |\n",
      "|    std                  | 2.68         |\n",
      "|    value_loss           | 24.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 877         |\n",
      "|    time_elapsed         | 16073       |\n",
      "|    total_timesteps      | 1796096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008505506 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 8760        |\n",
      "|    policy_gradient_loss | -0.00136    |\n",
      "|    reward               | 2.2812998   |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 878        |\n",
      "|    time_elapsed         | 16091      |\n",
      "|    total_timesteps      | 1798144    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02124985 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.5      |\n",
      "|    explained_variance   | 0.705      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.46       |\n",
      "|    n_updates            | 8770       |\n",
      "|    policy_gradient_loss | 0.000446   |\n",
      "|    reward               | -2.2933686 |\n",
      "|    std                  | 2.68       |\n",
      "|    value_loss           | 19.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 879         |\n",
      "|    time_elapsed         | 16109       |\n",
      "|    total_timesteps      | 1800192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018611304 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.72        |\n",
      "|    n_updates            | 8780        |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    reward               | 0.63983893  |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 880         |\n",
      "|    time_elapsed         | 16127       |\n",
      "|    total_timesteps      | 1802240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010614784 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.5         |\n",
      "|    n_updates            | 8790        |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    reward               | -0.06609525 |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 881          |\n",
      "|    time_elapsed         | 16146        |\n",
      "|    total_timesteps      | 1804288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039497893 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.6        |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.78         |\n",
      "|    n_updates            | 8800         |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    reward               | -4.429377    |\n",
      "|    std                  | 2.68         |\n",
      "|    value_loss           | 23.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 882         |\n",
      "|    time_elapsed         | 16164       |\n",
      "|    total_timesteps      | 1806336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02056351  |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 8810        |\n",
      "|    policy_gradient_loss | -0.00987    |\n",
      "|    reward               | -0.99095833 |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 883       |\n",
      "|    time_elapsed         | 16182     |\n",
      "|    total_timesteps      | 1808384   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0161734 |\n",
      "|    clip_fraction        | 0.122     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -69.6     |\n",
      "|    explained_variance   | 0.519     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 10.1      |\n",
      "|    n_updates            | 8820      |\n",
      "|    policy_gradient_loss | -0.00643  |\n",
      "|    reward               | 0.990787  |\n",
      "|    std                  | 2.69      |\n",
      "|    value_loss           | 26.6      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 884         |\n",
      "|    time_elapsed         | 16200       |\n",
      "|    total_timesteps      | 1810432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015223153 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 8830        |\n",
      "|    policy_gradient_loss | 0.00142     |\n",
      "|    reward               | 2.2472591   |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 16218       |\n",
      "|    total_timesteps      | 1812480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021390686 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.17        |\n",
      "|    n_updates            | 8840        |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    reward               | 2.8093464   |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 886         |\n",
      "|    time_elapsed         | 16237       |\n",
      "|    total_timesteps      | 1814528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010540204 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.68        |\n",
      "|    n_updates            | 8850        |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | -1.6658757  |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 887         |\n",
      "|    time_elapsed         | 16255       |\n",
      "|    total_timesteps      | 1816576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011026269 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 8860        |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    reward               | 1.4767549   |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 888       |\n",
      "|    time_elapsed         | 16274     |\n",
      "|    total_timesteps      | 1818624   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0197183 |\n",
      "|    clip_fraction        | 0.256     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -69.7     |\n",
      "|    explained_variance   | 0.629     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 15.7      |\n",
      "|    n_updates            | 8870      |\n",
      "|    policy_gradient_loss | 0.00612   |\n",
      "|    reward               | 1.8513608 |\n",
      "|    std                  | 2.7       |\n",
      "|    value_loss           | 26.7      |\n",
      "---------------------------------------\n",
      "day: 2892, episode: 630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3545647.62\n",
      "total_reward: 2545647.62\n",
      "total_cost: 50993.43\n",
      "total_trades: 52548\n",
      "Sharpe: 0.753\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 889         |\n",
      "|    time_elapsed         | 16293       |\n",
      "|    total_timesteps      | 1820672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018562058 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.95        |\n",
      "|    n_updates            | 8880        |\n",
      "|    policy_gradient_loss | -0.00256    |\n",
      "|    reward               | -0.68095076 |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 890         |\n",
      "|    time_elapsed         | 16311       |\n",
      "|    total_timesteps      | 1822720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014013359 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 8890        |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    reward               | -0.26162717 |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 891         |\n",
      "|    time_elapsed         | 16330       |\n",
      "|    total_timesteps      | 1824768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010836447 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 8900        |\n",
      "|    policy_gradient_loss | -4.03e-05   |\n",
      "|    reward               | 0.09295468  |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 892        |\n",
      "|    time_elapsed         | 16348      |\n",
      "|    total_timesteps      | 1826816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0214296  |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.8      |\n",
      "|    explained_variance   | 0.668      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.51       |\n",
      "|    n_updates            | 8910       |\n",
      "|    policy_gradient_loss | -0.000459  |\n",
      "|    reward               | 0.32014275 |\n",
      "|    std                  | 2.7        |\n",
      "|    value_loss           | 15.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 893         |\n",
      "|    time_elapsed         | 16367       |\n",
      "|    total_timesteps      | 1828864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010337021 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 8920        |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    reward               | -0.2908944  |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 894         |\n",
      "|    time_elapsed         | 16386       |\n",
      "|    total_timesteps      | 1830912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016150735 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 8930        |\n",
      "|    policy_gradient_loss | -0.00262    |\n",
      "|    reward               | 3.3334823   |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 895         |\n",
      "|    time_elapsed         | 16405       |\n",
      "|    total_timesteps      | 1832960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010173068 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 8940        |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    reward               | 0.043120783 |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 896          |\n",
      "|    time_elapsed         | 16423        |\n",
      "|    total_timesteps      | 1835008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014034703  |\n",
      "|    clip_fraction        | 0.201        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.9        |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.18         |\n",
      "|    n_updates            | 8950         |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | -0.035899688 |\n",
      "|    std                  | 2.71         |\n",
      "|    value_loss           | 15.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 897         |\n",
      "|    time_elapsed         | 16441       |\n",
      "|    total_timesteps      | 1837056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020457022 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.26        |\n",
      "|    n_updates            | 8960        |\n",
      "|    policy_gradient_loss | -0.000266   |\n",
      "|    reward               | -12.066413  |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 898         |\n",
      "|    time_elapsed         | 16460       |\n",
      "|    total_timesteps      | 1839104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003581659 |\n",
      "|    clip_fraction        | 0.00659     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 8970        |\n",
      "|    policy_gradient_loss | -0.00123    |\n",
      "|    reward               | 4.4605494   |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 899         |\n",
      "|    time_elapsed         | 16479       |\n",
      "|    total_timesteps      | 1841152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02412257  |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.79        |\n",
      "|    n_updates            | 8980        |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    reward               | 0.076600604 |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 900        |\n",
      "|    time_elapsed         | 16498      |\n",
      "|    total_timesteps      | 1843200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02155016 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70        |\n",
      "|    explained_variance   | 0.739      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.9       |\n",
      "|    n_updates            | 8990       |\n",
      "|    policy_gradient_loss | -0.00439   |\n",
      "|    reward               | 0.8073324  |\n",
      "|    std                  | 2.72       |\n",
      "|    value_loss           | 20         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 901         |\n",
      "|    time_elapsed         | 16517       |\n",
      "|    total_timesteps      | 1845248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019689502 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 9000        |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    reward               | 3.869837    |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 902         |\n",
      "|    time_elapsed         | 16536       |\n",
      "|    total_timesteps      | 1847296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007821708 |\n",
      "|    clip_fraction        | 0.0388      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.48        |\n",
      "|    n_updates            | 9010        |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | 0.38634413  |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3391481.48\n",
      "total_reward: 2391481.48\n",
      "total_cost: 51711.32\n",
      "total_trades: 51913\n",
      "Sharpe: 0.715\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 903         |\n",
      "|    time_elapsed         | 16555       |\n",
      "|    total_timesteps      | 1849344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016283942 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.59        |\n",
      "|    n_updates            | 9020        |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    reward               | -0.41556737 |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 904         |\n",
      "|    time_elapsed         | 16572       |\n",
      "|    total_timesteps      | 1851392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009399695 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 9030        |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    reward               | -0.17790796 |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 905          |\n",
      "|    time_elapsed         | 16590        |\n",
      "|    total_timesteps      | 1853440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149062965 |\n",
      "|    clip_fraction        | 0.188        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.1        |\n",
      "|    explained_variance   | 0.759        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.71         |\n",
      "|    n_updates            | 9040         |\n",
      "|    policy_gradient_loss | 0.00166      |\n",
      "|    reward               | -2.357842    |\n",
      "|    std                  | 2.73         |\n",
      "|    value_loss           | 24           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 906         |\n",
      "|    time_elapsed         | 16609       |\n",
      "|    total_timesteps      | 1855488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025627993 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.84        |\n",
      "|    n_updates            | 9050        |\n",
      "|    policy_gradient_loss | -0.00123    |\n",
      "|    reward               | 0.86949     |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 907         |\n",
      "|    time_elapsed         | 16627       |\n",
      "|    total_timesteps      | 1857536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016260143 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.62        |\n",
      "|    n_updates            | 9060        |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    reward               | 1.3021469   |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 908         |\n",
      "|    time_elapsed         | 16645       |\n",
      "|    total_timesteps      | 1859584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005080599 |\n",
      "|    clip_fraction        | 0.0194      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 9070        |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    reward               | 1.6441214   |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 31.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 909         |\n",
      "|    time_elapsed         | 16664       |\n",
      "|    total_timesteps      | 1861632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028058965 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.27        |\n",
      "|    n_updates            | 9080        |\n",
      "|    policy_gradient_loss | 0.000398    |\n",
      "|    reward               | -0.1694826  |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 910         |\n",
      "|    time_elapsed         | 16682       |\n",
      "|    total_timesteps      | 1863680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020237241 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.2       |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.76        |\n",
      "|    n_updates            | 9090        |\n",
      "|    policy_gradient_loss | 0.00094     |\n",
      "|    reward               | -0.90065205 |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 911         |\n",
      "|    time_elapsed         | 16700       |\n",
      "|    total_timesteps      | 1865728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008915525 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.2       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 9100        |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    reward               | 2.5630918   |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 912         |\n",
      "|    time_elapsed         | 16718       |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012546049 |\n",
      "|    clip_fraction        | 0.0832      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.2       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 9110        |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    reward               | 0.98718774  |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 913         |\n",
      "|    time_elapsed         | 16737       |\n",
      "|    total_timesteps      | 1869824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021201141 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.2         |\n",
      "|    n_updates            | 9120        |\n",
      "|    policy_gradient_loss | -0.0051     |\n",
      "|    reward               | 0.20769507  |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 914        |\n",
      "|    time_elapsed         | 16755      |\n",
      "|    total_timesteps      | 1871872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01375894 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.4      |\n",
      "|    explained_variance   | 0.75       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.18       |\n",
      "|    n_updates            | 9130       |\n",
      "|    policy_gradient_loss | -0.00299   |\n",
      "|    reward               | 0.431496   |\n",
      "|    std                  | 2.76       |\n",
      "|    value_loss           | 22.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 915         |\n",
      "|    time_elapsed         | 16773       |\n",
      "|    total_timesteps      | 1873920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014246019 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.53        |\n",
      "|    n_updates            | 9140        |\n",
      "|    policy_gradient_loss | 0.00373     |\n",
      "|    reward               | 4.541314    |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 916         |\n",
      "|    time_elapsed         | 16792       |\n",
      "|    total_timesteps      | 1875968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014528204 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.07        |\n",
      "|    n_updates            | 9150        |\n",
      "|    policy_gradient_loss | 4.68e-05    |\n",
      "|    reward               | -0.10624313 |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3396736.29\n",
      "total_reward: 2396736.29\n",
      "total_cost: 43532.77\n",
      "total_trades: 51490\n",
      "Sharpe: 0.731\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 917        |\n",
      "|    time_elapsed         | 16810      |\n",
      "|    total_timesteps      | 1878016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01807464 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.5      |\n",
      "|    explained_variance   | 0.706      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.5       |\n",
      "|    n_updates            | 9160       |\n",
      "|    policy_gradient_loss | -0.00401   |\n",
      "|    reward               | 0.24544439 |\n",
      "|    std                  | 2.77       |\n",
      "|    value_loss           | 23.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 918         |\n",
      "|    time_elapsed         | 16828       |\n",
      "|    total_timesteps      | 1880064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011404835 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 9170        |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    reward               | 2.7651436   |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 30.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 919         |\n",
      "|    time_elapsed         | 16846       |\n",
      "|    total_timesteps      | 1882112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014453795 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.16        |\n",
      "|    n_updates            | 9180        |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | -1.7052661  |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 920         |\n",
      "|    time_elapsed         | 16864       |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009675682 |\n",
      "|    clip_fraction        | 0.0846      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.7         |\n",
      "|    n_updates            | 9190        |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    reward               | 0.7004787   |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 921          |\n",
      "|    time_elapsed         | 16882        |\n",
      "|    total_timesteps      | 1886208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124136405 |\n",
      "|    clip_fraction        | 0.0538       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.5        |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 9200         |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    reward               | -2.1441953   |\n",
      "|    std                  | 2.77         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 922         |\n",
      "|    time_elapsed         | 16901       |\n",
      "|    total_timesteps      | 1888256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005032641 |\n",
      "|    clip_fraction        | 0.00674     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 9210        |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    reward               | -2.9481528  |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 923         |\n",
      "|    time_elapsed         | 16919       |\n",
      "|    total_timesteps      | 1890304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022827065 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.6       |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.67        |\n",
      "|    n_updates            | 9220        |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    reward               | 1.0896739   |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 9.29        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 924         |\n",
      "|    time_elapsed         | 16937       |\n",
      "|    total_timesteps      | 1892352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012226911 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.6       |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.46        |\n",
      "|    n_updates            | 9230        |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    reward               | -1.5774653  |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 925         |\n",
      "|    time_elapsed         | 16955       |\n",
      "|    total_timesteps      | 1894400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009254007 |\n",
      "|    clip_fraction        | 0.0359      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.6       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 9240        |\n",
      "|    policy_gradient_loss | -0.00246    |\n",
      "|    reward               | -0.5075331  |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 42          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 926         |\n",
      "|    time_elapsed         | 16973       |\n",
      "|    total_timesteps      | 1896448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017865675 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.7       |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 9250        |\n",
      "|    policy_gradient_loss | -0.000411   |\n",
      "|    reward               | 2.1595075   |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 927         |\n",
      "|    time_elapsed         | 16991       |\n",
      "|    total_timesteps      | 1898496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013560974 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.7       |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.53        |\n",
      "|    n_updates            | 9260        |\n",
      "|    policy_gradient_loss | 1.58e-05    |\n",
      "|    reward               | 2.1266258   |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 928         |\n",
      "|    time_elapsed         | 17009       |\n",
      "|    total_timesteps      | 1900544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015012064 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.7       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 9270        |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | -0.69978243 |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 929         |\n",
      "|    time_elapsed         | 17027       |\n",
      "|    total_timesteps      | 1902592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014593089 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.7       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 9280        |\n",
      "|    policy_gradient_loss | -0.00158    |\n",
      "|    reward               | 0.75498754  |\n",
      "|    std                  | 2.8         |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 930         |\n",
      "|    time_elapsed         | 17045       |\n",
      "|    total_timesteps      | 1904640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014668046 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.25        |\n",
      "|    n_updates            | 9290        |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    reward               | 1.1230745   |\n",
      "|    std                  | 2.8         |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3403101.60\n",
      "total_reward: 2403101.60\n",
      "total_cost: 46429.84\n",
      "total_trades: 51278\n",
      "Sharpe: 0.720\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 931        |\n",
      "|    time_elapsed         | 17063      |\n",
      "|    total_timesteps      | 1906688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01207168 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.8      |\n",
      "|    explained_variance   | 0.669      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.6       |\n",
      "|    n_updates            | 9300       |\n",
      "|    policy_gradient_loss | -0.00528   |\n",
      "|    reward               | -0.6571485 |\n",
      "|    std                  | 2.81       |\n",
      "|    value_loss           | 32.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 932         |\n",
      "|    time_elapsed         | 17081       |\n",
      "|    total_timesteps      | 1908736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004854962 |\n",
      "|    clip_fraction        | 0.0138      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 9310        |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    reward               | -2.3304975  |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 933         |\n",
      "|    time_elapsed         | 17099       |\n",
      "|    total_timesteps      | 1910784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013017505 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.46        |\n",
      "|    n_updates            | 9320        |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    reward               | -0.35133547 |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 934         |\n",
      "|    time_elapsed         | 17117       |\n",
      "|    total_timesteps      | 1912832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013204216 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 9330        |\n",
      "|    policy_gradient_loss | -0.000946   |\n",
      "|    reward               | 0.18809493  |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 935         |\n",
      "|    time_elapsed         | 17135       |\n",
      "|    total_timesteps      | 1914880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010854458 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 9340        |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    reward               | -0.8728091  |\n",
      "|    std                  | 2.82        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 936         |\n",
      "|    time_elapsed         | 17153       |\n",
      "|    total_timesteps      | 1916928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011266861 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.33        |\n",
      "|    n_updates            | 9350        |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    reward               | -4.63591    |\n",
      "|    std                  | 2.82        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 937          |\n",
      "|    time_elapsed         | 17171        |\n",
      "|    total_timesteps      | 1918976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013599782  |\n",
      "|    clip_fraction        | 0.226        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71          |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.98         |\n",
      "|    n_updates            | 9360         |\n",
      "|    policy_gradient_loss | -0.00818     |\n",
      "|    reward               | -0.088439964 |\n",
      "|    std                  | 2.83         |\n",
      "|    value_loss           | 18.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 938         |\n",
      "|    time_elapsed         | 17188       |\n",
      "|    total_timesteps      | 1921024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011339254 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 9370        |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    reward               | 0.023618348 |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 939         |\n",
      "|    time_elapsed         | 17206       |\n",
      "|    total_timesteps      | 1923072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005518054 |\n",
      "|    clip_fraction        | 0.0236      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 9380        |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    reward               | 0.76061624  |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 940         |\n",
      "|    time_elapsed         | 17225       |\n",
      "|    total_timesteps      | 1925120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015347008 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.4         |\n",
      "|    n_updates            | 9390        |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    reward               | 0.28948933  |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 941         |\n",
      "|    time_elapsed         | 17243       |\n",
      "|    total_timesteps      | 1927168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021493763 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 9400        |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    reward               | 0.22591883  |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 942         |\n",
      "|    time_elapsed         | 17261       |\n",
      "|    total_timesteps      | 1929216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010038397 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 9410        |\n",
      "|    policy_gradient_loss | -0.0066     |\n",
      "|    reward               | 3.4740148   |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 943         |\n",
      "|    time_elapsed         | 17279       |\n",
      "|    total_timesteps      | 1931264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016846536 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 9420        |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | -0.50657386 |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 944         |\n",
      "|    time_elapsed         | 17297       |\n",
      "|    total_timesteps      | 1933312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018215885 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.3       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 9430        |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    reward               | 0.26561746  |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 22.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 945         |\n",
      "|    time_elapsed         | 17315       |\n",
      "|    total_timesteps      | 1935360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008302684 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.3       |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 9440        |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    reward               | -4.3410935  |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3046947.48\n",
      "total_reward: 2046947.48\n",
      "total_cost: 53964.88\n",
      "total_trades: 51233\n",
      "Sharpe: 0.642\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 946        |\n",
      "|    time_elapsed         | 17333      |\n",
      "|    total_timesteps      | 1937408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00622134 |\n",
      "|    clip_fraction        | 0.0367     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.3      |\n",
      "|    explained_variance   | 0.558      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.3       |\n",
      "|    n_updates            | 9450       |\n",
      "|    policy_gradient_loss | -0.00405   |\n",
      "|    reward               | -1.4485376 |\n",
      "|    std                  | 2.85       |\n",
      "|    value_loss           | 36.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 947         |\n",
      "|    time_elapsed         | 17351       |\n",
      "|    total_timesteps      | 1939456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022392925 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.3       |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.67        |\n",
      "|    n_updates            | 9460        |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    reward               | -0.13421333 |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 948         |\n",
      "|    time_elapsed         | 17369       |\n",
      "|    total_timesteps      | 1941504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008354766 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 9470        |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    reward               | 0.45891416  |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 949         |\n",
      "|    time_elapsed         | 17387       |\n",
      "|    total_timesteps      | 1943552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008249635 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 9480        |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    reward               | -0.95860654 |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 950         |\n",
      "|    time_elapsed         | 17405       |\n",
      "|    total_timesteps      | 1945600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014551523 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.35        |\n",
      "|    n_updates            | 9490        |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    reward               | -5.22552    |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 951        |\n",
      "|    time_elapsed         | 17423      |\n",
      "|    total_timesteps      | 1947648    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01784237 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.5      |\n",
      "|    explained_variance   | 0.763      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.57       |\n",
      "|    n_updates            | 9500       |\n",
      "|    policy_gradient_loss | -0.00156   |\n",
      "|    reward               | 2.1255767  |\n",
      "|    std                  | 2.87       |\n",
      "|    value_loss           | 19.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 952          |\n",
      "|    time_elapsed         | 17440        |\n",
      "|    total_timesteps      | 1949696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047709006 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.5        |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28           |\n",
      "|    n_updates            | 9510         |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    reward               | 6.1148825    |\n",
      "|    std                  | 2.87         |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 953         |\n",
      "|    time_elapsed         | 17458       |\n",
      "|    total_timesteps      | 1951744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007968981 |\n",
      "|    clip_fraction        | 0.0269      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.5       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 9520        |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    reward               | -1.0075912  |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 17477       |\n",
      "|    total_timesteps      | 1953792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020395415 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.5       |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.42        |\n",
      "|    n_updates            | 9530        |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    reward               | 0.8801378   |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 955         |\n",
      "|    time_elapsed         | 17495       |\n",
      "|    total_timesteps      | 1955840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016235236 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.5       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 9540        |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    reward               | 0.7400041   |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 956         |\n",
      "|    time_elapsed         | 17513       |\n",
      "|    total_timesteps      | 1957888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009400874 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.6       |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 9550        |\n",
      "|    policy_gradient_loss | 0.000268    |\n",
      "|    reward               | -1.758908   |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 957        |\n",
      "|    time_elapsed         | 17531      |\n",
      "|    total_timesteps      | 1959936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02158739 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.6      |\n",
      "|    explained_variance   | 0.647      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.04       |\n",
      "|    n_updates            | 9560       |\n",
      "|    policy_gradient_loss | -0.00145   |\n",
      "|    reward               | 2.6206183  |\n",
      "|    std                  | 2.88       |\n",
      "|    value_loss           | 17.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 958         |\n",
      "|    time_elapsed         | 17550       |\n",
      "|    total_timesteps      | 1961984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014299616 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.6       |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.98        |\n",
      "|    n_updates            | 9570        |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    reward               | 0.08098861  |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 959          |\n",
      "|    time_elapsed         | 17568        |\n",
      "|    total_timesteps      | 1964032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108687505 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.7        |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.09         |\n",
      "|    n_updates            | 9580         |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    reward               | -3.061617    |\n",
      "|    std                  | 2.88         |\n",
      "|    value_loss           | 27.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3524020.50\n",
      "total_reward: 2524020.50\n",
      "total_cost: 49679.89\n",
      "total_trades: 50105\n",
      "Sharpe: 0.716\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 960         |\n",
      "|    time_elapsed         | 17586       |\n",
      "|    total_timesteps      | 1966080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012427508 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.27        |\n",
      "|    n_updates            | 9590        |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    reward               | -0.3334273  |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 961         |\n",
      "|    time_elapsed         | 17605       |\n",
      "|    total_timesteps      | 1968128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014363855 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 9600        |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | -0.3847694  |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 962         |\n",
      "|    time_elapsed         | 17624       |\n",
      "|    total_timesteps      | 1970176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016944686 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.9        |\n",
      "|    n_updates            | 9610        |\n",
      "|    policy_gradient_loss | 0.000561    |\n",
      "|    reward               | -0.09083465 |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 963          |\n",
      "|    time_elapsed         | 17642        |\n",
      "|    total_timesteps      | 1972224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031064544 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.7        |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 9620         |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | 1.0590687    |\n",
      "|    std                  | 2.89         |\n",
      "|    value_loss           | 38.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 964         |\n",
      "|    time_elapsed         | 17661       |\n",
      "|    total_timesteps      | 1974272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033841625 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.8       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.95        |\n",
      "|    n_updates            | 9630        |\n",
      "|    policy_gradient_loss | 0.000848    |\n",
      "|    reward               | 0.27031007  |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 965         |\n",
      "|    time_elapsed         | 17679       |\n",
      "|    total_timesteps      | 1976320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010800933 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.8       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.91        |\n",
      "|    n_updates            | 9640        |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    reward               | 0.14189452  |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 966         |\n",
      "|    time_elapsed         | 17697       |\n",
      "|    total_timesteps      | 1978368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011089745 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.9       |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 9650        |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    reward               | -3.958206   |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 967         |\n",
      "|    time_elapsed         | 17715       |\n",
      "|    total_timesteps      | 1980416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009275569 |\n",
      "|    clip_fraction        | 0.073       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.9       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.18        |\n",
      "|    n_updates            | 9660        |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    reward               | 0.9535014   |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 968         |\n",
      "|    time_elapsed         | 17734       |\n",
      "|    total_timesteps      | 1982464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01955896  |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.9       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.17        |\n",
      "|    n_updates            | 9670        |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    reward               | -0.49874732 |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 969         |\n",
      "|    time_elapsed         | 17752       |\n",
      "|    total_timesteps      | 1984512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016272686 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.23        |\n",
      "|    n_updates            | 9680        |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    reward               | -10.288007  |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 970         |\n",
      "|    time_elapsed         | 17770       |\n",
      "|    total_timesteps      | 1986560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004221479 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.76        |\n",
      "|    n_updates            | 9690        |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    reward               | -6.557583   |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 22.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 971         |\n",
      "|    time_elapsed         | 17789       |\n",
      "|    total_timesteps      | 1988608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018404208 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.33        |\n",
      "|    n_updates            | 9700        |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    reward               | -1.7518288  |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 972        |\n",
      "|    time_elapsed         | 17807      |\n",
      "|    total_timesteps      | 1990656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00950538 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.1      |\n",
      "|    explained_variance   | 0.663      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.3       |\n",
      "|    n_updates            | 9710       |\n",
      "|    policy_gradient_loss | -0.00101   |\n",
      "|    reward               | 1.2128894  |\n",
      "|    std                  | 2.93       |\n",
      "|    value_loss           | 23.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 973         |\n",
      "|    time_elapsed         | 17825       |\n",
      "|    total_timesteps      | 1992704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010879698 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 9720        |\n",
      "|    policy_gradient_loss | -0.00107    |\n",
      "|    reward               | -10.2715225 |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3587393.45\n",
      "total_reward: 2587393.45\n",
      "total_cost: 56537.00\n",
      "total_trades: 51049\n",
      "Sharpe: 0.750\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 974         |\n",
      "|    time_elapsed         | 17843       |\n",
      "|    total_timesteps      | 1994752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012186276 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.29        |\n",
      "|    n_updates            | 9730        |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    reward               | 0.17404321  |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 975         |\n",
      "|    time_elapsed         | 17861       |\n",
      "|    total_timesteps      | 1996800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011560734 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 9740        |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    reward               | 0.25968525  |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 976          |\n",
      "|    time_elapsed         | 17880        |\n",
      "|    total_timesteps      | 1998848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073885187 |\n",
      "|    clip_fraction        | 0.0732       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.1        |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 9750         |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    reward               | -8.147063    |\n",
      "|    std                  | 2.93         |\n",
      "|    value_loss           | 25.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 977          |\n",
      "|    time_elapsed         | 17898        |\n",
      "|    total_timesteps      | 2000896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063878763 |\n",
      "|    clip_fraction        | 0.0357       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.1        |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 9760         |\n",
      "|    policy_gradient_loss | -0.0093      |\n",
      "|    reward               | 0.7063864    |\n",
      "|    std                  | 2.94         |\n",
      "|    value_loss           | 22.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 978         |\n",
      "|    time_elapsed         | 17916       |\n",
      "|    total_timesteps      | 2002944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017592493 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.46        |\n",
      "|    n_updates            | 9770        |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | 0.28978544  |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 979         |\n",
      "|    time_elapsed         | 17935       |\n",
      "|    total_timesteps      | 2004992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009786727 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 9780        |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    reward               | -0.01463611 |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 980         |\n",
      "|    time_elapsed         | 17954       |\n",
      "|    total_timesteps      | 2007040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004949346 |\n",
      "|    clip_fraction        | 0.0111      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 9790        |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    reward               | 0.61538875  |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 981         |\n",
      "|    time_elapsed         | 17972       |\n",
      "|    total_timesteps      | 2009088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022734912 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.91        |\n",
      "|    n_updates            | 9800        |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | 0.78969556  |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 982        |\n",
      "|    time_elapsed         | 17990      |\n",
      "|    total_timesteps      | 2011136    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02026071 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.3      |\n",
      "|    explained_variance   | 0.702      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12         |\n",
      "|    n_updates            | 9810       |\n",
      "|    policy_gradient_loss | -0.000427  |\n",
      "|    reward               | 0.18599862 |\n",
      "|    std                  | 2.95       |\n",
      "|    value_loss           | 24.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 983         |\n",
      "|    time_elapsed         | 18008       |\n",
      "|    total_timesteps      | 2013184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005918244 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 9820        |\n",
      "|    policy_gradient_loss | -0.00158    |\n",
      "|    reward               | 1.550178    |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 984         |\n",
      "|    time_elapsed         | 18027       |\n",
      "|    total_timesteps      | 2015232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010953866 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 9830        |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    reward               | 0.6065699   |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 985         |\n",
      "|    time_elapsed         | 18045       |\n",
      "|    total_timesteps      | 2017280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014472039 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.69        |\n",
      "|    n_updates            | 9840        |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    reward               | 0.41591567  |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 986         |\n",
      "|    time_elapsed         | 18063       |\n",
      "|    total_timesteps      | 2019328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011685932 |\n",
      "|    clip_fraction        | 0.0597      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 9850        |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    reward               | 0.15042286  |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 987          |\n",
      "|    time_elapsed         | 18081        |\n",
      "|    total_timesteps      | 2021376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043153996 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.3        |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 9860         |\n",
      "|    policy_gradient_loss | -0.000504    |\n",
      "|    reward               | 0.9105474    |\n",
      "|    std                  | 2.96         |\n",
      "|    value_loss           | 47.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3746032.06\n",
      "total_reward: 2746032.06\n",
      "total_cost: 48442.86\n",
      "total_trades: 50400\n",
      "Sharpe: 0.737\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 988         |\n",
      "|    time_elapsed         | 18099       |\n",
      "|    total_timesteps      | 2023424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024028122 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.16        |\n",
      "|    n_updates            | 9870        |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    reward               | 1.4827209   |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 989         |\n",
      "|    time_elapsed         | 18118       |\n",
      "|    total_timesteps      | 2025472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014947513 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 9880        |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    reward               | -0.25354916 |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 990         |\n",
      "|    time_elapsed         | 18137       |\n",
      "|    total_timesteps      | 2027520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007641225 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 9890        |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    reward               | -2.2353091  |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 991         |\n",
      "|    time_elapsed         | 18156       |\n",
      "|    total_timesteps      | 2029568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009857615 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.03        |\n",
      "|    n_updates            | 9900        |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    reward               | 0.18345433  |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 22.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 992         |\n",
      "|    time_elapsed         | 18175       |\n",
      "|    total_timesteps      | 2031616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019496089 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.56        |\n",
      "|    n_updates            | 9910        |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    reward               | -2.3101735  |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 993          |\n",
      "|    time_elapsed         | 18193        |\n",
      "|    total_timesteps      | 2033664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143229775 |\n",
      "|    clip_fraction        | 0.0937       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.5        |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.86         |\n",
      "|    n_updates            | 9920         |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    reward               | 2.893718     |\n",
      "|    std                  | 2.97         |\n",
      "|    value_loss           | 30.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 994         |\n",
      "|    time_elapsed         | 18211       |\n",
      "|    total_timesteps      | 2035712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012829531 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 9930        |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    reward               | -0.32004482 |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 995         |\n",
      "|    time_elapsed         | 18230       |\n",
      "|    total_timesteps      | 2037760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009171233 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.02        |\n",
      "|    n_updates            | 9940        |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    reward               | -1.9229007  |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 996         |\n",
      "|    time_elapsed         | 18248       |\n",
      "|    total_timesteps      | 2039808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012032516 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 9950        |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    reward               | 0.4865424   |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 997          |\n",
      "|    time_elapsed         | 18266        |\n",
      "|    total_timesteps      | 2041856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074225734 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.5        |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 9960         |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    reward               | -11.638642   |\n",
      "|    std                  | 2.97         |\n",
      "|    value_loss           | 28           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 998         |\n",
      "|    time_elapsed         | 18284       |\n",
      "|    total_timesteps      | 2043904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021929657 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.6       |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 9970        |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    reward               | -4.7421427  |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 999         |\n",
      "|    time_elapsed         | 18302       |\n",
      "|    total_timesteps      | 2045952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015821807 |\n",
      "|    clip_fraction        | 0.0931      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.6       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 9980        |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | -1.1116105  |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1000         |\n",
      "|    time_elapsed         | 18320        |\n",
      "|    total_timesteps      | 2048000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073601976 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.6        |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.3          |\n",
      "|    n_updates            | 9990         |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    reward               | 0.9541209    |\n",
      "|    std                  | 2.99         |\n",
      "|    value_loss           | 30.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1001        |\n",
      "|    time_elapsed         | 18339       |\n",
      "|    total_timesteps      | 2050048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017454533 |\n",
      "|    clip_fraction        | 0.0937      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 10000       |\n",
      "|    policy_gradient_loss | 0.000162    |\n",
      "|    reward               | -0.32910243 |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3502859.51\n",
      "total_reward: 2502859.51\n",
      "total_cost: 48576.47\n",
      "total_trades: 51184\n",
      "Sharpe: 0.733\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1002        |\n",
      "|    time_elapsed         | 18357       |\n",
      "|    total_timesteps      | 2052096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017477386 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.69        |\n",
      "|    n_updates            | 10010       |\n",
      "|    policy_gradient_loss | 0.00168     |\n",
      "|    reward               | -0.38202098 |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1003        |\n",
      "|    time_elapsed         | 18375       |\n",
      "|    total_timesteps      | 2054144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030309482 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.44        |\n",
      "|    n_updates            | 10020       |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    reward               | -0.27561748 |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1004         |\n",
      "|    time_elapsed         | 18393        |\n",
      "|    total_timesteps      | 2056192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039207893 |\n",
      "|    clip_fraction        | 0.00806      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.7        |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 10030        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | -0.21474673  |\n",
      "|    std                  | 2.99         |\n",
      "|    value_loss           | 35.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1005        |\n",
      "|    time_elapsed         | 18411       |\n",
      "|    total_timesteps      | 2058240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027804017 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.3         |\n",
      "|    n_updates            | 10040       |\n",
      "|    policy_gradient_loss | 0.00314     |\n",
      "|    reward               | 0.2044732   |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1006        |\n",
      "|    time_elapsed         | 18429       |\n",
      "|    total_timesteps      | 2060288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029616214 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 10050       |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    reward               | -1.637793   |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1007        |\n",
      "|    time_elapsed         | 18447       |\n",
      "|    total_timesteps      | 2062336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010699892 |\n",
      "|    clip_fraction        | 0.0512      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.79        |\n",
      "|    n_updates            | 10060       |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | 1.3948368   |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1008        |\n",
      "|    time_elapsed         | 18465       |\n",
      "|    total_timesteps      | 2064384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016000658 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 10070       |\n",
      "|    policy_gradient_loss | -0.000165   |\n",
      "|    reward               | -2.2087135  |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1009        |\n",
      "|    time_elapsed         | 18483       |\n",
      "|    total_timesteps      | 2066432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030322313 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.15        |\n",
      "|    n_updates            | 10080       |\n",
      "|    policy_gradient_loss | 0.000305    |\n",
      "|    reward               | -0.3534033  |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1010        |\n",
      "|    time_elapsed         | 18501       |\n",
      "|    total_timesteps      | 2068480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013345123 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 10090       |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    reward               | 4.3085647   |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1011         |\n",
      "|    time_elapsed         | 18519        |\n",
      "|    total_timesteps      | 2070528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050437367 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.9        |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 10100        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    reward               | 0.0017303496 |\n",
      "|    std                  | 3.01         |\n",
      "|    value_loss           | 26.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1012        |\n",
      "|    time_elapsed         | 18536       |\n",
      "|    total_timesteps      | 2072576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039480172 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.3         |\n",
      "|    n_updates            | 10110       |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    reward               | -0.85508966 |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 9.56        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1013       |\n",
      "|    time_elapsed         | 18554      |\n",
      "|    total_timesteps      | 2074624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01101518 |\n",
      "|    clip_fraction        | 0.0966     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73        |\n",
      "|    explained_variance   | 0.712      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.64       |\n",
      "|    n_updates            | 10120      |\n",
      "|    policy_gradient_loss | -0.00675   |\n",
      "|    reward               | -2.1781363 |\n",
      "|    std                  | 3.03       |\n",
      "|    value_loss           | 21.3       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1014         |\n",
      "|    time_elapsed         | 18572        |\n",
      "|    total_timesteps      | 2076672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015654255 |\n",
      "|    clip_fraction        | 0.00474      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73          |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 10130        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    reward               | 2.559722     |\n",
      "|    std                  | 3.03         |\n",
      "|    value_loss           | 23.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1015        |\n",
      "|    time_elapsed         | 18590       |\n",
      "|    total_timesteps      | 2078720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016904041 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.05        |\n",
      "|    n_updates            | 10140       |\n",
      "|    policy_gradient_loss | 0.00124     |\n",
      "|    reward               | 0.7456003   |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3415192.81\n",
      "total_reward: 2415192.81\n",
      "total_cost: 55279.13\n",
      "total_trades: 52533\n",
      "Sharpe: 0.713\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1016        |\n",
      "|    time_elapsed         | 18609       |\n",
      "|    total_timesteps      | 2080768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023236312 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.1       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 10150       |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    reward               | -0.19670214 |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1017       |\n",
      "|    time_elapsed         | 18628      |\n",
      "|    total_timesteps      | 2082816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00874581 |\n",
      "|    clip_fraction        | 0.0705     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.1      |\n",
      "|    explained_variance   | 0.727      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13         |\n",
      "|    n_updates            | 10160      |\n",
      "|    policy_gradient_loss | -0.0022    |\n",
      "|    reward               | 4.822692   |\n",
      "|    std                  | 3.04       |\n",
      "|    value_loss           | 28.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1018         |\n",
      "|    time_elapsed         | 18646        |\n",
      "|    total_timesteps      | 2084864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023681126 |\n",
      "|    clip_fraction        | 0.004        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.1        |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 10170        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | -0.73643726  |\n",
      "|    std                  | 3.04         |\n",
      "|    value_loss           | 35.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1019        |\n",
      "|    time_elapsed         | 18664       |\n",
      "|    total_timesteps      | 2086912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014416075 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.1       |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.8         |\n",
      "|    n_updates            | 10180       |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    reward               | 0.6646577   |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1020        |\n",
      "|    time_elapsed         | 18681       |\n",
      "|    total_timesteps      | 2088960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012720327 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.2       |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 10190       |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    reward               | -0.15704687 |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1021         |\n",
      "|    time_elapsed         | 18699        |\n",
      "|    total_timesteps      | 2091008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070330175 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.2        |\n",
      "|    explained_variance   | 0.382        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 10200        |\n",
      "|    policy_gradient_loss | -0.00776     |\n",
      "|    reward               | 1.0734242    |\n",
      "|    std                  | 3.05         |\n",
      "|    value_loss           | 39.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1022        |\n",
      "|    time_elapsed         | 18717       |\n",
      "|    total_timesteps      | 2093056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013240872 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.2       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.53        |\n",
      "|    n_updates            | 10210       |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    reward               | 0.5105758   |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1023        |\n",
      "|    time_elapsed         | 18735       |\n",
      "|    total_timesteps      | 2095104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013203142 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.3       |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.27        |\n",
      "|    n_updates            | 10220       |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    reward               | 0.6647679   |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1024        |\n",
      "|    time_elapsed         | 18753       |\n",
      "|    total_timesteps      | 2097152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009070531 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.3       |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.71        |\n",
      "|    n_updates            | 10230       |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    reward               | -1.695458   |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1025        |\n",
      "|    time_elapsed         | 18771       |\n",
      "|    total_timesteps      | 2099200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016189307 |\n",
      "|    clip_fraction        | 0.0609      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.3       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 10240       |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    reward               | 1.818912    |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1026       |\n",
      "|    time_elapsed         | 18789      |\n",
      "|    total_timesteps      | 2101248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02315054 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.3      |\n",
      "|    explained_variance   | 0.717      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.67       |\n",
      "|    n_updates            | 10250      |\n",
      "|    policy_gradient_loss | -0.00284   |\n",
      "|    reward               | 0.11186116 |\n",
      "|    std                  | 3.07       |\n",
      "|    value_loss           | 17.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1027        |\n",
      "|    time_elapsed         | 18806       |\n",
      "|    total_timesteps      | 2103296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014416412 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 10260       |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | 1.0571245   |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1028        |\n",
      "|    time_elapsed         | 18824       |\n",
      "|    total_timesteps      | 2105344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008350806 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 10270       |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    reward               | 0.96225524  |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1029       |\n",
      "|    time_elapsed         | 18843      |\n",
      "|    total_timesteps      | 2107392    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02468888 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.4      |\n",
      "|    explained_variance   | 0.346      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.52       |\n",
      "|    n_updates            | 10280      |\n",
      "|    policy_gradient_loss | -0.00126   |\n",
      "|    reward               | 0.2996397  |\n",
      "|    std                  | 3.07       |\n",
      "|    value_loss           | 17.1       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3850185.24\n",
      "total_reward: 2850185.24\n",
      "total_cost: 43962.90\n",
      "total_trades: 50521\n",
      "Sharpe: 0.762\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1030        |\n",
      "|    time_elapsed         | 18861       |\n",
      "|    total_timesteps      | 2109440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010259677 |\n",
      "|    clip_fraction        | 0.0978      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.5       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.69        |\n",
      "|    n_updates            | 10290       |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    reward               | 0.49856108  |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 42.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1031        |\n",
      "|    time_elapsed         | 18879       |\n",
      "|    total_timesteps      | 2111488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003571935 |\n",
      "|    clip_fraction        | 0.00303     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.5       |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 10300       |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    reward               | 0.5412031   |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1032         |\n",
      "|    time_elapsed         | 18899        |\n",
      "|    total_timesteps      | 2113536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077708056 |\n",
      "|    clip_fraction        | 0.0461       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.5        |\n",
      "|    explained_variance   | 0.534        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 10310        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | 0.6088806    |\n",
      "|    std                  | 3.08         |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1033        |\n",
      "|    time_elapsed         | 18917       |\n",
      "|    total_timesteps      | 2115584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018571775 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.03        |\n",
      "|    n_updates            | 10320       |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    reward               | 1.0190793   |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1034       |\n",
      "|    time_elapsed         | 18934      |\n",
      "|    total_timesteps      | 2117632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01786781 |\n",
      "|    clip_fraction        | 0.0867     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.6      |\n",
      "|    explained_variance   | 0.766      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.1       |\n",
      "|    n_updates            | 10330      |\n",
      "|    policy_gradient_loss | -0.00101   |\n",
      "|    reward               | -2.72309   |\n",
      "|    std                  | 3.1        |\n",
      "|    value_loss           | 29.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1035        |\n",
      "|    time_elapsed         | 18953       |\n",
      "|    total_timesteps      | 2119680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008490407 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 10340       |\n",
      "|    policy_gradient_loss | -0.000104   |\n",
      "|    reward               | -0.09149608 |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1036        |\n",
      "|    time_elapsed         | 18971       |\n",
      "|    total_timesteps      | 2121728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02203694  |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.16        |\n",
      "|    n_updates            | 10350       |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    reward               | -0.62744415 |\n",
      "|    std                  | 3.11        |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1037        |\n",
      "|    time_elapsed         | 18989       |\n",
      "|    total_timesteps      | 2123776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010944731 |\n",
      "|    clip_fraction        | 0.0937      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.8       |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 10360       |\n",
      "|    policy_gradient_loss | -0.00106    |\n",
      "|    reward               | -0.6627532  |\n",
      "|    std                  | 3.11        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1038         |\n",
      "|    time_elapsed         | 19007        |\n",
      "|    total_timesteps      | 2125824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061068386 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.8        |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.93         |\n",
      "|    n_updates            | 10370        |\n",
      "|    policy_gradient_loss | -0.00128     |\n",
      "|    reward               | -1.8536732   |\n",
      "|    std                  | 3.11         |\n",
      "|    value_loss           | 33.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1039       |\n",
      "|    time_elapsed         | 19025      |\n",
      "|    total_timesteps      | 2127872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01310659 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.8      |\n",
      "|    explained_variance   | 0.709      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.2       |\n",
      "|    n_updates            | 10380      |\n",
      "|    policy_gradient_loss | -0.00116   |\n",
      "|    reward               | 0.2956319  |\n",
      "|    std                  | 3.11       |\n",
      "|    value_loss           | 19.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1040       |\n",
      "|    time_elapsed         | 19043      |\n",
      "|    total_timesteps      | 2129920    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01182257 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.8      |\n",
      "|    explained_variance   | 0.747      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.11       |\n",
      "|    n_updates            | 10390      |\n",
      "|    policy_gradient_loss | -0.00545   |\n",
      "|    reward               | -0.9687324 |\n",
      "|    std                  | 3.11       |\n",
      "|    value_loss           | 19.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1041        |\n",
      "|    time_elapsed         | 19061       |\n",
      "|    total_timesteps      | 2131968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00921587  |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.8       |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 10400       |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    reward               | -0.34018824 |\n",
      "|    std                  | 3.12        |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1042        |\n",
      "|    time_elapsed         | 19079       |\n",
      "|    total_timesteps      | 2134016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002049821 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 10410       |\n",
      "|    policy_gradient_loss | -0.00171    |\n",
      "|    reward               | -1.569362   |\n",
      "|    std                  | 3.12        |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1043        |\n",
      "|    time_elapsed         | 19097       |\n",
      "|    total_timesteps      | 2136064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010641282 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.9         |\n",
      "|    n_updates            | 10420       |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    reward               | 1.1548452   |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3319864.45\n",
      "total_reward: 2319864.45\n",
      "total_cost: 54548.17\n",
      "total_trades: 51218\n",
      "Sharpe: 0.692\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1044        |\n",
      "|    time_elapsed         | 19115       |\n",
      "|    total_timesteps      | 2138112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012799408 |\n",
      "|    clip_fraction        | 0.0858      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 10430       |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    reward               | 1.0730428   |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1045         |\n",
      "|    time_elapsed         | 19144        |\n",
      "|    total_timesteps      | 2140160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115712825 |\n",
      "|    clip_fraction        | 0.0858       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74          |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 10440        |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    reward               | -0.5761026   |\n",
      "|    std                  | 3.13         |\n",
      "|    value_loss           | 28.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1046        |\n",
      "|    time_elapsed         | 19162       |\n",
      "|    total_timesteps      | 2142208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015940322 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.68        |\n",
      "|    n_updates            | 10450       |\n",
      "|    policy_gradient_loss | 0.00229     |\n",
      "|    reward               | -0.3261053  |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1047        |\n",
      "|    time_elapsed         | 19180       |\n",
      "|    total_timesteps      | 2144256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011174493 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.54        |\n",
      "|    n_updates            | 10460       |\n",
      "|    policy_gradient_loss | -0.00257    |\n",
      "|    reward               | -1.671868   |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1048       |\n",
      "|    time_elapsed         | 19198      |\n",
      "|    total_timesteps      | 2146304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0163563  |\n",
      "|    clip_fraction        | 0.0535     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74        |\n",
      "|    explained_variance   | 0.774      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.8       |\n",
      "|    n_updates            | 10470      |\n",
      "|    policy_gradient_loss | -0.00306   |\n",
      "|    reward               | 0.66576225 |\n",
      "|    std                  | 3.13       |\n",
      "|    value_loss           | 25.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1049       |\n",
      "|    time_elapsed         | 19216      |\n",
      "|    total_timesteps      | 2148352    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00747703 |\n",
      "|    clip_fraction        | 0.0263     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74        |\n",
      "|    explained_variance   | 0.776      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.69       |\n",
      "|    n_updates            | 10480      |\n",
      "|    policy_gradient_loss | -0.00304   |\n",
      "|    reward               | -0.5813563 |\n",
      "|    std                  | 3.14       |\n",
      "|    value_loss           | 21.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1050        |\n",
      "|    time_elapsed         | 19234       |\n",
      "|    total_timesteps      | 2150400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020932615 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.32        |\n",
      "|    n_updates            | 10490       |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    reward               | -0.8404402  |\n",
      "|    std                  | 3.14        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1051        |\n",
      "|    time_elapsed         | 19252       |\n",
      "|    total_timesteps      | 2152448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014177099 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.72        |\n",
      "|    n_updates            | 10500       |\n",
      "|    policy_gradient_loss | -0.00141    |\n",
      "|    reward               | 0.25191936  |\n",
      "|    std                  | 3.14        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1052        |\n",
      "|    time_elapsed         | 19271       |\n",
      "|    total_timesteps      | 2154496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007977006 |\n",
      "|    clip_fraction        | 0.0115      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 10510       |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    reward               | 0.92259544  |\n",
      "|    std                  | 3.14        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1053        |\n",
      "|    time_elapsed         | 19290       |\n",
      "|    total_timesteps      | 2156544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031618048 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.36        |\n",
      "|    n_updates            | 10520       |\n",
      "|    policy_gradient_loss | -0.000601   |\n",
      "|    reward               | 1.2456932   |\n",
      "|    std                  | 3.15        |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1054         |\n",
      "|    time_elapsed         | 19308        |\n",
      "|    total_timesteps      | 2158592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.022963015  |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.1        |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.43         |\n",
      "|    n_updates            | 10530        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | -0.054883186 |\n",
      "|    std                  | 3.15         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1055         |\n",
      "|    time_elapsed         | 19325        |\n",
      "|    total_timesteps      | 2160640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068894625 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.1        |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 10540        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    reward               | 0.06937191   |\n",
      "|    std                  | 3.15         |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1056        |\n",
      "|    time_elapsed         | 19343       |\n",
      "|    total_timesteps      | 2162688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008820141 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.2       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.34        |\n",
      "|    n_updates            | 10550       |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | -1.3789034  |\n",
      "|    std                  | 3.15        |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1057        |\n",
      "|    time_elapsed         | 19361       |\n",
      "|    total_timesteps      | 2164736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023686375 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.2       |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.38        |\n",
      "|    n_updates            | 10560       |\n",
      "|    policy_gradient_loss | -0.00213    |\n",
      "|    reward               | 0.15324248  |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1058         |\n",
      "|    time_elapsed         | 19379        |\n",
      "|    total_timesteps      | 2166784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047771977 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.3        |\n",
      "|    explained_variance   | 0.788        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 10570        |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    reward               | -9.214393    |\n",
      "|    std                  | 3.16         |\n",
      "|    value_loss           | 27           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3164009.25\n",
      "total_reward: 2164009.25\n",
      "total_cost: 64288.06\n",
      "total_trades: 52054\n",
      "Sharpe: 0.668\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1059        |\n",
      "|    time_elapsed         | 19397       |\n",
      "|    total_timesteps      | 2168832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005311276 |\n",
      "|    clip_fraction        | 0.0245      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 10580       |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    reward               | 0.17451423  |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1060         |\n",
      "|    time_elapsed         | 19415        |\n",
      "|    total_timesteps      | 2170880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085868845 |\n",
      "|    clip_fraction        | 0.0933       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.3        |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.4          |\n",
      "|    n_updates            | 10590        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    reward               | 1.4125637    |\n",
      "|    std                  | 3.17         |\n",
      "|    value_loss           | 18.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1061        |\n",
      "|    time_elapsed         | 19434       |\n",
      "|    total_timesteps      | 2172928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013118699 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 10600       |\n",
      "|    policy_gradient_loss | 0.000191    |\n",
      "|    reward               | 0.2062433   |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1062        |\n",
      "|    time_elapsed         | 19451       |\n",
      "|    total_timesteps      | 2174976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004486342 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 10610       |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    reward               | -1.3020563  |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1063        |\n",
      "|    time_elapsed         | 19469       |\n",
      "|    total_timesteps      | 2177024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018738277 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.13        |\n",
      "|    n_updates            | 10620       |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | -0.52407336 |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1064        |\n",
      "|    time_elapsed         | 19487       |\n",
      "|    total_timesteps      | 2179072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031276077 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 10630       |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    reward               | 0.34779853  |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1065        |\n",
      "|    time_elapsed         | 19505       |\n",
      "|    total_timesteps      | 2181120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011037542 |\n",
      "|    clip_fraction        | 0.0591      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 10640       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | -1.6488401  |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 49          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1066        |\n",
      "|    time_elapsed         | 19523       |\n",
      "|    total_timesteps      | 2183168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018941013 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 10650       |\n",
      "|    policy_gradient_loss | -0.00267    |\n",
      "|    reward               | -0.99331754 |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1067        |\n",
      "|    time_elapsed         | 19540       |\n",
      "|    total_timesteps      | 2185216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02459722  |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.14        |\n",
      "|    n_updates            | 10660       |\n",
      "|    policy_gradient_loss | -0.00573    |\n",
      "|    reward               | -0.47840506 |\n",
      "|    std                  | 3.19        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1068        |\n",
      "|    time_elapsed         | 19558       |\n",
      "|    total_timesteps      | 2187264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011769826 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 10670       |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | -1.5433704  |\n",
      "|    std                  | 3.19        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1069        |\n",
      "|    time_elapsed         | 19576       |\n",
      "|    total_timesteps      | 2189312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010504176 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.6       |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 10680       |\n",
      "|    policy_gradient_loss | 9.6e-05     |\n",
      "|    reward               | 1.65917     |\n",
      "|    std                  | 3.19        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1070        |\n",
      "|    time_elapsed         | 19594       |\n",
      "|    total_timesteps      | 2191360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013839237 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.6       |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.09        |\n",
      "|    n_updates            | 10690       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | 0.92956173  |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1071       |\n",
      "|    time_elapsed         | 19613      |\n",
      "|    total_timesteps      | 2193408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01359818 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.6      |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.7        |\n",
      "|    n_updates            | 10700      |\n",
      "|    policy_gradient_loss | -0.00214   |\n",
      "|    reward               | 0.97337025 |\n",
      "|    std                  | 3.2        |\n",
      "|    value_loss           | 20         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1072        |\n",
      "|    time_elapsed         | 19631       |\n",
      "|    total_timesteps      | 2195456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008450108 |\n",
      "|    clip_fraction        | 0.0591      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.6       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 10710       |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    reward               | 1.2109319   |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3474447.54\n",
      "total_reward: 2474447.54\n",
      "total_cost: 46703.45\n",
      "total_trades: 49767\n",
      "Sharpe: 0.713\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1073         |\n",
      "|    time_elapsed         | 19650        |\n",
      "|    total_timesteps      | 2197504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060537285 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.6        |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 10720        |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    reward               | 0.65007573   |\n",
      "|    std                  | 3.2          |\n",
      "|    value_loss           | 24           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1074        |\n",
      "|    time_elapsed         | 19669       |\n",
      "|    total_timesteps      | 2199552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011228219 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.64        |\n",
      "|    n_updates            | 10730       |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | 0.6986475   |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1075        |\n",
      "|    time_elapsed         | 19687       |\n",
      "|    total_timesteps      | 2201600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011520781 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 10740       |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    reward               | 0.19402647  |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1076         |\n",
      "|    time_elapsed         | 19705        |\n",
      "|    total_timesteps      | 2203648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052247057 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.7        |\n",
      "|    explained_variance   | 0.763        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 10750        |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    reward               | -0.25093186  |\n",
      "|    std                  | 3.21         |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1077        |\n",
      "|    time_elapsed         | 19723       |\n",
      "|    total_timesteps      | 2205696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021758365 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.03        |\n",
      "|    n_updates            | 10760       |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    reward               | 0.53559744  |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1078        |\n",
      "|    time_elapsed         | 19742       |\n",
      "|    total_timesteps      | 2207744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014464567 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 10770       |\n",
      "|    policy_gradient_loss | 0.000586    |\n",
      "|    reward               | -0.48858172 |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1079        |\n",
      "|    time_elapsed         | 19761       |\n",
      "|    total_timesteps      | 2209792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003877306 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 10780       |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    reward               | -0.6555353  |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1080        |\n",
      "|    time_elapsed         | 19779       |\n",
      "|    total_timesteps      | 2211840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013423146 |\n",
      "|    clip_fraction        | 0.0356      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.79        |\n",
      "|    n_updates            | 10790       |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | -1.0852848  |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1081        |\n",
      "|    time_elapsed         | 19798       |\n",
      "|    total_timesteps      | 2213888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016689193 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 10800       |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    reward               | -0.48972788 |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1082        |\n",
      "|    time_elapsed         | 19816       |\n",
      "|    total_timesteps      | 2215936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014722897 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.89        |\n",
      "|    n_updates            | 10810       |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    reward               | 6.0356555   |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1083        |\n",
      "|    time_elapsed         | 19834       |\n",
      "|    total_timesteps      | 2217984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008102839 |\n",
      "|    clip_fraction        | 0.0582      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.8         |\n",
      "|    n_updates            | 10820       |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    reward               | -2.3741379  |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1084        |\n",
      "|    time_elapsed         | 19852       |\n",
      "|    total_timesteps      | 2220032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020572413 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.74        |\n",
      "|    n_updates            | 10830       |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    reward               | -0.25424933 |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1085        |\n",
      "|    time_elapsed         | 19870       |\n",
      "|    total_timesteps      | 2222080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01316933  |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 10840       |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    reward               | -0.07576032 |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1086        |\n",
      "|    time_elapsed         | 19888       |\n",
      "|    total_timesteps      | 2224128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009044404 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 10850       |\n",
      "|    policy_gradient_loss | 5.69e-05    |\n",
      "|    reward               | -4.2043552  |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3500735.04\n",
      "total_reward: 2500735.04\n",
      "total_cost: 52254.06\n",
      "total_trades: 51034\n",
      "Sharpe: 0.720\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1087        |\n",
      "|    time_elapsed         | 19906       |\n",
      "|    total_timesteps      | 2226176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019998426 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 10860       |\n",
      "|    policy_gradient_loss | 0.000637    |\n",
      "|    reward               | 1.2825595   |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1088       |\n",
      "|    time_elapsed         | 19924      |\n",
      "|    total_timesteps      | 2228224    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01612256 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.9      |\n",
      "|    explained_variance   | 0.586      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.6       |\n",
      "|    n_updates            | 10870      |\n",
      "|    policy_gradient_loss | -0.00476   |\n",
      "|    reward               | -1.4752973 |\n",
      "|    std                  | 3.23       |\n",
      "|    value_loss           | 29.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1089        |\n",
      "|    time_elapsed         | 19942       |\n",
      "|    total_timesteps      | 2230272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014927178 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 10880       |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    reward               | 0.14641766  |\n",
      "|    std                  | 3.24        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1090         |\n",
      "|    time_elapsed         | 19960        |\n",
      "|    total_timesteps      | 2232320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024621456 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75          |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.99         |\n",
      "|    n_updates            | 10890        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | 1.875309     |\n",
      "|    std                  | 3.24         |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1091        |\n",
      "|    time_elapsed         | 19978       |\n",
      "|    total_timesteps      | 2234368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018773878 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75         |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.2         |\n",
      "|    n_updates            | 10900       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -0.17375718 |\n",
      "|    std                  | 3.24        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1092        |\n",
      "|    time_elapsed         | 19997       |\n",
      "|    total_timesteps      | 2236416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014806872 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75         |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 10910       |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    reward               | -1.0038687  |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1093         |\n",
      "|    time_elapsed         | 20015        |\n",
      "|    total_timesteps      | 2238464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051814197 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75          |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.4         |\n",
      "|    n_updates            | 10920        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | -4.4267607   |\n",
      "|    std                  | 3.25         |\n",
      "|    value_loss           | 43.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1094        |\n",
      "|    time_elapsed         | 20033       |\n",
      "|    total_timesteps      | 2240512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012636811 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75         |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.85        |\n",
      "|    n_updates            | 10930       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | -0.8600447  |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1095        |\n",
      "|    time_elapsed         | 20051       |\n",
      "|    total_timesteps      | 2242560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011355645 |\n",
      "|    clip_fraction        | 0.0852      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 10940       |\n",
      "|    policy_gradient_loss | 0.000414    |\n",
      "|    reward               | -0.2568374  |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1096         |\n",
      "|    time_elapsed         | 20069        |\n",
      "|    total_timesteps      | 2244608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080882665 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.1        |\n",
      "|    explained_variance   | 0.753        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 10950        |\n",
      "|    policy_gradient_loss | -0.0084      |\n",
      "|    reward               | 1.6883764    |\n",
      "|    std                  | 3.25         |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1097        |\n",
      "|    time_elapsed         | 20087       |\n",
      "|    total_timesteps      | 2246656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012287589 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 10960       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    reward               | 0.44556803  |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1098         |\n",
      "|    time_elapsed         | 20105        |\n",
      "|    total_timesteps      | 2248704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058916504 |\n",
      "|    clip_fraction        | 0.05         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.1        |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 10970        |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    reward               | 0.0901214    |\n",
      "|    std                  | 3.26         |\n",
      "|    value_loss           | 18.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1099        |\n",
      "|    time_elapsed         | 20123       |\n",
      "|    total_timesteps      | 2250752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014732953 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 10980       |\n",
      "|    policy_gradient_loss | -0.00112    |\n",
      "|    reward               | 3.2061388   |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1100         |\n",
      "|    time_elapsed         | 20141        |\n",
      "|    total_timesteps      | 2252800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033388645 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.2        |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 10990        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | 1.6361266    |\n",
      "|    std                  | 3.26         |\n",
      "|    value_loss           | 36.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3253330.09\n",
      "total_reward: 2253330.09\n",
      "total_cost: 47407.02\n",
      "total_trades: 50527\n",
      "Sharpe: 0.680\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1101        |\n",
      "|    time_elapsed         | 20160       |\n",
      "|    total_timesteps      | 2254848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029668905 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.86        |\n",
      "|    n_updates            | 11000       |\n",
      "|    policy_gradient_loss | -0.000986   |\n",
      "|    reward               | 3.6608312   |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 9.98        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1102        |\n",
      "|    time_elapsed         | 20179       |\n",
      "|    total_timesteps      | 2256896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012667796 |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 11010       |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    reward               | -0.13409954 |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1103       |\n",
      "|    time_elapsed         | 20197      |\n",
      "|    total_timesteps      | 2258944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01060515 |\n",
      "|    clip_fraction        | 0.076      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.2      |\n",
      "|    explained_variance   | 0.732      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.1       |\n",
      "|    n_updates            | 11020      |\n",
      "|    policy_gradient_loss | -0.00507   |\n",
      "|    reward               | 1.6727177  |\n",
      "|    std                  | 3.27       |\n",
      "|    value_loss           | 26.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1104       |\n",
      "|    time_elapsed         | 20215      |\n",
      "|    total_timesteps      | 2260992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01094218 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.3      |\n",
      "|    explained_variance   | 0.731      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.16       |\n",
      "|    n_updates            | 11030      |\n",
      "|    policy_gradient_loss | 0.00118    |\n",
      "|    reward               | 3.663198   |\n",
      "|    std                  | 3.27       |\n",
      "|    value_loss           | 15.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1105        |\n",
      "|    time_elapsed         | 20233       |\n",
      "|    total_timesteps      | 2263040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039977726 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.3       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.54        |\n",
      "|    n_updates            | 11040       |\n",
      "|    policy_gradient_loss | -0.000468   |\n",
      "|    reward               | -1.9823377  |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1106        |\n",
      "|    time_elapsed         | 20251       |\n",
      "|    total_timesteps      | 2265088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011632396 |\n",
      "|    clip_fraction        | 0.051       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.3       |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 11050       |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    reward               | 0.9293006   |\n",
      "|    std                  | 3.28        |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1107         |\n",
      "|    time_elapsed         | 20269        |\n",
      "|    total_timesteps      | 2267136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024594436 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.3        |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 11060        |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    reward               | -2.1430423   |\n",
      "|    std                  | 3.28         |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1108        |\n",
      "|    time_elapsed         | 20287       |\n",
      "|    total_timesteps      | 2269184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014915898 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.4       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.79        |\n",
      "|    n_updates            | 11070       |\n",
      "|    policy_gradient_loss | -0.0012     |\n",
      "|    reward               | 0.71551114  |\n",
      "|    std                  | 3.29        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1109        |\n",
      "|    time_elapsed         | 20305       |\n",
      "|    total_timesteps      | 2271232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012212047 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.4       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 11080       |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    reward               | 0.23797786  |\n",
      "|    std                  | 3.29        |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1110         |\n",
      "|    time_elapsed         | 20323        |\n",
      "|    total_timesteps      | 2273280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047628405 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.4        |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 11090        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    reward               | 0.42920038   |\n",
      "|    std                  | 3.29         |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1111        |\n",
      "|    time_elapsed         | 20341       |\n",
      "|    total_timesteps      | 2275328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020398423 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.11        |\n",
      "|    n_updates            | 11100       |\n",
      "|    policy_gradient_loss | -0.000815   |\n",
      "|    reward               | -0.4959146  |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1112        |\n",
      "|    time_elapsed         | 20358       |\n",
      "|    total_timesteps      | 2277376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023225816 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.96        |\n",
      "|    n_updates            | 11110       |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    reward               | 0.81961197  |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1113         |\n",
      "|    time_elapsed         | 20376        |\n",
      "|    total_timesteps      | 2279424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046431534 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.5        |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.54         |\n",
      "|    n_updates            | 11120        |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    reward               | 4.3695545    |\n",
      "|    std                  | 3.3          |\n",
      "|    value_loss           | 27.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1114        |\n",
      "|    time_elapsed         | 20394       |\n",
      "|    total_timesteps      | 2281472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010914773 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 11130       |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    reward               | -0.5255032  |\n",
      "|    std                  | 3.31        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3472586.02\n",
      "total_reward: 2472586.02\n",
      "total_cost: 40216.29\n",
      "total_trades: 50068\n",
      "Sharpe: 0.711\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1115        |\n",
      "|    time_elapsed         | 20412       |\n",
      "|    total_timesteps      | 2283520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014972268 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.32        |\n",
      "|    n_updates            | 11140       |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    reward               | -0.23242562 |\n",
      "|    std                  | 3.31        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1116        |\n",
      "|    time_elapsed         | 20430       |\n",
      "|    total_timesteps      | 2285568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021589635 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.48        |\n",
      "|    n_updates            | 11150       |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | 1.2613453   |\n",
      "|    std                  | 3.32        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1117        |\n",
      "|    time_elapsed         | 20448       |\n",
      "|    total_timesteps      | 2287616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005064119 |\n",
      "|    clip_fraction        | 0.0235      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 11160       |\n",
      "|    policy_gradient_loss | -0.00154    |\n",
      "|    reward               | -0.8040306  |\n",
      "|    std                  | 3.32        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1118         |\n",
      "|    time_elapsed         | 20466        |\n",
      "|    total_timesteps      | 2289664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067463163 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.6        |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.21         |\n",
      "|    n_updates            | 11170        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    reward               | 0.64272135   |\n",
      "|    std                  | 3.32         |\n",
      "|    value_loss           | 12.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1119       |\n",
      "|    time_elapsed         | 20485      |\n",
      "|    total_timesteps      | 2291712    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01887516 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.7      |\n",
      "|    explained_variance   | 0.816      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.78       |\n",
      "|    n_updates            | 11180      |\n",
      "|    policy_gradient_loss | -0.00459   |\n",
      "|    reward               | 0.36971655 |\n",
      "|    std                  | 3.33       |\n",
      "|    value_loss           | 23.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1120        |\n",
      "|    time_elapsed         | 20503       |\n",
      "|    total_timesteps      | 2293760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010365697 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 11190       |\n",
      "|    policy_gradient_loss | -0.000697   |\n",
      "|    reward               | 1.7420193   |\n",
      "|    std                  | 3.33        |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1121        |\n",
      "|    time_elapsed         | 20520       |\n",
      "|    total_timesteps      | 2295808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008351768 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.98        |\n",
      "|    n_updates            | 11200       |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    reward               | -3.2557194  |\n",
      "|    std                  | 3.33        |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1122        |\n",
      "|    time_elapsed         | 20539       |\n",
      "|    total_timesteps      | 2297856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013815092 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.49        |\n",
      "|    n_updates            | 11210       |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    reward               | 0.16922246  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1123        |\n",
      "|    time_elapsed         | 20556       |\n",
      "|    total_timesteps      | 2299904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013676424 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 11220       |\n",
      "|    policy_gradient_loss | -0.000747   |\n",
      "|    reward               | 0.19286962  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1124        |\n",
      "|    time_elapsed         | 20575       |\n",
      "|    total_timesteps      | 2301952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009684281 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 11230       |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    reward               | -1.2700436  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1125        |\n",
      "|    time_elapsed         | 20593       |\n",
      "|    total_timesteps      | 2304000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018283164 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.64        |\n",
      "|    n_updates            | 11240       |\n",
      "|    policy_gradient_loss | 0.000738    |\n",
      "|    reward               | 0.078651205 |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 11.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1126        |\n",
      "|    time_elapsed         | 20610       |\n",
      "|    total_timesteps      | 2306048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010120319 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.1         |\n",
      "|    n_updates            | 11250       |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    reward               | 0.9148669   |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1127        |\n",
      "|    time_elapsed         | 20629       |\n",
      "|    total_timesteps      | 2308096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004818371 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 11260       |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    reward               | -3.12624    |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1128        |\n",
      "|    time_elapsed         | 20647       |\n",
      "|    total_timesteps      | 2310144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014152139 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.4         |\n",
      "|    n_updates            | 11270       |\n",
      "|    policy_gradient_loss | 0.00382     |\n",
      "|    reward               | 1.4029242   |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3308212.61\n",
      "total_reward: 2308212.61\n",
      "total_cost: 41083.80\n",
      "total_trades: 50910\n",
      "Sharpe: 0.688\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1129       |\n",
      "|    time_elapsed         | 20665      |\n",
      "|    total_timesteps      | 2312192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01107603 |\n",
      "|    clip_fraction        | 0.0864     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.9      |\n",
      "|    explained_variance   | 0.812      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.56       |\n",
      "|    n_updates            | 11280      |\n",
      "|    policy_gradient_loss | -0.00148   |\n",
      "|    reward               | -2.4286172 |\n",
      "|    std                  | 3.35       |\n",
      "|    value_loss           | 19.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1130        |\n",
      "|    time_elapsed         | 20683       |\n",
      "|    total_timesteps      | 2314240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014620566 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 11290       |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    reward               | -2.5058768  |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1131        |\n",
      "|    time_elapsed         | 20701       |\n",
      "|    total_timesteps      | 2316288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005838885 |\n",
      "|    clip_fraction        | 0.0603      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 11300       |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    reward               | 2.0555534   |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1132        |\n",
      "|    time_elapsed         | 20718       |\n",
      "|    total_timesteps      | 2318336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010238668 |\n",
      "|    clip_fraction        | 0.0791      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.12        |\n",
      "|    n_updates            | 11310       |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    reward               | 0.38628808  |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1133         |\n",
      "|    time_elapsed         | 20736        |\n",
      "|    total_timesteps      | 2320384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0150625985 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76          |\n",
      "|    explained_variance   | 0.761        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 11320        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | 0.056525026  |\n",
      "|    std                  | 3.36         |\n",
      "|    value_loss           | 21.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1134        |\n",
      "|    time_elapsed         | 20754       |\n",
      "|    total_timesteps      | 2322432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009626612 |\n",
      "|    clip_fraction        | 0.0467      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76         |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 11330       |\n",
      "|    policy_gradient_loss | -0.000735   |\n",
      "|    reward               | -2.0251985  |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1135        |\n",
      "|    time_elapsed         | 20772       |\n",
      "|    total_timesteps      | 2324480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005657837 |\n",
      "|    clip_fraction        | 0.0123      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76         |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.62        |\n",
      "|    n_updates            | 11340       |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    reward               | -0.2910911  |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1136        |\n",
      "|    time_elapsed         | 20790       |\n",
      "|    total_timesteps      | 2326528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014958259 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76         |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 11350       |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | 1.2140456   |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 19.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1137        |\n",
      "|    time_elapsed         | 20808       |\n",
      "|    total_timesteps      | 2328576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022365052 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7           |\n",
      "|    n_updates            | 11360       |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    reward               | -2.2720337  |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1138        |\n",
      "|    time_elapsed         | 20826       |\n",
      "|    total_timesteps      | 2330624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020490263 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.58        |\n",
      "|    n_updates            | 11370       |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    reward               | 1.6596358   |\n",
      "|    std                  | 3.38        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1139        |\n",
      "|    time_elapsed         | 20844       |\n",
      "|    total_timesteps      | 2332672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024588704 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.69        |\n",
      "|    n_updates            | 11380       |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    reward               | -0.43493575 |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1140        |\n",
      "|    time_elapsed         | 20862       |\n",
      "|    total_timesteps      | 2334720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019061822 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.52        |\n",
      "|    n_updates            | 11390       |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    reward               | -1.057489   |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1141        |\n",
      "|    time_elapsed         | 20880       |\n",
      "|    total_timesteps      | 2336768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007209632 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.98        |\n",
      "|    n_updates            | 11400       |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    reward               | 1.0802982   |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1142        |\n",
      "|    time_elapsed         | 20899       |\n",
      "|    total_timesteps      | 2338816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022124102 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.55        |\n",
      "|    n_updates            | 11410       |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    reward               | -3.1643775  |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3525312.91\n",
      "total_reward: 2525312.91\n",
      "total_cost: 54276.14\n",
      "total_trades: 52285\n",
      "Sharpe: 0.709\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1143        |\n",
      "|    time_elapsed         | 20918       |\n",
      "|    total_timesteps      | 2340864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016777266 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.79        |\n",
      "|    n_updates            | 11420       |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    reward               | -0.8657943  |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1144        |\n",
      "|    time_elapsed         | 20936       |\n",
      "|    total_timesteps      | 2342912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010112129 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 11430       |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    reward               | -1.8734131  |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1145        |\n",
      "|    time_elapsed         | 20954       |\n",
      "|    total_timesteps      | 2344960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010251029 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.97        |\n",
      "|    n_updates            | 11440       |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | -0.42796862 |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1146        |\n",
      "|    time_elapsed         | 20972       |\n",
      "|    total_timesteps      | 2347008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019018508 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 11450       |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    reward               | 0.3054146   |\n",
      "|    std                  | 3.41        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1147         |\n",
      "|    time_elapsed         | 20990        |\n",
      "|    total_timesteps      | 2349056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094722295 |\n",
      "|    clip_fraction        | 0.0498       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.5        |\n",
      "|    explained_variance   | 0.733        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.79         |\n",
      "|    n_updates            | 11460        |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    reward               | 13.241101    |\n",
      "|    std                  | 3.41         |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1148        |\n",
      "|    time_elapsed         | 21008       |\n",
      "|    total_timesteps      | 2351104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012025167 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.784       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 11470       |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    reward               | 0.73236567  |\n",
      "|    std                  | 3.41        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1149        |\n",
      "|    time_elapsed         | 21026       |\n",
      "|    total_timesteps      | 2353152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014996371 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.9         |\n",
      "|    n_updates            | 11480       |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    reward               | 3.2211864   |\n",
      "|    std                  | 3.42        |\n",
      "|    value_loss           | 13.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1150        |\n",
      "|    time_elapsed         | 21044       |\n",
      "|    total_timesteps      | 2355200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019969618 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 11490       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | 0.8731592   |\n",
      "|    std                  | 3.43        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1151         |\n",
      "|    time_elapsed         | 21063        |\n",
      "|    total_timesteps      | 2357248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016785982 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.6        |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 11500        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    reward               | -4.30339     |\n",
      "|    std                  | 3.43         |\n",
      "|    value_loss           | 32.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1152        |\n",
      "|    time_elapsed         | 21080       |\n",
      "|    total_timesteps      | 2359296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010037344 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.97        |\n",
      "|    n_updates            | 11510       |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | 5.879725    |\n",
      "|    std                  | 3.43        |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1153        |\n",
      "|    time_elapsed         | 21099       |\n",
      "|    total_timesteps      | 2361344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015412483 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.47        |\n",
      "|    n_updates            | 11520       |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | -6.0549293  |\n",
      "|    std                  | 3.43        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1154       |\n",
      "|    time_elapsed         | 21117      |\n",
      "|    total_timesteps      | 2363392    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01478827 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.6      |\n",
      "|    explained_variance   | 0.793      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.3       |\n",
      "|    n_updates            | 11530      |\n",
      "|    policy_gradient_loss | -0.00033   |\n",
      "|    reward               | 1.5512064  |\n",
      "|    std                  | 3.44       |\n",
      "|    value_loss           | 29.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1155         |\n",
      "|    time_elapsed         | 21135        |\n",
      "|    total_timesteps      | 2365440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116715375 |\n",
      "|    clip_fraction        | 0.0854       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.7        |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 11540        |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    reward               | -0.9891798   |\n",
      "|    std                  | 3.44         |\n",
      "|    value_loss           | 24.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1156        |\n",
      "|    time_elapsed         | 21153       |\n",
      "|    total_timesteps      | 2367488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004718475 |\n",
      "|    clip_fraction        | 0.0286      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.4         |\n",
      "|    n_updates            | 11550       |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | 0.60611886  |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3275460.15\n",
      "total_reward: 2275460.15\n",
      "total_cost: 55821.63\n",
      "total_trades: 51846\n",
      "Sharpe: 0.674\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1157         |\n",
      "|    time_elapsed         | 21171        |\n",
      "|    total_timesteps      | 2369536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077406163 |\n",
      "|    clip_fraction        | 0.0862       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.7        |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 11560        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | 0.4968933    |\n",
      "|    std                  | 3.44         |\n",
      "|    value_loss           | 28.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1158        |\n",
      "|    time_elapsed         | 21189       |\n",
      "|    total_timesteps      | 2371584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008577186 |\n",
      "|    clip_fraction        | 0.0613      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 11570       |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    reward               | 2.848083    |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1159        |\n",
      "|    time_elapsed         | 21207       |\n",
      "|    total_timesteps      | 2373632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011528873 |\n",
      "|    clip_fraction        | 0.0974      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.48        |\n",
      "|    n_updates            | 11580       |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    reward               | -1.1140367  |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1160        |\n",
      "|    time_elapsed         | 21226       |\n",
      "|    total_timesteps      | 2375680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013373359 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.43        |\n",
      "|    n_updates            | 11590       |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    reward               | 0.46607497  |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1161       |\n",
      "|    time_elapsed         | 21244      |\n",
      "|    total_timesteps      | 2377728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00627956 |\n",
      "|    clip_fraction        | 0.0859     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.8      |\n",
      "|    explained_variance   | 0.759      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.5       |\n",
      "|    n_updates            | 11600      |\n",
      "|    policy_gradient_loss | -0.0035    |\n",
      "|    reward               | 0.4191407  |\n",
      "|    std                  | 3.45       |\n",
      "|    value_loss           | 30.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1162        |\n",
      "|    time_elapsed         | 21262       |\n",
      "|    total_timesteps      | 2379776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012807709 |\n",
      "|    clip_fraction        | 0.0691      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.9         |\n",
      "|    n_updates            | 11610       |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    reward               | 3.0930076   |\n",
      "|    std                  | 3.46        |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1163        |\n",
      "|    time_elapsed         | 21280       |\n",
      "|    total_timesteps      | 2381824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017499939 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.67        |\n",
      "|    n_updates            | 11620       |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    reward               | 0.5750819   |\n",
      "|    std                  | 3.46        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1164        |\n",
      "|    time_elapsed         | 21298       |\n",
      "|    total_timesteps      | 2383872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016807375 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 11630       |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    reward               | -0.5435704  |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1165         |\n",
      "|    time_elapsed         | 21316        |\n",
      "|    total_timesteps      | 2385920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043593096 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.9        |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 11640        |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    reward               | 1.121769     |\n",
      "|    std                  | 3.47         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1166       |\n",
      "|    time_elapsed         | 21334      |\n",
      "|    total_timesteps      | 2387968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01566537 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.9      |\n",
      "|    explained_variance   | 0.732      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.41       |\n",
      "|    n_updates            | 11650      |\n",
      "|    policy_gradient_loss | -0.00495   |\n",
      "|    reward               | -1.2360867 |\n",
      "|    std                  | 3.47       |\n",
      "|    value_loss           | 11.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1167        |\n",
      "|    time_elapsed         | 21353       |\n",
      "|    total_timesteps      | 2390016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009184982 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.8         |\n",
      "|    n_updates            | 11660       |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    reward               | -0.99994534 |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1168        |\n",
      "|    time_elapsed         | 21372       |\n",
      "|    total_timesteps      | 2392064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008054683 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 11670       |\n",
      "|    policy_gradient_loss | -0.000942   |\n",
      "|    reward               | 3.406212    |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1169        |\n",
      "|    time_elapsed         | 21391       |\n",
      "|    total_timesteps      | 2394112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015659656 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.76        |\n",
      "|    n_updates            | 11680       |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    reward               | 3.0812657   |\n",
      "|    std                  | 3.48        |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1170        |\n",
      "|    time_elapsed         | 21410       |\n",
      "|    total_timesteps      | 2396160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017412465 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.1         |\n",
      "|    n_updates            | 11690       |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    reward               | 1.3376      |\n",
      "|    std                  | 3.48        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1171        |\n",
      "|    time_elapsed         | 21428       |\n",
      "|    total_timesteps      | 2398208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008503701 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 11700       |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    reward               | -3.0321858  |\n",
      "|    std                  | 3.48        |\n",
      "|    value_loss           | 58.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3407855.93\n",
      "total_reward: 2407855.93\n",
      "total_cost: 55484.12\n",
      "total_trades: 51779\n",
      "Sharpe: 0.681\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1172         |\n",
      "|    time_elapsed         | 21446        |\n",
      "|    total_timesteps      | 2400256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020904434 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77          |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 11710        |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    reward               | 0.82410824   |\n",
      "|    std                  | 3.48         |\n",
      "|    value_loss           | 31.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1173        |\n",
      "|    time_elapsed         | 21464       |\n",
      "|    total_timesteps      | 2402304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027013749 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.86        |\n",
      "|    n_updates            | 11720       |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    reward               | 1.3844378   |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1174        |\n",
      "|    time_elapsed         | 21482       |\n",
      "|    total_timesteps      | 2404352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009751596 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 11730       |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | -1.0356805  |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1175        |\n",
      "|    time_elapsed         | 21500       |\n",
      "|    total_timesteps      | 2406400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005708521 |\n",
      "|    clip_fraction        | 0.0349      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.66        |\n",
      "|    n_updates            | 11740       |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    reward               | -2.1496572  |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1176        |\n",
      "|    time_elapsed         | 21518       |\n",
      "|    total_timesteps      | 2408448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019327331 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | -0.306      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 11750       |\n",
      "|    policy_gradient_loss | 0.00145     |\n",
      "|    reward               | -0.5580655  |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1177       |\n",
      "|    time_elapsed         | 21537      |\n",
      "|    total_timesteps      | 2410496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04043573 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.1      |\n",
      "|    explained_variance   | -0.0697    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 117        |\n",
      "|    n_updates            | 11760      |\n",
      "|    policy_gradient_loss | -0.00287   |\n",
      "|    reward               | 1.8368815  |\n",
      "|    std                  | 3.5        |\n",
      "|    value_loss           | 159        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1178        |\n",
      "|    time_elapsed         | 21555       |\n",
      "|    total_timesteps      | 2412544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029276568 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | -0.00746    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96          |\n",
      "|    n_updates            | 11770       |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    reward               | -4.5616484  |\n",
      "|    std                  | 3.5         |\n",
      "|    value_loss           | 220         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1179        |\n",
      "|    time_elapsed         | 21573       |\n",
      "|    total_timesteps      | 2414592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021787994 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 11780       |\n",
      "|    policy_gradient_loss | 0.00107     |\n",
      "|    reward               | 2.8294697   |\n",
      "|    std                  | 3.5         |\n",
      "|    value_loss           | 40.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1180        |\n",
      "|    time_elapsed         | 21591       |\n",
      "|    total_timesteps      | 2416640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027087277 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.9         |\n",
      "|    n_updates            | 11790       |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    reward               | 0.065479696 |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1181        |\n",
      "|    time_elapsed         | 21609       |\n",
      "|    total_timesteps      | 2418688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019816708 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 11800       |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    reward               | -0.04020892 |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 1182      |\n",
      "|    time_elapsed         | 21627     |\n",
      "|    total_timesteps      | 2420736   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0156549 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -77.3     |\n",
      "|    explained_variance   | 0.0359    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 42.3      |\n",
      "|    n_updates            | 11810     |\n",
      "|    policy_gradient_loss | -0.00677  |\n",
      "|    reward               | 1.4980471 |\n",
      "|    std                  | 3.52      |\n",
      "|    value_loss           | 251       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1183        |\n",
      "|    time_elapsed         | 21646       |\n",
      "|    total_timesteps      | 2422784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032950886 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.4       |\n",
      "|    explained_variance   | -0.0423     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 11820       |\n",
      "|    policy_gradient_loss | 0.00537     |\n",
      "|    reward               | -2.5692976  |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1184       |\n",
      "|    time_elapsed         | 21664      |\n",
      "|    total_timesteps      | 2424832    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01647793 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.4      |\n",
      "|    explained_variance   | 0.0545     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.4       |\n",
      "|    n_updates            | 11830      |\n",
      "|    policy_gradient_loss | -0.00754   |\n",
      "|    reward               | 0.1230591  |\n",
      "|    std                  | 3.53       |\n",
      "|    value_loss           | 194        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1185        |\n",
      "|    time_elapsed         | 21683       |\n",
      "|    total_timesteps      | 2426880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009973879 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.4       |\n",
      "|    explained_variance   | 0.0593      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.2        |\n",
      "|    n_updates            | 11840       |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    reward               | 0.10582515  |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3914531.57\n",
      "total_reward: 2914531.57\n",
      "total_cost: 111246.47\n",
      "total_trades: 56125\n",
      "Sharpe: 0.749\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1186        |\n",
      "|    time_elapsed         | 21701       |\n",
      "|    total_timesteps      | 2428928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019267246 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.5       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 11850       |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    reward               | -0.5330056  |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1187        |\n",
      "|    time_elapsed         | 21720       |\n",
      "|    total_timesteps      | 2430976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022625448 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.6       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 11860       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -1.0438709  |\n",
      "|    std                  | 3.55        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1188        |\n",
      "|    time_elapsed         | 21739       |\n",
      "|    total_timesteps      | 2433024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008911921 |\n",
      "|    clip_fraction        | 0.0379      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.6       |\n",
      "|    explained_variance   | 0.0465      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 159         |\n",
      "|    n_updates            | 11870       |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    reward               | -0.5400986  |\n",
      "|    std                  | 3.55        |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1189        |\n",
      "|    time_elapsed         | 21758       |\n",
      "|    total_timesteps      | 2435072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010245055 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.6       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 11880       |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    reward               | 0.32189205  |\n",
      "|    std                  | 3.55        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1190        |\n",
      "|    time_elapsed         | 21778       |\n",
      "|    total_timesteps      | 2437120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024565864 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | -0.0478     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.79        |\n",
      "|    n_updates            | 11890       |\n",
      "|    policy_gradient_loss | -0.0021     |\n",
      "|    reward               | 1.1502281   |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1191        |\n",
      "|    time_elapsed         | 21796       |\n",
      "|    total_timesteps      | 2439168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023252212 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 11900       |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    reward               | -1.882147   |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 61.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1192        |\n",
      "|    time_elapsed         | 21814       |\n",
      "|    total_timesteps      | 2441216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01795287  |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | 0.0538      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 11910       |\n",
      "|    policy_gradient_loss | 0.00138     |\n",
      "|    reward               | -0.42835882 |\n",
      "|    std                  | 3.57        |\n",
      "|    value_loss           | 235         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1193        |\n",
      "|    time_elapsed         | 21832       |\n",
      "|    total_timesteps      | 2443264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027500253 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.8       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.53        |\n",
      "|    n_updates            | 11920       |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    reward               | 0.7664093   |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1194        |\n",
      "|    time_elapsed         | 21850       |\n",
      "|    total_timesteps      | 2445312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027031353 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.8       |\n",
      "|    explained_variance   | 0.0422      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 11930       |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    reward               | 0.67514014  |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1195       |\n",
      "|    time_elapsed         | 21868      |\n",
      "|    total_timesteps      | 2447360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02511283 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.9      |\n",
      "|    explained_variance   | 0.19       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.4       |\n",
      "|    n_updates            | 11940      |\n",
      "|    policy_gradient_loss | -0.00625   |\n",
      "|    reward               | 0.9408297  |\n",
      "|    std                  | 3.59       |\n",
      "|    value_loss           | 36.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1196        |\n",
      "|    time_elapsed         | 21887       |\n",
      "|    total_timesteps      | 2449408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01687095  |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.54        |\n",
      "|    n_updates            | 11950       |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    reward               | 0.017618164 |\n",
      "|    std                  | 3.59        |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1197        |\n",
      "|    time_elapsed         | 21907       |\n",
      "|    total_timesteps      | 2451456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024446603 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | 0.0538      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.22        |\n",
      "|    n_updates            | 11960       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 0.15789782  |\n",
      "|    std                  | 3.6         |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1198        |\n",
      "|    time_elapsed         | 21925       |\n",
      "|    total_timesteps      | 2453504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019870846 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.0296      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.5        |\n",
      "|    n_updates            | 11970       |\n",
      "|    policy_gradient_loss | -0.00894    |\n",
      "|    reward               | -0.6800512  |\n",
      "|    std                  | 3.6         |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1199        |\n",
      "|    time_elapsed         | 21943       |\n",
      "|    total_timesteps      | 2455552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016688626 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.0057      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 11980       |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    reward               | -17.105862  |\n",
      "|    std                  | 3.6         |\n",
      "|    value_loss           | 230         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3714979.26\n",
      "total_reward: 2714979.26\n",
      "total_cost: 128839.71\n",
      "total_trades: 57815\n",
      "Sharpe: 0.726\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1200        |\n",
      "|    time_elapsed         | 21962       |\n",
      "|    total_timesteps      | 2457600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021816298 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 11990       |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    reward               | 3.7634823   |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1201        |\n",
      "|    time_elapsed         | 21980       |\n",
      "|    total_timesteps      | 2459648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011505561 |\n",
      "|    clip_fraction        | 0.0782      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.95        |\n",
      "|    n_updates            | 12000       |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | 0.8606982   |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1202        |\n",
      "|    time_elapsed         | 21999       |\n",
      "|    total_timesteps      | 2461696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026117027 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.0467      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.3        |\n",
      "|    n_updates            | 12010       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 0.8049951   |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1203        |\n",
      "|    time_elapsed         | 22017       |\n",
      "|    total_timesteps      | 2463744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024587952 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.7        |\n",
      "|    n_updates            | 12020       |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    reward               | 4.4801307   |\n",
      "|    std                  | 3.63        |\n",
      "|    value_loss           | 64.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1204       |\n",
      "|    time_elapsed         | 22035      |\n",
      "|    total_timesteps      | 2465792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02320543 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.2      |\n",
      "|    explained_variance   | 0.0518     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 51.3       |\n",
      "|    n_updates            | 12030      |\n",
      "|    policy_gradient_loss | -0.0032    |\n",
      "|    reward               | 1.2708099  |\n",
      "|    std                  | 3.63       |\n",
      "|    value_loss           | 175        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1205        |\n",
      "|    time_elapsed         | 22053       |\n",
      "|    total_timesteps      | 2467840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018467866 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.0441      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.6        |\n",
      "|    n_updates            | 12040       |\n",
      "|    policy_gradient_loss | 0.00308     |\n",
      "|    reward               | -0.09902686 |\n",
      "|    std                  | 3.63        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1206        |\n",
      "|    time_elapsed         | 22072       |\n",
      "|    total_timesteps      | 2469888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016978549 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 12050       |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | 0.884964    |\n",
      "|    std                  | 3.64        |\n",
      "|    value_loss           | 57.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1207        |\n",
      "|    time_elapsed         | 22090       |\n",
      "|    total_timesteps      | 2471936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02565281  |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.13        |\n",
      "|    n_updates            | 12060       |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    reward               | -0.36961043 |\n",
      "|    std                  | 3.64        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1208        |\n",
      "|    time_elapsed         | 22108       |\n",
      "|    total_timesteps      | 2473984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016893284 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 12070       |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    reward               | -0.95027196 |\n",
      "|    std                  | 3.65        |\n",
      "|    value_loss           | 46.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1209        |\n",
      "|    time_elapsed         | 22126       |\n",
      "|    total_timesteps      | 2476032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015518632 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.026       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.6        |\n",
      "|    n_updates            | 12080       |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    reward               | -4.918458   |\n",
      "|    std                  | 3.65        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1210        |\n",
      "|    time_elapsed         | 22144       |\n",
      "|    total_timesteps      | 2478080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016832035 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 12090       |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    reward               | -4.522012   |\n",
      "|    std                  | 3.65        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1211        |\n",
      "|    time_elapsed         | 22162       |\n",
      "|    total_timesteps      | 2480128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017431004 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 12100       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | 0.9020268   |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1212        |\n",
      "|    time_elapsed         | 22180       |\n",
      "|    total_timesteps      | 2482176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023239944 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 12110       |\n",
      "|    policy_gradient_loss | 0.00327     |\n",
      "|    reward               | 1.5158371   |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1213         |\n",
      "|    time_elapsed         | 22198        |\n",
      "|    total_timesteps      | 2484224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134554785 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -78.5        |\n",
      "|    explained_variance   | 0.248        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.3         |\n",
      "|    n_updates            | 12120        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | -1.3695492   |\n",
      "|    std                  | 3.67         |\n",
      "|    value_loss           | 47.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3669460.31\n",
      "total_reward: 2669460.31\n",
      "total_cost: 177714.56\n",
      "total_trades: 61052\n",
      "Sharpe: 0.728\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1214        |\n",
      "|    time_elapsed         | 22216       |\n",
      "|    total_timesteps      | 2486272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021868002 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.25        |\n",
      "|    n_updates            | 12130       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 1.9672183   |\n",
      "|    std                  | 3.67        |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1215       |\n",
      "|    time_elapsed         | 22234      |\n",
      "|    total_timesteps      | 2488320    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02098023 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.6      |\n",
      "|    explained_variance   | 0.358      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19         |\n",
      "|    n_updates            | 12140      |\n",
      "|    policy_gradient_loss | -0.00978   |\n",
      "|    reward               | -1.4360708 |\n",
      "|    std                  | 3.68       |\n",
      "|    value_loss           | 40.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1216        |\n",
      "|    time_elapsed         | 22252       |\n",
      "|    total_timesteps      | 2490368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026071636 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.6       |\n",
      "|    explained_variance   | 0.00852     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 12150       |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    reward               | 1.4598644   |\n",
      "|    std                  | 3.68        |\n",
      "|    value_loss           | 95.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1217        |\n",
      "|    time_elapsed         | 22270       |\n",
      "|    total_timesteps      | 2492416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018873997 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.35        |\n",
      "|    n_updates            | 12160       |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | 0.9671683   |\n",
      "|    std                  | 3.68        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1218        |\n",
      "|    time_elapsed         | 22288       |\n",
      "|    total_timesteps      | 2494464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018759586 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 12170       |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    reward               | 3.952902    |\n",
      "|    std                  | 3.69        |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1219        |\n",
      "|    time_elapsed         | 22306       |\n",
      "|    total_timesteps      | 2496512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018696336 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.1        |\n",
      "|    n_updates            | 12180       |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    reward               | -0.8224323  |\n",
      "|    std                  | 3.7         |\n",
      "|    value_loss           | 82          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1220       |\n",
      "|    time_elapsed         | 22324      |\n",
      "|    total_timesteps      | 2498560    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02001226 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.9      |\n",
      "|    explained_variance   | 0.331      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15         |\n",
      "|    n_updates            | 12190      |\n",
      "|    policy_gradient_loss | -0.00764   |\n",
      "|    reward               | 1.0754304  |\n",
      "|    std                  | 3.71       |\n",
      "|    value_loss           | 35.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1221        |\n",
      "|    time_elapsed         | 22342       |\n",
      "|    total_timesteps      | 2500608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018776722 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.9       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 12200       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | 0.2885641   |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1222        |\n",
      "|    time_elapsed         | 22360       |\n",
      "|    total_timesteps      | 2502656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015747622 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.9       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 12210       |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    reward               | 0.12019131  |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 54.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1223        |\n",
      "|    time_elapsed         | 22378       |\n",
      "|    total_timesteps      | 2504704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014222428 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 12220       |\n",
      "|    policy_gradient_loss | -0.00222    |\n",
      "|    reward               | -0.96261096 |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 72.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1224        |\n",
      "|    time_elapsed         | 22396       |\n",
      "|    total_timesteps      | 2506752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019012563 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.9         |\n",
      "|    n_updates            | 12230       |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    reward               | -0.15549406 |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1225        |\n",
      "|    time_elapsed         | 22414       |\n",
      "|    total_timesteps      | 2508800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015372681 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.1       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 12240       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 1.2690914   |\n",
      "|    std                  | 3.74        |\n",
      "|    value_loss           | 45.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1226        |\n",
      "|    time_elapsed         | 22432       |\n",
      "|    total_timesteps      | 2510848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009167213 |\n",
      "|    clip_fraction        | 0.0536      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.1       |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40          |\n",
      "|    n_updates            | 12250       |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | -12.10817   |\n",
      "|    std                  | 3.74        |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1227       |\n",
      "|    time_elapsed         | 22450      |\n",
      "|    total_timesteps      | 2512896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03049944 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -79.1      |\n",
      "|    explained_variance   | 0.589      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.1       |\n",
      "|    n_updates            | 12260      |\n",
      "|    policy_gradient_loss | -0.002     |\n",
      "|    reward               | 1.1040218  |\n",
      "|    std                  | 3.75       |\n",
      "|    value_loss           | 28.3       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3537859.82\n",
      "total_reward: 2537859.82\n",
      "total_cost: 93842.81\n",
      "total_trades: 55431\n",
      "Sharpe: 0.719\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1228        |\n",
      "|    time_elapsed         | 22468       |\n",
      "|    total_timesteps      | 2514944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012505267 |\n",
      "|    clip_fraction        | 0.0834      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.2       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.74        |\n",
      "|    n_updates            | 12270       |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    reward               | 2.3747668   |\n",
      "|    std                  | 3.75        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1229        |\n",
      "|    time_elapsed         | 22487       |\n",
      "|    total_timesteps      | 2516992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021177221 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.2       |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 12280       |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    reward               | -0.08218585 |\n",
      "|    std                  | 3.76        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1230        |\n",
      "|    time_elapsed         | 22505       |\n",
      "|    total_timesteps      | 2519040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010813938 |\n",
      "|    clip_fraction        | 0.0935      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 12290       |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    reward               | -0.28218654 |\n",
      "|    std                  | 3.77        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1231        |\n",
      "|    time_elapsed         | 22523       |\n",
      "|    total_timesteps      | 2521088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015304659 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.93        |\n",
      "|    n_updates            | 12300       |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    reward               | 3.1766827   |\n",
      "|    std                  | 3.78        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1232        |\n",
      "|    time_elapsed         | 22541       |\n",
      "|    total_timesteps      | 2523136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013721738 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 12310       |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    reward               | -0.14537138 |\n",
      "|    std                  | 3.78        |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1233        |\n",
      "|    time_elapsed         | 22559       |\n",
      "|    total_timesteps      | 2525184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008233381 |\n",
      "|    clip_fraction        | 0.0861      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 12320       |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    reward               | 3.0999491   |\n",
      "|    std                  | 3.78        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1234       |\n",
      "|    time_elapsed         | 22577      |\n",
      "|    total_timesteps      | 2527232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01904953 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -79.4      |\n",
      "|    explained_variance   | 0.566      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.5       |\n",
      "|    n_updates            | 12330      |\n",
      "|    policy_gradient_loss | -0.00285   |\n",
      "|    reward               | 0.93284595 |\n",
      "|    std                  | 3.78       |\n",
      "|    value_loss           | 18.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1235        |\n",
      "|    time_elapsed         | 22595       |\n",
      "|    total_timesteps      | 2529280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010049572 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.25        |\n",
      "|    n_updates            | 12340       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    reward               | -0.2808415  |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 19.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1236         |\n",
      "|    time_elapsed         | 22613        |\n",
      "|    total_timesteps      | 2531328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054009454 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.4        |\n",
      "|    explained_variance   | 0.392        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.5         |\n",
      "|    n_updates            | 12350        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | -1.450778    |\n",
      "|    std                  | 3.78         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1237         |\n",
      "|    time_elapsed         | 22632        |\n",
      "|    total_timesteps      | 2533376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043192618 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.4        |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 12360        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | 1.328879     |\n",
      "|    std                  | 3.79         |\n",
      "|    value_loss           | 30.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1238        |\n",
      "|    time_elapsed         | 22651       |\n",
      "|    total_timesteps      | 2535424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025388699 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.22        |\n",
      "|    n_updates            | 12370       |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    reward               | -0.04187217 |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1239        |\n",
      "|    time_elapsed         | 22669       |\n",
      "|    total_timesteps      | 2537472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013664775 |\n",
      "|    clip_fraction        | 0.079       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.5       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 12380       |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | 0.4630727   |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1240        |\n",
      "|    time_elapsed         | 22687       |\n",
      "|    total_timesteps      | 2539520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008149842 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.5       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 12390       |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    reward               | -2.6111586  |\n",
      "|    std                  | 3.8         |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1241        |\n",
      "|    time_elapsed         | 22705       |\n",
      "|    total_timesteps      | 2541568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016946048 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.54        |\n",
      "|    n_updates            | 12400       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 2.4338562   |\n",
      "|    std                  | 3.81        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3328807.84\n",
      "total_reward: 2328807.84\n",
      "total_cost: 74566.10\n",
      "total_trades: 53939\n",
      "Sharpe: 0.700\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1242        |\n",
      "|    time_elapsed         | 22723       |\n",
      "|    total_timesteps      | 2543616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012766475 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.95        |\n",
      "|    n_updates            | 12410       |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    reward               | 2.450769    |\n",
      "|    std                  | 3.81        |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1243        |\n",
      "|    time_elapsed         | 22741       |\n",
      "|    total_timesteps      | 2545664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014685495 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 12420       |\n",
      "|    policy_gradient_loss | 0.00142     |\n",
      "|    reward               | -15.14622   |\n",
      "|    std                  | 3.81        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1244        |\n",
      "|    time_elapsed         | 22760       |\n",
      "|    total_timesteps      | 2547712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010659067 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.74        |\n",
      "|    n_updates            | 12430       |\n",
      "|    policy_gradient_loss | -0.000702   |\n",
      "|    reward               | 0.18422069  |\n",
      "|    std                  | 3.82        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1245        |\n",
      "|    time_elapsed         | 22778       |\n",
      "|    total_timesteps      | 2549760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021224976 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.72        |\n",
      "|    n_updates            | 12440       |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | 1.213507    |\n",
      "|    std                  | 3.82        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1246        |\n",
      "|    time_elapsed         | 22796       |\n",
      "|    total_timesteps      | 2551808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008549596 |\n",
      "|    clip_fraction        | 0.0681      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 12450       |\n",
      "|    policy_gradient_loss | -0.00993    |\n",
      "|    reward               | -0.74543524 |\n",
      "|    std                  | 3.82        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1247         |\n",
      "|    time_elapsed         | 22814        |\n",
      "|    total_timesteps      | 2553856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054838266 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.7        |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.81         |\n",
      "|    n_updates            | 12460        |\n",
      "|    policy_gradient_loss | -0.00634     |\n",
      "|    reward               | -1.9334692   |\n",
      "|    std                  | 3.82         |\n",
      "|    value_loss           | 27.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1248        |\n",
      "|    time_elapsed         | 22833       |\n",
      "|    total_timesteps      | 2555904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017607667 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.69        |\n",
      "|    n_updates            | 12470       |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    reward               | 1.140413    |\n",
      "|    std                  | 3.83        |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1249        |\n",
      "|    time_elapsed         | 22851       |\n",
      "|    total_timesteps      | 2557952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022503428 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 12480       |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    reward               | 0.01637229  |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1250         |\n",
      "|    time_elapsed         | 22869        |\n",
      "|    total_timesteps      | 2560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053266296 |\n",
      "|    clip_fraction        | 0.0454       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.9        |\n",
      "|    explained_variance   | 0.258        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 12490        |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | 3.3441799    |\n",
      "|    std                  | 3.85         |\n",
      "|    value_loss           | 41.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1251        |\n",
      "|    time_elapsed         | 22887       |\n",
      "|    total_timesteps      | 2562048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017251292 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.66        |\n",
      "|    n_updates            | 12500       |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    reward               | 4.449259    |\n",
      "|    std                  | 3.85        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1252        |\n",
      "|    time_elapsed         | 22905       |\n",
      "|    total_timesteps      | 2564096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010612199 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.62        |\n",
      "|    n_updates            | 12510       |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    reward               | 2.2386856   |\n",
      "|    std                  | 3.85        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1253        |\n",
      "|    time_elapsed         | 22923       |\n",
      "|    total_timesteps      | 2566144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011362005 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 12520       |\n",
      "|    policy_gradient_loss | -0.00387    |\n",
      "|    reward               | -0.65218943 |\n",
      "|    std                  | 3.85        |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1254        |\n",
      "|    time_elapsed         | 22942       |\n",
      "|    total_timesteps      | 2568192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013785573 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 12530       |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    reward               | -0.20661002 |\n",
      "|    std                  | 3.86        |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1255        |\n",
      "|    time_elapsed         | 22960       |\n",
      "|    total_timesteps      | 2570240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013673471 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.31        |\n",
      "|    n_updates            | 12540       |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | 0.34678766  |\n",
      "|    std                  | 3.86        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3436137.86\n",
      "total_reward: 2436137.86\n",
      "total_cost: 107248.82\n",
      "total_trades: 57445\n",
      "Sharpe: 0.694\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1256       |\n",
      "|    time_elapsed         | 22980      |\n",
      "|    total_timesteps      | 2572288    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01588446 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80        |\n",
      "|    explained_variance   | 0.553      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.6       |\n",
      "|    n_updates            | 12550      |\n",
      "|    policy_gradient_loss | -0.00962   |\n",
      "|    reward               | -0.2993362 |\n",
      "|    std                  | 3.87       |\n",
      "|    value_loss           | 27.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1257         |\n",
      "|    time_elapsed         | 22998        |\n",
      "|    total_timesteps      | 2574336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036334437 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80          |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 12560        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | -0.39937976  |\n",
      "|    std                  | 3.87         |\n",
      "|    value_loss           | 31.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1258        |\n",
      "|    time_elapsed         | 23016       |\n",
      "|    total_timesteps      | 2576384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005397573 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.01        |\n",
      "|    n_updates            | 12570       |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    reward               | 0.13708386  |\n",
      "|    std                  | 3.87        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1259       |\n",
      "|    time_elapsed         | 23035      |\n",
      "|    total_timesteps      | 2578432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0194732  |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.1      |\n",
      "|    explained_variance   | 0.716      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.21       |\n",
      "|    n_updates            | 12580      |\n",
      "|    policy_gradient_loss | -0.00653   |\n",
      "|    reward               | -0.1096049 |\n",
      "|    std                  | 3.88       |\n",
      "|    value_loss           | 16.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1260         |\n",
      "|    time_elapsed         | 23053        |\n",
      "|    total_timesteps      | 2580480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108945025 |\n",
      "|    clip_fraction        | 0.0513       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80.1        |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.98         |\n",
      "|    n_updates            | 12590        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    reward               | 17.138931    |\n",
      "|    std                  | 3.88         |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1261        |\n",
      "|    time_elapsed         | 23071       |\n",
      "|    total_timesteps      | 2582528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010777185 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.28        |\n",
      "|    n_updates            | 12600       |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    reward               | -1.3527796  |\n",
      "|    std                  | 3.88        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1262        |\n",
      "|    time_elapsed         | 23090       |\n",
      "|    total_timesteps      | 2584576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009588078 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.2       |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.64        |\n",
      "|    n_updates            | 12610       |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    reward               | 2.5387104   |\n",
      "|    std                  | 3.89        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1263        |\n",
      "|    time_elapsed         | 23109       |\n",
      "|    total_timesteps      | 2586624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010261962 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.2       |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 12620       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 0.30215564  |\n",
      "|    std                  | 3.89        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1264       |\n",
      "|    time_elapsed         | 23128      |\n",
      "|    total_timesteps      | 2588672    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00931448 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.2      |\n",
      "|    explained_variance   | 0.363      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.9       |\n",
      "|    n_updates            | 12630      |\n",
      "|    policy_gradient_loss | -0.00479   |\n",
      "|    reward               | -5.3904753 |\n",
      "|    std                  | 3.89       |\n",
      "|    value_loss           | 33.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1265        |\n",
      "|    time_elapsed         | 23147       |\n",
      "|    total_timesteps      | 2590720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017237395 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.2       |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.36        |\n",
      "|    n_updates            | 12640       |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | -0.42955822 |\n",
      "|    std                  | 3.9         |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1266        |\n",
      "|    time_elapsed         | 23166       |\n",
      "|    total_timesteps      | 2592768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015324712 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.3       |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.56        |\n",
      "|    n_updates            | 12650       |\n",
      "|    policy_gradient_loss | -0.00262    |\n",
      "|    reward               | 1.0682948   |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1267        |\n",
      "|    time_elapsed         | 23183       |\n",
      "|    total_timesteps      | 2594816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007585888 |\n",
      "|    clip_fraction        | 0.0678      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.3       |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.05        |\n",
      "|    n_updates            | 12660       |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    reward               | -2.4101253  |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1268        |\n",
      "|    time_elapsed         | 23201       |\n",
      "|    total_timesteps      | 2596864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012275044 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.3       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 12670       |\n",
      "|    policy_gradient_loss | -0.0008     |\n",
      "|    reward               | -1.2452897  |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1269        |\n",
      "|    time_elapsed         | 23219       |\n",
      "|    total_timesteps      | 2598912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006703957 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.3       |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.15        |\n",
      "|    n_updates            | 12680       |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | -0.7535525  |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3475725.28\n",
      "total_reward: 2475725.28\n",
      "total_cost: 82978.50\n",
      "total_trades: 54752\n",
      "Sharpe: 0.734\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1270        |\n",
      "|    time_elapsed         | 23236       |\n",
      "|    total_timesteps      | 2600960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014866836 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.38        |\n",
      "|    n_updates            | 12690       |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    reward               | 1.2135879   |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1271        |\n",
      "|    time_elapsed         | 23254       |\n",
      "|    total_timesteps      | 2603008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012004455 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 12700       |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    reward               | 1.0324124   |\n",
      "|    std                  | 3.92        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1272        |\n",
      "|    time_elapsed         | 23273       |\n",
      "|    total_timesteps      | 2605056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026903676 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.18        |\n",
      "|    n_updates            | 12710       |\n",
      "|    policy_gradient_loss | -0.0021     |\n",
      "|    reward               | 0.23382513  |\n",
      "|    std                  | 3.93        |\n",
      "|    value_loss           | 9.83        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1273        |\n",
      "|    time_elapsed         | 23291       |\n",
      "|    total_timesteps      | 2607104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017855441 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.5       |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.02        |\n",
      "|    n_updates            | 12720       |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    reward               | 0.8946147   |\n",
      "|    std                  | 3.93        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1274         |\n",
      "|    time_elapsed         | 23309        |\n",
      "|    total_timesteps      | 2609152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013462135  |\n",
      "|    clip_fraction        | 0.0854       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80.5        |\n",
      "|    explained_variance   | 0.283        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.3         |\n",
      "|    n_updates            | 12730        |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    reward               | -0.031191677 |\n",
      "|    std                  | 3.93         |\n",
      "|    value_loss           | 37.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1275        |\n",
      "|    time_elapsed         | 23328       |\n",
      "|    total_timesteps      | 2611200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012694409 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.32        |\n",
      "|    n_updates            | 12740       |\n",
      "|    policy_gradient_loss | 0.00122     |\n",
      "|    reward               | 2.870359    |\n",
      "|    std                  | 3.94        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1276        |\n",
      "|    time_elapsed         | 23346       |\n",
      "|    total_timesteps      | 2613248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013292482 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.47        |\n",
      "|    n_updates            | 12750       |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    reward               | 1.5077709   |\n",
      "|    std                  | 3.95        |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1277        |\n",
      "|    time_elapsed         | 23365       |\n",
      "|    total_timesteps      | 2615296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017453734 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.7       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.84        |\n",
      "|    n_updates            | 12760       |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    reward               | 0.35336408  |\n",
      "|    std                  | 3.96        |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1278         |\n",
      "|    time_elapsed         | 23382        |\n",
      "|    total_timesteps      | 2617344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046605174 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80.7        |\n",
      "|    explained_variance   | 0.399        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 12770        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    reward               | 0.41857174   |\n",
      "|    std                  | 3.96         |\n",
      "|    value_loss           | 29.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1279        |\n",
      "|    time_elapsed         | 23400       |\n",
      "|    total_timesteps      | 2619392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022041097 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.7       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.36        |\n",
      "|    n_updates            | 12780       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | 0.5676489   |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1280        |\n",
      "|    time_elapsed         | 23419       |\n",
      "|    total_timesteps      | 2621440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01125519  |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.8       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 12790       |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    reward               | 0.044891767 |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1281        |\n",
      "|    time_elapsed         | 23437       |\n",
      "|    total_timesteps      | 2623488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005879085 |\n",
      "|    clip_fraction        | 0.0659      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.8       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.47        |\n",
      "|    n_updates            | 12800       |\n",
      "|    policy_gradient_loss | 0.0015      |\n",
      "|    reward               | 0.92235726  |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1282        |\n",
      "|    time_elapsed         | 23455       |\n",
      "|    total_timesteps      | 2625536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024840897 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.8       |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.42        |\n",
      "|    n_updates            | 12810       |\n",
      "|    policy_gradient_loss | 0.000126    |\n",
      "|    reward               | 0.9553124   |\n",
      "|    std                  | 3.98        |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1283        |\n",
      "|    time_elapsed         | 23473       |\n",
      "|    total_timesteps      | 2627584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012814475 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.9       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 12820       |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    reward               | -3.169069   |\n",
      "|    std                  | 3.99        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1284        |\n",
      "|    time_elapsed         | 23491       |\n",
      "|    total_timesteps      | 2629632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009232532 |\n",
      "|    clip_fraction        | 0.0641      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.9       |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 12830       |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    reward               | -7.2376227  |\n",
      "|    std                  | 3.99        |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3889532.72\n",
      "total_reward: 2889532.72\n",
      "total_cost: 97250.71\n",
      "total_trades: 55305\n",
      "Sharpe: 0.814\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1285       |\n",
      "|    time_elapsed         | 23509      |\n",
      "|    total_timesteps      | 2631680    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00823944 |\n",
      "|    clip_fraction        | 0.0406     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81        |\n",
      "|    explained_variance   | 0.398      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.6       |\n",
      "|    n_updates            | 12840      |\n",
      "|    policy_gradient_loss | -0.00705   |\n",
      "|    reward               | 1.8393412  |\n",
      "|    std                  | 3.99       |\n",
      "|    value_loss           | 25.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1286        |\n",
      "|    time_elapsed         | 23529       |\n",
      "|    total_timesteps      | 2633728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022924608 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.37        |\n",
      "|    n_updates            | 12850       |\n",
      "|    policy_gradient_loss | -0.00104    |\n",
      "|    reward               | 1.776375    |\n",
      "|    std                  | 4           |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1287        |\n",
      "|    time_elapsed         | 23547       |\n",
      "|    total_timesteps      | 2635776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008465655 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 12860       |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    reward               | 0.16780886  |\n",
      "|    std                  | 4           |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1288        |\n",
      "|    time_elapsed         | 23566       |\n",
      "|    total_timesteps      | 2637824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013800457 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 12870       |\n",
      "|    policy_gradient_loss | 0.0133      |\n",
      "|    reward               | 3.8789296   |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1289        |\n",
      "|    time_elapsed         | 23584       |\n",
      "|    total_timesteps      | 2639872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018879864 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.1       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.85        |\n",
      "|    n_updates            | 12880       |\n",
      "|    policy_gradient_loss | -0.000696   |\n",
      "|    reward               | -4.0835557  |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1290         |\n",
      "|    time_elapsed         | 23602        |\n",
      "|    total_timesteps      | 2641920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072465213 |\n",
      "|    clip_fraction        | 0.0709       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81          |\n",
      "|    explained_variance   | 0.407        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 12890        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | -0.21158774  |\n",
      "|    std                  | 4.01         |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1291       |\n",
      "|    time_elapsed         | 23620      |\n",
      "|    total_timesteps      | 2643968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02207864 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.1      |\n",
      "|    explained_variance   | 0.326      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.2       |\n",
      "|    n_updates            | 12900      |\n",
      "|    policy_gradient_loss | 0.0069     |\n",
      "|    reward               | 0.9526352  |\n",
      "|    std                  | 4.01       |\n",
      "|    value_loss           | 24.9       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1292       |\n",
      "|    time_elapsed         | 23639      |\n",
      "|    total_timesteps      | 2646016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00679575 |\n",
      "|    clip_fraction        | 0.0402     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.1      |\n",
      "|    explained_variance   | 0.466      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.36       |\n",
      "|    n_updates            | 12910      |\n",
      "|    policy_gradient_loss | -0.00341   |\n",
      "|    reward               | 0.9648969  |\n",
      "|    std                  | 4.01       |\n",
      "|    value_loss           | 21.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1293        |\n",
      "|    time_elapsed         | 23659       |\n",
      "|    total_timesteps      | 2648064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009957101 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.1       |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 12920       |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | -1.9150796  |\n",
      "|    std                  | 4.02        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1294        |\n",
      "|    time_elapsed         | 23677       |\n",
      "|    total_timesteps      | 2650112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015445048 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.1       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.01        |\n",
      "|    n_updates            | 12930       |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    reward               | 0.14309224  |\n",
      "|    std                  | 4.02        |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1295       |\n",
      "|    time_elapsed         | 23696      |\n",
      "|    total_timesteps      | 2652160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00804225 |\n",
      "|    clip_fraction        | 0.0597     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.1      |\n",
      "|    explained_variance   | 0.439      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.8       |\n",
      "|    n_updates            | 12940      |\n",
      "|    policy_gradient_loss | -0.00271   |\n",
      "|    reward               | -0.9541172 |\n",
      "|    std                  | 4.02       |\n",
      "|    value_loss           | 23.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1296        |\n",
      "|    time_elapsed         | 23715       |\n",
      "|    total_timesteps      | 2654208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011448188 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.53        |\n",
      "|    n_updates            | 12950       |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | -0.07329541 |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 9.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1297        |\n",
      "|    time_elapsed         | 23734       |\n",
      "|    total_timesteps      | 2656256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006167278 |\n",
      "|    clip_fraction        | 0.0431      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.85        |\n",
      "|    n_updates            | 12960       |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    reward               | 2.2042835   |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1298        |\n",
      "|    time_elapsed         | 23753       |\n",
      "|    total_timesteps      | 2658304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022529092 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 12970       |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    reward               | 2.4556782   |\n",
      "|    std                  | 4.05        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3371829.77\n",
      "total_reward: 2371829.77\n",
      "total_cost: 71489.15\n",
      "total_trades: 52392\n",
      "Sharpe: 0.708\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1299        |\n",
      "|    time_elapsed         | 23772       |\n",
      "|    total_timesteps      | 2660352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008648919 |\n",
      "|    clip_fraction        | 0.0866      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 12980       |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | -0.28933737 |\n",
      "|    std                  | 4.05        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1300        |\n",
      "|    time_elapsed         | 23791       |\n",
      "|    total_timesteps      | 2662400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013166279 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.01        |\n",
      "|    n_updates            | 12990       |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    reward               | -0.7584695  |\n",
      "|    std                  | 4.05        |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1301        |\n",
      "|    time_elapsed         | 23809       |\n",
      "|    total_timesteps      | 2664448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005637411 |\n",
      "|    clip_fraction        | 0.0353      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 13000       |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    reward               | -4.4512424  |\n",
      "|    std                  | 4.06        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1302         |\n",
      "|    time_elapsed         | 23827        |\n",
      "|    total_timesteps      | 2666496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069517493 |\n",
      "|    clip_fraction        | 0.0553       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.4        |\n",
      "|    explained_variance   | 0.343        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 13010        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    reward               | 1.724854     |\n",
      "|    std                  | 4.06         |\n",
      "|    value_loss           | 33.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1303        |\n",
      "|    time_elapsed         | 23845       |\n",
      "|    total_timesteps      | 2668544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014141551 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.39        |\n",
      "|    n_updates            | 13020       |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    reward               | -1.7593479  |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 9.52        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1304        |\n",
      "|    time_elapsed         | 23864       |\n",
      "|    total_timesteps      | 2670592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007312604 |\n",
      "|    clip_fraction        | 0.0518      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.12        |\n",
      "|    n_updates            | 13030       |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    reward               | -0.87878025 |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1305        |\n",
      "|    time_elapsed         | 23882       |\n",
      "|    total_timesteps      | 2672640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006413175 |\n",
      "|    clip_fraction        | 0.0394      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 13040       |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    reward               | -1.7905602  |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1306        |\n",
      "|    time_elapsed         | 23900       |\n",
      "|    total_timesteps      | 2674688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009658467 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.75        |\n",
      "|    n_updates            | 13050       |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    reward               | -1.8673211  |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1307        |\n",
      "|    time_elapsed         | 23918       |\n",
      "|    total_timesteps      | 2676736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016350608 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.68        |\n",
      "|    n_updates            | 13060       |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    reward               | 2.226671    |\n",
      "|    std                  | 4.08        |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1308        |\n",
      "|    time_elapsed         | 23937       |\n",
      "|    total_timesteps      | 2678784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016675605 |\n",
      "|    clip_fraction        | 0.0343      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 13070       |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    reward               | -2.3008232  |\n",
      "|    std                  | 4.08        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1309        |\n",
      "|    time_elapsed         | 23957       |\n",
      "|    total_timesteps      | 2680832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008283448 |\n",
      "|    clip_fraction        | 0.0455      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.04        |\n",
      "|    n_updates            | 13080       |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    reward               | 0.92855006  |\n",
      "|    std                  | 4.09        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1310        |\n",
      "|    time_elapsed         | 23975       |\n",
      "|    total_timesteps      | 2682880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011346249 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.18        |\n",
      "|    n_updates            | 13090       |\n",
      "|    policy_gradient_loss | -0.0012     |\n",
      "|    reward               | 0.52921164  |\n",
      "|    std                  | 4.09        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1311        |\n",
      "|    time_elapsed         | 23993       |\n",
      "|    total_timesteps      | 2684928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025025167 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.57        |\n",
      "|    n_updates            | 13100       |\n",
      "|    policy_gradient_loss | 0.00336     |\n",
      "|    reward               | -0.48900697 |\n",
      "|    std                  | 4.09        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1312        |\n",
      "|    time_elapsed         | 24012       |\n",
      "|    total_timesteps      | 2686976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020821601 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 13110       |\n",
      "|    policy_gradient_loss | -0.00171    |\n",
      "|    reward               | 1.5629712   |\n",
      "|    std                  | 4.09        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3115160.32\n",
      "total_reward: 2115160.32\n",
      "total_cost: 78587.87\n",
      "total_trades: 53265\n",
      "Sharpe: 0.717\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1313        |\n",
      "|    time_elapsed         | 24030       |\n",
      "|    total_timesteps      | 2689024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016252983 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.42        |\n",
      "|    n_updates            | 13120       |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    reward               | 0.7267303   |\n",
      "|    std                  | 4.1         |\n",
      "|    value_loss           | 9.62        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1314        |\n",
      "|    time_elapsed         | 24048       |\n",
      "|    total_timesteps      | 2691072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018057521 |\n",
      "|    clip_fraction        | 0.0727      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.25        |\n",
      "|    n_updates            | 13130       |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    reward               | 1.5121362   |\n",
      "|    std                  | 4.1         |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1315         |\n",
      "|    time_elapsed         | 24066        |\n",
      "|    total_timesteps      | 2693120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064166756 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.7        |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.87         |\n",
      "|    n_updates            | 13140        |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | -0.814336    |\n",
      "|    std                  | 4.1          |\n",
      "|    value_loss           | 18.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1316        |\n",
      "|    time_elapsed         | 24085       |\n",
      "|    total_timesteps      | 2695168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008994728 |\n",
      "|    clip_fraction        | 0.0511      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.51        |\n",
      "|    n_updates            | 13150       |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    reward               | -4.2022715  |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1317        |\n",
      "|    time_elapsed         | 24103       |\n",
      "|    total_timesteps      | 2697216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01600179  |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.29        |\n",
      "|    n_updates            | 13160       |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | -0.15896057 |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1318        |\n",
      "|    time_elapsed         | 24121       |\n",
      "|    total_timesteps      | 2699264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018991861 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.88        |\n",
      "|    n_updates            | 13170       |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    reward               | -0.25684047 |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1319        |\n",
      "|    time_elapsed         | 24139       |\n",
      "|    total_timesteps      | 2701312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020016525 |\n",
      "|    clip_fraction        | 0.0441      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.8       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 13180       |\n",
      "|    policy_gradient_loss | -0.00134    |\n",
      "|    reward               | -3.5490205  |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1320        |\n",
      "|    time_elapsed         | 24157       |\n",
      "|    total_timesteps      | 2703360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011041049 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.8       |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.16        |\n",
      "|    n_updates            | 13190       |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | -1.190388   |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 9.52        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1321         |\n",
      "|    time_elapsed         | 24175        |\n",
      "|    total_timesteps      | 2705408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068043377 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.8        |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 13200        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | 1.497024     |\n",
      "|    std                  | 4.11         |\n",
      "|    value_loss           | 16.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1322         |\n",
      "|    time_elapsed         | 24193        |\n",
      "|    total_timesteps      | 2707456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028674905 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.8        |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.16         |\n",
      "|    n_updates            | 13210        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | 1.0886104    |\n",
      "|    std                  | 4.11         |\n",
      "|    value_loss           | 18.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1323         |\n",
      "|    time_elapsed         | 24211        |\n",
      "|    total_timesteps      | 2709504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010216184  |\n",
      "|    clip_fraction        | 0.042        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.8        |\n",
      "|    explained_variance   | 0.54         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.55         |\n",
      "|    n_updates            | 13220        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | -0.006897625 |\n",
      "|    std                  | 4.12         |\n",
      "|    value_loss           | 15.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1324         |\n",
      "|    time_elapsed         | 24229        |\n",
      "|    total_timesteps      | 2711552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0145869125 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.9        |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.83         |\n",
      "|    n_updates            | 13230        |\n",
      "|    policy_gradient_loss | -0.00808     |\n",
      "|    reward               | 0.0063165575 |\n",
      "|    std                  | 4.13         |\n",
      "|    value_loss           | 11.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1325         |\n",
      "|    time_elapsed         | 24247        |\n",
      "|    total_timesteps      | 2713600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008101727  |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.9        |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.67         |\n",
      "|    n_updates            | 13240        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | -0.114973806 |\n",
      "|    std                  | 4.13         |\n",
      "|    value_loss           | 16.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1326        |\n",
      "|    time_elapsed         | 24265       |\n",
      "|    total_timesteps      | 2715648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010729279 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.16        |\n",
      "|    n_updates            | 13250       |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    reward               | -0.17724873 |\n",
      "|    std                  | 4.13        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3659024.18\n",
      "total_reward: 2659024.18\n",
      "total_cost: 76909.11\n",
      "total_trades: 53069\n",
      "Sharpe: 0.785\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1327        |\n",
      "|    time_elapsed         | 24284       |\n",
      "|    total_timesteps      | 2717696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011994886 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.01        |\n",
      "|    n_updates            | 13260       |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    reward               | -1.3464702  |\n",
      "|    std                  | 4.13        |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1328        |\n",
      "|    time_elapsed         | 24302       |\n",
      "|    total_timesteps      | 2719744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009063524 |\n",
      "|    clip_fraction        | 0.0779      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.11        |\n",
      "|    n_updates            | 13270       |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    reward               | 1.0514013   |\n",
      "|    std                  | 4.13        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1329       |\n",
      "|    time_elapsed         | 24321      |\n",
      "|    total_timesteps      | 2721792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00606508 |\n",
      "|    clip_fraction        | 0.0449     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.9      |\n",
      "|    explained_variance   | 0.649      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.19       |\n",
      "|    n_updates            | 13280      |\n",
      "|    policy_gradient_loss | -0.00299   |\n",
      "|    reward               | 1.6238955  |\n",
      "|    std                  | 4.14       |\n",
      "|    value_loss           | 20.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1330        |\n",
      "|    time_elapsed         | 24339       |\n",
      "|    total_timesteps      | 2723840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010872817 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82         |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.54        |\n",
      "|    n_updates            | 13290       |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | -1.4130114  |\n",
      "|    std                  | 4.14        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1331        |\n",
      "|    time_elapsed         | 24357       |\n",
      "|    total_timesteps      | 2725888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031048568 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82         |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.18        |\n",
      "|    n_updates            | 13300       |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    reward               | 0.78452766  |\n",
      "|    std                  | 4.14        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1332        |\n",
      "|    time_elapsed         | 24389       |\n",
      "|    total_timesteps      | 2727936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011626705 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82         |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.37        |\n",
      "|    n_updates            | 13310       |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    reward               | 1.5146016   |\n",
      "|    std                  | 4.14        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1333        |\n",
      "|    time_elapsed         | 24407       |\n",
      "|    total_timesteps      | 2729984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014135196 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82         |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.27        |\n",
      "|    n_updates            | 13320       |\n",
      "|    policy_gradient_loss | -0.00657    |\n",
      "|    reward               | 2.0897086   |\n",
      "|    std                  | 4.15        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1334        |\n",
      "|    time_elapsed         | 24425       |\n",
      "|    total_timesteps      | 2732032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012669078 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.13        |\n",
      "|    n_updates            | 13330       |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    reward               | 0.3676638   |\n",
      "|    std                  | 4.15        |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1335        |\n",
      "|    time_elapsed         | 24443       |\n",
      "|    total_timesteps      | 2734080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015163813 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 13340       |\n",
      "|    policy_gradient_loss | -0.00721    |\n",
      "|    reward               | 0.27271822  |\n",
      "|    std                  | 4.16        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1336        |\n",
      "|    time_elapsed         | 24462       |\n",
      "|    total_timesteps      | 2736128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004074457 |\n",
      "|    clip_fraction        | 0.0186      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.77        |\n",
      "|    n_updates            | 13350       |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    reward               | 1.4659493   |\n",
      "|    std                  | 4.16        |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1337        |\n",
      "|    time_elapsed         | 24481       |\n",
      "|    total_timesteps      | 2738176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02563437  |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.74        |\n",
      "|    n_updates            | 13360       |\n",
      "|    policy_gradient_loss | 0.000775    |\n",
      "|    reward               | -0.81769556 |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1338         |\n",
      "|    time_elapsed         | 24500        |\n",
      "|    total_timesteps      | 2740224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072709075 |\n",
      "|    clip_fraction        | 0.0501       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.2        |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.64         |\n",
      "|    n_updates            | 13370        |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    reward               | -1.2095993   |\n",
      "|    std                  | 4.18         |\n",
      "|    value_loss           | 17.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1339        |\n",
      "|    time_elapsed         | 24520       |\n",
      "|    total_timesteps      | 2742272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010388793 |\n",
      "|    clip_fraction        | 0.0995      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.42        |\n",
      "|    n_updates            | 13380       |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    reward               | 0.76688135  |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1340        |\n",
      "|    time_elapsed         | 24538       |\n",
      "|    total_timesteps      | 2744320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010265682 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.67        |\n",
      "|    n_updates            | 13390       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    reward               | 1.4461224   |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3224123.54\n",
      "total_reward: 2224123.54\n",
      "total_cost: 88534.51\n",
      "total_trades: 53532\n",
      "Sharpe: 0.721\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1341        |\n",
      "|    time_elapsed         | 24557       |\n",
      "|    total_timesteps      | 2746368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014408071 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.38        |\n",
      "|    n_updates            | 13400       |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | 0.5494523   |\n",
      "|    std                  | 4.17        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1342       |\n",
      "|    time_elapsed         | 24575      |\n",
      "|    total_timesteps      | 2748416    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00842974 |\n",
      "|    clip_fraction        | 0.0637     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.2      |\n",
      "|    explained_variance   | 0.724      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.67       |\n",
      "|    n_updates            | 13410      |\n",
      "|    policy_gradient_loss | -0.00645   |\n",
      "|    reward               | 0.19435014 |\n",
      "|    std                  | 4.18       |\n",
      "|    value_loss           | 16.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1343        |\n",
      "|    time_elapsed         | 24593       |\n",
      "|    total_timesteps      | 2750464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006005699 |\n",
      "|    clip_fraction        | 0.0286      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.23        |\n",
      "|    n_updates            | 13420       |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | -0.84894913 |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1344        |\n",
      "|    time_elapsed         | 24611       |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016856046 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.4         |\n",
      "|    n_updates            | 13430       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -0.4869794  |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 8.2         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1345         |\n",
      "|    time_elapsed         | 24629        |\n",
      "|    total_timesteps      | 2754560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016604977  |\n",
      "|    clip_fraction        | 0.0823       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.3        |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 13440        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | -0.108208224 |\n",
      "|    std                  | 4.19         |\n",
      "|    value_loss           | 14.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1346        |\n",
      "|    time_elapsed         | 24647       |\n",
      "|    total_timesteps      | 2756608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013611547 |\n",
      "|    clip_fraction        | 0.0937      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.4       |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 13450       |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    reward               | -2.3577452  |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1347       |\n",
      "|    time_elapsed         | 24665      |\n",
      "|    total_timesteps      | 2758656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01359054 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.4      |\n",
      "|    explained_variance   | 0.193      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.92       |\n",
      "|    n_updates            | 13460      |\n",
      "|    policy_gradient_loss | 0.00436    |\n",
      "|    reward               | 0.30885097 |\n",
      "|    std                  | 4.2        |\n",
      "|    value_loss           | 20.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1348        |\n",
      "|    time_elapsed         | 24683       |\n",
      "|    total_timesteps      | 2760704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014876227 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.4       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.98        |\n",
      "|    n_updates            | 13470       |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    reward               | 0.36270854  |\n",
      "|    std                  | 4.21        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1349        |\n",
      "|    time_elapsed         | 24701       |\n",
      "|    total_timesteps      | 2762752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017210744 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.17        |\n",
      "|    n_updates            | 13480       |\n",
      "|    policy_gradient_loss | -0.000766   |\n",
      "|    reward               | -3.8733091  |\n",
      "|    std                  | 4.22        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1350        |\n",
      "|    time_elapsed         | 24719       |\n",
      "|    total_timesteps      | 2764800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004370912 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.7         |\n",
      "|    n_updates            | 13490       |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    reward               | -1.0804883  |\n",
      "|    std                  | 4.22        |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1351        |\n",
      "|    time_elapsed         | 24738       |\n",
      "|    total_timesteps      | 2766848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016286502 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.6       |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.58        |\n",
      "|    n_updates            | 13500       |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | -0.19545972 |\n",
      "|    std                  | 4.23        |\n",
      "|    value_loss           | 8.04        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1352       |\n",
      "|    time_elapsed         | 24757      |\n",
      "|    total_timesteps      | 2768896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02021163 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.6      |\n",
      "|    explained_variance   | 0.736      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.48       |\n",
      "|    n_updates            | 13510      |\n",
      "|    policy_gradient_loss | -0.00377   |\n",
      "|    reward               | 0.14900054 |\n",
      "|    std                  | 4.24       |\n",
      "|    value_loss           | 15.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1353        |\n",
      "|    time_elapsed         | 24776       |\n",
      "|    total_timesteps      | 2770944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008431032 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.27        |\n",
      "|    n_updates            | 13520       |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    reward               | 1.3403802   |\n",
      "|    std                  | 4.24        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1354        |\n",
      "|    time_elapsed         | 24795       |\n",
      "|    total_timesteps      | 2772992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005830286 |\n",
      "|    clip_fraction        | 0.0218      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.92        |\n",
      "|    n_updates            | 13530       |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    reward               | -0.2760023  |\n",
      "|    std                  | 4.24        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2737375.09\n",
      "total_reward: 1737375.09\n",
      "total_cost: 89141.88\n",
      "total_trades: 54214\n",
      "Sharpe: 0.645\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1355        |\n",
      "|    time_elapsed         | 24813       |\n",
      "|    total_timesteps      | 2775040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012251113 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.26        |\n",
      "|    n_updates            | 13540       |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    reward               | 0.6791541   |\n",
      "|    std                  | 4.24        |\n",
      "|    value_loss           | 10          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1356        |\n",
      "|    time_elapsed         | 24832       |\n",
      "|    total_timesteps      | 2777088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008972649 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.99        |\n",
      "|    n_updates            | 13550       |\n",
      "|    policy_gradient_loss | -0.00681    |\n",
      "|    reward               | -2.3661628  |\n",
      "|    std                  | 4.25        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1357         |\n",
      "|    time_elapsed         | 24850        |\n",
      "|    total_timesteps      | 2779136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074882256 |\n",
      "|    clip_fraction        | 0.0381       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.7        |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.77         |\n",
      "|    n_updates            | 13560        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | -3.2319298   |\n",
      "|    std                  | 4.25         |\n",
      "|    value_loss           | 14.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1358        |\n",
      "|    time_elapsed         | 24868       |\n",
      "|    total_timesteps      | 2781184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012872623 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.65        |\n",
      "|    n_updates            | 13570       |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    reward               | 0.30380028  |\n",
      "|    std                  | 4.26        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1359        |\n",
      "|    time_elapsed         | 24887       |\n",
      "|    total_timesteps      | 2783232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008045111 |\n",
      "|    clip_fraction        | 0.0869      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.8       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 13580       |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | -0.2539146  |\n",
      "|    std                  | 4.26        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1360       |\n",
      "|    time_elapsed         | 24905      |\n",
      "|    total_timesteps      | 2785280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00811636 |\n",
      "|    clip_fraction        | 0.0372     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.8      |\n",
      "|    explained_variance   | 0.566      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.83       |\n",
      "|    n_updates            | 13590      |\n",
      "|    policy_gradient_loss | -0.00565   |\n",
      "|    reward               | 0.2921667  |\n",
      "|    std                  | 4.26       |\n",
      "|    value_loss           | 21.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1361        |\n",
      "|    time_elapsed         | 24924       |\n",
      "|    total_timesteps      | 2787328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022313654 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.44        |\n",
      "|    n_updates            | 13600       |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    reward               | -1.0012538  |\n",
      "|    std                  | 4.28        |\n",
      "|    value_loss           | 8.4         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1362        |\n",
      "|    time_elapsed         | 24942       |\n",
      "|    total_timesteps      | 2789376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010600422 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.58        |\n",
      "|    n_updates            | 13610       |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    reward               | 1.0557249   |\n",
      "|    std                  | 4.28        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1363         |\n",
      "|    time_elapsed         | 24960        |\n",
      "|    total_timesteps      | 2791424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069553605 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83          |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.5          |\n",
      "|    n_updates            | 13620        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | -0.3996078   |\n",
      "|    std                  | 4.29         |\n",
      "|    value_loss           | 18.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1364         |\n",
      "|    time_elapsed         | 24978        |\n",
      "|    total_timesteps      | 2793472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085116085 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83          |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.82         |\n",
      "|    n_updates            | 13630        |\n",
      "|    policy_gradient_loss | -0.008       |\n",
      "|    reward               | -0.5492563   |\n",
      "|    std                  | 4.29         |\n",
      "|    value_loss           | 11.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1365         |\n",
      "|    time_elapsed         | 24997        |\n",
      "|    total_timesteps      | 2795520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148231555 |\n",
      "|    clip_fraction        | 0.0617       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83          |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.8          |\n",
      "|    n_updates            | 13640        |\n",
      "|    policy_gradient_loss | -0.00723     |\n",
      "|    reward               | 1.7369118    |\n",
      "|    std                  | 4.29         |\n",
      "|    value_loss           | 11.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1366        |\n",
      "|    time_elapsed         | 25015       |\n",
      "|    total_timesteps      | 2797568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009798519 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83         |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.52        |\n",
      "|    n_updates            | 13650       |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    reward               | -0.23080271 |\n",
      "|    std                  | 4.29        |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1367         |\n",
      "|    time_elapsed         | 25033        |\n",
      "|    total_timesteps      | 2799616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058179465 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83          |\n",
      "|    explained_variance   | 0.647        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.6          |\n",
      "|    n_updates            | 13660        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    reward               | 0.88169575   |\n",
      "|    std                  | 4.3          |\n",
      "|    value_loss           | 15.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1368         |\n",
      "|    time_elapsed         | 25052        |\n",
      "|    total_timesteps      | 2801664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126724485 |\n",
      "|    clip_fraction        | 0.0827       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.1        |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.63         |\n",
      "|    n_updates            | 13670        |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    reward               | -1.1995847   |\n",
      "|    std                  | 4.3          |\n",
      "|    value_loss           | 9.76         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3217638.81\n",
      "total_reward: 2217638.81\n",
      "total_cost: 56060.83\n",
      "total_trades: 51261\n",
      "Sharpe: 0.737\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1369        |\n",
      "|    time_elapsed         | 25069       |\n",
      "|    total_timesteps      | 2803712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018051382 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.1       |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.71        |\n",
      "|    n_updates            | 13680       |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    reward               | 0.3957879   |\n",
      "|    std                  | 4.31        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1370       |\n",
      "|    time_elapsed         | 25087      |\n",
      "|    total_timesteps      | 2805760    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00439918 |\n",
      "|    clip_fraction        | 0.018      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.1      |\n",
      "|    explained_variance   | 0.478      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.2       |\n",
      "|    n_updates            | 13690      |\n",
      "|    policy_gradient_loss | -0.00597   |\n",
      "|    reward               | 0.78581583 |\n",
      "|    std                  | 4.31       |\n",
      "|    value_loss           | 23.5       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1371         |\n",
      "|    time_elapsed         | 25105        |\n",
      "|    total_timesteps      | 2807808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075461203 |\n",
      "|    clip_fraction        | 0.0457       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.2        |\n",
      "|    explained_variance   | 0.0984       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.86         |\n",
      "|    n_updates            | 13700        |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | -0.9102251   |\n",
      "|    std                  | 4.31         |\n",
      "|    value_loss           | 25.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1372         |\n",
      "|    time_elapsed         | 25123        |\n",
      "|    total_timesteps      | 2809856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076307924 |\n",
      "|    clip_fraction        | 0.0596       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.2        |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.94         |\n",
      "|    n_updates            | 13710        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    reward               | -0.39282554  |\n",
      "|    std                  | 4.32         |\n",
      "|    value_loss           | 14.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1373         |\n",
      "|    time_elapsed         | 25141        |\n",
      "|    total_timesteps      | 2811904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063944156 |\n",
      "|    clip_fraction        | 0.0541       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.2        |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.2          |\n",
      "|    n_updates            | 13720        |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    reward               | -0.042864393 |\n",
      "|    std                  | 4.32         |\n",
      "|    value_loss           | 18.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1374        |\n",
      "|    time_elapsed         | 25159       |\n",
      "|    total_timesteps      | 2813952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008234084 |\n",
      "|    clip_fraction        | 0.0787      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 13730       |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    reward               | -0.18143755 |\n",
      "|    std                  | 4.32        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1375        |\n",
      "|    time_elapsed         | 25178       |\n",
      "|    total_timesteps      | 2816000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011155323 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.4         |\n",
      "|    n_updates            | 13740       |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    reward               | 0.10468677  |\n",
      "|    std                  | 4.32        |\n",
      "|    value_loss           | 9.96        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1376        |\n",
      "|    time_elapsed         | 25196       |\n",
      "|    total_timesteps      | 2818048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007911023 |\n",
      "|    clip_fraction        | 0.0826      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.17        |\n",
      "|    n_updates            | 13750       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 0.19893609  |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1377        |\n",
      "|    time_elapsed         | 25214       |\n",
      "|    total_timesteps      | 2820096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011579996 |\n",
      "|    clip_fraction        | 0.0445      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 13760       |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    reward               | -2.352426   |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1378       |\n",
      "|    time_elapsed         | 25232      |\n",
      "|    total_timesteps      | 2822144    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00711939 |\n",
      "|    clip_fraction        | 0.0323     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.3      |\n",
      "|    explained_variance   | 0.48       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.65       |\n",
      "|    n_updates            | 13770      |\n",
      "|    policy_gradient_loss | -0.00366   |\n",
      "|    reward               | -0.1764593 |\n",
      "|    std                  | 4.33       |\n",
      "|    value_loss           | 17.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1379        |\n",
      "|    time_elapsed         | 25251       |\n",
      "|    total_timesteps      | 2824192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009242505 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.12        |\n",
      "|    n_updates            | 13780       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -1.3297263  |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1380        |\n",
      "|    time_elapsed         | 25269       |\n",
      "|    total_timesteps      | 2826240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010529669 |\n",
      "|    clip_fraction        | 0.0761      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.59        |\n",
      "|    n_updates            | 13790       |\n",
      "|    policy_gradient_loss | -0.0093     |\n",
      "|    reward               | 7.064315    |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1381        |\n",
      "|    time_elapsed         | 25287       |\n",
      "|    total_timesteps      | 2828288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013959412 |\n",
      "|    clip_fraction        | 0.0696      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.46        |\n",
      "|    n_updates            | 13800       |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | -0.8970985  |\n",
      "|    std                  | 4.34        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1382       |\n",
      "|    time_elapsed         | 25305      |\n",
      "|    total_timesteps      | 2830336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01809528 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.4      |\n",
      "|    explained_variance   | 0.63       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.57       |\n",
      "|    n_updates            | 13810      |\n",
      "|    policy_gradient_loss | -0.00123   |\n",
      "|    reward               | -0.7005477 |\n",
      "|    std                  | 4.35       |\n",
      "|    value_loss           | 9.97       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3518294.29\n",
      "total_reward: 2518294.29\n",
      "total_cost: 68477.29\n",
      "total_trades: 52626\n",
      "Sharpe: 0.792\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1383       |\n",
      "|    time_elapsed         | 25323      |\n",
      "|    total_timesteps      | 2832384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01502946 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.4      |\n",
      "|    explained_variance   | 0.564      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.01       |\n",
      "|    n_updates            | 13820      |\n",
      "|    policy_gradient_loss | -0.00574   |\n",
      "|    reward               | 0.2561223  |\n",
      "|    std                  | 4.35       |\n",
      "|    value_loss           | 19         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1384         |\n",
      "|    time_elapsed         | 25342        |\n",
      "|    total_timesteps      | 2834432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055502644 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.4        |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.83         |\n",
      "|    n_updates            | 13830        |\n",
      "|    policy_gradient_loss | -0.0069      |\n",
      "|    reward               | 0.7728796    |\n",
      "|    std                  | 4.36         |\n",
      "|    value_loss           | 22.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1385        |\n",
      "|    time_elapsed         | 25360       |\n",
      "|    total_timesteps      | 2836480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016835915 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.48        |\n",
      "|    n_updates            | 13840       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -0.9012792  |\n",
      "|    std                  | 4.36        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1386        |\n",
      "|    time_elapsed         | 25379       |\n",
      "|    total_timesteps      | 2838528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012518333 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.5       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 13850       |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | -0.8796686  |\n",
      "|    std                  | 4.37        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1387        |\n",
      "|    time_elapsed         | 25397       |\n",
      "|    total_timesteps      | 2840576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004072332 |\n",
      "|    clip_fraction        | 0.0118      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.5       |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.19        |\n",
      "|    n_updates            | 13860       |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    reward               | 0.4260099   |\n",
      "|    std                  | 4.37        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1388        |\n",
      "|    time_elapsed         | 25416       |\n",
      "|    total_timesteps      | 2842624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008222289 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.5       |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 13870       |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    reward               | -0.94263154 |\n",
      "|    std                  | 4.37        |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1389        |\n",
      "|    time_elapsed         | 25435       |\n",
      "|    total_timesteps      | 2844672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016458228 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.5       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.86        |\n",
      "|    n_updates            | 13880       |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    reward               | 0.84407955  |\n",
      "|    std                  | 4.37        |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1390        |\n",
      "|    time_elapsed         | 25454       |\n",
      "|    total_timesteps      | 2846720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010123156 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.5       |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.4         |\n",
      "|    n_updates            | 13890       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.44035116 |\n",
      "|    std                  | 4.38        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1391        |\n",
      "|    time_elapsed         | 25473       |\n",
      "|    total_timesteps      | 2848768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005389652 |\n",
      "|    clip_fraction        | 0.018       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.5       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.22        |\n",
      "|    n_updates            | 13900       |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    reward               | -0.30845004 |\n",
      "|    std                  | 4.38        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1392        |\n",
      "|    time_elapsed         | 25492       |\n",
      "|    total_timesteps      | 2850816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026848223 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.6       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.42        |\n",
      "|    n_updates            | 13910       |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    reward               | 1.0421641   |\n",
      "|    std                  | 4.39        |\n",
      "|    value_loss           | 8.73        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1393        |\n",
      "|    time_elapsed         | 25511       |\n",
      "|    total_timesteps      | 2852864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017066851 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.6       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.87        |\n",
      "|    n_updates            | 13920       |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    reward               | 0.588812    |\n",
      "|    std                  | 4.4         |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1394         |\n",
      "|    time_elapsed         | 25530        |\n",
      "|    total_timesteps      | 2854912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036600435 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.7        |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.65         |\n",
      "|    n_updates            | 13930        |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    reward               | 0.19066925   |\n",
      "|    std                  | 4.4          |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1395        |\n",
      "|    time_elapsed         | 25548       |\n",
      "|    total_timesteps      | 2856960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006409888 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.46        |\n",
      "|    n_updates            | 13940       |\n",
      "|    policy_gradient_loss | -0.000935   |\n",
      "|    reward               | 2.258201    |\n",
      "|    std                  | 4.4         |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1396        |\n",
      "|    time_elapsed         | 25567       |\n",
      "|    total_timesteps      | 2859008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011068275 |\n",
      "|    clip_fraction        | 0.0403      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 13950       |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    reward               | -0.20926729 |\n",
      "|    std                  | 4.4         |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1397        |\n",
      "|    time_elapsed         | 25585       |\n",
      "|    total_timesteps      | 2861056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007576558 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 13960       |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    reward               | -0.5393444  |\n",
      "|    std                  | 4.4         |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3068436.76\n",
      "total_reward: 2068436.76\n",
      "total_cost: 75053.36\n",
      "total_trades: 53516\n",
      "Sharpe: 0.697\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1398        |\n",
      "|    time_elapsed         | 25604       |\n",
      "|    total_timesteps      | 2863104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006387525 |\n",
      "|    clip_fraction        | 0.0387      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.44        |\n",
      "|    n_updates            | 13970       |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    reward               | 1.4931828   |\n",
      "|    std                  | 4.4         |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1399        |\n",
      "|    time_elapsed         | 25622       |\n",
      "|    total_timesteps      | 2865152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018691352 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4           |\n",
      "|    n_updates            | 13980       |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    reward               | 2.1908903   |\n",
      "|    std                  | 4.4         |\n",
      "|    value_loss           | 9.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1400        |\n",
      "|    time_elapsed         | 25641       |\n",
      "|    total_timesteps      | 2867200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020623773 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 13990       |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    reward               | 0.84911925  |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1401        |\n",
      "|    time_elapsed         | 25660       |\n",
      "|    total_timesteps      | 2869248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003166103 |\n",
      "|    clip_fraction        | 0.00654     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.04        |\n",
      "|    n_updates            | 14000       |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    reward               | -5.6800604  |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1402        |\n",
      "|    time_elapsed         | 25679       |\n",
      "|    total_timesteps      | 2871296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010072252 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.71        |\n",
      "|    n_updates            | 14010       |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    reward               | -1.4723772  |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 10.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1403        |\n",
      "|    time_elapsed         | 25697       |\n",
      "|    total_timesteps      | 2873344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011319332 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.8         |\n",
      "|    n_updates            | 14020       |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | -0.77670556 |\n",
      "|    std                  | 4.42        |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1404        |\n",
      "|    time_elapsed         | 25716       |\n",
      "|    total_timesteps      | 2875392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004624254 |\n",
      "|    clip_fraction        | 0.0188      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 14030       |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    reward               | -2.138291   |\n",
      "|    std                  | 4.42        |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1405        |\n",
      "|    time_elapsed         | 25735       |\n",
      "|    total_timesteps      | 2877440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014138892 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.08        |\n",
      "|    n_updates            | 14040       |\n",
      "|    policy_gradient_loss | 0.000453    |\n",
      "|    reward               | 2.4286506   |\n",
      "|    std                  | 4.43        |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1406        |\n",
      "|    time_elapsed         | 25753       |\n",
      "|    total_timesteps      | 2879488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008958969 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.01        |\n",
      "|    n_updates            | 14050       |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    reward               | 0.7604668   |\n",
      "|    std                  | 4.43        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1407        |\n",
      "|    time_elapsed         | 25772       |\n",
      "|    total_timesteps      | 2881536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012864124 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.71        |\n",
      "|    n_updates            | 14060       |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    reward               | -0.01311329 |\n",
      "|    std                  | 4.44        |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1408         |\n",
      "|    time_elapsed         | 25790        |\n",
      "|    total_timesteps      | 2883584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027720272 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84          |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.04         |\n",
      "|    n_updates            | 14070        |\n",
      "|    policy_gradient_loss | -0.000728    |\n",
      "|    reward               | 1.1341057    |\n",
      "|    std                  | 4.44         |\n",
      "|    value_loss           | 18.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1409        |\n",
      "|    time_elapsed         | 25809       |\n",
      "|    total_timesteps      | 2885632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015493603 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.28        |\n",
      "|    n_updates            | 14080       |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    reward               | 1.7199062   |\n",
      "|    std                  | 4.45        |\n",
      "|    value_loss           | 8.99        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1410        |\n",
      "|    time_elapsed         | 25827       |\n",
      "|    total_timesteps      | 2887680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01336772  |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.78        |\n",
      "|    n_updates            | 14090       |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    reward               | -0.93308365 |\n",
      "|    std                  | 4.45        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1411         |\n",
      "|    time_elapsed         | 25846        |\n",
      "|    total_timesteps      | 2889728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062310863 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84          |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.71         |\n",
      "|    n_updates            | 14100        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | 0.55537325   |\n",
      "|    std                  | 4.45         |\n",
      "|    value_loss           | 16.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3206916.25\n",
      "total_reward: 2206916.25\n",
      "total_cost: 58175.30\n",
      "total_trades: 52414\n",
      "Sharpe: 0.725\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1412        |\n",
      "|    time_elapsed         | 25864       |\n",
      "|    total_timesteps      | 2891776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007362981 |\n",
      "|    clip_fraction        | 0.0616      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.3         |\n",
      "|    n_updates            | 14110       |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | -0.75388044 |\n",
      "|    std                  | 4.45        |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1413        |\n",
      "|    time_elapsed         | 25883       |\n",
      "|    total_timesteps      | 2893824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016577277 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.22        |\n",
      "|    n_updates            | 14120       |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | -0.14178418 |\n",
      "|    std                  | 4.46        |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1414        |\n",
      "|    time_elapsed         | 25901       |\n",
      "|    total_timesteps      | 2895872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015113327 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.52        |\n",
      "|    n_updates            | 14130       |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    reward               | 1.8996825   |\n",
      "|    std                  | 4.48        |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1415         |\n",
      "|    time_elapsed         | 25920        |\n",
      "|    total_timesteps      | 2897920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120123625 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.2        |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 14140        |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    reward               | -0.89731747  |\n",
      "|    std                  | 4.48         |\n",
      "|    value_loss           | 20.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1416        |\n",
      "|    time_elapsed         | 25939       |\n",
      "|    total_timesteps      | 2899968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016349182 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.2       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.47        |\n",
      "|    n_updates            | 14150       |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    reward               | 0.45826212  |\n",
      "|    std                  | 4.49        |\n",
      "|    value_loss           | 8.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1417        |\n",
      "|    time_elapsed         | 25957       |\n",
      "|    total_timesteps      | 2902016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008883535 |\n",
      "|    clip_fraction        | 0.0788      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.33        |\n",
      "|    n_updates            | 14160       |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    reward               | -3.5455294  |\n",
      "|    std                  | 4.49        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1418         |\n",
      "|    time_elapsed         | 25975        |\n",
      "|    total_timesteps      | 2904064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026443421 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.3        |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.19         |\n",
      "|    n_updates            | 14170        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | 1.302045     |\n",
      "|    std                  | 4.49         |\n",
      "|    value_loss           | 14.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1419         |\n",
      "|    time_elapsed         | 25994        |\n",
      "|    total_timesteps      | 2906112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066937497 |\n",
      "|    clip_fraction        | 0.0314       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.3        |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.81         |\n",
      "|    n_updates            | 14180        |\n",
      "|    policy_gradient_loss | -0.00846     |\n",
      "|    reward               | 0.15150324   |\n",
      "|    std                  | 4.5          |\n",
      "|    value_loss           | 12.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1420        |\n",
      "|    time_elapsed         | 26013       |\n",
      "|    total_timesteps      | 2908160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010614922 |\n",
      "|    clip_fraction        | 0.0943      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.43        |\n",
      "|    n_updates            | 14190       |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    reward               | 0.27636477  |\n",
      "|    std                  | 4.5         |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1421        |\n",
      "|    time_elapsed         | 26032       |\n",
      "|    total_timesteps      | 2910208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010946499 |\n",
      "|    clip_fraction        | 0.0722      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 14200       |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    reward               | -0.32011956 |\n",
      "|    std                  | 4.51        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1422         |\n",
      "|    time_elapsed         | 26050        |\n",
      "|    total_timesteps      | 2912256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025861245 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.4        |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.64         |\n",
      "|    n_updates            | 14210        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | 1.897706     |\n",
      "|    std                  | 4.51         |\n",
      "|    value_loss           | 14.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1423        |\n",
      "|    time_elapsed         | 26070       |\n",
      "|    total_timesteps      | 2914304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011909336 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.85        |\n",
      "|    n_updates            | 14220       |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    reward               | 0.8979508   |\n",
      "|    std                  | 4.52        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1424        |\n",
      "|    time_elapsed         | 26089       |\n",
      "|    total_timesteps      | 2916352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014175343 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.81        |\n",
      "|    n_updates            | 14230       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | 1.8532227   |\n",
      "|    std                  | 4.53        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1425        |\n",
      "|    time_elapsed         | 26107       |\n",
      "|    total_timesteps      | 2918400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004248865 |\n",
      "|    clip_fraction        | 0.0361      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.78        |\n",
      "|    n_updates            | 14240       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | 0.32694298  |\n",
      "|    std                  | 4.53        |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2955605.75\n",
      "total_reward: 1955605.75\n",
      "total_cost: 61405.63\n",
      "total_trades: 51866\n",
      "Sharpe: 0.675\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1426       |\n",
      "|    time_elapsed         | 26126      |\n",
      "|    total_timesteps      | 2920448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01938744 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.5      |\n",
      "|    explained_variance   | -0.067     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.97       |\n",
      "|    n_updates            | 14250      |\n",
      "|    policy_gradient_loss | -0.00243   |\n",
      "|    reward               | -0.7723256 |\n",
      "|    std                  | 4.52       |\n",
      "|    value_loss           | 11.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1427        |\n",
      "|    time_elapsed         | 26144       |\n",
      "|    total_timesteps      | 2922496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009516439 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.13        |\n",
      "|    n_updates            | 14260       |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | 0.18381187  |\n",
      "|    std                  | 4.53        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1428        |\n",
      "|    time_elapsed         | 26162       |\n",
      "|    total_timesteps      | 2924544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012490971 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.14        |\n",
      "|    n_updates            | 14270       |\n",
      "|    policy_gradient_loss | -0.00147    |\n",
      "|    reward               | 1.5831109   |\n",
      "|    std                  | 4.53        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1429        |\n",
      "|    time_elapsed         | 26182       |\n",
      "|    total_timesteps      | 2926592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014890787 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.21        |\n",
      "|    n_updates            | 14280       |\n",
      "|    policy_gradient_loss | 0.000962    |\n",
      "|    reward               | -3.1639004  |\n",
      "|    std                  | 4.53        |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1430        |\n",
      "|    time_elapsed         | 26201       |\n",
      "|    total_timesteps      | 2928640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013458688 |\n",
      "|    clip_fraction        | 0.0963      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.36        |\n",
      "|    n_updates            | 14290       |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    reward               | 0.68106395  |\n",
      "|    std                  | 4.54        |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1431        |\n",
      "|    time_elapsed         | 26220       |\n",
      "|    total_timesteps      | 2930688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018213661 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.82        |\n",
      "|    n_updates            | 14300       |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    reward               | -0.11512315 |\n",
      "|    std                  | 4.54        |\n",
      "|    value_loss           | 16.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1432         |\n",
      "|    time_elapsed         | 26239        |\n",
      "|    total_timesteps      | 2932736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039888895 |\n",
      "|    clip_fraction        | 0.00986      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.6        |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.79         |\n",
      "|    n_updates            | 14310        |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    reward               | -0.39747846  |\n",
      "|    std                  | 4.54         |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1433        |\n",
      "|    time_elapsed         | 26259       |\n",
      "|    total_timesteps      | 2934784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021227488 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.23        |\n",
      "|    n_updates            | 14320       |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    reward               | 1.4290668   |\n",
      "|    std                  | 4.54        |\n",
      "|    value_loss           | 7.62        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1434        |\n",
      "|    time_elapsed         | 26278       |\n",
      "|    total_timesteps      | 2936832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005323086 |\n",
      "|    clip_fraction        | 0.0213      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.92        |\n",
      "|    n_updates            | 14330       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    reward               | 0.75423443  |\n",
      "|    std                  | 4.55        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1435        |\n",
      "|    time_elapsed         | 26298       |\n",
      "|    total_timesteps      | 2938880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010877534 |\n",
      "|    clip_fraction        | 0.0589      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.62        |\n",
      "|    n_updates            | 14340       |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    reward               | -2.2592154  |\n",
      "|    std                  | 4.55        |\n",
      "|    value_loss           | 16.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1436        |\n",
      "|    time_elapsed         | 26317       |\n",
      "|    total_timesteps      | 2940928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013535125 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.88        |\n",
      "|    n_updates            | 14350       |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    reward               | 0.9754941   |\n",
      "|    std                  | 4.55        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1437        |\n",
      "|    time_elapsed         | 26336       |\n",
      "|    total_timesteps      | 2942976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013189353 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.14        |\n",
      "|    n_updates            | 14360       |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | 0.07443936  |\n",
      "|    std                  | 4.55        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1438         |\n",
      "|    time_elapsed         | 26354        |\n",
      "|    total_timesteps      | 2945024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028127483 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.7        |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 14370        |\n",
      "|    policy_gradient_loss | -0.00115     |\n",
      "|    reward               | -2.8503528   |\n",
      "|    std                  | 4.55         |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1439        |\n",
      "|    time_elapsed         | 26372       |\n",
      "|    total_timesteps      | 2947072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009030912 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.08        |\n",
      "|    n_updates            | 14380       |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | -0.48564768 |\n",
      "|    std                  | 4.56        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3114576.56\n",
      "total_reward: 2114576.56\n",
      "total_cost: 57500.01\n",
      "total_trades: 50928\n",
      "Sharpe: 0.718\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1440        |\n",
      "|    time_elapsed         | 26390       |\n",
      "|    total_timesteps      | 2949120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016233824 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.72        |\n",
      "|    n_updates            | 14390       |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    reward               | 1.2648461   |\n",
      "|    std                  | 4.57        |\n",
      "|    value_loss           | 8.1         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1441         |\n",
      "|    time_elapsed         | 26409        |\n",
      "|    total_timesteps      | 2951168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065447195 |\n",
      "|    clip_fraction        | 0.0439       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.8        |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.82         |\n",
      "|    n_updates            | 14400        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    reward               | 0.23613341   |\n",
      "|    std                  | 4.58         |\n",
      "|    value_loss           | 15.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1442         |\n",
      "|    time_elapsed         | 26427        |\n",
      "|    total_timesteps      | 2953216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019578668 |\n",
      "|    clip_fraction        | 0.00376      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.9        |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 14410        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    reward               | 0.30068      |\n",
      "|    std                  | 4.58         |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1443        |\n",
      "|    time_elapsed         | 26445       |\n",
      "|    total_timesteps      | 2955264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009959315 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.9       |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.7         |\n",
      "|    n_updates            | 14420       |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    reward               | -0.9605807  |\n",
      "|    std                  | 4.58        |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1444        |\n",
      "|    time_elapsed         | 26464       |\n",
      "|    total_timesteps      | 2957312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015596512 |\n",
      "|    clip_fraction        | 0.0932      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.9       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.86        |\n",
      "|    n_updates            | 14430       |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    reward               | 0.5965604   |\n",
      "|    std                  | 4.59        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1445         |\n",
      "|    time_elapsed         | 26482        |\n",
      "|    total_timesteps      | 2959360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103218015 |\n",
      "|    clip_fraction        | 0.0894       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.9        |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.13         |\n",
      "|    n_updates            | 14440        |\n",
      "|    policy_gradient_loss | -0.00513     |\n",
      "|    reward               | 3.7010162    |\n",
      "|    std                  | 4.59         |\n",
      "|    value_loss           | 17.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1446        |\n",
      "|    time_elapsed         | 26500       |\n",
      "|    total_timesteps      | 2961408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017653435 |\n",
      "|    clip_fraction        | 0.0889      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.8         |\n",
      "|    n_updates            | 14450       |\n",
      "|    policy_gradient_loss | 0.000305    |\n",
      "|    reward               | -0.06913566 |\n",
      "|    std                  | 4.59        |\n",
      "|    value_loss           | 16.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1447        |\n",
      "|    time_elapsed         | 26519       |\n",
      "|    total_timesteps      | 2963456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016972443 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.61        |\n",
      "|    n_updates            | 14460       |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | 1.2378815   |\n",
      "|    std                  | 4.61        |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1448        |\n",
      "|    time_elapsed         | 26537       |\n",
      "|    total_timesteps      | 2965504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012459524 |\n",
      "|    clip_fraction        | 0.0734      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.1       |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 14470       |\n",
      "|    policy_gradient_loss | -0.00161    |\n",
      "|    reward               | 0.0639362   |\n",
      "|    std                  | 4.61        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1449         |\n",
      "|    time_elapsed         | 26555        |\n",
      "|    total_timesteps      | 2967552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052988017 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.1        |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.92         |\n",
      "|    n_updates            | 14480        |\n",
      "|    policy_gradient_loss | -0.00473     |\n",
      "|    reward               | -1.0292861   |\n",
      "|    std                  | 4.62         |\n",
      "|    value_loss           | 16.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1450        |\n",
      "|    time_elapsed         | 26573       |\n",
      "|    total_timesteps      | 2969600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015147663 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.1       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.34        |\n",
      "|    n_updates            | 14490       |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    reward               | 1.5946978   |\n",
      "|    std                  | 4.62        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1451        |\n",
      "|    time_elapsed         | 26591       |\n",
      "|    total_timesteps      | 2971648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010461637 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.59        |\n",
      "|    n_updates            | 14500       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    reward               | 0.78615695  |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1452        |\n",
      "|    time_elapsed         | 26610       |\n",
      "|    total_timesteps      | 2973696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010074491 |\n",
      "|    clip_fraction        | 0.063       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.65        |\n",
      "|    n_updates            | 14510       |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    reward               | -0.74209124 |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1453        |\n",
      "|    time_elapsed         | 26627       |\n",
      "|    total_timesteps      | 2975744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013554025 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.07        |\n",
      "|    n_updates            | 14520       |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    reward               | 1.191616    |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3189871.46\n",
      "total_reward: 2189871.46\n",
      "total_cost: 50788.93\n",
      "total_trades: 49826\n",
      "Sharpe: 0.726\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1454        |\n",
      "|    time_elapsed         | 26645       |\n",
      "|    total_timesteps      | 2977792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022327814 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.77        |\n",
      "|    n_updates            | 14530       |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    reward               | -0.9281022  |\n",
      "|    std                  | 4.64        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1455        |\n",
      "|    time_elapsed         | 26663       |\n",
      "|    total_timesteps      | 2979840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005686247 |\n",
      "|    clip_fraction        | 0.0367      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.57        |\n",
      "|    n_updates            | 14540       |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | 0.7497506   |\n",
      "|    std                  | 4.65        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1456        |\n",
      "|    time_elapsed         | 26682       |\n",
      "|    total_timesteps      | 2981888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007864276 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.59        |\n",
      "|    n_updates            | 14550       |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    reward               | 1.2352916   |\n",
      "|    std                  | 4.64        |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1457        |\n",
      "|    time_elapsed         | 26699       |\n",
      "|    total_timesteps      | 2983936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016577445 |\n",
      "|    clip_fraction        | 0.0974      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.71        |\n",
      "|    n_updates            | 14560       |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    reward               | 0.17989585  |\n",
      "|    std                  | 4.65        |\n",
      "|    value_loss           | 7.68        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1458        |\n",
      "|    time_elapsed         | 26718       |\n",
      "|    total_timesteps      | 2985984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011401851 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.92        |\n",
      "|    n_updates            | 14570       |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | 1.0880817   |\n",
      "|    std                  | 4.65        |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1459        |\n",
      "|    time_elapsed         | 26736       |\n",
      "|    total_timesteps      | 2988032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008006634 |\n",
      "|    clip_fraction        | 0.0233      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 14580       |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    reward               | 0.57640535  |\n",
      "|    std                  | 4.66        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1460        |\n",
      "|    time_elapsed         | 26754       |\n",
      "|    total_timesteps      | 2990080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010426931 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.6         |\n",
      "|    n_updates            | 14590       |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    reward               | -1.7009382  |\n",
      "|    std                  | 4.66        |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1461        |\n",
      "|    time_elapsed         | 26772       |\n",
      "|    total_timesteps      | 2992128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008326359 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.61        |\n",
      "|    n_updates            | 14600       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.39438504  |\n",
      "|    std                  | 4.66        |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1462        |\n",
      "|    time_elapsed         | 26790       |\n",
      "|    total_timesteps      | 2994176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009585876 |\n",
      "|    clip_fraction        | 0.0573      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.92        |\n",
      "|    n_updates            | 14610       |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    reward               | 10.853181   |\n",
      "|    std                  | 4.67        |\n",
      "|    value_loss           | 16.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1463        |\n",
      "|    time_elapsed         | 26808       |\n",
      "|    total_timesteps      | 2996224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006956091 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.01        |\n",
      "|    n_updates            | 14620       |\n",
      "|    policy_gradient_loss | 0.000214    |\n",
      "|    reward               | 1.7827252   |\n",
      "|    std                  | 4.67        |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1464       |\n",
      "|    time_elapsed         | 26826      |\n",
      "|    total_timesteps      | 2998272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01800214 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.5      |\n",
      "|    explained_variance   | 0.756      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.53       |\n",
      "|    n_updates            | 14630      |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    reward               | 1.001653   |\n",
      "|    std                  | 4.68       |\n",
      "|    value_loss           | 9.18       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1465        |\n",
      "|    time_elapsed         | 26844       |\n",
      "|    total_timesteps      | 3000320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011990225 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.5       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.67        |\n",
      "|    n_updates            | 14640       |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    reward               | 0.8295662   |\n",
      "|    std                  | 4.69        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1466        |\n",
      "|    time_elapsed         | 26862       |\n",
      "|    total_timesteps      | 3002368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009552961 |\n",
      "|    clip_fraction        | 0.0581      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.5       |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.57        |\n",
      "|    n_updates            | 14650       |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    reward               | 5.4212303   |\n",
      "|    std                  | 4.69        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1467        |\n",
      "|    time_elapsed         | 26880       |\n",
      "|    total_timesteps      | 3004416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017526872 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.31        |\n",
      "|    n_updates            | 14660       |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    reward               | -0.82275504 |\n",
      "|    std                  | 4.69        |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3014786.58\n",
      "total_reward: 2014786.58\n",
      "total_cost: 75437.44\n",
      "total_trades: 52291\n",
      "Sharpe: 0.665\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1468        |\n",
      "|    time_elapsed         | 26898       |\n",
      "|    total_timesteps      | 3006464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017436072 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.73        |\n",
      "|    n_updates            | 14670       |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    reward               | -0.7407615  |\n",
      "|    std                  | 4.69        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1469        |\n",
      "|    time_elapsed         | 26916       |\n",
      "|    total_timesteps      | 3008512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011765288 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.33        |\n",
      "|    n_updates            | 14680       |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    reward               | 2.2032373   |\n",
      "|    std                  | 4.7         |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1470        |\n",
      "|    time_elapsed         | 26934       |\n",
      "|    total_timesteps      | 3010560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008737421 |\n",
      "|    clip_fraction        | 0.0747      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.75        |\n",
      "|    n_updates            | 14690       |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    reward               | -1.0261295  |\n",
      "|    std                  | 4.7         |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1471        |\n",
      "|    time_elapsed         | 26952       |\n",
      "|    total_timesteps      | 3012608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025781658 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.15        |\n",
      "|    n_updates            | 14700       |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    reward               | -0.42672455 |\n",
      "|    std                  | 4.7         |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1472         |\n",
      "|    time_elapsed         | 26970        |\n",
      "|    total_timesteps      | 3014656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054521235 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.6        |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.84         |\n",
      "|    n_updates            | 14710        |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    reward               | 0.797652     |\n",
      "|    std                  | 4.71         |\n",
      "|    value_loss           | 20           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1473         |\n",
      "|    time_elapsed         | 26988        |\n",
      "|    total_timesteps      | 3016704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020013074 |\n",
      "|    clip_fraction        | 0.00947      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.7        |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 14720        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | 0.33053723   |\n",
      "|    std                  | 4.71         |\n",
      "|    value_loss           | 25.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1474        |\n",
      "|    time_elapsed         | 27005       |\n",
      "|    total_timesteps      | 3018752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008198592 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.82        |\n",
      "|    n_updates            | 14730       |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    reward               | -1.5447986  |\n",
      "|    std                  | 4.71        |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1475         |\n",
      "|    time_elapsed         | 27023        |\n",
      "|    total_timesteps      | 3020800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067379978 |\n",
      "|    clip_fraction        | 0.0455       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.7        |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.39         |\n",
      "|    n_updates            | 14740        |\n",
      "|    policy_gradient_loss | -0.00659     |\n",
      "|    reward               | -0.008827878 |\n",
      "|    std                  | 4.71         |\n",
      "|    value_loss           | 19.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1476        |\n",
      "|    time_elapsed         | 27041       |\n",
      "|    total_timesteps      | 3022848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008861089 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.93        |\n",
      "|    n_updates            | 14750       |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    reward               | -0.7862589  |\n",
      "|    std                  | 4.72        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1477        |\n",
      "|    time_elapsed         | 27059       |\n",
      "|    total_timesteps      | 3024896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011046769 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.36        |\n",
      "|    n_updates            | 14760       |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    reward               | -0.4745178  |\n",
      "|    std                  | 4.72        |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1478        |\n",
      "|    time_elapsed         | 27077       |\n",
      "|    total_timesteps      | 3026944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023096744 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.3         |\n",
      "|    n_updates            | 14770       |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    reward               | -1.5194203  |\n",
      "|    std                  | 4.73        |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1479         |\n",
      "|    time_elapsed         | 27096        |\n",
      "|    total_timesteps      | 3028992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0142944865 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.8        |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.23         |\n",
      "|    n_updates            | 14780        |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    reward               | 0.33172226   |\n",
      "|    std                  | 4.73         |\n",
      "|    value_loss           | 13.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1480        |\n",
      "|    time_elapsed         | 27113       |\n",
      "|    total_timesteps      | 3031040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008720157 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.64        |\n",
      "|    n_updates            | 14790       |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    reward               | -0.89801097 |\n",
      "|    std                  | 4.73        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1481        |\n",
      "|    time_elapsed         | 27131       |\n",
      "|    total_timesteps      | 3033088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014441806 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.83        |\n",
      "|    n_updates            | 14800       |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | -0.8960331  |\n",
      "|    std                  | 4.75        |\n",
      "|    value_loss           | 9.39        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2847164.03\n",
      "total_reward: 1847164.03\n",
      "total_cost: 81310.26\n",
      "total_trades: 52471\n",
      "Sharpe: 0.646\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1482         |\n",
      "|    time_elapsed         | 27150        |\n",
      "|    total_timesteps      | 3035136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071500354 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.9        |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.67         |\n",
      "|    n_updates            | 14810        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    reward               | 3.1652088    |\n",
      "|    std                  | 4.75         |\n",
      "|    value_loss           | 17.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1483         |\n",
      "|    time_elapsed         | 27170        |\n",
      "|    total_timesteps      | 3037184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055757547 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.9        |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.44         |\n",
      "|    n_updates            | 14820        |\n",
      "|    policy_gradient_loss | -0.00701     |\n",
      "|    reward               | -0.36640254  |\n",
      "|    std                  | 4.76         |\n",
      "|    value_loss           | 19.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1484       |\n",
      "|    time_elapsed         | 27189      |\n",
      "|    total_timesteps      | 3039232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01182765 |\n",
      "|    clip_fraction        | 0.0699     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86        |\n",
      "|    explained_variance   | 0.171      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.94       |\n",
      "|    n_updates            | 14830      |\n",
      "|    policy_gradient_loss | -0.00381   |\n",
      "|    reward               | -1.5251033 |\n",
      "|    std                  | 4.77       |\n",
      "|    value_loss           | 23.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1485       |\n",
      "|    time_elapsed         | 27209      |\n",
      "|    total_timesteps      | 3041280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01441528 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.1      |\n",
      "|    explained_variance   | 0.462      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.41       |\n",
      "|    n_updates            | 14840      |\n",
      "|    policy_gradient_loss | -0.00742   |\n",
      "|    reward               | 0.40918565 |\n",
      "|    std                  | 4.78       |\n",
      "|    value_loss           | 17         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1486       |\n",
      "|    time_elapsed         | 27228      |\n",
      "|    total_timesteps      | 3043328    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01216761 |\n",
      "|    clip_fraction        | 0.0951     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.1      |\n",
      "|    explained_variance   | 0.469      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.51       |\n",
      "|    n_updates            | 14850      |\n",
      "|    policy_gradient_loss | -0.00461   |\n",
      "|    reward               | 1.8798504  |\n",
      "|    std                  | 4.79       |\n",
      "|    value_loss           | 18.5       |\n",
      "----------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 111            |\n",
      "|    iterations           | 1487           |\n",
      "|    time_elapsed         | 27247          |\n",
      "|    total_timesteps      | 3045376        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.009967074    |\n",
      "|    clip_fraction        | 0.0592         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -86.2          |\n",
      "|    explained_variance   | 0.533          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 8.55           |\n",
      "|    n_updates            | 14860          |\n",
      "|    policy_gradient_loss | -0.00681       |\n",
      "|    reward               | -0.00059355475 |\n",
      "|    std                  | 4.79           |\n",
      "|    value_loss           | 18.5           |\n",
      "--------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1488        |\n",
      "|    time_elapsed         | 27266       |\n",
      "|    total_timesteps      | 3047424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025807265 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.2       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.94        |\n",
      "|    n_updates            | 14870       |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | 1.1025313   |\n",
      "|    std                  | 4.8         |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1489         |\n",
      "|    time_elapsed         | 27284        |\n",
      "|    total_timesteps      | 3049472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0133120995 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.2        |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.5          |\n",
      "|    n_updates            | 14880        |\n",
      "|    policy_gradient_loss | -0.00657     |\n",
      "|    reward               | 0.13473476   |\n",
      "|    std                  | 4.81         |\n",
      "|    value_loss           | 21.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1490         |\n",
      "|    time_elapsed         | 27302        |\n",
      "|    total_timesteps      | 3051520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069511235 |\n",
      "|    clip_fraction        | 0.0522       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.3        |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 14890        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | -16.214626   |\n",
      "|    std                  | 4.81         |\n",
      "|    value_loss           | 18.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1491        |\n",
      "|    time_elapsed         | 27321       |\n",
      "|    total_timesteps      | 3053568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019569483 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.3       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.6         |\n",
      "|    n_updates            | 14900       |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    reward               | -0.4986012  |\n",
      "|    std                  | 4.81        |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1492        |\n",
      "|    time_elapsed         | 27340       |\n",
      "|    total_timesteps      | 3055616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013734508 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.3       |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.98        |\n",
      "|    n_updates            | 14910       |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    reward               | -0.13598329 |\n",
      "|    std                  | 4.82        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1493        |\n",
      "|    time_elapsed         | 27358       |\n",
      "|    total_timesteps      | 3057664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005377592 |\n",
      "|    clip_fraction        | 0.0197      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.3       |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8           |\n",
      "|    n_updates            | 14920       |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | -1.4320915  |\n",
      "|    std                  | 4.82        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1494        |\n",
      "|    time_elapsed         | 27378       |\n",
      "|    total_timesteps      | 3059712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027012773 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.4       |\n",
      "|    explained_variance   | -0.092      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 14930       |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | 1.0528555   |\n",
      "|    std                  | 4.83        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1495        |\n",
      "|    time_elapsed         | 27397       |\n",
      "|    total_timesteps      | 3061760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017917503 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.4       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 14940       |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | -1.451688   |\n",
      "|    std                  | 4.84        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4592046.61\n",
      "total_reward: 3592046.61\n",
      "total_cost: 426030.42\n",
      "total_trades: 69877\n",
      "Sharpe: 0.922\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1496        |\n",
      "|    time_elapsed         | 27415       |\n",
      "|    total_timesteps      | 3063808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007355502 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.4       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.86        |\n",
      "|    n_updates            | 14950       |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    reward               | 0.3224505   |\n",
      "|    std                  | 4.84        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1497        |\n",
      "|    time_elapsed         | 27434       |\n",
      "|    total_timesteps      | 3065856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021683235 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.5       |\n",
      "|    explained_variance   | -0.000304   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 14960       |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    reward               | -0.17672603 |\n",
      "|    std                  | 4.87        |\n",
      "|    value_loss           | 56          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1498       |\n",
      "|    time_elapsed         | 27452      |\n",
      "|    total_timesteps      | 3067904    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01691943 |\n",
      "|    clip_fraction        | 0.0991     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.7      |\n",
      "|    explained_variance   | 0.361      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.04       |\n",
      "|    n_updates            | 14970      |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    reward               | 0.39003885 |\n",
      "|    std                  | 4.88       |\n",
      "|    value_loss           | 13         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1499        |\n",
      "|    time_elapsed         | 27471       |\n",
      "|    total_timesteps      | 3069952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011880888 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 14980       |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    reward               | -1.0900725  |\n",
      "|    std                  | 4.89        |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1500       |\n",
      "|    time_elapsed         | 27490      |\n",
      "|    total_timesteps      | 3072000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02253641 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.8      |\n",
      "|    explained_variance   | 0.0339     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22         |\n",
      "|    n_updates            | 14990      |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    reward               | 1.933708   |\n",
      "|    std                  | 4.9        |\n",
      "|    value_loss           | 49.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1501        |\n",
      "|    time_elapsed         | 27509       |\n",
      "|    total_timesteps      | 3074048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016850188 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | -0.0194     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 15000       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | -3.0527704  |\n",
      "|    std                  | 4.93        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1502       |\n",
      "|    time_elapsed         | 27528      |\n",
      "|    total_timesteps      | 3076096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01692875 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87        |\n",
      "|    explained_variance   | 0.0168     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.3       |\n",
      "|    n_updates            | 15010      |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    reward               | -0.2446406 |\n",
      "|    std                  | 4.94       |\n",
      "|    value_loss           | 32.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1503        |\n",
      "|    time_elapsed         | 27547       |\n",
      "|    total_timesteps      | 3078144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008290676 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 15020       |\n",
      "|    policy_gradient_loss | 0.000338    |\n",
      "|    reward               | 0.76695     |\n",
      "|    std                  | 4.95        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1504        |\n",
      "|    time_elapsed         | 27567       |\n",
      "|    total_timesteps      | 3080192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007603182 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.96        |\n",
      "|    n_updates            | 15030       |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | 1.7605376   |\n",
      "|    std                  | 4.95        |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1505        |\n",
      "|    time_elapsed         | 27586       |\n",
      "|    total_timesteps      | 3082240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018965457 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.2       |\n",
      "|    explained_variance   | -0.082      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.19        |\n",
      "|    n_updates            | 15040       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | -0.18834314 |\n",
      "|    std                  | 4.98        |\n",
      "|    value_loss           | 10          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1506        |\n",
      "|    time_elapsed         | 27606       |\n",
      "|    total_timesteps      | 3084288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013893678 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.3       |\n",
      "|    explained_variance   | 0.0513      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 15050       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.31866467 |\n",
      "|    std                  | 5           |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1507        |\n",
      "|    time_elapsed         | 27625       |\n",
      "|    total_timesteps      | 3086336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013031516 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.4       |\n",
      "|    explained_variance   | 0.0227      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 15060       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 1.7162378   |\n",
      "|    std                  | 5.01        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1508        |\n",
      "|    time_elapsed         | 27643       |\n",
      "|    total_timesteps      | 3088384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016254505 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.4       |\n",
      "|    explained_variance   | -0.0426     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.43        |\n",
      "|    n_updates            | 15070       |\n",
      "|    policy_gradient_loss | -0.00927    |\n",
      "|    reward               | -4.405924   |\n",
      "|    std                  | 5.02        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1509        |\n",
      "|    time_elapsed         | 27661       |\n",
      "|    total_timesteps      | 3090432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015446948 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.5       |\n",
      "|    explained_variance   | 0.0679      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 15080       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | 0.46541592  |\n",
      "|    std                  | 5.03        |\n",
      "|    value_loss           | 58.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1510        |\n",
      "|    time_elapsed         | 27681       |\n",
      "|    total_timesteps      | 3092480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010224423 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.5       |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 15090       |\n",
      "|    policy_gradient_loss | 0.00121     |\n",
      "|    reward               | 1.2077746   |\n",
      "|    std                  | 5.03        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3936844.61\n",
      "total_reward: 2936844.61\n",
      "total_cost: 350452.87\n",
      "total_trades: 67150\n",
      "Sharpe: 0.835\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1511        |\n",
      "|    time_elapsed         | 27700       |\n",
      "|    total_timesteps      | 3094528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011661584 |\n",
      "|    clip_fraction        | 0.0913      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.0597      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.66        |\n",
      "|    n_updates            | 15100       |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    reward               | 0.86498135  |\n",
      "|    std                  | 5.04        |\n",
      "|    value_loss           | 23.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1512         |\n",
      "|    time_elapsed         | 27719        |\n",
      "|    total_timesteps      | 3096576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111639965 |\n",
      "|    clip_fraction        | 0.0929       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.6        |\n",
      "|    explained_variance   | 0.0305       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 15110        |\n",
      "|    policy_gradient_loss | -0.00778     |\n",
      "|    reward               | -0.7965804   |\n",
      "|    std                  | 5.05         |\n",
      "|    value_loss           | 27.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1513        |\n",
      "|    time_elapsed         | 27738       |\n",
      "|    total_timesteps      | 3098624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007398554 |\n",
      "|    clip_fraction        | 0.0483      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 15120       |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    reward               | 0.38202226  |\n",
      "|    std                  | 5.05        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1514        |\n",
      "|    time_elapsed         | 27756       |\n",
      "|    total_timesteps      | 3100672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008686433 |\n",
      "|    clip_fraction        | 0.0601      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 15130       |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    reward               | -0.32948834 |\n",
      "|    std                  | 5.05        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1515       |\n",
      "|    time_elapsed         | 27776      |\n",
      "|    total_timesteps      | 3102720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01935002 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.7      |\n",
      "|    explained_variance   | 0.0444     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.23       |\n",
      "|    n_updates            | 15140      |\n",
      "|    policy_gradient_loss | -0.00636   |\n",
      "|    reward               | 0.17072201 |\n",
      "|    std                  | 5.06       |\n",
      "|    value_loss           | 20.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1516        |\n",
      "|    time_elapsed         | 27796       |\n",
      "|    total_timesteps      | 3104768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016403574 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.7       |\n",
      "|    explained_variance   | 0.015       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 15150       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 2.120549    |\n",
      "|    std                  | 5.06        |\n",
      "|    value_loss           | 72.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1517        |\n",
      "|    time_elapsed         | 27815       |\n",
      "|    total_timesteps      | 3106816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012605859 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.8       |\n",
      "|    explained_variance   | 0.00882     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 15160       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 4.0580854   |\n",
      "|    std                  | 5.08        |\n",
      "|    value_loss           | 98.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1518         |\n",
      "|    time_elapsed         | 27835        |\n",
      "|    total_timesteps      | 3108864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124609005 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.8        |\n",
      "|    explained_variance   | 0.353        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.51         |\n",
      "|    n_updates            | 15170        |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    reward               | -2.7948236   |\n",
      "|    std                  | 5.08         |\n",
      "|    value_loss           | 27.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1519        |\n",
      "|    time_elapsed         | 27854       |\n",
      "|    total_timesteps      | 3110912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020147957 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.8       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 15180       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 0.11113179  |\n",
      "|    std                  | 5.09        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1520        |\n",
      "|    time_elapsed         | 27872       |\n",
      "|    total_timesteps      | 3112960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019659849 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.9       |\n",
      "|    explained_variance   | 0.0986      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 15190       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.08778368 |\n",
      "|    std                  | 5.09        |\n",
      "|    value_loss           | 55.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1521       |\n",
      "|    time_elapsed         | 27890      |\n",
      "|    total_timesteps      | 3115008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02105815 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.9      |\n",
      "|    explained_variance   | 0.00452    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.8       |\n",
      "|    n_updates            | 15200      |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    reward               | 0.59856015 |\n",
      "|    std                  | 5.1        |\n",
      "|    value_loss           | 61.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1522        |\n",
      "|    time_elapsed         | 27910       |\n",
      "|    total_timesteps      | 3117056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018508457 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.9       |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.24        |\n",
      "|    n_updates            | 15210       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 1.1405613   |\n",
      "|    std                  | 5.1         |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1523         |\n",
      "|    time_elapsed         | 27928        |\n",
      "|    total_timesteps      | 3119104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053113555 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.9        |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 15220        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    reward               | 0.34809944   |\n",
      "|    std                  | 5.1          |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1524        |\n",
      "|    time_elapsed         | 27947       |\n",
      "|    total_timesteps      | 3121152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003902365 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.8        |\n",
      "|    n_updates            | 15230       |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    reward               | -1.2919089  |\n",
      "|    std                  | 5.1         |\n",
      "|    value_loss           | 48.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1080\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3808217.47\n",
      "total_reward: 2808217.47\n",
      "total_cost: 161963.16\n",
      "total_trades: 58642\n",
      "Sharpe: 0.784\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1525        |\n",
      "|    time_elapsed         | 27965       |\n",
      "|    total_timesteps      | 3123200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009063757 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 15240       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | 0.5006588   |\n",
      "|    std                  | 5.11        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1526        |\n",
      "|    time_elapsed         | 27983       |\n",
      "|    total_timesteps      | 3125248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014058864 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.81        |\n",
      "|    n_updates            | 15250       |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    reward               | 0.9278581   |\n",
      "|    std                  | 5.11        |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1527        |\n",
      "|    time_elapsed         | 28001       |\n",
      "|    total_timesteps      | 3127296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012902021 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.00908     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 15260       |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    reward               | 2.4091818   |\n",
      "|    std                  | 5.11        |\n",
      "|    value_loss           | 44          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1528        |\n",
      "|    time_elapsed         | 28020       |\n",
      "|    total_timesteps      | 3129344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008744849 |\n",
      "|    clip_fraction        | 0.0733      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 15270       |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    reward               | -1.8588316  |\n",
      "|    std                  | 5.12        |\n",
      "|    value_loss           | 41.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1529        |\n",
      "|    time_elapsed         | 28038       |\n",
      "|    total_timesteps      | 3131392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015583673 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.56        |\n",
      "|    n_updates            | 15280       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -1.7409383  |\n",
      "|    std                  | 5.13        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1530         |\n",
      "|    time_elapsed         | 28057        |\n",
      "|    total_timesteps      | 3133440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071816156 |\n",
      "|    clip_fraction        | 0.0438       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.1        |\n",
      "|    explained_variance   | 0.292        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 15290        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    reward               | 1.0857663    |\n",
      "|    std                  | 5.13         |\n",
      "|    value_loss           | 40.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1531        |\n",
      "|    time_elapsed         | 28075       |\n",
      "|    total_timesteps      | 3135488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008160071 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 15300       |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    reward               | 4.676543    |\n",
      "|    std                  | 5.14        |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1532        |\n",
      "|    time_elapsed         | 28095       |\n",
      "|    total_timesteps      | 3137536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007154129 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 15310       |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    reward               | -2.9998314  |\n",
      "|    std                  | 5.14        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1533        |\n",
      "|    time_elapsed         | 28113       |\n",
      "|    total_timesteps      | 3139584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010696035 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 15320       |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    reward               | 0.46828774  |\n",
      "|    std                  | 5.15        |\n",
      "|    value_loss           | 36.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1534         |\n",
      "|    time_elapsed         | 28132        |\n",
      "|    total_timesteps      | 3141632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065565417 |\n",
      "|    clip_fraction        | 0.0568       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.2        |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 15330        |\n",
      "|    policy_gradient_loss | 8.14e-06     |\n",
      "|    reward               | -1.9851372   |\n",
      "|    std                  | 5.16         |\n",
      "|    value_loss           | 45.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1535        |\n",
      "|    time_elapsed         | 28150       |\n",
      "|    total_timesteps      | 3143680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021480527 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.3       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 15340       |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    reward               | -4.690425   |\n",
      "|    std                  | 5.17        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1536        |\n",
      "|    time_elapsed         | 28168       |\n",
      "|    total_timesteps      | 3145728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017907618 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.4       |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 15350       |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    reward               | 0.23335855  |\n",
      "|    std                  | 5.18        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1537         |\n",
      "|    time_elapsed         | 28186        |\n",
      "|    total_timesteps      | 3147776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072172075 |\n",
      "|    clip_fraction        | 0.0267       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.4        |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 15360        |\n",
      "|    policy_gradient_loss | -0.00699     |\n",
      "|    reward               | 0.1689707    |\n",
      "|    std                  | 5.19         |\n",
      "|    value_loss           | 47.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1538        |\n",
      "|    time_elapsed         | 28205       |\n",
      "|    total_timesteps      | 3149824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006040207 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.4       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 15370       |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    reward               | 0.703666    |\n",
      "|    std                  | 5.19        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1090\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4032544.59\n",
      "total_reward: 3032544.59\n",
      "total_cost: 207304.09\n",
      "total_trades: 61960\n",
      "Sharpe: 0.823\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1539        |\n",
      "|    time_elapsed         | 28223       |\n",
      "|    total_timesteps      | 3151872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020508803 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | -0.0462     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.73        |\n",
      "|    n_updates            | 15380       |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    reward               | -0.77544874 |\n",
      "|    std                  | 5.21        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1540        |\n",
      "|    time_elapsed         | 28242       |\n",
      "|    total_timesteps      | 3153920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010038463 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.6       |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 15390       |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    reward               | -1.6807832  |\n",
      "|    std                  | 5.22        |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1541         |\n",
      "|    time_elapsed         | 28260        |\n",
      "|    total_timesteps      | 3155968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068816897 |\n",
      "|    clip_fraction        | 0.0726       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.6        |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 15400        |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    reward               | 1.2319843    |\n",
      "|    std                  | 5.22         |\n",
      "|    value_loss           | 50.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1542         |\n",
      "|    time_elapsed         | 28278        |\n",
      "|    total_timesteps      | 3158016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071135205 |\n",
      "|    clip_fraction        | 0.0677       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.6        |\n",
      "|    explained_variance   | 0.307        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 15410        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | -4.463925    |\n",
      "|    std                  | 5.22         |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1543         |\n",
      "|    time_elapsed         | 28297        |\n",
      "|    total_timesteps      | 3160064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.021288542  |\n",
      "|    clip_fraction        | 0.185        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.7        |\n",
      "|    explained_variance   | 0.262        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 15420        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    reward               | -0.019636577 |\n",
      "|    std                  | 5.24         |\n",
      "|    value_loss           | 33.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1544        |\n",
      "|    time_elapsed         | 28315       |\n",
      "|    total_timesteps      | 3162112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013238234 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.4        |\n",
      "|    n_updates            | 15430       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | 0.2030897   |\n",
      "|    std                  | 5.26        |\n",
      "|    value_loss           | 61.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1545        |\n",
      "|    time_elapsed         | 28333       |\n",
      "|    total_timesteps      | 3164160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009941023 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 15440       |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    reward               | 0.62119836  |\n",
      "|    std                  | 5.26        |\n",
      "|    value_loss           | 61          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1546       |\n",
      "|    time_elapsed         | 28352      |\n",
      "|    total_timesteps      | 3166208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01090507 |\n",
      "|    clip_fraction        | 0.0906     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88.8      |\n",
      "|    explained_variance   | 0.379      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.42       |\n",
      "|    n_updates            | 15450      |\n",
      "|    policy_gradient_loss | -0.00618   |\n",
      "|    reward               | 1.7084     |\n",
      "|    std                  | 5.27       |\n",
      "|    value_loss           | 16.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1547         |\n",
      "|    time_elapsed         | 28370        |\n",
      "|    total_timesteps      | 3168256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061737914 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.9        |\n",
      "|    explained_variance   | 0.125        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 15460        |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    reward               | 1.3689795    |\n",
      "|    std                  | 5.27         |\n",
      "|    value_loss           | 49.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1548        |\n",
      "|    time_elapsed         | 28389       |\n",
      "|    total_timesteps      | 3170304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011398527 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.9       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 15470       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | 0.81675375  |\n",
      "|    std                  | 5.28        |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1549        |\n",
      "|    time_elapsed         | 28407       |\n",
      "|    total_timesteps      | 3172352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018731177 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89         |\n",
      "|    explained_variance   | -0.0174     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 15480       |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    reward               | 0.6006536   |\n",
      "|    std                  | 5.29        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1550        |\n",
      "|    time_elapsed         | 28425       |\n",
      "|    total_timesteps      | 3174400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013088895 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89         |\n",
      "|    explained_variance   | 0.0883      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 15490       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.30551904 |\n",
      "|    std                  | 5.3         |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1551        |\n",
      "|    time_elapsed         | 28444       |\n",
      "|    total_timesteps      | 3176448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013886699 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89         |\n",
      "|    explained_variance   | 0.0611      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 15500       |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    reward               | -12.742285  |\n",
      "|    std                  | 5.3         |\n",
      "|    value_loss           | 65.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1552        |\n",
      "|    time_elapsed         | 28464       |\n",
      "|    total_timesteps      | 3178496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019052424 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.00311     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.3        |\n",
      "|    n_updates            | 15510       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.28169954 |\n",
      "|    std                  | 5.31        |\n",
      "|    value_loss           | 83.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4919862.96\n",
      "total_reward: 3919862.96\n",
      "total_cost: 406902.78\n",
      "total_trades: 70507\n",
      "Sharpe: 0.947\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1553        |\n",
      "|    time_elapsed         | 28482       |\n",
      "|    total_timesteps      | 3180544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020577444 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | -0.118      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.48        |\n",
      "|    n_updates            | 15520       |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    reward               | 1.8053242   |\n",
      "|    std                  | 5.32        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1554        |\n",
      "|    time_elapsed         | 28500       |\n",
      "|    total_timesteps      | 3182592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012483394 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | 0.07        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 15530       |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | 0.1623565   |\n",
      "|    std                  | 5.33        |\n",
      "|    value_loss           | 70.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1555        |\n",
      "|    time_elapsed         | 28518       |\n",
      "|    total_timesteps      | 3184640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009458844 |\n",
      "|    clip_fraction        | 0.0633      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 15540       |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | -3.3206282  |\n",
      "|    std                  | 5.33        |\n",
      "|    value_loss           | 53.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1556        |\n",
      "|    time_elapsed         | 28536       |\n",
      "|    total_timesteps      | 3186688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010132304 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 15550       |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    reward               | -3.7157195  |\n",
      "|    std                  | 5.33        |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1557        |\n",
      "|    time_elapsed         | 28554       |\n",
      "|    total_timesteps      | 3188736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008269783 |\n",
      "|    clip_fraction        | 0.0365      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.01        |\n",
      "|    n_updates            | 15560       |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    reward               | -3.329409   |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 31.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1558        |\n",
      "|    time_elapsed         | 28573       |\n",
      "|    total_timesteps      | 3190784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008047304 |\n",
      "|    clip_fraction        | 0.0565      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | 0.0889      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.7        |\n",
      "|    n_updates            | 15570       |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    reward               | 0.28123194  |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 61.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1559        |\n",
      "|    time_elapsed         | 28591       |\n",
      "|    total_timesteps      | 3192832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009482839 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.3       |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 15580       |\n",
      "|    policy_gradient_loss | 0.000484    |\n",
      "|    reward               | -2.687723   |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1560        |\n",
      "|    time_elapsed         | 28609       |\n",
      "|    total_timesteps      | 3194880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015075071 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.3       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 15590       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | 0.9623942   |\n",
      "|    std                  | 5.35        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1561        |\n",
      "|    time_elapsed         | 28627       |\n",
      "|    total_timesteps      | 3196928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011461999 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.0927      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 15600       |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    reward               | 0.17611857  |\n",
      "|    std                  | 5.37        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1562        |\n",
      "|    time_elapsed         | 28645       |\n",
      "|    total_timesteps      | 3198976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007380877 |\n",
      "|    clip_fraction        | 0.0512      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 15610       |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | 0.06380749  |\n",
      "|    std                  | 5.37        |\n",
      "|    value_loss           | 43          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1563        |\n",
      "|    time_elapsed         | 28663       |\n",
      "|    total_timesteps      | 3201024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012722114 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.92        |\n",
      "|    n_updates            | 15620       |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    reward               | 0.3673036   |\n",
      "|    std                  | 5.37        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1564        |\n",
      "|    time_elapsed         | 28682       |\n",
      "|    total_timesteps      | 3203072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007091254 |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 15630       |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    reward               | 0.5203898   |\n",
      "|    std                  | 5.37        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1565        |\n",
      "|    time_elapsed         | 28700       |\n",
      "|    total_timesteps      | 3205120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007841315 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 15640       |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    reward               | -2.769221   |\n",
      "|    std                  | 5.38        |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1566         |\n",
      "|    time_elapsed         | 28718        |\n",
      "|    total_timesteps      | 3207168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029285895 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.5        |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 15650        |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    reward               | -0.49372977  |\n",
      "|    std                  | 5.38         |\n",
      "|    value_loss           | 34.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3442118.92\n",
      "total_reward: 2442118.92\n",
      "total_cost: 153714.83\n",
      "total_trades: 58362\n",
      "Sharpe: 0.755\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1567        |\n",
      "|    time_elapsed         | 28736       |\n",
      "|    total_timesteps      | 3209216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008883774 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 15660       |\n",
      "|    policy_gradient_loss | -0.00745    |\n",
      "|    reward               | -0.53753835 |\n",
      "|    std                  | 5.38        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1568        |\n",
      "|    time_elapsed         | 28754       |\n",
      "|    total_timesteps      | 3211264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009355713 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 15670       |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    reward               | -0.44947374 |\n",
      "|    std                  | 5.39        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1569        |\n",
      "|    time_elapsed         | 28772       |\n",
      "|    total_timesteps      | 3213312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010559997 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 15680       |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    reward               | 0.036361363 |\n",
      "|    std                  | 5.39        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1570        |\n",
      "|    time_elapsed         | 28790       |\n",
      "|    total_timesteps      | 3215360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018091515 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.82        |\n",
      "|    n_updates            | 15690       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -0.62380457 |\n",
      "|    std                  | 5.41        |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1571        |\n",
      "|    time_elapsed         | 28808       |\n",
      "|    total_timesteps      | 3217408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007659983 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.61        |\n",
      "|    n_updates            | 15700       |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    reward               | 0.40430793  |\n",
      "|    std                  | 5.42        |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1572       |\n",
      "|    time_elapsed         | 28826      |\n",
      "|    total_timesteps      | 3219456    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00621349 |\n",
      "|    clip_fraction        | 0.0288     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -89.7      |\n",
      "|    explained_variance   | 0.467      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.2       |\n",
      "|    n_updates            | 15710      |\n",
      "|    policy_gradient_loss | -0.00803   |\n",
      "|    reward               | -0.5999566 |\n",
      "|    std                  | 5.42       |\n",
      "|    value_loss           | 39.3       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1573         |\n",
      "|    time_elapsed         | 28844        |\n",
      "|    total_timesteps      | 3221504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067411093 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.7        |\n",
      "|    explained_variance   | 0.228        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 15720        |\n",
      "|    policy_gradient_loss | -0.00718     |\n",
      "|    reward               | -0.43435472  |\n",
      "|    std                  | 5.42         |\n",
      "|    value_loss           | 27.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1574        |\n",
      "|    time_elapsed         | 28863       |\n",
      "|    total_timesteps      | 3223552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016289666 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.7       |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.58        |\n",
      "|    n_updates            | 15730       |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    reward               | 0.2626048   |\n",
      "|    std                  | 5.44        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1575        |\n",
      "|    time_elapsed         | 28882       |\n",
      "|    total_timesteps      | 3225600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007527967 |\n",
      "|    clip_fraction        | 0.0469      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.8       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 15740       |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    reward               | 0.34174064  |\n",
      "|    std                  | 5.44        |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1576        |\n",
      "|    time_elapsed         | 28900       |\n",
      "|    total_timesteps      | 3227648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005774342 |\n",
      "|    clip_fraction        | 0.0411      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.8       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 15750       |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    reward               | 0.48898807  |\n",
      "|    std                  | 5.44        |\n",
      "|    value_loss           | 44.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1577         |\n",
      "|    time_elapsed         | 28919        |\n",
      "|    total_timesteps      | 3229696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117202215 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.8        |\n",
      "|    explained_variance   | 0.335        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 15760        |\n",
      "|    policy_gradient_loss | -0.0157      |\n",
      "|    reward               | 0.2165454    |\n",
      "|    std                  | 5.46         |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1578         |\n",
      "|    time_elapsed         | 28938        |\n",
      "|    total_timesteps      | 3231744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065958425 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.9        |\n",
      "|    explained_variance   | 0.42         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.9         |\n",
      "|    n_updates            | 15770        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    reward               | -1.063226    |\n",
      "|    std                  | 5.47         |\n",
      "|    value_loss           | 42           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1579         |\n",
      "|    time_elapsed         | 28958        |\n",
      "|    total_timesteps      | 3233792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037265276 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.9        |\n",
      "|    explained_variance   | 0.273        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 15780        |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    reward               | 3.4934213    |\n",
      "|    std                  | 5.47         |\n",
      "|    value_loss           | 48.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1580        |\n",
      "|    time_elapsed         | 28976       |\n",
      "|    total_timesteps      | 3235840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008372749 |\n",
      "|    clip_fraction        | 0.0397      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.9       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 15790       |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    reward               | 0.7861548   |\n",
      "|    std                  | 5.47        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3304039.39\n",
      "total_reward: 2304039.39\n",
      "total_cost: 126628.59\n",
      "total_trades: 56145\n",
      "Sharpe: 0.745\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1581        |\n",
      "|    time_elapsed         | 28994       |\n",
      "|    total_timesteps      | 3237888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013273925 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90         |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 15800       |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    reward               | 1.1703928   |\n",
      "|    std                  | 5.49        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1582         |\n",
      "|    time_elapsed         | 29013        |\n",
      "|    total_timesteps      | 3239936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087257065 |\n",
      "|    clip_fraction        | 0.0488       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.1        |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 15810        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | -1.0191039   |\n",
      "|    std                  | 5.5          |\n",
      "|    value_loss           | 30.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1583         |\n",
      "|    time_elapsed         | 29031        |\n",
      "|    total_timesteps      | 3241984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097514475 |\n",
      "|    clip_fraction        | 0.0752       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.1        |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 15820        |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    reward               | -0.8708804   |\n",
      "|    std                  | 5.51         |\n",
      "|    value_loss           | 23           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1584        |\n",
      "|    time_elapsed         | 29050       |\n",
      "|    total_timesteps      | 3244032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009277315 |\n",
      "|    clip_fraction        | 0.0435      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.1       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.57        |\n",
      "|    n_updates            | 15830       |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    reward               | 0.06398888  |\n",
      "|    std                  | 5.51        |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1585        |\n",
      "|    time_elapsed         | 29069       |\n",
      "|    total_timesteps      | 3246080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009598255 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 15840       |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | 0.7364422   |\n",
      "|    std                  | 5.51        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1586        |\n",
      "|    time_elapsed         | 29087       |\n",
      "|    total_timesteps      | 3248128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004324341 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 15850       |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    reward               | -1.9442986  |\n",
      "|    std                  | 5.51        |\n",
      "|    value_loss           | 70          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1587        |\n",
      "|    time_elapsed         | 29105       |\n",
      "|    total_timesteps      | 3250176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014840842 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.87        |\n",
      "|    n_updates            | 15860       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 2.1326058   |\n",
      "|    std                  | 5.52        |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1588        |\n",
      "|    time_elapsed         | 29124       |\n",
      "|    total_timesteps      | 3252224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010123007 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 15870       |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    reward               | -0.399591   |\n",
      "|    std                  | 5.53        |\n",
      "|    value_loss           | 42          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1589        |\n",
      "|    time_elapsed         | 29143       |\n",
      "|    total_timesteps      | 3254272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00947932  |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.3       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 15880       |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    reward               | -0.42949668 |\n",
      "|    std                  | 5.53        |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1590        |\n",
      "|    time_elapsed         | 29161       |\n",
      "|    total_timesteps      | 3256320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010504821 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.3       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 15890       |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    reward               | 0.17009565  |\n",
      "|    std                  | 5.54        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1591        |\n",
      "|    time_elapsed         | 29180       |\n",
      "|    total_timesteps      | 3258368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019163834 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 15900       |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    reward               | -1.5562456  |\n",
      "|    std                  | 5.56        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1592        |\n",
      "|    time_elapsed         | 29198       |\n",
      "|    total_timesteps      | 3260416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008034822 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 15910       |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    reward               | -0.08101309 |\n",
      "|    std                  | 5.57        |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1593       |\n",
      "|    time_elapsed         | 29216      |\n",
      "|    total_timesteps      | 3262464    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00512525 |\n",
      "|    clip_fraction        | 0.0345     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -90.4      |\n",
      "|    explained_variance   | 0.462      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.9       |\n",
      "|    n_updates            | 15920      |\n",
      "|    policy_gradient_loss | -0.0056    |\n",
      "|    reward               | 3.6693666  |\n",
      "|    std                  | 5.57       |\n",
      "|    value_loss           | 50.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1594        |\n",
      "|    time_elapsed         | 29235       |\n",
      "|    total_timesteps      | 3264512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013499323 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.06        |\n",
      "|    n_updates            | 15930       |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    reward               | -0.261479   |\n",
      "|    std                  | 5.57        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3581527.34\n",
      "total_reward: 2581527.34\n",
      "total_cost: 132610.78\n",
      "total_trades: 57475\n",
      "Sharpe: 0.770\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1595         |\n",
      "|    time_elapsed         | 29255        |\n",
      "|    total_timesteps      | 3266560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012445036  |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.5        |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.8         |\n",
      "|    n_updates            | 15940        |\n",
      "|    policy_gradient_loss | -0.00943     |\n",
      "|    reward               | -0.025888186 |\n",
      "|    std                  | 5.58         |\n",
      "|    value_loss           | 41.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1596        |\n",
      "|    time_elapsed         | 29274       |\n",
      "|    total_timesteps      | 3268608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008292219 |\n",
      "|    clip_fraction        | 0.0396      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.5       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 15950       |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    reward               | 0.26954722  |\n",
      "|    std                  | 5.58        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1597        |\n",
      "|    time_elapsed         | 29292       |\n",
      "|    total_timesteps      | 3270656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007605866 |\n",
      "|    clip_fraction        | 0.0377      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.5       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 15960       |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    reward               | -3.662734   |\n",
      "|    std                  | 5.59        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1598         |\n",
      "|    time_elapsed         | 29312        |\n",
      "|    total_timesteps      | 3272704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0147398915 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.6        |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 15970        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | 0.48684487   |\n",
      "|    std                  | 5.6          |\n",
      "|    value_loss           | 34.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1599         |\n",
      "|    time_elapsed         | 29331        |\n",
      "|    total_timesteps      | 3274752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110158585 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.6        |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 15980        |\n",
      "|    policy_gradient_loss | -0.00925     |\n",
      "|    reward               | -3.7318807   |\n",
      "|    std                  | 5.61         |\n",
      "|    value_loss           | 45.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1600         |\n",
      "|    time_elapsed         | 29351        |\n",
      "|    total_timesteps      | 3276800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062063625 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.7        |\n",
      "|    explained_variance   | 0.292        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 15990        |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    reward               | -1.3422439   |\n",
      "|    std                  | 5.61         |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1601        |\n",
      "|    time_elapsed         | 29369       |\n",
      "|    total_timesteps      | 3278848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017472576 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.7       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 16000       |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    reward               | -1.2363335  |\n",
      "|    std                  | 5.62        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1602        |\n",
      "|    time_elapsed         | 29388       |\n",
      "|    total_timesteps      | 3280896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016161583 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.7       |\n",
      "|    explained_variance   | 0.0451      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 16010       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -0.06230432 |\n",
      "|    std                  | 5.62        |\n",
      "|    value_loss           | 63.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1603         |\n",
      "|    time_elapsed         | 29406        |\n",
      "|    total_timesteps      | 3282944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035350774 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.7        |\n",
      "|    explained_variance   | 0.222        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 16020        |\n",
      "|    policy_gradient_loss | -0.000634    |\n",
      "|    reward               | 3.3811011    |\n",
      "|    std                  | 5.63         |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1604        |\n",
      "|    time_elapsed         | 29425       |\n",
      "|    total_timesteps      | 3284992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013188241 |\n",
      "|    clip_fraction        | 0.069       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.8       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.29        |\n",
      "|    n_updates            | 16030       |\n",
      "|    policy_gradient_loss | -0.0051     |\n",
      "|    reward               | 1.2898846   |\n",
      "|    std                  | 5.63        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1605        |\n",
      "|    time_elapsed         | 29443       |\n",
      "|    total_timesteps      | 3287040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013163713 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.8       |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 16040       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 0.9080237   |\n",
      "|    std                  | 5.65        |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1606        |\n",
      "|    time_elapsed         | 29463       |\n",
      "|    total_timesteps      | 3289088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009051982 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | 0.0491      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31          |\n",
      "|    n_updates            | 16050       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -0.38251334 |\n",
      "|    std                  | 5.66        |\n",
      "|    value_loss           | 60          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1607        |\n",
      "|    time_elapsed         | 29482       |\n",
      "|    total_timesteps      | 3291136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014414204 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 16060       |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    reward               | 2.1772814   |\n",
      "|    std                  | 5.67        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1608        |\n",
      "|    time_elapsed         | 29501       |\n",
      "|    total_timesteps      | 3293184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013667935 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 16070       |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    reward               | -2.1885629  |\n",
      "|    std                  | 5.68        |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4355613.96\n",
      "total_reward: 3355613.96\n",
      "total_cost: 194009.74\n",
      "total_trades: 61239\n",
      "Sharpe: 0.872\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1609        |\n",
      "|    time_elapsed         | 29520       |\n",
      "|    total_timesteps      | 3295232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009408406 |\n",
      "|    clip_fraction        | 0.0974      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 16080       |\n",
      "|    policy_gradient_loss | 0.00155     |\n",
      "|    reward               | 0.60591215  |\n",
      "|    std                  | 5.68        |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1610        |\n",
      "|    time_elapsed         | 29538       |\n",
      "|    total_timesteps      | 3297280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014269423 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | 0.0284      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 16090       |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | -2.9012964  |\n",
      "|    std                  | 5.71        |\n",
      "|    value_loss           | 65.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1611        |\n",
      "|    time_elapsed         | 29556       |\n",
      "|    total_timesteps      | 3299328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014831213 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.2       |\n",
      "|    explained_variance   | 0.056       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 16100       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 2.0141702   |\n",
      "|    std                  | 5.72        |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1612         |\n",
      "|    time_elapsed         | 29575        |\n",
      "|    total_timesteps      | 3301376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070163677 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.2        |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 16110        |\n",
      "|    policy_gradient_loss | -0.00696     |\n",
      "|    reward               | 0.42083973   |\n",
      "|    std                  | 5.73         |\n",
      "|    value_loss           | 44.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1613        |\n",
      "|    time_elapsed         | 29593       |\n",
      "|    total_timesteps      | 3303424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008466717 |\n",
      "|    clip_fraction        | 0.0609      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 16120       |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    reward               | -9.447549   |\n",
      "|    std                  | 5.74        |\n",
      "|    value_loss           | 61.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1614        |\n",
      "|    time_elapsed         | 29611       |\n",
      "|    total_timesteps      | 3305472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011098757 |\n",
      "|    clip_fraction        | 0.0725      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 16130       |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    reward               | 1.5224946   |\n",
      "|    std                  | 5.74        |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1615        |\n",
      "|    time_elapsed         | 29630       |\n",
      "|    total_timesteps      | 3307520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01328822  |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 16140       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.015350766 |\n",
      "|    std                  | 5.74        |\n",
      "|    value_loss           | 31.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1616        |\n",
      "|    time_elapsed         | 29648       |\n",
      "|    total_timesteps      | 3309568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010430726 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 16150       |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    reward               | 3.7585297   |\n",
      "|    std                  | 5.74        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1617         |\n",
      "|    time_elapsed         | 29668        |\n",
      "|    total_timesteps      | 3311616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014563263 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.3        |\n",
      "|    explained_variance   | 0.182        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 16160        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    reward               | -0.7282586   |\n",
      "|    std                  | 5.74         |\n",
      "|    value_loss           | 44.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1618        |\n",
      "|    time_elapsed         | 29686       |\n",
      "|    total_timesteps      | 3313664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011434349 |\n",
      "|    clip_fraction        | 0.0861      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.06        |\n",
      "|    n_updates            | 16170       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    reward               | 1.3992063   |\n",
      "|    std                  | 5.74        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1619        |\n",
      "|    time_elapsed         | 29705       |\n",
      "|    total_timesteps      | 3315712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009684098 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 16180       |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    reward               | 1.4361606   |\n",
      "|    std                  | 5.74        |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1620         |\n",
      "|    time_elapsed         | 29724        |\n",
      "|    total_timesteps      | 3317760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068124826 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.4        |\n",
      "|    explained_variance   | 0.119        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23           |\n",
      "|    n_updates            | 16190        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    reward               | 4.016866     |\n",
      "|    std                  | 5.75         |\n",
      "|    value_loss           | 39.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1621        |\n",
      "|    time_elapsed         | 29742       |\n",
      "|    total_timesteps      | 3319808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016136358 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 16200       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | 1.1510026   |\n",
      "|    std                  | 5.76        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1622        |\n",
      "|    time_elapsed         | 29760       |\n",
      "|    total_timesteps      | 3321856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008087678 |\n",
      "|    clip_fraction        | 0.0486      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 16210       |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    reward               | -2.1942701  |\n",
      "|    std                  | 5.77        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1623         |\n",
      "|    time_elapsed         | 29778        |\n",
      "|    total_timesteps      | 3323904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042207157 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.5        |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 16220        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    reward               | -1.8757114   |\n",
      "|    std                  | 5.77         |\n",
      "|    value_loss           | 42.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4114580.79\n",
      "total_reward: 3114580.79\n",
      "total_cost: 274969.98\n",
      "total_trades: 66724\n",
      "Sharpe: 0.804\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1624        |\n",
      "|    time_elapsed         | 29796       |\n",
      "|    total_timesteps      | 3325952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008548608 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 16230       |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | 1.0456611   |\n",
      "|    std                  | 5.78        |\n",
      "|    value_loss           | 36.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1625       |\n",
      "|    time_elapsed         | 29815      |\n",
      "|    total_timesteps      | 3328000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01015452 |\n",
      "|    clip_fraction        | 0.0591     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.5      |\n",
      "|    explained_variance   | 0.318      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.97       |\n",
      "|    n_updates            | 16240      |\n",
      "|    policy_gradient_loss | -0.00664   |\n",
      "|    reward               | 0.30099532 |\n",
      "|    std                  | 5.78       |\n",
      "|    value_loss           | 26.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1626        |\n",
      "|    time_elapsed         | 29834       |\n",
      "|    total_timesteps      | 3330048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008640875 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 16250       |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    reward               | -1.0711209  |\n",
      "|    std                  | 5.78        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1627        |\n",
      "|    time_elapsed         | 29852       |\n",
      "|    total_timesteps      | 3332096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009136186 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 16260       |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    reward               | 1.2775644   |\n",
      "|    std                  | 5.79        |\n",
      "|    value_loss           | 43.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1628        |\n",
      "|    time_elapsed         | 29871       |\n",
      "|    total_timesteps      | 3334144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020869605 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.6       |\n",
      "|    explained_variance   | 0.0611      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.87        |\n",
      "|    n_updates            | 16270       |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    reward               | -0.72845715 |\n",
      "|    std                  | 5.79        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1629        |\n",
      "|    time_elapsed         | 29889       |\n",
      "|    total_timesteps      | 3336192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010244046 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.6       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 16280       |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    reward               | 1.141739    |\n",
      "|    std                  | 5.8         |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1630        |\n",
      "|    time_elapsed         | 29907       |\n",
      "|    total_timesteps      | 3338240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010599207 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.7       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 16290       |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | 0.46681663  |\n",
      "|    std                  | 5.81        |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1631         |\n",
      "|    time_elapsed         | 29927        |\n",
      "|    total_timesteps      | 3340288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069708456 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.7        |\n",
      "|    explained_variance   | 0.296        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.29         |\n",
      "|    n_updates            | 16300        |\n",
      "|    policy_gradient_loss | -0.00705     |\n",
      "|    reward               | -1.4156797   |\n",
      "|    std                  | 5.81         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1632        |\n",
      "|    time_elapsed         | 29945       |\n",
      "|    total_timesteps      | 3342336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012440538 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.7       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.96        |\n",
      "|    n_updates            | 16310       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -0.5321334  |\n",
      "|    std                  | 5.82        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1633        |\n",
      "|    time_elapsed         | 29964       |\n",
      "|    total_timesteps      | 3344384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012525908 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.8       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 16320       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 0.44669595  |\n",
      "|    std                  | 5.83        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1634       |\n",
      "|    time_elapsed         | 29982      |\n",
      "|    total_timesteps      | 3346432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00973525 |\n",
      "|    clip_fraction        | 0.0827     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.8      |\n",
      "|    explained_variance   | 0.309      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.3       |\n",
      "|    n_updates            | 16330      |\n",
      "|    policy_gradient_loss | -0.00733   |\n",
      "|    reward               | 0.96720874 |\n",
      "|    std                  | 5.84       |\n",
      "|    value_loss           | 34.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1635        |\n",
      "|    time_elapsed         | 30002       |\n",
      "|    total_timesteps      | 3348480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019370174 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.8       |\n",
      "|    explained_variance   | 0.0718      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.97        |\n",
      "|    n_updates            | 16340       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -4.0322757  |\n",
      "|    std                  | 5.85        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1636       |\n",
      "|    time_elapsed         | 30021      |\n",
      "|    total_timesteps      | 3350528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0130945  |\n",
      "|    clip_fraction        | 0.087      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.9      |\n",
      "|    explained_variance   | 0.326      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15         |\n",
      "|    n_updates            | 16350      |\n",
      "|    policy_gradient_loss | -0.00538   |\n",
      "|    reward               | -0.9581831 |\n",
      "|    std                  | 5.86       |\n",
      "|    value_loss           | 35.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1637        |\n",
      "|    time_elapsed         | 30040       |\n",
      "|    total_timesteps      | 3352576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011979407 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.9       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 16360       |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    reward               | -4.9468293  |\n",
      "|    std                  | 5.86        |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5719212.38\n",
      "total_reward: 4719212.38\n",
      "total_cost: 438909.38\n",
      "total_trades: 73553\n",
      "Sharpe: 0.909\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1638        |\n",
      "|    time_elapsed         | 30058       |\n",
      "|    total_timesteps      | 3354624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021108959 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | -0.00109    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 16370       |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | 2.5642955   |\n",
      "|    std                  | 5.88        |\n",
      "|    value_loss           | 42.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1639        |\n",
      "|    time_elapsed         | 30077       |\n",
      "|    total_timesteps      | 3356672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017524946 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | 0.00851     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94.8        |\n",
      "|    n_updates            | 16380       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | 0.15108116  |\n",
      "|    std                  | 5.89        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1640        |\n",
      "|    time_elapsed         | 30095       |\n",
      "|    total_timesteps      | 3358720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013272302 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.1       |\n",
      "|    explained_variance   | 0.00947     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.7        |\n",
      "|    n_updates            | 16390       |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | 0.92645264  |\n",
      "|    std                  | 5.9         |\n",
      "|    value_loss           | 79.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1641        |\n",
      "|    time_elapsed         | 30114       |\n",
      "|    total_timesteps      | 3360768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007558277 |\n",
      "|    clip_fraction        | 0.0346      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.1       |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 16400       |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    reward               | -0.29670477 |\n",
      "|    std                  | 5.91        |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1642        |\n",
      "|    time_elapsed         | 30133       |\n",
      "|    total_timesteps      | 3362816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010787224 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.1       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.47        |\n",
      "|    n_updates            | 16410       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -0.13850158 |\n",
      "|    std                  | 5.92        |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1643        |\n",
      "|    time_elapsed         | 30151       |\n",
      "|    total_timesteps      | 3364864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007771724 |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 16420       |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | 0.71831477  |\n",
      "|    std                  | 5.92        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1644         |\n",
      "|    time_elapsed         | 30170        |\n",
      "|    total_timesteps      | 3366912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064715156 |\n",
      "|    clip_fraction        | 0.0568       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.2        |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 16430        |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    reward               | -0.30221832  |\n",
      "|    std                  | 5.92         |\n",
      "|    value_loss           | 31.7         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1645       |\n",
      "|    time_elapsed         | 30188      |\n",
      "|    total_timesteps      | 3368960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0158288  |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.3      |\n",
      "|    explained_variance   | 0.196      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.1       |\n",
      "|    n_updates            | 16440      |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    reward               | -1.0882156 |\n",
      "|    std                  | 5.95       |\n",
      "|    value_loss           | 26.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1646        |\n",
      "|    time_elapsed         | 30207       |\n",
      "|    total_timesteps      | 3371008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012928748 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 16450       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -2.2733796  |\n",
      "|    std                  | 5.96        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1647        |\n",
      "|    time_elapsed         | 30226       |\n",
      "|    total_timesteps      | 3373056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007293096 |\n",
      "|    clip_fraction        | 0.0512      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 16460       |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    reward               | 0.38688505  |\n",
      "|    std                  | 5.96        |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1648         |\n",
      "|    time_elapsed         | 30245        |\n",
      "|    total_timesteps      | 3375104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102441795 |\n",
      "|    clip_fraction        | 0.0696       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.4        |\n",
      "|    explained_variance   | 0.247        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 16470        |\n",
      "|    policy_gradient_loss | -0.00691     |\n",
      "|    reward               | 3.547849     |\n",
      "|    std                  | 5.97         |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1649        |\n",
      "|    time_elapsed         | 30264       |\n",
      "|    total_timesteps      | 3377152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009512933 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.99        |\n",
      "|    n_updates            | 16480       |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    reward               | -0.32015565 |\n",
      "|    std                  | 5.98        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1650         |\n",
      "|    time_elapsed         | 30283        |\n",
      "|    total_timesteps      | 3379200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064272545 |\n",
      "|    clip_fraction        | 0.0457       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.5        |\n",
      "|    explained_variance   | 0.259        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 16490        |\n",
      "|    policy_gradient_loss | -0.0075      |\n",
      "|    reward               | 0.41478428   |\n",
      "|    std                  | 5.99         |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1651        |\n",
      "|    time_elapsed         | 30302       |\n",
      "|    total_timesteps      | 3381248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003402304 |\n",
      "|    clip_fraction        | 0.0063      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 16500       |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    reward               | 2.0494156   |\n",
      "|    std                  | 5.99        |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3848457.14\n",
      "total_reward: 2848457.14\n",
      "total_cost: 290909.57\n",
      "total_trades: 67029\n",
      "Sharpe: 0.779\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1652        |\n",
      "|    time_elapsed         | 30322       |\n",
      "|    total_timesteps      | 3383296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013433127 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 16510       |\n",
      "|    policy_gradient_loss | -0.00981    |\n",
      "|    reward               | -0.2716608  |\n",
      "|    std                  | 5.99        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1653        |\n",
      "|    time_elapsed         | 30342       |\n",
      "|    total_timesteps      | 3385344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007868454 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 16520       |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    reward               | -0.2965157  |\n",
      "|    std                  | 6           |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1654        |\n",
      "|    time_elapsed         | 30361       |\n",
      "|    total_timesteps      | 3387392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006505817 |\n",
      "|    clip_fraction        | 0.0275      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.6       |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 16530       |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | 0.6407893   |\n",
      "|    std                  | 6           |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1655         |\n",
      "|    time_elapsed         | 30381        |\n",
      "|    total_timesteps      | 3389440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061197584 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.6        |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 16540        |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    reward               | 0.35837474   |\n",
      "|    std                  | 6            |\n",
      "|    value_loss           | 28.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1656        |\n",
      "|    time_elapsed         | 30400       |\n",
      "|    total_timesteps      | 3391488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011040398 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.6       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 16550       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 1.039193    |\n",
      "|    std                  | 6.01        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1657         |\n",
      "|    time_elapsed         | 30419        |\n",
      "|    total_timesteps      | 3393536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047662356 |\n",
      "|    clip_fraction        | 0.0342       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.6        |\n",
      "|    explained_variance   | 0.45         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 16560        |\n",
      "|    policy_gradient_loss | -0.00776     |\n",
      "|    reward               | 0.89778745   |\n",
      "|    std                  | 6.01         |\n",
      "|    value_loss           | 35.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1658        |\n",
      "|    time_elapsed         | 30438       |\n",
      "|    total_timesteps      | 3395584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006087093 |\n",
      "|    clip_fraction        | 0.0363      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.6       |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 16570       |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    reward               | -0.15034348 |\n",
      "|    std                  | 6.02        |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1659        |\n",
      "|    time_elapsed         | 30456       |\n",
      "|    total_timesteps      | 3397632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018574465 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.68        |\n",
      "|    n_updates            | 16580       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -0.59289074 |\n",
      "|    std                  | 6.04        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1660        |\n",
      "|    time_elapsed         | 30474       |\n",
      "|    total_timesteps      | 3399680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009310665 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.8       |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 16590       |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    reward               | -0.36575004 |\n",
      "|    std                  | 6.04        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1661       |\n",
      "|    time_elapsed         | 30493      |\n",
      "|    total_timesteps      | 3401728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01126301 |\n",
      "|    clip_fraction        | 0.0986     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.8      |\n",
      "|    explained_variance   | 0.0765     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.5       |\n",
      "|    n_updates            | 16600      |\n",
      "|    policy_gradient_loss | -0.00148   |\n",
      "|    reward               | 1.4222274  |\n",
      "|    std                  | 6.06       |\n",
      "|    value_loss           | 41.1       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1662        |\n",
      "|    time_elapsed         | 30511       |\n",
      "|    total_timesteps      | 3403776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021013957 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | 0.0344      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.46        |\n",
      "|    n_updates            | 16610       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -2.362184   |\n",
      "|    std                  | 6.07        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1663        |\n",
      "|    time_elapsed         | 30530       |\n",
      "|    total_timesteps      | 3405824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011181385 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 16620       |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | -0.25254267 |\n",
      "|    std                  | 6.07        |\n",
      "|    value_loss           | 30.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1664         |\n",
      "|    time_elapsed         | 30548        |\n",
      "|    total_timesteps      | 3407872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059044706 |\n",
      "|    clip_fraction        | 0.0832       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.9        |\n",
      "|    explained_variance   | 0.121        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 16630        |\n",
      "|    policy_gradient_loss | 0.002        |\n",
      "|    reward               | -2.6515481   |\n",
      "|    std                  | 6.07         |\n",
      "|    value_loss           | 42.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1665        |\n",
      "|    time_elapsed         | 30567       |\n",
      "|    total_timesteps      | 3409920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009729545 |\n",
      "|    clip_fraction        | 0.0632      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 16640       |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    reward               | 2.1452582   |\n",
      "|    std                  | 6.08        |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3732717.93\n",
      "total_reward: 2732717.93\n",
      "total_cost: 293999.07\n",
      "total_trades: 65902\n",
      "Sharpe: 0.745\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1666        |\n",
      "|    time_elapsed         | 30585       |\n",
      "|    total_timesteps      | 3411968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015346021 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.77        |\n",
      "|    n_updates            | 16650       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | 1.6047708   |\n",
      "|    std                  | 6.09        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1667         |\n",
      "|    time_elapsed         | 30604        |\n",
      "|    total_timesteps      | 3414016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108083915 |\n",
      "|    clip_fraction        | 0.0828       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93          |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 16660        |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    reward               | -0.9235462   |\n",
      "|    std                  | 6.1          |\n",
      "|    value_loss           | 30.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1668        |\n",
      "|    time_elapsed         | 30623       |\n",
      "|    total_timesteps      | 3416064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003231987 |\n",
      "|    clip_fraction        | 0.0381      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 16670       |\n",
      "|    policy_gradient_loss | -0.000746   |\n",
      "|    reward               | 4.867555    |\n",
      "|    std                  | 6.1         |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1669         |\n",
      "|    time_elapsed         | 30642        |\n",
      "|    total_timesteps      | 3418112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074725687 |\n",
      "|    clip_fraction        | 0.0546       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93          |\n",
      "|    explained_variance   | 0.342        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 16680        |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    reward               | 0.812434     |\n",
      "|    std                  | 6.1          |\n",
      "|    value_loss           | 31.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1670        |\n",
      "|    time_elapsed         | 30660       |\n",
      "|    total_timesteps      | 3420160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010597389 |\n",
      "|    clip_fraction        | 0.0735      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.11        |\n",
      "|    n_updates            | 16690       |\n",
      "|    policy_gradient_loss | 0.00145     |\n",
      "|    reward               | -1.7352695  |\n",
      "|    std                  | 6.11        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1671        |\n",
      "|    time_elapsed         | 30679       |\n",
      "|    total_timesteps      | 3422208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012497034 |\n",
      "|    clip_fraction        | 0.0487      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 16700       |\n",
      "|    policy_gradient_loss | 0.00162     |\n",
      "|    reward               | 3.7938395   |\n",
      "|    std                  | 6.11        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1672        |\n",
      "|    time_elapsed         | 30697       |\n",
      "|    total_timesteps      | 3424256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008063624 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 16710       |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    reward               | -1.8473521  |\n",
      "|    std                  | 6.11        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1673        |\n",
      "|    time_elapsed         | 30717       |\n",
      "|    total_timesteps      | 3426304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015678119 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.78        |\n",
      "|    n_updates            | 16720       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 0.70557564  |\n",
      "|    std                  | 6.12        |\n",
      "|    value_loss           | 23.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1674        |\n",
      "|    time_elapsed         | 30736       |\n",
      "|    total_timesteps      | 3428352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012175149 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 16730       |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    reward               | 0.7401351   |\n",
      "|    std                  | 6.13        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1675        |\n",
      "|    time_elapsed         | 30754       |\n",
      "|    total_timesteps      | 3430400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016982976 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.2       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 16740       |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    reward               | -2.328611   |\n",
      "|    std                  | 6.13        |\n",
      "|    value_loss           | 48.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1676       |\n",
      "|    time_elapsed         | 30773      |\n",
      "|    total_timesteps      | 3432448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01682745 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.2      |\n",
      "|    explained_variance   | 0.0551     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.2       |\n",
      "|    n_updates            | 16750      |\n",
      "|    policy_gradient_loss | -0.00913   |\n",
      "|    reward               | -2.6976912 |\n",
      "|    std                  | 6.16       |\n",
      "|    value_loss           | 18         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1677        |\n",
      "|    time_elapsed         | 30792       |\n",
      "|    total_timesteps      | 3434496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006716251 |\n",
      "|    clip_fraction        | 0.0343      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.3       |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 16760       |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | 0.62292856  |\n",
      "|    std                  | 6.16        |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1678        |\n",
      "|    time_elapsed         | 30811       |\n",
      "|    total_timesteps      | 3436544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010042228 |\n",
      "|    clip_fraction        | 0.0466      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.3       |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 16770       |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | -1.2985201  |\n",
      "|    std                  | 6.17        |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1679        |\n",
      "|    time_elapsed         | 30829       |\n",
      "|    total_timesteps      | 3438592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006558816 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.4       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 16780       |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    reward               | 1.1757303   |\n",
      "|    std                  | 6.17        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4210992.85\n",
      "total_reward: 3210992.85\n",
      "total_cost: 247690.65\n",
      "total_trades: 64871\n",
      "Sharpe: 0.802\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1680        |\n",
      "|    time_elapsed         | 30848       |\n",
      "|    total_timesteps      | 3440640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013819022 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.4       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 16790       |\n",
      "|    policy_gradient_loss | -0.00977    |\n",
      "|    reward               | 2.837432    |\n",
      "|    std                  | 6.18        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1681         |\n",
      "|    time_elapsed         | 30867        |\n",
      "|    total_timesteps      | 3442688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090461075 |\n",
      "|    clip_fraction        | 0.0601       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.4        |\n",
      "|    explained_variance   | 0.316        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 16800        |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    reward               | -0.7283246   |\n",
      "|    std                  | 6.18         |\n",
      "|    value_loss           | 47.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1682        |\n",
      "|    time_elapsed         | 30887       |\n",
      "|    total_timesteps      | 3444736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006483394 |\n",
      "|    clip_fraction        | 0.03        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.4       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 16810       |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    reward               | -0.5534889  |\n",
      "|    std                  | 6.19        |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1683        |\n",
      "|    time_elapsed         | 30906       |\n",
      "|    total_timesteps      | 3446784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020697542 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.5       |\n",
      "|    explained_variance   | -0.00373    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 16820       |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    reward               | -3.32053    |\n",
      "|    std                  | 6.21        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1684        |\n",
      "|    time_elapsed         | 30925       |\n",
      "|    total_timesteps      | 3448832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013352249 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.0968      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 16830       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -0.48929042 |\n",
      "|    std                  | 6.22        |\n",
      "|    value_loss           | 77.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1685        |\n",
      "|    time_elapsed         | 30944       |\n",
      "|    total_timesteps      | 3450880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009894063 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.8        |\n",
      "|    n_updates            | 16840       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | -2.1532202  |\n",
      "|    std                  | 6.22        |\n",
      "|    value_loss           | 49.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1686        |\n",
      "|    time_elapsed         | 30963       |\n",
      "|    total_timesteps      | 3452928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017784197 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.89        |\n",
      "|    n_updates            | 16850       |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    reward               | 0.15209004  |\n",
      "|    std                  | 6.22        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1687        |\n",
      "|    time_elapsed         | 30981       |\n",
      "|    total_timesteps      | 3454976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012773344 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.28        |\n",
      "|    n_updates            | 16860       |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    reward               | 5.740366    |\n",
      "|    std                  | 6.23        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1688        |\n",
      "|    time_elapsed         | 30998       |\n",
      "|    total_timesteps      | 3457024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007280522 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.7       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 16870       |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    reward               | -0.9972298  |\n",
      "|    std                  | 6.24        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1689         |\n",
      "|    time_elapsed         | 31017        |\n",
      "|    total_timesteps      | 3459072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009017344 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.7        |\n",
      "|    explained_variance   | 0.216        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.3         |\n",
      "|    n_updates            | 16880        |\n",
      "|    policy_gradient_loss | -0.000365    |\n",
      "|    reward               | -2.8139853   |\n",
      "|    std                  | 6.24         |\n",
      "|    value_loss           | 43.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1690         |\n",
      "|    time_elapsed         | 31054        |\n",
      "|    total_timesteps      | 3461120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134777315 |\n",
      "|    clip_fraction        | 0.0962       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.7        |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 16890        |\n",
      "|    policy_gradient_loss | -0.0127      |\n",
      "|    reward               | 2.4114587    |\n",
      "|    std                  | 6.25         |\n",
      "|    value_loss           | 23.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1691        |\n",
      "|    time_elapsed         | 31072       |\n",
      "|    total_timesteps      | 3463168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006422686 |\n",
      "|    clip_fraction        | 0.0316      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 16900       |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | 0.7475271   |\n",
      "|    std                  | 6.25        |\n",
      "|    value_loss           | 40.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1692        |\n",
      "|    time_elapsed         | 31091       |\n",
      "|    total_timesteps      | 3465216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005024305 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 16910       |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    reward               | 2.5979128   |\n",
      "|    std                  | 6.26        |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1693        |\n",
      "|    time_elapsed         | 31109       |\n",
      "|    total_timesteps      | 3467264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017182209 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.3         |\n",
      "|    n_updates            | 16920       |\n",
      "|    policy_gradient_loss | -0.00943    |\n",
      "|    reward               | -3.5536196  |\n",
      "|    std                  | 6.27        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4798578.05\n",
      "total_reward: 3798578.05\n",
      "total_cost: 378979.50\n",
      "total_trades: 70185\n",
      "Sharpe: 0.814\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1694        |\n",
      "|    time_elapsed         | 31127       |\n",
      "|    total_timesteps      | 3469312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009530343 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 16930       |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    reward               | 0.63418305  |\n",
      "|    std                  | 6.27        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1695         |\n",
      "|    time_elapsed         | 31146        |\n",
      "|    total_timesteps      | 3471360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058893496 |\n",
      "|    clip_fraction        | 0.0511       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.9        |\n",
      "|    explained_variance   | 0.102        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40           |\n",
      "|    n_updates            | 16940        |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    reward               | -3.9932573   |\n",
      "|    std                  | 6.27         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1696        |\n",
      "|    time_elapsed         | 31164       |\n",
      "|    total_timesteps      | 3473408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021834405 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.9       |\n",
      "|    explained_variance   | 0.00572     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 16950       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -0.6011336  |\n",
      "|    std                  | 6.28        |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1697        |\n",
      "|    time_elapsed         | 31182       |\n",
      "|    total_timesteps      | 3475456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014562326 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.9       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 16960       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 0.032612115 |\n",
      "|    std                  | 6.29        |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1698       |\n",
      "|    time_elapsed         | 31201      |\n",
      "|    total_timesteps      | 3477504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01868281 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94        |\n",
      "|    explained_variance   | 0.175      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 37.5       |\n",
      "|    n_updates            | 16970      |\n",
      "|    policy_gradient_loss | -0.00446   |\n",
      "|    reward               | -0.2747928 |\n",
      "|    std                  | 6.31       |\n",
      "|    value_loss           | 90.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1699        |\n",
      "|    time_elapsed         | 31220       |\n",
      "|    total_timesteps      | 3479552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005749745 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.0704      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 16980       |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    reward               | -4.426506   |\n",
      "|    std                  | 6.32        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1700        |\n",
      "|    time_elapsed         | 31239       |\n",
      "|    total_timesteps      | 3481600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019554164 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.19        |\n",
      "|    n_updates            | 16990       |\n",
      "|    policy_gradient_loss | -0.00267    |\n",
      "|    reward               | 0.9847617   |\n",
      "|    std                  | 6.31        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1701        |\n",
      "|    time_elapsed         | 31257       |\n",
      "|    total_timesteps      | 3483648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011436303 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.0569      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 17000       |\n",
      "|    policy_gradient_loss | -0.00655    |\n",
      "|    reward               | -0.4007175  |\n",
      "|    std                  | 6.32        |\n",
      "|    value_loss           | 67.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1702        |\n",
      "|    time_elapsed         | 31275       |\n",
      "|    total_timesteps      | 3485696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013084147 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.5        |\n",
      "|    n_updates            | 17010       |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    reward               | -1.5042144  |\n",
      "|    std                  | 6.32        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1703        |\n",
      "|    time_elapsed         | 31293       |\n",
      "|    total_timesteps      | 3487744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017959762 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 17020       |\n",
      "|    policy_gradient_loss | 0.00131     |\n",
      "|    reward               | -0.31672055 |\n",
      "|    std                  | 6.33        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1704        |\n",
      "|    time_elapsed         | 31311       |\n",
      "|    total_timesteps      | 3489792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015633238 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.5        |\n",
      "|    n_updates            | 17030       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 1.202525    |\n",
      "|    std                  | 6.33        |\n",
      "|    value_loss           | 60.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1705        |\n",
      "|    time_elapsed         | 31329       |\n",
      "|    total_timesteps      | 3491840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009116262 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 17040       |\n",
      "|    policy_gradient_loss | 0.000366    |\n",
      "|    reward               | 4.956461    |\n",
      "|    std                  | 6.34        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1706        |\n",
      "|    time_elapsed         | 31348       |\n",
      "|    total_timesteps      | 3493888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005616556 |\n",
      "|    clip_fraction        | 0.0359      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 17050       |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    reward               | 0.031830028 |\n",
      "|    std                  | 6.34        |\n",
      "|    value_loss           | 83.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1707         |\n",
      "|    time_elapsed         | 31366        |\n",
      "|    total_timesteps      | 3495936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0139691215 |\n",
      "|    clip_fraction        | 0.0982       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.2        |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 17060        |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | -1.1148102   |\n",
      "|    std                  | 6.35         |\n",
      "|    value_loss           | 24.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4116514.82\n",
      "total_reward: 3116514.82\n",
      "total_cost: 309384.64\n",
      "total_trades: 65999\n",
      "Sharpe: 0.663\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1708       |\n",
      "|    time_elapsed         | 31384      |\n",
      "|    total_timesteps      | 3497984    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01253729 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.2      |\n",
      "|    explained_variance   | 0.202      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32         |\n",
      "|    n_updates            | 17070      |\n",
      "|    policy_gradient_loss | -0.00631   |\n",
      "|    reward               | -4.7001724 |\n",
      "|    std                  | 6.35       |\n",
      "|    value_loss           | 56         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1709        |\n",
      "|    time_elapsed         | 31404       |\n",
      "|    total_timesteps      | 3500032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009154957 |\n",
      "|    clip_fraction        | 0.0533      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.2       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.4        |\n",
      "|    n_updates            | 17080       |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    reward               | 0.4114936   |\n",
      "|    std                  | 6.35        |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1710        |\n",
      "|    time_elapsed         | 31423       |\n",
      "|    total_timesteps      | 3502080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012320099 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.2       |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 17090       |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    reward               | -0.4011907  |\n",
      "|    std                  | 6.35        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1711         |\n",
      "|    time_elapsed         | 31441        |\n",
      "|    total_timesteps      | 3504128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126254335 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.2        |\n",
      "|    explained_variance   | 0.132        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.4         |\n",
      "|    n_updates            | 17100        |\n",
      "|    policy_gradient_loss | -0.00878     |\n",
      "|    reward               | -2.7023246   |\n",
      "|    std                  | 6.36         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1712        |\n",
      "|    time_elapsed         | 31460       |\n",
      "|    total_timesteps      | 3506176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011074672 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.0647      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 17110       |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | 1.1713048   |\n",
      "|    std                  | 6.36        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1713        |\n",
      "|    time_elapsed         | 31478       |\n",
      "|    total_timesteps      | 3508224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013444778 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 17120       |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    reward               | -2.1986578  |\n",
      "|    std                  | 6.37        |\n",
      "|    value_loss           | 51.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1714        |\n",
      "|    time_elapsed         | 31496       |\n",
      "|    total_timesteps      | 3510272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010062899 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 17130       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 1.8611676   |\n",
      "|    std                  | 6.37        |\n",
      "|    value_loss           | 97.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1715        |\n",
      "|    time_elapsed         | 31516       |\n",
      "|    total_timesteps      | 3512320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015503616 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.0754      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.2        |\n",
      "|    n_updates            | 17140       |\n",
      "|    policy_gradient_loss | 0.00138     |\n",
      "|    reward               | -1.2825367  |\n",
      "|    std                  | 6.38        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1716        |\n",
      "|    time_elapsed         | 31535       |\n",
      "|    total_timesteps      | 3514368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009219453 |\n",
      "|    clip_fraction        | 0.0725      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.085       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.5        |\n",
      "|    n_updates            | 17150       |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    reward               | 1.5553083   |\n",
      "|    std                  | 6.39        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1717        |\n",
      "|    time_elapsed         | 31553       |\n",
      "|    total_timesteps      | 3516416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020220555 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.4       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 17160       |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    reward               | -0.86495477 |\n",
      "|    std                  | 6.4         |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1718        |\n",
      "|    time_elapsed         | 31572       |\n",
      "|    total_timesteps      | 3518464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009156604 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.4       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.9        |\n",
      "|    n_updates            | 17170       |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    reward               | 0.27724105  |\n",
      "|    std                  | 6.41        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1719        |\n",
      "|    time_elapsed         | 31590       |\n",
      "|    total_timesteps      | 3520512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015509641 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 17180       |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    reward               | 5.34545     |\n",
      "|    std                  | 6.41        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1720        |\n",
      "|    time_elapsed         | 31608       |\n",
      "|    total_timesteps      | 3522560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011275675 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 17190       |\n",
      "|    policy_gradient_loss | -0.00497    |\n",
      "|    reward               | -1.9296716  |\n",
      "|    std                  | 6.42        |\n",
      "|    value_loss           | 52          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1721        |\n",
      "|    time_elapsed         | 31627       |\n",
      "|    total_timesteps      | 3524608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008499315 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.1        |\n",
      "|    n_updates            | 17200       |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    reward               | -0.42539263 |\n",
      "|    std                  | 6.43        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3180472.53\n",
      "total_reward: 2180472.53\n",
      "total_cost: 296057.93\n",
      "total_trades: 64258\n",
      "Sharpe: 0.551\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1722        |\n",
      "|    time_elapsed         | 31644       |\n",
      "|    total_timesteps      | 3526656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008537024 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.6       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.6        |\n",
      "|    n_updates            | 17210       |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    reward               | 0.08330804  |\n",
      "|    std                  | 6.44        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1723       |\n",
      "|    time_elapsed         | 31663      |\n",
      "|    total_timesteps      | 3528704    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00823597 |\n",
      "|    clip_fraction        | 0.0427     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.6      |\n",
      "|    explained_variance   | 0.16       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 55.3       |\n",
      "|    n_updates            | 17220      |\n",
      "|    policy_gradient_loss | -0.00448   |\n",
      "|    reward               | -1.9440202 |\n",
      "|    std                  | 6.44       |\n",
      "|    value_loss           | 117        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1724        |\n",
      "|    time_elapsed         | 31682       |\n",
      "|    total_timesteps      | 3530752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010786066 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.7       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 17230       |\n",
      "|    policy_gradient_loss | -0.0012     |\n",
      "|    reward               | -0.4740733  |\n",
      "|    std                  | 6.45        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1725        |\n",
      "|    time_elapsed         | 31701       |\n",
      "|    total_timesteps      | 3532800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011282707 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.7       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.7        |\n",
      "|    n_updates            | 17240       |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    reward               | 0.12647438  |\n",
      "|    std                  | 6.47        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1726         |\n",
      "|    time_elapsed         | 31721        |\n",
      "|    total_timesteps      | 3534848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061273817 |\n",
      "|    clip_fraction        | 0.0502       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.8        |\n",
      "|    explained_variance   | 0.194        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 17250        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    reward               | -4.438766    |\n",
      "|    std                  | 6.48         |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1727         |\n",
      "|    time_elapsed         | 31740        |\n",
      "|    total_timesteps      | 3536896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0145128565 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.8        |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.2         |\n",
      "|    n_updates            | 17260        |\n",
      "|    policy_gradient_loss | 0.0018       |\n",
      "|    reward               | -2.7214415   |\n",
      "|    std                  | 6.48         |\n",
      "|    value_loss           | 49.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1728       |\n",
      "|    time_elapsed         | 31758      |\n",
      "|    total_timesteps      | 3538944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01601715 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.8      |\n",
      "|    explained_variance   | 0.139      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 39.7       |\n",
      "|    n_updates            | 17270      |\n",
      "|    policy_gradient_loss | -0.00577   |\n",
      "|    reward               | 2.6031115  |\n",
      "|    std                  | 6.5        |\n",
      "|    value_loss           | 137        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 1729      |\n",
      "|    time_elapsed         | 31777     |\n",
      "|    total_timesteps      | 3540992   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0044521 |\n",
      "|    clip_fraction        | 0.0153    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -94.9     |\n",
      "|    explained_variance   | 0.174     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 52.2      |\n",
      "|    n_updates            | 17280     |\n",
      "|    policy_gradient_loss | -0.00629  |\n",
      "|    reward               | 2.0886962 |\n",
      "|    std                  | 6.51      |\n",
      "|    value_loss           | 131       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1730         |\n",
      "|    time_elapsed         | 31795        |\n",
      "|    total_timesteps      | 3543040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075102323 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.9        |\n",
      "|    explained_variance   | 0.276        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 105          |\n",
      "|    n_updates            | 17290        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    reward               | -1.980248    |\n",
      "|    std                  | 6.51         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1731        |\n",
      "|    time_elapsed         | 31813       |\n",
      "|    total_timesteps      | 3545088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013734577 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95         |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 17300       |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | 0.5002532   |\n",
      "|    std                  | 6.53        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1732         |\n",
      "|    time_elapsed         | 31831        |\n",
      "|    total_timesteps      | 3547136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069012986 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95          |\n",
      "|    explained_variance   | 0.169        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.1         |\n",
      "|    n_updates            | 17310        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    reward               | 0.81318665   |\n",
      "|    std                  | 6.53         |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1733        |\n",
      "|    time_elapsed         | 31851       |\n",
      "|    total_timesteps      | 3549184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007889001 |\n",
      "|    clip_fraction        | 0.0537      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95         |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42          |\n",
      "|    n_updates            | 17320       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    reward               | -8.438294   |\n",
      "|    std                  | 6.53        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1734         |\n",
      "|    time_elapsed         | 31870        |\n",
      "|    total_timesteps      | 3551232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093853995 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.1        |\n",
      "|    explained_variance   | 0.241        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 17330        |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    reward               | 2.1870942    |\n",
      "|    std                  | 6.54         |\n",
      "|    value_loss           | 37.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1735         |\n",
      "|    time_elapsed         | 31888        |\n",
      "|    total_timesteps      | 3553280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109820515 |\n",
      "|    clip_fraction        | 0.0648       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.1        |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.8         |\n",
      "|    n_updates            | 17340        |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    reward               | -1.6697259   |\n",
      "|    std                  | 6.55         |\n",
      "|    value_loss           | 98.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1736        |\n",
      "|    time_elapsed         | 31907       |\n",
      "|    total_timesteps      | 3555328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009120708 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.1       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.8        |\n",
      "|    n_updates            | 17350       |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | -3.5931306  |\n",
      "|    std                  | 6.56        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3133638.09\n",
      "total_reward: 2133638.09\n",
      "total_cost: 281886.50\n",
      "total_trades: 64555\n",
      "Sharpe: 0.523\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1737        |\n",
      "|    time_elapsed         | 31925       |\n",
      "|    total_timesteps      | 3557376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015152643 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 17360       |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    reward               | 0.048724964 |\n",
      "|    std                  | 6.57        |\n",
      "|    value_loss           | 56.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1738       |\n",
      "|    time_elapsed         | 31943      |\n",
      "|    total_timesteps      | 3559424    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01242511 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.2      |\n",
      "|    explained_variance   | 0.138      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 43.5       |\n",
      "|    n_updates            | 17370      |\n",
      "|    policy_gradient_loss | -0.0098    |\n",
      "|    reward               | 0.2854193  |\n",
      "|    std                  | 6.57       |\n",
      "|    value_loss           | 131        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1739        |\n",
      "|    time_elapsed         | 31963       |\n",
      "|    total_timesteps      | 3561472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008290754 |\n",
      "|    clip_fraction        | 0.0753      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | 0.0997      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.7        |\n",
      "|    n_updates            | 17380       |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | 0.06661952  |\n",
      "|    std                  | 6.58        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1740         |\n",
      "|    time_elapsed         | 31981        |\n",
      "|    total_timesteps      | 3563520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048862454 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.2        |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.7         |\n",
      "|    n_updates            | 17390        |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | 0.6027989    |\n",
      "|    std                  | 6.58         |\n",
      "|    value_loss           | 137          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1741        |\n",
      "|    time_elapsed         | 32000       |\n",
      "|    total_timesteps      | 3565568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013933953 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 17400       |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    reward               | 0.3632301   |\n",
      "|    std                  | 6.59        |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1742        |\n",
      "|    time_elapsed         | 32018       |\n",
      "|    total_timesteps      | 3567616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013322979 |\n",
      "|    clip_fraction        | 0.0736      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61          |\n",
      "|    n_updates            | 17410       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | -1.0229716  |\n",
      "|    std                  | 6.6         |\n",
      "|    value_loss           | 99.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1743       |\n",
      "|    time_elapsed         | 32038      |\n",
      "|    total_timesteps      | 3569664    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01750458 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.3      |\n",
      "|    explained_variance   | 0.145      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.5       |\n",
      "|    n_updates            | 17420      |\n",
      "|    policy_gradient_loss | 0.00197    |\n",
      "|    reward               | 4.3069596  |\n",
      "|    std                  | 6.6        |\n",
      "|    value_loss           | 148        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1744        |\n",
      "|    time_elapsed         | 32057       |\n",
      "|    total_timesteps      | 3571712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010535303 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 17430       |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    reward               | 1.5211538   |\n",
      "|    std                  | 6.6         |\n",
      "|    value_loss           | 49.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1745         |\n",
      "|    time_elapsed         | 32075        |\n",
      "|    total_timesteps      | 3573760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0138803385 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.3        |\n",
      "|    explained_variance   | 0.12         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.3         |\n",
      "|    n_updates            | 17440        |\n",
      "|    policy_gradient_loss | -0.00972     |\n",
      "|    reward               | 0.103285275  |\n",
      "|    std                  | 6.61         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1746        |\n",
      "|    time_elapsed         | 32093       |\n",
      "|    total_timesteps      | 3575808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012252626 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.6        |\n",
      "|    n_updates            | 17450       |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | 0.76562     |\n",
      "|    std                  | 6.62        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1747         |\n",
      "|    time_elapsed         | 32112        |\n",
      "|    total_timesteps      | 3577856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068031796 |\n",
      "|    clip_fraction        | 0.0689       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.4        |\n",
      "|    explained_variance   | 0.0317       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93           |\n",
      "|    n_updates            | 17460        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    reward               | 0.4397025    |\n",
      "|    std                  | 6.62         |\n",
      "|    value_loss           | 173          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1748        |\n",
      "|    time_elapsed         | 32130       |\n",
      "|    total_timesteps      | 3579904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012091221 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 17470       |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | -1.444369   |\n",
      "|    std                  | 6.65        |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1749        |\n",
      "|    time_elapsed         | 32149       |\n",
      "|    total_timesteps      | 3581952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010524889 |\n",
      "|    clip_fraction        | 0.0824      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.5       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.2        |\n",
      "|    n_updates            | 17480       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.35383782  |\n",
      "|    std                  | 6.65        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1750        |\n",
      "|    time_elapsed         | 32167       |\n",
      "|    total_timesteps      | 3584000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007590015 |\n",
      "|    clip_fraction        | 0.0967      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.5       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.8        |\n",
      "|    n_updates            | 17490       |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    reward               | -6.5607877  |\n",
      "|    std                  | 6.66        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4382782.33\n",
      "total_reward: 3382782.33\n",
      "total_cost: 292566.06\n",
      "total_trades: 64684\n",
      "Sharpe: 0.687\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1751       |\n",
      "|    time_elapsed         | 32186      |\n",
      "|    total_timesteps      | 3586048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0133056  |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.6      |\n",
      "|    explained_variance   | 0.318      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.4       |\n",
      "|    n_updates            | 17500      |\n",
      "|    policy_gradient_loss | -0.00743   |\n",
      "|    reward               | -2.0837953 |\n",
      "|    std                  | 6.67       |\n",
      "|    value_loss           | 49.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1752        |\n",
      "|    time_elapsed         | 32204       |\n",
      "|    total_timesteps      | 3588096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013401335 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.6       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 17510       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 1.3841649   |\n",
      "|    std                  | 6.68        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1753        |\n",
      "|    time_elapsed         | 32223       |\n",
      "|    total_timesteps      | 3590144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007414017 |\n",
      "|    clip_fraction        | 0.0712      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.6       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.5        |\n",
      "|    n_updates            | 17520       |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    reward               | 50.580433   |\n",
      "|    std                  | 6.68        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1754        |\n",
      "|    time_elapsed         | 32241       |\n",
      "|    total_timesteps      | 3592192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012388705 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.6       |\n",
      "|    explained_variance   | 0.0734      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.5        |\n",
      "|    n_updates            | 17530       |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    reward               | 2.3578115   |\n",
      "|    std                  | 6.69        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1755       |\n",
      "|    time_elapsed         | 32260      |\n",
      "|    total_timesteps      | 3594240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01805831 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.7      |\n",
      "|    explained_variance   | 0.294      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.9       |\n",
      "|    n_updates            | 17540      |\n",
      "|    policy_gradient_loss | -0.00879   |\n",
      "|    reward               | 1.654084   |\n",
      "|    std                  | 6.7        |\n",
      "|    value_loss           | 43.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1756        |\n",
      "|    time_elapsed         | 32279       |\n",
      "|    total_timesteps      | 3596288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015419863 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.7       |\n",
      "|    explained_variance   | 0.0747      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 17550       |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    reward               | 0.014299672 |\n",
      "|    std                  | 6.72        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1757        |\n",
      "|    time_elapsed         | 32298       |\n",
      "|    total_timesteps      | 3598336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008766178 |\n",
      "|    clip_fraction        | 0.0718      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.8       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 17560       |\n",
      "|    policy_gradient_loss | 0.00191     |\n",
      "|    reward               | 1.2775578   |\n",
      "|    std                  | 6.73        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1758         |\n",
      "|    time_elapsed         | 32316        |\n",
      "|    total_timesteps      | 3600384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084008165 |\n",
      "|    clip_fraction        | 0.0771       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.8        |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 17570        |\n",
      "|    policy_gradient_loss | -0.00723     |\n",
      "|    reward               | 1.3721164    |\n",
      "|    std                  | 6.73         |\n",
      "|    value_loss           | 33.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1759       |\n",
      "|    time_elapsed         | 32335      |\n",
      "|    total_timesteps      | 3602432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01204763 |\n",
      "|    clip_fraction        | 0.0905     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.8      |\n",
      "|    explained_variance   | 0.158      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31         |\n",
      "|    n_updates            | 17580      |\n",
      "|    policy_gradient_loss | -0.00853   |\n",
      "|    reward               | -0.5341875 |\n",
      "|    std                  | 6.74       |\n",
      "|    value_loss           | 113        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1760        |\n",
      "|    time_elapsed         | 32354       |\n",
      "|    total_timesteps      | 3604480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012360738 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.0279      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 160         |\n",
      "|    n_updates            | 17590       |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    reward               | -0.8761912  |\n",
      "|    std                  | 6.77        |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1761       |\n",
      "|    time_elapsed         | 32372      |\n",
      "|    total_timesteps      | 3606528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01235106 |\n",
      "|    clip_fraction        | 0.0935     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96        |\n",
      "|    explained_variance   | 0.294      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.7       |\n",
      "|    n_updates            | 17600      |\n",
      "|    policy_gradient_loss | -0.00562   |\n",
      "|    reward               | 2.815611   |\n",
      "|    std                  | 6.78       |\n",
      "|    value_loss           | 60.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1762        |\n",
      "|    time_elapsed         | 32391       |\n",
      "|    total_timesteps      | 3608576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018105192 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96         |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.7        |\n",
      "|    n_updates            | 17610       |\n",
      "|    policy_gradient_loss | -0.000746   |\n",
      "|    reward               | 2.7228515   |\n",
      "|    std                  | 6.79        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1763        |\n",
      "|    time_elapsed         | 32409       |\n",
      "|    total_timesteps      | 3610624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011314178 |\n",
      "|    clip_fraction        | 0.0843      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.1       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.2        |\n",
      "|    n_updates            | 17620       |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    reward               | 1.1433842   |\n",
      "|    std                  | 6.8         |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1764        |\n",
      "|    time_elapsed         | 32427       |\n",
      "|    total_timesteps      | 3612672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010876768 |\n",
      "|    clip_fraction        | 0.0795      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.1       |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.5        |\n",
      "|    n_updates            | 17630       |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    reward               | 0.6527368   |\n",
      "|    std                  | 6.8         |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3002147.60\n",
      "total_reward: 2002147.60\n",
      "total_cost: 267768.13\n",
      "total_trades: 63935\n",
      "Sharpe: 0.511\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1765        |\n",
      "|    time_elapsed         | 32446       |\n",
      "|    total_timesteps      | 3614720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012973158 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.1       |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 17640       |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    reward               | 1.1991187   |\n",
      "|    std                  | 6.81        |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1766        |\n",
      "|    time_elapsed         | 32464       |\n",
      "|    total_timesteps      | 3616768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012695737 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.4        |\n",
      "|    n_updates            | 17650       |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    reward               | 0.9670125   |\n",
      "|    std                  | 6.82        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1767         |\n",
      "|    time_elapsed         | 32483        |\n",
      "|    total_timesteps      | 3618816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037668752 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.2        |\n",
      "|    explained_variance   | 0.149        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75           |\n",
      "|    n_updates            | 17660        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | 4.0888224    |\n",
      "|    std                  | 6.82         |\n",
      "|    value_loss           | 159          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1768        |\n",
      "|    time_elapsed         | 32502       |\n",
      "|    total_timesteps      | 3620864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007047071 |\n",
      "|    clip_fraction        | 0.0468      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 17670       |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    reward               | 0.66520464  |\n",
      "|    std                  | 6.83        |\n",
      "|    value_loss           | 61.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1769        |\n",
      "|    time_elapsed         | 32521       |\n",
      "|    total_timesteps      | 3622912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012331107 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 17680       |\n",
      "|    policy_gradient_loss | -0.00554    |\n",
      "|    reward               | -2.262609   |\n",
      "|    std                  | 6.84        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1770         |\n",
      "|    time_elapsed         | 32540        |\n",
      "|    total_timesteps      | 3624960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075923437 |\n",
      "|    clip_fraction        | 0.0563       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.3        |\n",
      "|    explained_variance   | 0.208        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 17690        |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    reward               | 0.04980736   |\n",
      "|    std                  | 6.85         |\n",
      "|    value_loss           | 172          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1771         |\n",
      "|    time_elapsed         | 32558        |\n",
      "|    total_timesteps      | 3627008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069870776 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.3        |\n",
      "|    explained_variance   | 0.273        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 17700        |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    reward               | 0.45741045   |\n",
      "|    std                  | 6.85         |\n",
      "|    value_loss           | 153          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1772        |\n",
      "|    time_elapsed         | 32576       |\n",
      "|    total_timesteps      | 3629056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012764972 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.3       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 17710       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | 1.3569878   |\n",
      "|    std                  | 6.85        |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1773        |\n",
      "|    time_elapsed         | 32595       |\n",
      "|    total_timesteps      | 3631104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016432919 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.3       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.4        |\n",
      "|    n_updates            | 17720       |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    reward               | -1.497313   |\n",
      "|    std                  | 6.87        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1774        |\n",
      "|    time_elapsed         | 32613       |\n",
      "|    total_timesteps      | 3633152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005446334 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.4       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 99          |\n",
      "|    n_updates            | 17730       |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    reward               | 2.0531936   |\n",
      "|    std                  | 6.87        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1775        |\n",
      "|    time_elapsed         | 32632       |\n",
      "|    total_timesteps      | 3635200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014273573 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.4       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 17740       |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | 0.78029424  |\n",
      "|    std                  | 6.87        |\n",
      "|    value_loss           | 56.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1776       |\n",
      "|    time_elapsed         | 32651      |\n",
      "|    total_timesteps      | 3637248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0096904  |\n",
      "|    clip_fraction        | 0.0782     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96.4      |\n",
      "|    explained_variance   | 0.257      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.4       |\n",
      "|    n_updates            | 17750      |\n",
      "|    policy_gradient_loss | -0.0075    |\n",
      "|    reward               | -2.1097195 |\n",
      "|    std                  | 6.89       |\n",
      "|    value_loss           | 150        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1777         |\n",
      "|    time_elapsed         | 32669        |\n",
      "|    total_timesteps      | 3639296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059423484 |\n",
      "|    clip_fraction        | 0.0236       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.5        |\n",
      "|    explained_variance   | 0.247        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.3         |\n",
      "|    n_updates            | 17760        |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    reward               | 1.0681466    |\n",
      "|    std                  | 6.89         |\n",
      "|    value_loss           | 145          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1778         |\n",
      "|    time_elapsed         | 32688        |\n",
      "|    total_timesteps      | 3641344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066389195 |\n",
      "|    clip_fraction        | 0.0537       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.5        |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.2         |\n",
      "|    n_updates            | 17770        |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    reward               | 2.1463206    |\n",
      "|    std                  | 6.9          |\n",
      "|    value_loss           | 66.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3276036.03\n",
      "total_reward: 2276036.03\n",
      "total_cost: 228929.51\n",
      "total_trades: 63284\n",
      "Sharpe: 0.543\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1779        |\n",
      "|    time_elapsed         | 32707       |\n",
      "|    total_timesteps      | 3643392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013349859 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.5       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.2        |\n",
      "|    n_updates            | 17780       |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    reward               | 1.587133    |\n",
      "|    std                  | 6.91        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1780        |\n",
      "|    time_elapsed         | 32725       |\n",
      "|    total_timesteps      | 3645440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011932731 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.5       |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.2        |\n",
      "|    n_updates            | 17790       |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    reward               | 0.36131474  |\n",
      "|    std                  | 6.92        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1781        |\n",
      "|    time_elapsed         | 32745       |\n",
      "|    total_timesteps      | 3647488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007886001 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.4        |\n",
      "|    n_updates            | 17800       |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    reward               | -2.3753223  |\n",
      "|    std                  | 6.92        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1782        |\n",
      "|    time_elapsed         | 32764       |\n",
      "|    total_timesteps      | 3649536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011395827 |\n",
      "|    clip_fraction        | 0.0592      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 17810       |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    reward               | 2.2806537   |\n",
      "|    std                  | 6.93        |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1783       |\n",
      "|    time_elapsed         | 32784      |\n",
      "|    total_timesteps      | 3651584    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01065109 |\n",
      "|    clip_fraction        | 0.0709     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96.6      |\n",
      "|    explained_variance   | 0.212      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.6       |\n",
      "|    n_updates            | 17820      |\n",
      "|    policy_gradient_loss | -0.00309   |\n",
      "|    reward               | 2.1812031  |\n",
      "|    std                  | 6.94       |\n",
      "|    value_loss           | 108        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1784        |\n",
      "|    time_elapsed         | 32802       |\n",
      "|    total_timesteps      | 3653632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008030861 |\n",
      "|    clip_fraction        | 0.0444      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.2        |\n",
      "|    n_updates            | 17830       |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    reward               | 3.0858479   |\n",
      "|    std                  | 6.95        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1785        |\n",
      "|    time_elapsed         | 32822       |\n",
      "|    total_timesteps      | 3655680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012306473 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 17840       |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    reward               | -0.12418194 |\n",
      "|    std                  | 6.95        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1786        |\n",
      "|    time_elapsed         | 32841       |\n",
      "|    total_timesteps      | 3657728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013555662 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.1        |\n",
      "|    n_updates            | 17850       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | 1.6924024   |\n",
      "|    std                  | 6.96        |\n",
      "|    value_loss           | 92.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1787        |\n",
      "|    time_elapsed         | 32860       |\n",
      "|    total_timesteps      | 3659776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014192243 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.8       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 17860       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | 1.7752712   |\n",
      "|    std                  | 6.98        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1788        |\n",
      "|    time_elapsed         | 32879       |\n",
      "|    total_timesteps      | 3661824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007606753 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.9       |\n",
      "|    explained_variance   | 0.096       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98.7        |\n",
      "|    n_updates            | 17870       |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    reward               | 0.319363    |\n",
      "|    std                  | 6.98        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1789        |\n",
      "|    time_elapsed         | 32898       |\n",
      "|    total_timesteps      | 3663872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012994635 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.9       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 17880       |\n",
      "|    policy_gradient_loss | -0.000743   |\n",
      "|    reward               | 0.16036159  |\n",
      "|    std                  | 6.99        |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1790        |\n",
      "|    time_elapsed         | 32917       |\n",
      "|    total_timesteps      | 3665920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008703511 |\n",
      "|    clip_fraction        | 0.0741      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.9       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.5        |\n",
      "|    n_updates            | 17890       |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    reward               | 0.7766001   |\n",
      "|    std                  | 7           |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1791       |\n",
      "|    time_elapsed         | 32936      |\n",
      "|    total_timesteps      | 3667968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00631789 |\n",
      "|    clip_fraction        | 0.0863     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97        |\n",
      "|    explained_variance   | 0.208      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 73.3       |\n",
      "|    n_updates            | 17900      |\n",
      "|    policy_gradient_loss | -0.00374   |\n",
      "|    reward               | 0.98003167 |\n",
      "|    std                  | 7.01       |\n",
      "|    value_loss           | 168        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1792        |\n",
      "|    time_elapsed         | 32955       |\n",
      "|    total_timesteps      | 3670016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009797221 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 17910       |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    reward               | -0.11061769 |\n",
      "|    std                  | 7.02        |\n",
      "|    value_loss           | 56.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3317957.53\n",
      "total_reward: 2317957.53\n",
      "total_cost: 212576.13\n",
      "total_trades: 61952\n",
      "Sharpe: 0.592\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1793       |\n",
      "|    time_elapsed         | 32974      |\n",
      "|    total_timesteps      | 3672064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01204426 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97        |\n",
      "|    explained_variance   | 0.386      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 37.1       |\n",
      "|    n_updates            | 17920      |\n",
      "|    policy_gradient_loss | -0.00657   |\n",
      "|    reward               | -2.93711   |\n",
      "|    std                  | 7.03       |\n",
      "|    value_loss           | 107        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1794        |\n",
      "|    time_elapsed         | 32994       |\n",
      "|    total_timesteps      | 3674112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010853682 |\n",
      "|    clip_fraction        | 0.0826      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.1       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 17930       |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    reward               | 0.024350934 |\n",
      "|    std                  | 7.04        |\n",
      "|    value_loss           | 83.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1795        |\n",
      "|    time_elapsed         | 33013       |\n",
      "|    total_timesteps      | 3676160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007488083 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.1       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.3        |\n",
      "|    n_updates            | 17940       |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    reward               | -0.818144   |\n",
      "|    std                  | 7.05        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1796        |\n",
      "|    time_elapsed         | 33031       |\n",
      "|    total_timesteps      | 3678208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014745733 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.2       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 17950       |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    reward               | 3.6241608   |\n",
      "|    std                  | 7.05        |\n",
      "|    value_loss           | 42          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1797        |\n",
      "|    time_elapsed         | 33049       |\n",
      "|    total_timesteps      | 3680256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012851832 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.2       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.6        |\n",
      "|    n_updates            | 17960       |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    reward               | -2.2076323  |\n",
      "|    std                  | 7.07        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1798         |\n",
      "|    time_elapsed         | 33069        |\n",
      "|    total_timesteps      | 3682304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060039535 |\n",
      "|    clip_fraction        | 0.062        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.3        |\n",
      "|    explained_variance   | 0.223        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 128          |\n",
      "|    n_updates            | 17970        |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    reward               | 3.7857995    |\n",
      "|    std                  | 7.07         |\n",
      "|    value_loss           | 205          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1799        |\n",
      "|    time_elapsed         | 33087       |\n",
      "|    total_timesteps      | 3684352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010035972 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 17980       |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    reward               | 3.8491788   |\n",
      "|    std                  | 7.08        |\n",
      "|    value_loss           | 56.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1800        |\n",
      "|    time_elapsed         | 33107       |\n",
      "|    total_timesteps      | 3686400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012593203 |\n",
      "|    clip_fraction        | 0.0977      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.5        |\n",
      "|    n_updates            | 17990       |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    reward               | 0.20500955  |\n",
      "|    std                  | 7.08        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1801        |\n",
      "|    time_elapsed         | 33125       |\n",
      "|    total_timesteps      | 3688448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008627305 |\n",
      "|    clip_fraction        | 0.0595      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 18000       |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    reward               | -2.727018   |\n",
      "|    std                  | 7.09        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1802        |\n",
      "|    time_elapsed         | 33145       |\n",
      "|    total_timesteps      | 3690496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010620842 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 18010       |\n",
      "|    policy_gradient_loss | -0.000682   |\n",
      "|    reward               | -0.8994454  |\n",
      "|    std                  | 7.1         |\n",
      "|    value_loss           | 63.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1803       |\n",
      "|    time_elapsed         | 33166      |\n",
      "|    total_timesteps      | 3692544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0083746  |\n",
      "|    clip_fraction        | 0.0404     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.4      |\n",
      "|    explained_variance   | 0.386      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 51.3       |\n",
      "|    n_updates            | 18020      |\n",
      "|    policy_gradient_loss | -0.00577   |\n",
      "|    reward               | -4.4920373 |\n",
      "|    std                  | 7.1        |\n",
      "|    value_loss           | 121        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1804        |\n",
      "|    time_elapsed         | 33185       |\n",
      "|    total_timesteps      | 3694592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007008476 |\n",
      "|    clip_fraction        | 0.0669      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.4       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.3        |\n",
      "|    n_updates            | 18030       |\n",
      "|    policy_gradient_loss | -0.00256    |\n",
      "|    reward               | -0.7227492  |\n",
      "|    std                  | 7.11        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1805        |\n",
      "|    time_elapsed         | 33203       |\n",
      "|    total_timesteps      | 3696640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006435845 |\n",
      "|    clip_fraction        | 0.0323      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.4       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 173         |\n",
      "|    n_updates            | 18040       |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    reward               | -1.1963216  |\n",
      "|    std                  | 7.11        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1806        |\n",
      "|    time_elapsed         | 33222       |\n",
      "|    total_timesteps      | 3698688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010851939 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.4       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 18050       |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    reward               | -0.75127584 |\n",
      "|    std                  | 7.12        |\n",
      "|    value_loss           | 52.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3056177.27\n",
      "total_reward: 2056177.27\n",
      "total_cost: 159843.57\n",
      "total_trades: 58148\n",
      "Sharpe: 0.502\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1807        |\n",
      "|    time_elapsed         | 33243       |\n",
      "|    total_timesteps      | 3700736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008498653 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 18060       |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    reward               | -0.93485594 |\n",
      "|    std                  | 7.12        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1808        |\n",
      "|    time_elapsed         | 33261       |\n",
      "|    total_timesteps      | 3702784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010860255 |\n",
      "|    clip_fraction        | 0.0432      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.3        |\n",
      "|    n_updates            | 18070       |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    reward               | 1.4961723   |\n",
      "|    std                  | 7.13        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1809        |\n",
      "|    time_elapsed         | 33281       |\n",
      "|    total_timesteps      | 3704832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011691998 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 18080       |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    reward               | 1.4192677   |\n",
      "|    std                  | 7.13        |\n",
      "|    value_loss           | 73.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1810        |\n",
      "|    time_elapsed         | 33301       |\n",
      "|    total_timesteps      | 3706880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011476522 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.7        |\n",
      "|    n_updates            | 18090       |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | 2.7151575   |\n",
      "|    std                  | 7.14        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1811        |\n",
      "|    time_elapsed         | 33320       |\n",
      "|    total_timesteps      | 3708928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013706006 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.6       |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 18100       |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    reward               | 1.3468074   |\n",
      "|    std                  | 7.16        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1812        |\n",
      "|    time_elapsed         | 33339       |\n",
      "|    total_timesteps      | 3710976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005523547 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.6       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.2        |\n",
      "|    n_updates            | 18110       |\n",
      "|    policy_gradient_loss | -0.00281    |\n",
      "|    reward               | 1.102852    |\n",
      "|    std                  | 7.16        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1813        |\n",
      "|    time_elapsed         | 33358       |\n",
      "|    total_timesteps      | 3713024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009706844 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.6       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 18120       |\n",
      "|    policy_gradient_loss | -0.00134    |\n",
      "|    reward               | -0.76922446 |\n",
      "|    std                  | 7.18        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1814        |\n",
      "|    time_elapsed         | 33377       |\n",
      "|    total_timesteps      | 3715072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011400332 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.7       |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.9        |\n",
      "|    n_updates            | 18130       |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    reward               | 0.34644547  |\n",
      "|    std                  | 7.19        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1815       |\n",
      "|    time_elapsed         | 33396      |\n",
      "|    total_timesteps      | 3717120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00999196 |\n",
      "|    clip_fraction        | 0.0785     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.7      |\n",
      "|    explained_variance   | 0.407      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 71         |\n",
      "|    n_updates            | 18140      |\n",
      "|    policy_gradient_loss | -0.00854   |\n",
      "|    reward               | -6.8853254 |\n",
      "|    std                  | 7.2        |\n",
      "|    value_loss           | 142        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1816        |\n",
      "|    time_elapsed         | 33416       |\n",
      "|    total_timesteps      | 3719168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012718363 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 18150       |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    reward               | -0.9336083  |\n",
      "|    std                  | 7.2         |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1817        |\n",
      "|    time_elapsed         | 33434       |\n",
      "|    total_timesteps      | 3721216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013723634 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.9        |\n",
      "|    n_updates            | 18160       |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    reward               | 0.89828473  |\n",
      "|    std                  | 7.21        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1818        |\n",
      "|    time_elapsed         | 33453       |\n",
      "|    total_timesteps      | 3723264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008563625 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.3        |\n",
      "|    n_updates            | 18170       |\n",
      "|    policy_gradient_loss | -0.00366    |\n",
      "|    reward               | -1.3779305  |\n",
      "|    std                  | 7.22        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1819        |\n",
      "|    time_elapsed         | 33471       |\n",
      "|    total_timesteps      | 3725312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003939944 |\n",
      "|    clip_fraction        | 0.0174      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 18180       |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    reward               | -0.1579396  |\n",
      "|    std                  | 7.22        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1820        |\n",
      "|    time_elapsed         | 33490       |\n",
      "|    total_timesteps      | 3727360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009253107 |\n",
      "|    clip_fraction        | 0.0599      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 18190       |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    reward               | 1.2650522   |\n",
      "|    std                  | 7.23        |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2914312.89\n",
      "total_reward: 1914312.89\n",
      "total_cost: 226970.81\n",
      "total_trades: 62053\n",
      "Sharpe: 0.495\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1821        |\n",
      "|    time_elapsed         | 33508       |\n",
      "|    total_timesteps      | 3729408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013480503 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94.7        |\n",
      "|    n_updates            | 18200       |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    reward               | 0.96484643  |\n",
      "|    std                  | 7.23        |\n",
      "|    value_loss           | 94.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1822        |\n",
      "|    time_elapsed         | 33526       |\n",
      "|    total_timesteps      | 3731456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008378111 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77          |\n",
      "|    n_updates            | 18210       |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    reward               | -3.6340754  |\n",
      "|    std                  | 7.24        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1823        |\n",
      "|    time_elapsed         | 33545       |\n",
      "|    total_timesteps      | 3733504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009040174 |\n",
      "|    clip_fraction        | 0.0815      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 18220       |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    reward               | 0.41445678  |\n",
      "|    std                  | 7.24        |\n",
      "|    value_loss           | 46.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1824        |\n",
      "|    time_elapsed         | 33564       |\n",
      "|    total_timesteps      | 3735552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00964383  |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 18230       |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    reward               | -0.59528375 |\n",
      "|    std                  | 7.25        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1825        |\n",
      "|    time_elapsed         | 33582       |\n",
      "|    total_timesteps      | 3737600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011444502 |\n",
      "|    clip_fraction        | 0.0573      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98         |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 18240       |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    reward               | -0.58772373 |\n",
      "|    std                  | 7.26        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1826         |\n",
      "|    time_elapsed         | 33603        |\n",
      "|    total_timesteps      | 3739648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063199224 |\n",
      "|    clip_fraction        | 0.05         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98          |\n",
      "|    explained_variance   | 0.462        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 18250        |\n",
      "|    policy_gradient_loss | -0.00078     |\n",
      "|    reward               | 1.9063944    |\n",
      "|    std                  | 7.26         |\n",
      "|    value_loss           | 57.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1827        |\n",
      "|    time_elapsed         | 33622       |\n",
      "|    total_timesteps      | 3741696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012132156 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.6        |\n",
      "|    n_updates            | 18260       |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    reward               | 0.28046545  |\n",
      "|    std                  | 7.29        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1828        |\n",
      "|    time_elapsed         | 33641       |\n",
      "|    total_timesteps      | 3743744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005195465 |\n",
      "|    clip_fraction        | 0.0494      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.9        |\n",
      "|    n_updates            | 18270       |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | -1.0043577  |\n",
      "|    std                  | 7.31        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1829         |\n",
      "|    time_elapsed         | 33660        |\n",
      "|    total_timesteps      | 3745792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014472739 |\n",
      "|    clip_fraction        | 0.00669      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.2        |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.4         |\n",
      "|    n_updates            | 18280        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | 0.1939679    |\n",
      "|    std                  | 7.31         |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1830        |\n",
      "|    time_elapsed         | 33678       |\n",
      "|    total_timesteps      | 3747840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016293876 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.2       |\n",
      "|    explained_variance   | 0.058       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 18290       |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    reward               | 1.6938305   |\n",
      "|    std                  | 7.33        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1831       |\n",
      "|    time_elapsed         | 33697      |\n",
      "|    total_timesteps      | 3749888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01066549 |\n",
      "|    clip_fraction        | 0.0725     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -98.3      |\n",
      "|    explained_variance   | 0.38       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.1       |\n",
      "|    n_updates            | 18300      |\n",
      "|    policy_gradient_loss | -0.00615   |\n",
      "|    reward               | 1.1859119  |\n",
      "|    std                  | 7.34       |\n",
      "|    value_loss           | 104        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1832         |\n",
      "|    time_elapsed         | 33715        |\n",
      "|    total_timesteps      | 3751936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044491496 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.3        |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 97.1         |\n",
      "|    n_updates            | 18310        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | 1.2920003    |\n",
      "|    std                  | 7.34         |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1833         |\n",
      "|    time_elapsed         | 33734        |\n",
      "|    total_timesteps      | 3753984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076073357 |\n",
      "|    clip_fraction        | 0.0512       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.3        |\n",
      "|    explained_variance   | 0.332        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 18320        |\n",
      "|    policy_gradient_loss | -0.00508     |\n",
      "|    reward               | -2.4175794   |\n",
      "|    std                  | 7.35         |\n",
      "|    value_loss           | 48.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1834        |\n",
      "|    time_elapsed         | 33752       |\n",
      "|    total_timesteps      | 3756032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011657401 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.8        |\n",
      "|    n_updates            | 18330       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -1.4847575  |\n",
      "|    std                  | 7.37        |\n",
      "|    value_loss           | 91.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2882516.80\n",
      "total_reward: 1882516.80\n",
      "total_cost: 268467.37\n",
      "total_trades: 63944\n",
      "Sharpe: 0.497\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1835        |\n",
      "|    time_elapsed         | 33771       |\n",
      "|    total_timesteps      | 3758080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009548884 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.9        |\n",
      "|    n_updates            | 18340       |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    reward               | -2.3090348  |\n",
      "|    std                  | 7.38        |\n",
      "|    value_loss           | 93.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1836        |\n",
      "|    time_elapsed         | 33789       |\n",
      "|    total_timesteps      | 3760128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003863321 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.4        |\n",
      "|    n_updates            | 18350       |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    reward               | 1.6062232   |\n",
      "|    std                  | 7.38        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1837        |\n",
      "|    time_elapsed         | 33808       |\n",
      "|    total_timesteps      | 3762176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016017482 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.5       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 18360       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -3.589783   |\n",
      "|    std                  | 7.4         |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1838        |\n",
      "|    time_elapsed         | 33827       |\n",
      "|    total_timesteps      | 3764224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011287304 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.6       |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 18370       |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    reward               | 3.6163485   |\n",
      "|    std                  | 7.41        |\n",
      "|    value_loss           | 92.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1839        |\n",
      "|    time_elapsed         | 33846       |\n",
      "|    total_timesteps      | 3766272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010299468 |\n",
      "|    clip_fraction        | 0.064       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.6       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.9        |\n",
      "|    n_updates            | 18380       |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    reward               | -0.52856165 |\n",
      "|    std                  | 7.43        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1840        |\n",
      "|    time_elapsed         | 33865       |\n",
      "|    total_timesteps      | 3768320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009641321 |\n",
      "|    clip_fraction        | 0.0585      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.6       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 18390       |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    reward               | 1.6001897   |\n",
      "|    std                  | 7.43        |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1841        |\n",
      "|    time_elapsed         | 33883       |\n",
      "|    total_timesteps      | 3770368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006362336 |\n",
      "|    clip_fraction        | 0.037       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.5        |\n",
      "|    n_updates            | 18400       |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | 0.5282398   |\n",
      "|    std                  | 7.44        |\n",
      "|    value_loss           | 96.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1842       |\n",
      "|    time_elapsed         | 33902      |\n",
      "|    total_timesteps      | 3772416    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0098836  |\n",
      "|    clip_fraction        | 0.0875     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -98.7      |\n",
      "|    explained_variance   | 0.323      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38.8       |\n",
      "|    n_updates            | 18410      |\n",
      "|    policy_gradient_loss | -0.00301   |\n",
      "|    reward               | -13.781722 |\n",
      "|    std                  | 7.44       |\n",
      "|    value_loss           | 147        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1843        |\n",
      "|    time_elapsed         | 33920       |\n",
      "|    total_timesteps      | 3774464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011685707 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 18420       |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    reward               | 1.5556141   |\n",
      "|    std                  | 7.44        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1844         |\n",
      "|    time_elapsed         | 33939        |\n",
      "|    total_timesteps      | 3776512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115518775 |\n",
      "|    clip_fraction        | 0.0695       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.7        |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 18430        |\n",
      "|    policy_gradient_loss | -0.00605     |\n",
      "|    reward               | 0.1647304    |\n",
      "|    std                  | 7.45         |\n",
      "|    value_loss           | 48.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1845         |\n",
      "|    time_elapsed         | 33958        |\n",
      "|    total_timesteps      | 3778560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087581035 |\n",
      "|    clip_fraction        | 0.0615       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.7        |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 18440        |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    reward               | 0.55414003   |\n",
      "|    std                  | 7.45         |\n",
      "|    value_loss           | 94.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1846         |\n",
      "|    time_elapsed         | 33976        |\n",
      "|    total_timesteps      | 3780608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050831344 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.7        |\n",
      "|    explained_variance   | 0.405        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.2         |\n",
      "|    n_updates            | 18450        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | 3.7234797    |\n",
      "|    std                  | 7.45         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1847        |\n",
      "|    time_elapsed         | 33995       |\n",
      "|    total_timesteps      | 3782656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017400274 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.8       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 18460       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 0.59126663  |\n",
      "|    std                  | 7.47        |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1848        |\n",
      "|    time_elapsed         | 34014       |\n",
      "|    total_timesteps      | 3784704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008135987 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.9       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 18470       |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    reward               | -4.541741   |\n",
      "|    std                  | 7.5         |\n",
      "|    value_loss           | 94.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1849        |\n",
      "|    time_elapsed         | 34032       |\n",
      "|    total_timesteps      | 3786752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004480671 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.9       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 18480       |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    reward               | -2.7413135  |\n",
      "|    std                  | 7.5         |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3792631.25\n",
      "total_reward: 2792631.25\n",
      "total_cost: 275753.15\n",
      "total_trades: 65252\n",
      "Sharpe: 0.598\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1850        |\n",
      "|    time_elapsed         | 34051       |\n",
      "|    total_timesteps      | 3788800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010095999 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.9       |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 18490       |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    reward               | 0.676331    |\n",
      "|    std                  | 7.5         |\n",
      "|    value_loss           | 71.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1851         |\n",
      "|    time_elapsed         | 34069        |\n",
      "|    total_timesteps      | 3790848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089888945 |\n",
      "|    clip_fraction        | 0.0507       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.9        |\n",
      "|    explained_variance   | 0.132        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.9         |\n",
      "|    n_updates            | 18500        |\n",
      "|    policy_gradient_loss | -0.00501     |\n",
      "|    reward               | 0.3324392    |\n",
      "|    std                  | 7.5          |\n",
      "|    value_loss           | 185          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1852        |\n",
      "|    time_elapsed         | 34087       |\n",
      "|    total_timesteps      | 3792896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006432915 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.9       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.9        |\n",
      "|    n_updates            | 18510       |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    reward               | 0.4122647   |\n",
      "|    std                  | 7.51        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1853        |\n",
      "|    time_elapsed         | 34105       |\n",
      "|    total_timesteps      | 3794944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010707997 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.9       |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 18520       |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    reward               | 0.5487136   |\n",
      "|    std                  | 7.51        |\n",
      "|    value_loss           | 88.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1854        |\n",
      "|    time_elapsed         | 34125       |\n",
      "|    total_timesteps      | 3796992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022487424 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99         |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 18530       |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    reward               | -0.63564694 |\n",
      "|    std                  | 7.52        |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1855        |\n",
      "|    time_elapsed         | 34144       |\n",
      "|    total_timesteps      | 3799040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009267218 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99         |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 18540       |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    reward               | 1.4533826   |\n",
      "|    std                  | 7.53        |\n",
      "|    value_loss           | 90          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1856         |\n",
      "|    time_elapsed         | 34164        |\n",
      "|    total_timesteps      | 3801088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096283965 |\n",
      "|    clip_fraction        | 0.0648       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99          |\n",
      "|    explained_variance   | 0.337        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40           |\n",
      "|    n_updates            | 18550        |\n",
      "|    policy_gradient_loss | -0.00605     |\n",
      "|    reward               | -1.3906975   |\n",
      "|    std                  | 7.54         |\n",
      "|    value_loss           | 85.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1857        |\n",
      "|    time_elapsed         | 34182       |\n",
      "|    total_timesteps      | 3803136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018702071 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.1       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 18560       |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    reward               | 0.33363014  |\n",
      "|    std                  | 7.54        |\n",
      "|    value_loss           | 44.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1858        |\n",
      "|    time_elapsed         | 34200       |\n",
      "|    total_timesteps      | 3805184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009344652 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.1       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 18570       |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    reward               | 3.3438833   |\n",
      "|    std                  | 7.55        |\n",
      "|    value_loss           | 72.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1859        |\n",
      "|    time_elapsed         | 34219       |\n",
      "|    total_timesteps      | 3807232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008401373 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.1       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.9        |\n",
      "|    n_updates            | 18580       |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    reward               | -0.46168178 |\n",
      "|    std                  | 7.56        |\n",
      "|    value_loss           | 75.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1860        |\n",
      "|    time_elapsed         | 34237       |\n",
      "|    total_timesteps      | 3809280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005934716 |\n",
      "|    clip_fraction        | 0.0276      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.2       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 18590       |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    reward               | 0.1396008   |\n",
      "|    std                  | 7.57        |\n",
      "|    value_loss           | 65.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1861       |\n",
      "|    time_elapsed         | 34255      |\n",
      "|    total_timesteps      | 3811328    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01614561 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -99.2      |\n",
      "|    explained_variance   | 0.386      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.2       |\n",
      "|    n_updates            | 18600      |\n",
      "|    policy_gradient_loss | -0.00545   |\n",
      "|    reward               | 2.3504891  |\n",
      "|    std                  | 7.56       |\n",
      "|    value_loss           | 26.9       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1862        |\n",
      "|    time_elapsed         | 34274       |\n",
      "|    total_timesteps      | 3813376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007051103 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.2       |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.9        |\n",
      "|    n_updates            | 18610       |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    reward               | 0.82665104  |\n",
      "|    std                  | 7.56        |\n",
      "|    value_loss           | 70.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1863         |\n",
      "|    time_elapsed         | 34292        |\n",
      "|    total_timesteps      | 3815424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032481398 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.2        |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.1         |\n",
      "|    n_updates            | 18620        |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    reward               | -2.8120844   |\n",
      "|    std                  | 7.56         |\n",
      "|    value_loss           | 65.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2585587.36\n",
      "total_reward: 1585587.36\n",
      "total_cost: 253090.16\n",
      "total_trades: 63368\n",
      "Sharpe: 0.472\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1864        |\n",
      "|    time_elapsed         | 34310       |\n",
      "|    total_timesteps      | 3817472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016089521 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.2       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 18630       |\n",
      "|    policy_gradient_loss | -0.00244    |\n",
      "|    reward               | 0.3163986   |\n",
      "|    std                  | 7.57        |\n",
      "|    value_loss           | 35.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1865         |\n",
      "|    time_elapsed         | 34329        |\n",
      "|    total_timesteps      | 3819520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074023525 |\n",
      "|    clip_fraction        | 0.0459       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.2        |\n",
      "|    explained_variance   | 0.53         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 18640        |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    reward               | 0.18235444   |\n",
      "|    std                  | 7.58         |\n",
      "|    value_loss           | 59.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1866         |\n",
      "|    time_elapsed         | 34347        |\n",
      "|    total_timesteps      | 3821568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051962268 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.3        |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.5         |\n",
      "|    n_updates            | 18650        |\n",
      "|    policy_gradient_loss | -0.006       |\n",
      "|    reward               | 10.0324135   |\n",
      "|    std                  | 7.59         |\n",
      "|    value_loss           | 63.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1867        |\n",
      "|    time_elapsed         | 34366       |\n",
      "|    total_timesteps      | 3823616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008209152 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.3       |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 18660       |\n",
      "|    policy_gradient_loss | -0.00554    |\n",
      "|    reward               | 2.6731894   |\n",
      "|    std                  | 7.6         |\n",
      "|    value_loss           | 46          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1868         |\n",
      "|    time_elapsed         | 34384        |\n",
      "|    total_timesteps      | 3825664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146074165 |\n",
      "|    clip_fraction        | 0.157        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.3        |\n",
      "|    explained_variance   | 0.315        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.9         |\n",
      "|    n_updates            | 18670        |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    reward               | 2.3924682    |\n",
      "|    std                  | 7.61         |\n",
      "|    value_loss           | 54.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1869        |\n",
      "|    time_elapsed         | 34402       |\n",
      "|    total_timesteps      | 3827712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011452172 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.3       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.4        |\n",
      "|    n_updates            | 18680       |\n",
      "|    policy_gradient_loss | -0.00834    |\n",
      "|    reward               | -0.6094659  |\n",
      "|    std                  | 7.6         |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1870         |\n",
      "|    time_elapsed         | 34420        |\n",
      "|    total_timesteps      | 3829760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066651525 |\n",
      "|    clip_fraction        | 0.04         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.3        |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26           |\n",
      "|    n_updates            | 18690        |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    reward               | -4.6376357   |\n",
      "|    std                  | 7.6          |\n",
      "|    value_loss           | 72           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1871         |\n",
      "|    time_elapsed         | 34439        |\n",
      "|    total_timesteps      | 3831808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013464075  |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.4        |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 18700        |\n",
      "|    policy_gradient_loss | -0.00805     |\n",
      "|    reward               | -0.114652924 |\n",
      "|    std                  | 7.63         |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1872         |\n",
      "|    time_elapsed         | 34457        |\n",
      "|    total_timesteps      | 3833856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070306296 |\n",
      "|    clip_fraction        | 0.05         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.4        |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.4         |\n",
      "|    n_updates            | 18710        |\n",
      "|    policy_gradient_loss | -0.00768     |\n",
      "|    reward               | 1.9255869    |\n",
      "|    std                  | 7.64         |\n",
      "|    value_loss           | 85.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1873         |\n",
      "|    time_elapsed         | 34476        |\n",
      "|    total_timesteps      | 3835904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021845135 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.4        |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.6         |\n",
      "|    n_updates            | 18720        |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    reward               | 2.1742914    |\n",
      "|    std                  | 7.64         |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1874        |\n",
      "|    time_elapsed         | 34495       |\n",
      "|    total_timesteps      | 3837952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007358857 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.5       |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 18730       |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    reward               | 1.1302489   |\n",
      "|    std                  | 7.65        |\n",
      "|    value_loss           | 49.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1875        |\n",
      "|    time_elapsed         | 34514       |\n",
      "|    total_timesteps      | 3840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008856022 |\n",
      "|    clip_fraction        | 0.0712      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.5       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 18740       |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    reward               | -0.49730155 |\n",
      "|    std                  | 7.66        |\n",
      "|    value_loss           | 73.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1876        |\n",
      "|    time_elapsed         | 34532       |\n",
      "|    total_timesteps      | 3842048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011472864 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.5       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96          |\n",
      "|    n_updates            | 18750       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | 0.59488904  |\n",
      "|    std                  | 7.67        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1877         |\n",
      "|    time_elapsed         | 34551        |\n",
      "|    total_timesteps      | 3844096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070012948 |\n",
      "|    clip_fraction        | 0.0339       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.6        |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.1         |\n",
      "|    n_updates            | 18760        |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    reward               | 4.018614     |\n",
      "|    std                  | 7.67         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3001486.88\n",
      "total_reward: 2001486.88\n",
      "total_cost: 224660.76\n",
      "total_trades: 62279\n",
      "Sharpe: 0.522\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1878        |\n",
      "|    time_elapsed         | 34570       |\n",
      "|    total_timesteps      | 3846144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013687874 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.6       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 18770       |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    reward               | 2.53669     |\n",
      "|    std                  | 7.67        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1879         |\n",
      "|    time_elapsed         | 34589        |\n",
      "|    total_timesteps      | 3848192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124177765 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.6        |\n",
      "|    explained_variance   | 0.3          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.4         |\n",
      "|    n_updates            | 18780        |\n",
      "|    policy_gradient_loss | -0.00672     |\n",
      "|    reward               | -0.54843336  |\n",
      "|    std                  | 7.69         |\n",
      "|    value_loss           | 88.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1880        |\n",
      "|    time_elapsed         | 34608       |\n",
      "|    total_timesteps      | 3850240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007588377 |\n",
      "|    clip_fraction        | 0.0562      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 18790       |\n",
      "|    policy_gradient_loss | 0.00108     |\n",
      "|    reward               | -1.4240735  |\n",
      "|    std                  | 7.7         |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1881        |\n",
      "|    time_elapsed         | 34627       |\n",
      "|    total_timesteps      | 3852288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009493116 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 18800       |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    reward               | -0.6594076  |\n",
      "|    std                  | 7.72        |\n",
      "|    value_loss           | 48.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1882       |\n",
      "|    time_elapsed         | 34645      |\n",
      "|    total_timesteps      | 3854336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00726799 |\n",
      "|    clip_fraction        | 0.0481     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -99.8      |\n",
      "|    explained_variance   | 0.45       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 39.5       |\n",
      "|    n_updates            | 18810      |\n",
      "|    policy_gradient_loss | -0.00591   |\n",
      "|    reward               | -7.3979716 |\n",
      "|    std                  | 7.73       |\n",
      "|    value_loss           | 73.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1883         |\n",
      "|    time_elapsed         | 34663        |\n",
      "|    total_timesteps      | 3856384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085055055 |\n",
      "|    clip_fraction        | 0.0674       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.8        |\n",
      "|    explained_variance   | 0.421        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 18820        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | 0.065507956  |\n",
      "|    std                  | 7.74         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1884         |\n",
      "|    time_elapsed         | 34681        |\n",
      "|    total_timesteps      | 3858432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038574087 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.8        |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46           |\n",
      "|    n_updates            | 18830        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    reward               | 0.29618698   |\n",
      "|    std                  | 7.74         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1885        |\n",
      "|    time_elapsed         | 34699       |\n",
      "|    total_timesteps      | 3860480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010681889 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.9       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 18840       |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    reward               | -0.20977394 |\n",
      "|    std                  | 7.76        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1886        |\n",
      "|    time_elapsed         | 34717       |\n",
      "|    total_timesteps      | 3862528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009167742 |\n",
      "|    clip_fraction        | 0.0758      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.9       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.7        |\n",
      "|    n_updates            | 18850       |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    reward               | -0.9268536  |\n",
      "|    std                  | 7.76        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1887         |\n",
      "|    time_elapsed         | 34735        |\n",
      "|    total_timesteps      | 3864576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023814323 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.9        |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 84.5         |\n",
      "|    n_updates            | 18860        |\n",
      "|    policy_gradient_loss | -0.0011      |\n",
      "|    reward               | -2.4094155   |\n",
      "|    std                  | 7.76         |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1888        |\n",
      "|    time_elapsed         | 34754       |\n",
      "|    total_timesteps      | 3866624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010313606 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.9       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 18870       |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    reward               | 1.159278    |\n",
      "|    std                  | 7.77        |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1889        |\n",
      "|    time_elapsed         | 34772       |\n",
      "|    total_timesteps      | 3868672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008336246 |\n",
      "|    clip_fraction        | 0.0511      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.8        |\n",
      "|    n_updates            | 18880       |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    reward               | -1.1572646  |\n",
      "|    std                  | 7.78        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1890        |\n",
      "|    time_elapsed         | 34789       |\n",
      "|    total_timesteps      | 3870720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005220424 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.9        |\n",
      "|    n_updates            | 18890       |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | 2.8707383   |\n",
      "|    std                  | 7.79        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1891         |\n",
      "|    time_elapsed         | 34807        |\n",
      "|    total_timesteps      | 3872768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009548325  |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.1         |\n",
      "|    n_updates            | 18900        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    reward               | 0.0015680931 |\n",
      "|    std                  | 7.79         |\n",
      "|    value_loss           | 60.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3274586.97\n",
      "total_reward: 2274586.97\n",
      "total_cost: 216841.45\n",
      "total_trades: 62648\n",
      "Sharpe: 0.535\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1892       |\n",
      "|    time_elapsed         | 34825      |\n",
      "|    total_timesteps      | 3874816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01197123 |\n",
      "|    clip_fraction        | 0.0714     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -100       |\n",
      "|    explained_variance   | 0.468      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 59.5       |\n",
      "|    n_updates            | 18910      |\n",
      "|    policy_gradient_loss | -0.00579   |\n",
      "|    reward               | 3.000634   |\n",
      "|    std                  | 7.79       |\n",
      "|    value_loss           | 95         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1893         |\n",
      "|    time_elapsed         | 34844        |\n",
      "|    total_timesteps      | 3876864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055164415 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 92.3         |\n",
      "|    n_updates            | 18920        |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    reward               | 1.1994461    |\n",
      "|    std                  | 7.8          |\n",
      "|    value_loss           | 147          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1894         |\n",
      "|    time_elapsed         | 34862        |\n",
      "|    total_timesteps      | 3878912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024124663 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.1         |\n",
      "|    n_updates            | 18930        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | 9.733011     |\n",
      "|    std                  | 7.8          |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1895         |\n",
      "|    time_elapsed         | 34880        |\n",
      "|    total_timesteps      | 3880960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010509422  |\n",
      "|    clip_fraction        | 0.0698       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 18940        |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    reward               | -0.034488853 |\n",
      "|    std                  | 7.81         |\n",
      "|    value_loss           | 51.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1896        |\n",
      "|    time_elapsed         | 34898       |\n",
      "|    total_timesteps      | 3883008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009037765 |\n",
      "|    clip_fraction        | 0.0412      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.8        |\n",
      "|    n_updates            | 18950       |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    reward               | -1.2609053  |\n",
      "|    std                  | 7.82        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1897         |\n",
      "|    time_elapsed         | 34916        |\n",
      "|    total_timesteps      | 3885056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055937003 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.2         |\n",
      "|    n_updates            | 18960        |\n",
      "|    policy_gradient_loss | -0.00606     |\n",
      "|    reward               | -1.6779164   |\n",
      "|    std                  | 7.81         |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1898         |\n",
      "|    time_elapsed         | 34935        |\n",
      "|    total_timesteps      | 3887104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083525535 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.1         |\n",
      "|    n_updates            | 18970        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    reward               | 2.2453806    |\n",
      "|    std                  | 7.81         |\n",
      "|    value_loss           | 72.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1899        |\n",
      "|    time_elapsed         | 34953       |\n",
      "|    total_timesteps      | 3889152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009532786 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.1        |\n",
      "|    n_updates            | 18980       |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    reward               | -4.5658264  |\n",
      "|    std                  | 7.82        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1900         |\n",
      "|    time_elapsed         | 34972        |\n",
      "|    total_timesteps      | 3891200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051489496 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90.2         |\n",
      "|    n_updates            | 18990        |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    reward               | 0.14892592   |\n",
      "|    std                  | 7.84         |\n",
      "|    value_loss           | 125          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1901        |\n",
      "|    time_elapsed         | 34990       |\n",
      "|    total_timesteps      | 3893248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008403523 |\n",
      "|    clip_fraction        | 0.0499      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.8        |\n",
      "|    n_updates            | 19000       |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    reward               | -0.28856668 |\n",
      "|    std                  | 7.84        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1902        |\n",
      "|    time_elapsed         | 35009       |\n",
      "|    total_timesteps      | 3895296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009930767 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 19010       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -0.6408909  |\n",
      "|    std                  | 7.86        |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1903        |\n",
      "|    time_elapsed         | 35027       |\n",
      "|    total_timesteps      | 3897344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009494457 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.4        |\n",
      "|    n_updates            | 19020       |\n",
      "|    policy_gradient_loss | -0.000957   |\n",
      "|    reward               | 0.3302736   |\n",
      "|    std                  | 7.87        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1904         |\n",
      "|    time_elapsed         | 35045        |\n",
      "|    total_timesteps      | 3899392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009988734 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.8         |\n",
      "|    n_updates            | 19030        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | 0.6235085    |\n",
      "|    std                  | 7.87         |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1905        |\n",
      "|    time_elapsed         | 35064       |\n",
      "|    total_timesteps      | 3901440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010540825 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 19040       |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    reward               | 0.38917044  |\n",
      "|    std                  | 7.87        |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3037646.70\n",
      "total_reward: 2037646.70\n",
      "total_cost: 212132.93\n",
      "total_trades: 61452\n",
      "Sharpe: 0.516\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1906         |\n",
      "|    time_elapsed         | 35083        |\n",
      "|    total_timesteps      | 3903488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090763485 |\n",
      "|    clip_fraction        | 0.0426       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.5         |\n",
      "|    n_updates            | 19050        |\n",
      "|    policy_gradient_loss | -0.00715     |\n",
      "|    reward               | 0.2822744    |\n",
      "|    std                  | 7.88         |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1907         |\n",
      "|    time_elapsed         | 35102        |\n",
      "|    total_timesteps      | 3905536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075301426 |\n",
      "|    clip_fraction        | 0.0278       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.2         |\n",
      "|    n_updates            | 19060        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | -23.529078   |\n",
      "|    std                  | 7.89         |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1908        |\n",
      "|    time_elapsed         | 35121       |\n",
      "|    total_timesteps      | 3907584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010486895 |\n",
      "|    clip_fraction        | 0.0571      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63          |\n",
      "|    n_updates            | 19070       |\n",
      "|    policy_gradient_loss | -0.00326    |\n",
      "|    reward               | 0.497411    |\n",
      "|    std                  | 7.89        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1909        |\n",
      "|    time_elapsed         | 35140       |\n",
      "|    total_timesteps      | 3909632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011099216 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 19080       |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    reward               | -0.5897922  |\n",
      "|    std                  | 7.9         |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1910         |\n",
      "|    time_elapsed         | 35160        |\n",
      "|    total_timesteps      | 3911680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058272853 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39           |\n",
      "|    n_updates            | 19090        |\n",
      "|    policy_gradient_loss | -0.00639     |\n",
      "|    reward               | -0.29042497  |\n",
      "|    std                  | 7.9          |\n",
      "|    value_loss           | 94.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1911         |\n",
      "|    time_elapsed         | 35178        |\n",
      "|    total_timesteps      | 3913728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039333096 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.434        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.7         |\n",
      "|    n_updates            | 19100        |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    reward               | 3.620606     |\n",
      "|    std                  | 7.9          |\n",
      "|    value_loss           | 96.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1912       |\n",
      "|    time_elapsed         | 35198      |\n",
      "|    total_timesteps      | 3915776    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01122846 |\n",
      "|    clip_fraction        | 0.0922     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -100       |\n",
      "|    explained_variance   | 0.228      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.4       |\n",
      "|    n_updates            | 19110      |\n",
      "|    policy_gradient_loss | -0.00813   |\n",
      "|    reward               | 0.9553926  |\n",
      "|    std                  | 7.92       |\n",
      "|    value_loss           | 50.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1913         |\n",
      "|    time_elapsed         | 35217        |\n",
      "|    total_timesteps      | 3917824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087617915 |\n",
      "|    clip_fraction        | 0.0412       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.7         |\n",
      "|    n_updates            | 19120        |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    reward               | 2.8183718    |\n",
      "|    std                  | 7.92         |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1914        |\n",
      "|    time_elapsed         | 35236       |\n",
      "|    total_timesteps      | 3919872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006121691 |\n",
      "|    clip_fraction        | 0.0298      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.9        |\n",
      "|    n_updates            | 19130       |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | 1.2951506   |\n",
      "|    std                  | 7.93        |\n",
      "|    value_loss           | 91.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1915        |\n",
      "|    time_elapsed         | 35255       |\n",
      "|    total_timesteps      | 3921920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005922787 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 19140       |\n",
      "|    policy_gradient_loss | -0.000429   |\n",
      "|    reward               | -0.3574301  |\n",
      "|    std                  | 7.93        |\n",
      "|    value_loss           | 63.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1916        |\n",
      "|    time_elapsed         | 35275       |\n",
      "|    total_timesteps      | 3923968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009812379 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 19150       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -1.572226   |\n",
      "|    std                  | 7.94        |\n",
      "|    value_loss           | 69.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1917        |\n",
      "|    time_elapsed         | 35293       |\n",
      "|    total_timesteps      | 3926016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005334678 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.4        |\n",
      "|    n_updates            | 19160       |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    reward               | 3.5501678   |\n",
      "|    std                  | 7.94        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1918         |\n",
      "|    time_elapsed         | 35312        |\n",
      "|    total_timesteps      | 3928064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052685393 |\n",
      "|    clip_fraction        | 0.04         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.7         |\n",
      "|    n_updates            | 19170        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    reward               | 1.8380593    |\n",
      "|    std                  | 7.96         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1919        |\n",
      "|    time_elapsed         | 35330       |\n",
      "|    total_timesteps      | 3930112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016371347 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 19180       |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | 1.5492485   |\n",
      "|    std                  | 7.98        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2849284.27\n",
      "total_reward: 1849284.27\n",
      "total_cost: 203126.88\n",
      "total_trades: 60884\n",
      "Sharpe: 0.488\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1920         |\n",
      "|    time_elapsed         | 35349        |\n",
      "|    total_timesteps      | 3932160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024658865 |\n",
      "|    clip_fraction        | 0.00576      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.2         |\n",
      "|    n_updates            | 19190        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | -2.739537    |\n",
      "|    std                  | 7.99         |\n",
      "|    value_loss           | 98.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1921         |\n",
      "|    time_elapsed         | 35368        |\n",
      "|    total_timesteps      | 3934208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020418412 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.686        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 111          |\n",
      "|    n_updates            | 19200        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | 5.7861743    |\n",
      "|    std                  | 7.99         |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1922         |\n",
      "|    time_elapsed         | 35387        |\n",
      "|    total_timesteps      | 3936256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035421194 |\n",
      "|    clip_fraction        | 0.00947      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.9         |\n",
      "|    n_updates            | 19210        |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    reward               | -2.8123918   |\n",
      "|    std                  | 8            |\n",
      "|    value_loss           | 67.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1923        |\n",
      "|    time_elapsed         | 35406       |\n",
      "|    total_timesteps      | 3938304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007730171 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.2        |\n",
      "|    n_updates            | 19220       |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    reward               | 0.50343835  |\n",
      "|    std                  | 8           |\n",
      "|    value_loss           | 96.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1924        |\n",
      "|    time_elapsed         | 35425       |\n",
      "|    total_timesteps      | 3940352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008066365 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 19230       |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    reward               | -1.6587844  |\n",
      "|    std                  | 8.01        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1925         |\n",
      "|    time_elapsed         | 35443        |\n",
      "|    total_timesteps      | 3942400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055985246 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.7         |\n",
      "|    n_updates            | 19240        |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    reward               | 1.6374302    |\n",
      "|    std                  | 8.01         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1926        |\n",
      "|    time_elapsed         | 35462       |\n",
      "|    total_timesteps      | 3944448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015559899 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 19250       |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    reward               | -0.03848361 |\n",
      "|    std                  | 8.03        |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1927        |\n",
      "|    time_elapsed         | 35480       |\n",
      "|    total_timesteps      | 3946496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010375546 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 19260       |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    reward               | -0.56447685 |\n",
      "|    std                  | 8.05        |\n",
      "|    value_loss           | 81          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1928        |\n",
      "|    time_elapsed         | 35498       |\n",
      "|    total_timesteps      | 3948544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002667639 |\n",
      "|    clip_fraction        | 0.00391     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 19270       |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    reward               | 8.6136265   |\n",
      "|    std                  | 8.05        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1929        |\n",
      "|    time_elapsed         | 35517       |\n",
      "|    total_timesteps      | 3950592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014321629 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 19280       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | -0.6613493  |\n",
      "|    std                  | 8.06        |\n",
      "|    value_loss           | 49.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1930        |\n",
      "|    time_elapsed         | 35536       |\n",
      "|    total_timesteps      | 3952640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009172558 |\n",
      "|    clip_fraction        | 0.0712      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 19290       |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | 0.14288415  |\n",
      "|    std                  | 8.07        |\n",
      "|    value_loss           | 78.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1931       |\n",
      "|    time_elapsed         | 35554      |\n",
      "|    total_timesteps      | 3954688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0056001  |\n",
      "|    clip_fraction        | 0.0277     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -101       |\n",
      "|    explained_variance   | 0.607      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 43.8       |\n",
      "|    n_updates            | 19300      |\n",
      "|    policy_gradient_loss | -0.00338   |\n",
      "|    reward               | -10.589812 |\n",
      "|    std                  | 8.07       |\n",
      "|    value_loss           | 97.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1932         |\n",
      "|    time_elapsed         | 35573        |\n",
      "|    total_timesteps      | 3956736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055764243 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.1         |\n",
      "|    n_updates            | 19310        |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    reward               | -0.37768131  |\n",
      "|    std                  | 8.08         |\n",
      "|    value_loss           | 75.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1933        |\n",
      "|    time_elapsed         | 35592       |\n",
      "|    total_timesteps      | 3958784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011453716 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 19320       |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    reward               | 0.3801389   |\n",
      "|    std                  | 8.09        |\n",
      "|    value_loss           | 37.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3077534.91\n",
      "total_reward: 2077534.91\n",
      "total_cost: 223556.76\n",
      "total_trades: 61083\n",
      "Sharpe: 0.538\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1934        |\n",
      "|    time_elapsed         | 35611       |\n",
      "|    total_timesteps      | 3960832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006875845 |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.5        |\n",
      "|    n_updates            | 19330       |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    reward               | 0.10570452  |\n",
      "|    std                  | 8.1         |\n",
      "|    value_loss           | 79.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1935        |\n",
      "|    time_elapsed         | 35630       |\n",
      "|    total_timesteps      | 3962880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002523747 |\n",
      "|    clip_fraction        | 0.00635     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 19340       |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    reward               | 1.0717181   |\n",
      "|    std                  | 8.1         |\n",
      "|    value_loss           | 71.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1936        |\n",
      "|    time_elapsed         | 35650       |\n",
      "|    total_timesteps      | 3964928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010017165 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 19350       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -2.604873   |\n",
      "|    std                  | 8.13        |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1937        |\n",
      "|    time_elapsed         | 35668       |\n",
      "|    total_timesteps      | 3966976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005244343 |\n",
      "|    clip_fraction        | 0.0247      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.7        |\n",
      "|    n_updates            | 19360       |\n",
      "|    policy_gradient_loss | -0.00409    |\n",
      "|    reward               | -4.643197   |\n",
      "|    std                  | 8.14        |\n",
      "|    value_loss           | 90.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1938        |\n",
      "|    time_elapsed         | 35686       |\n",
      "|    total_timesteps      | 3969024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009519158 |\n",
      "|    clip_fraction        | 0.0416      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 19370       |\n",
      "|    policy_gradient_loss | -0.000556   |\n",
      "|    reward               | -2.504678   |\n",
      "|    std                  | 8.15        |\n",
      "|    value_loss           | 72.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1939        |\n",
      "|    time_elapsed         | 35705       |\n",
      "|    total_timesteps      | 3971072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004450562 |\n",
      "|    clip_fraction        | 0.0326      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 19380       |\n",
      "|    policy_gradient_loss | -0.00246    |\n",
      "|    reward               | 0.4726706   |\n",
      "|    std                  | 8.15        |\n",
      "|    value_loss           | 67.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1940        |\n",
      "|    time_elapsed         | 35724       |\n",
      "|    total_timesteps      | 3973120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008973185 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 19390       |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    reward               | 0.15668477  |\n",
      "|    std                  | 8.16        |\n",
      "|    value_loss           | 59.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1941         |\n",
      "|    time_elapsed         | 35742        |\n",
      "|    total_timesteps      | 3975168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067025293 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.8         |\n",
      "|    n_updates            | 19400        |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | -0.42825836  |\n",
      "|    std                  | 8.16         |\n",
      "|    value_loss           | 76           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1942         |\n",
      "|    time_elapsed         | 35761        |\n",
      "|    total_timesteps      | 3977216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049915365 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.3         |\n",
      "|    n_updates            | 19410        |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    reward               | -5.492812    |\n",
      "|    std                  | 8.16         |\n",
      "|    value_loss           | 87.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1943        |\n",
      "|    time_elapsed         | 35780       |\n",
      "|    total_timesteps      | 3979264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013854895 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 19420       |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    reward               | 0.86875117  |\n",
      "|    std                  | 8.18        |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1944        |\n",
      "|    time_elapsed         | 35799       |\n",
      "|    total_timesteps      | 3981312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005328875 |\n",
      "|    clip_fraction        | 0.0155      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.3        |\n",
      "|    n_updates            | 19430       |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    reward               | 0.98504627  |\n",
      "|    std                  | 8.19        |\n",
      "|    value_loss           | 89.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1945         |\n",
      "|    time_elapsed         | 35817        |\n",
      "|    total_timesteps      | 3983360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059585324 |\n",
      "|    clip_fraction        | 0.0413       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.293        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.9         |\n",
      "|    n_updates            | 19440        |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    reward               | 1.6530094    |\n",
      "|    std                  | 8.19         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1946         |\n",
      "|    time_elapsed         | 35836        |\n",
      "|    total_timesteps      | 3985408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059214523 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.5         |\n",
      "|    n_updates            | 19450        |\n",
      "|    policy_gradient_loss | -0.00557     |\n",
      "|    reward               | 1.0278152    |\n",
      "|    std                  | 8.2          |\n",
      "|    value_loss           | 58.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1947         |\n",
      "|    time_elapsed         | 35854        |\n",
      "|    total_timesteps      | 3987456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069673923 |\n",
      "|    clip_fraction        | 0.0684       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.8         |\n",
      "|    n_updates            | 19460        |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    reward               | -2.8911836   |\n",
      "|    std                  | 8.2          |\n",
      "|    value_loss           | 75.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3232269.70\n",
      "total_reward: 2232269.70\n",
      "total_cost: 220966.20\n",
      "total_trades: 61173\n",
      "Sharpe: 0.546\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1948        |\n",
      "|    time_elapsed         | 35872       |\n",
      "|    total_timesteps      | 3989504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008192273 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.5        |\n",
      "|    n_updates            | 19470       |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    reward               | 0.90418726  |\n",
      "|    std                  | 8.21        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1949         |\n",
      "|    time_elapsed         | 35891        |\n",
      "|    total_timesteps      | 3991552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074137645 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.5         |\n",
      "|    n_updates            | 19480        |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    reward               | 3.8349206    |\n",
      "|    std                  | 8.22         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1950        |\n",
      "|    time_elapsed         | 35909       |\n",
      "|    total_timesteps      | 3993600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004732634 |\n",
      "|    clip_fraction        | 0.0236      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 19490       |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    reward               | -2.2650993  |\n",
      "|    std                  | 8.22        |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1951        |\n",
      "|    time_elapsed         | 35928       |\n",
      "|    total_timesteps      | 3995648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005135392 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.4        |\n",
      "|    n_updates            | 19500       |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    reward               | -1.1592102  |\n",
      "|    std                  | 8.22        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1952         |\n",
      "|    time_elapsed         | 35946        |\n",
      "|    total_timesteps      | 3997696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023703577 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.1         |\n",
      "|    n_updates            | 19510        |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    reward               | -0.70814425  |\n",
      "|    std                  | 8.23         |\n",
      "|    value_loss           | 85.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1953         |\n",
      "|    time_elapsed         | 35963        |\n",
      "|    total_timesteps      | 3999744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029777735 |\n",
      "|    clip_fraction        | 0.00913      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.6         |\n",
      "|    n_updates            | 19520        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    reward               | 0.91020745   |\n",
      "|    std                  | 8.23         |\n",
      "|    value_loss           | 51.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1954         |\n",
      "|    time_elapsed         | 35981        |\n",
      "|    total_timesteps      | 4001792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070423246 |\n",
      "|    clip_fraction        | 0.0357       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.3         |\n",
      "|    n_updates            | 19530        |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    reward               | -0.1368545   |\n",
      "|    std                  | 8.24         |\n",
      "|    value_loss           | 66.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1955         |\n",
      "|    time_elapsed         | 35999        |\n",
      "|    total_timesteps      | 4003840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027731531 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.1         |\n",
      "|    n_updates            | 19540        |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    reward               | 6.8148336    |\n",
      "|    std                  | 8.24         |\n",
      "|    value_loss           | 82.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1956         |\n",
      "|    time_elapsed         | 36017        |\n",
      "|    total_timesteps      | 4005888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047085336 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.9         |\n",
      "|    n_updates            | 19550        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | 3.8367808    |\n",
      "|    std                  | 8.24         |\n",
      "|    value_loss           | 84.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1957        |\n",
      "|    time_elapsed         | 36035       |\n",
      "|    total_timesteps      | 4007936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017469544 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 19560       |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | -0.8012226  |\n",
      "|    std                  | 8.27        |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1958        |\n",
      "|    time_elapsed         | 36053       |\n",
      "|    total_timesteps      | 4009984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009851004 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.7        |\n",
      "|    n_updates            | 19570       |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    reward               | -2.0495546  |\n",
      "|    std                  | 8.28        |\n",
      "|    value_loss           | 84          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1959         |\n",
      "|    time_elapsed         | 36071        |\n",
      "|    total_timesteps      | 4012032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069084764 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.5         |\n",
      "|    n_updates            | 19580        |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | 7.0664506    |\n",
      "|    std                  | 8.29         |\n",
      "|    value_loss           | 62.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1960        |\n",
      "|    time_elapsed         | 36089       |\n",
      "|    total_timesteps      | 4014080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004725866 |\n",
      "|    clip_fraction        | 0.0212      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 19590       |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    reward               | 1.9599235   |\n",
      "|    std                  | 8.3         |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1961        |\n",
      "|    time_elapsed         | 36107       |\n",
      "|    total_timesteps      | 4016128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008313689 |\n",
      "|    clip_fraction        | 0.053       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 19600       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.26637378 |\n",
      "|    std                  | 8.31        |\n",
      "|    value_loss           | 73.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1962        |\n",
      "|    time_elapsed         | 36125       |\n",
      "|    total_timesteps      | 4018176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009102321 |\n",
      "|    clip_fraction        | 0.0486      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.9        |\n",
      "|    n_updates            | 19610       |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    reward               | 3.265807    |\n",
      "|    std                  | 8.31        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3357389.56\n",
      "total_reward: 2357389.56\n",
      "total_cost: 216240.36\n",
      "total_trades: 61637\n",
      "Sharpe: 0.560\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1963         |\n",
      "|    time_elapsed         | 36143        |\n",
      "|    total_timesteps      | 4020224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076906136 |\n",
      "|    clip_fraction        | 0.0557       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27           |\n",
      "|    n_updates            | 19620        |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | -2.3054578   |\n",
      "|    std                  | 8.31         |\n",
      "|    value_loss           | 72.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1964         |\n",
      "|    time_elapsed         | 36162        |\n",
      "|    total_timesteps      | 4022272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066971914 |\n",
      "|    clip_fraction        | 0.0446       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.2         |\n",
      "|    n_updates            | 19630        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    reward               | -0.28525504  |\n",
      "|    std                  | 8.32         |\n",
      "|    value_loss           | 63.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1965         |\n",
      "|    time_elapsed         | 36181        |\n",
      "|    total_timesteps      | 4024320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016347151 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.9         |\n",
      "|    n_updates            | 19640        |\n",
      "|    policy_gradient_loss | 0.000732     |\n",
      "|    reward               | 1.5872254    |\n",
      "|    std                  | 8.33         |\n",
      "|    value_loss           | 80           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1966         |\n",
      "|    time_elapsed         | 36200        |\n",
      "|    total_timesteps      | 4026368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043274323 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.5         |\n",
      "|    n_updates            | 19650        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    reward               | -0.18227303  |\n",
      "|    std                  | 8.33         |\n",
      "|    value_loss           | 85.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1967         |\n",
      "|    time_elapsed         | 36218        |\n",
      "|    total_timesteps      | 4028416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077733733 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 19660        |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | -2.3901253   |\n",
      "|    std                  | 8.34         |\n",
      "|    value_loss           | 40.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1968        |\n",
      "|    time_elapsed         | 36237       |\n",
      "|    total_timesteps      | 4030464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001741189 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.9        |\n",
      "|    n_updates            | 19670       |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    reward               | -2.0547204  |\n",
      "|    std                  | 8.35        |\n",
      "|    value_loss           | 87.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1969         |\n",
      "|    time_elapsed         | 36256        |\n",
      "|    total_timesteps      | 4032512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005360093 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.9         |\n",
      "|    n_updates            | 19680        |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    reward               | 0.03189896   |\n",
      "|    std                  | 8.35         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1970        |\n",
      "|    time_elapsed         | 36274       |\n",
      "|    total_timesteps      | 4034560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009183876 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 19690       |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | -0.12697074 |\n",
      "|    std                  | 8.35        |\n",
      "|    value_loss           | 66.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1971        |\n",
      "|    time_elapsed         | 36292       |\n",
      "|    total_timesteps      | 4036608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009694407 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 19700       |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    reward               | -1.129039   |\n",
      "|    std                  | 8.37        |\n",
      "|    value_loss           | 75.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1972         |\n",
      "|    time_elapsed         | 36310        |\n",
      "|    total_timesteps      | 4038656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023221835 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.9         |\n",
      "|    n_updates            | 19710        |\n",
      "|    policy_gradient_loss | -0.000885    |\n",
      "|    reward               | 0.03631298   |\n",
      "|    std                  | 8.37         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1973        |\n",
      "|    time_elapsed         | 36329       |\n",
      "|    total_timesteps      | 4040704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010079119 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.4        |\n",
      "|    n_updates            | 19720       |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    reward               | -1.3128638  |\n",
      "|    std                  | 8.37        |\n",
      "|    value_loss           | 86.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1974        |\n",
      "|    time_elapsed         | 36347       |\n",
      "|    total_timesteps      | 4042752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009571629 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 19730       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 1.15941     |\n",
      "|    std                  | 8.38        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1975        |\n",
      "|    time_elapsed         | 36365       |\n",
      "|    total_timesteps      | 4044800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007585257 |\n",
      "|    clip_fraction        | 0.0699      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 19740       |\n",
      "|    policy_gradient_loss | -0.00919    |\n",
      "|    reward               | -3.8037863  |\n",
      "|    std                  | 8.39        |\n",
      "|    value_loss           | 80.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1976        |\n",
      "|    time_elapsed         | 36383       |\n",
      "|    total_timesteps      | 4046848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002009302 |\n",
      "|    clip_fraction        | 0.00137     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.9        |\n",
      "|    n_updates            | 19750       |\n",
      "|    policy_gradient_loss | -0.00161    |\n",
      "|    reward               | 0.48916256  |\n",
      "|    std                  | 8.4         |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2978658.69\n",
      "total_reward: 1978658.69\n",
      "total_cost: 181171.95\n",
      "total_trades: 59120\n",
      "Sharpe: 0.521\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1977        |\n",
      "|    time_elapsed         | 36402       |\n",
      "|    total_timesteps      | 4048896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004727954 |\n",
      "|    clip_fraction        | 0.00566     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 19760       |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    reward               | 1.2061304   |\n",
      "|    std                  | 8.41        |\n",
      "|    value_loss           | 45.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1978         |\n",
      "|    time_elapsed         | 36420        |\n",
      "|    total_timesteps      | 4050944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029046992 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.7         |\n",
      "|    n_updates            | 19770        |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    reward               | -4.8417287   |\n",
      "|    std                  | 8.42         |\n",
      "|    value_loss           | 96           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1979         |\n",
      "|    time_elapsed         | 36439        |\n",
      "|    total_timesteps      | 4052992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060419356 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.1         |\n",
      "|    n_updates            | 19780        |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    reward               | -0.83740306  |\n",
      "|    std                  | 8.43         |\n",
      "|    value_loss           | 80.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1980         |\n",
      "|    time_elapsed         | 36458        |\n",
      "|    total_timesteps      | 4055040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056016706 |\n",
      "|    clip_fraction        | 0.0085       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 19790        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    reward               | 1.8685062    |\n",
      "|    std                  | 8.43         |\n",
      "|    value_loss           | 60.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1981        |\n",
      "|    time_elapsed         | 36476       |\n",
      "|    total_timesteps      | 4057088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010273643 |\n",
      "|    clip_fraction        | 0.06        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.8        |\n",
      "|    n_updates            | 19800       |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    reward               | 0.9462308   |\n",
      "|    std                  | 8.43        |\n",
      "|    value_loss           | 65.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1982         |\n",
      "|    time_elapsed         | 36495        |\n",
      "|    total_timesteps      | 4059136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051408745 |\n",
      "|    clip_fraction        | 0.00986      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.515        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.4         |\n",
      "|    n_updates            | 19810        |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    reward               | 1.5457352    |\n",
      "|    std                  | 8.44         |\n",
      "|    value_loss           | 88           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1983         |\n",
      "|    time_elapsed         | 36513        |\n",
      "|    total_timesteps      | 4061184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018245027 |\n",
      "|    clip_fraction        | 0.00801      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.3         |\n",
      "|    n_updates            | 19820        |\n",
      "|    policy_gradient_loss | -7.44e-05    |\n",
      "|    reward               | -8.278022    |\n",
      "|    std                  | 8.44         |\n",
      "|    value_loss           | 170          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1984        |\n",
      "|    time_elapsed         | 36532       |\n",
      "|    total_timesteps      | 4063232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009806309 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 19830       |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | 2.420567    |\n",
      "|    std                  | 8.44        |\n",
      "|    value_loss           | 47.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1985         |\n",
      "|    time_elapsed         | 36551        |\n",
      "|    total_timesteps      | 4065280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076879314 |\n",
      "|    clip_fraction        | 0.0637       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.1         |\n",
      "|    n_updates            | 19840        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    reward               | -1.160746    |\n",
      "|    std                  | 8.44         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1986        |\n",
      "|    time_elapsed         | 36569       |\n",
      "|    total_timesteps      | 4067328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002038295 |\n",
      "|    clip_fraction        | 0.00132     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 19850       |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    reward               | -3.6485846  |\n",
      "|    std                  | 8.45        |\n",
      "|    value_loss           | 99.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1987         |\n",
      "|    time_elapsed         | 36588        |\n",
      "|    total_timesteps      | 4069376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034792908 |\n",
      "|    clip_fraction        | 0.00884      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.4         |\n",
      "|    n_updates            | 19860        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | 1.4863046    |\n",
      "|    std                  | 8.45         |\n",
      "|    value_loss           | 70.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1988        |\n",
      "|    time_elapsed         | 36606       |\n",
      "|    total_timesteps      | 4071424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012569402 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 19870       |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    reward               | -2.945793   |\n",
      "|    std                  | 8.47        |\n",
      "|    value_loss           | 56.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1989         |\n",
      "|    time_elapsed         | 36624        |\n",
      "|    total_timesteps      | 4073472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044028764 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.2         |\n",
      "|    n_updates            | 19880        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | 0.5809839    |\n",
      "|    std                  | 8.47         |\n",
      "|    value_loss           | 88.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1990         |\n",
      "|    time_elapsed         | 36643        |\n",
      "|    total_timesteps      | 4075520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026178325 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.4         |\n",
      "|    n_updates            | 19890        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | 0.1515526    |\n",
      "|    std                  | 8.46         |\n",
      "|    value_loss           | 82.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3031271.88\n",
      "total_reward: 2031271.88\n",
      "total_cost: 164711.23\n",
      "total_trades: 57056\n",
      "Sharpe: 0.517\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1991        |\n",
      "|    time_elapsed         | 36661       |\n",
      "|    total_timesteps      | 4077568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012338661 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 19900       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -1.7660947  |\n",
      "|    std                  | 8.48        |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1992        |\n",
      "|    time_elapsed         | 36679       |\n",
      "|    total_timesteps      | 4079616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003016926 |\n",
      "|    clip_fraction        | 0.00874     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 19910       |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    reward               | 1.021828    |\n",
      "|    std                  | 8.48        |\n",
      "|    value_loss           | 74.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1993         |\n",
      "|    time_elapsed         | 36697        |\n",
      "|    total_timesteps      | 4081664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016204596 |\n",
      "|    clip_fraction        | 0.00723      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.737        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.1         |\n",
      "|    n_updates            | 19920        |\n",
      "|    policy_gradient_loss | -0.000593    |\n",
      "|    reward               | 3.9871528    |\n",
      "|    std                  | 8.48         |\n",
      "|    value_loss           | 82.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1994        |\n",
      "|    time_elapsed         | 36717       |\n",
      "|    total_timesteps      | 4083712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011703393 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.8        |\n",
      "|    n_updates            | 19930       |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    reward               | -4.6352663  |\n",
      "|    std                  | 8.49        |\n",
      "|    value_loss           | 71.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1995         |\n",
      "|    time_elapsed         | 36735        |\n",
      "|    total_timesteps      | 4085760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064633214 |\n",
      "|    clip_fraction        | 0.0519       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.1         |\n",
      "|    n_updates            | 19940        |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    reward               | -1.1635289   |\n",
      "|    std                  | 8.49         |\n",
      "|    value_loss           | 91.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1996        |\n",
      "|    time_elapsed         | 36753       |\n",
      "|    total_timesteps      | 4087808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003225488 |\n",
      "|    clip_fraction        | 0.0167      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.2        |\n",
      "|    n_updates            | 19950       |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    reward               | 2.9666924   |\n",
      "|    std                  | 8.5         |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1997          |\n",
      "|    time_elapsed         | 36772         |\n",
      "|    total_timesteps      | 4089856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053076807 |\n",
      "|    clip_fraction        | 0.00264       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -102          |\n",
      "|    explained_variance   | 0.765         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 42            |\n",
      "|    n_updates            | 19960         |\n",
      "|    policy_gradient_loss | -0.000578     |\n",
      "|    reward               | -0.42143494   |\n",
      "|    std                  | 8.5           |\n",
      "|    value_loss           | 80            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1998         |\n",
      "|    time_elapsed         | 36790        |\n",
      "|    total_timesteps      | 4091904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094818985 |\n",
      "|    clip_fraction        | 0.0946       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 19970        |\n",
      "|    policy_gradient_loss | -0.00794     |\n",
      "|    reward               | 1.9247991    |\n",
      "|    std                  | 8.52         |\n",
      "|    value_loss           | 47.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1999         |\n",
      "|    time_elapsed         | 36809        |\n",
      "|    total_timesteps      | 4093952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026743277 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.4         |\n",
      "|    n_updates            | 19980        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    reward               | -5.320266    |\n",
      "|    std                  | 8.52         |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2000         |\n",
      "|    time_elapsed         | 36827        |\n",
      "|    total_timesteps      | 4096000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013792978 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.8         |\n",
      "|    n_updates            | 19990        |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    reward               | 2.7764041    |\n",
      "|    std                  | 8.52         |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2001         |\n",
      "|    time_elapsed         | 36847        |\n",
      "|    total_timesteps      | 4098048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061385697 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 20000        |\n",
      "|    policy_gradient_loss | -0.00597     |\n",
      "|    reward               | -3.549807    |\n",
      "|    std                  | 8.54         |\n",
      "|    value_loss           | 44.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2002        |\n",
      "|    time_elapsed         | 36867       |\n",
      "|    total_timesteps      | 4100096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007827889 |\n",
      "|    clip_fraction        | 0.0302      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.6        |\n",
      "|    n_updates            | 20010       |\n",
      "|    policy_gradient_loss | -0.00489    |\n",
      "|    reward               | 4.11592     |\n",
      "|    std                  | 8.54        |\n",
      "|    value_loss           | 88          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2003         |\n",
      "|    time_elapsed         | 36885        |\n",
      "|    total_timesteps      | 4102144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031783748 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.6         |\n",
      "|    n_updates            | 20020        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | -0.31979257  |\n",
      "|    std                  | 8.55         |\n",
      "|    value_loss           | 80.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2004         |\n",
      "|    time_elapsed         | 36904        |\n",
      "|    total_timesteps      | 4104192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076363934 |\n",
      "|    clip_fraction        | 0.0763       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 20030        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | -0.5198938   |\n",
      "|    std                  | 8.56         |\n",
      "|    value_loss           | 55.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3191584.27\n",
      "total_reward: 2191584.27\n",
      "total_cost: 174727.18\n",
      "total_trades: 57800\n",
      "Sharpe: 0.539\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2005        |\n",
      "|    time_elapsed         | 36922       |\n",
      "|    total_timesteps      | 4106240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009397445 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.4        |\n",
      "|    n_updates            | 20040       |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | 0.99687827  |\n",
      "|    std                  | 8.59        |\n",
      "|    value_loss           | 68.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2006         |\n",
      "|    time_elapsed         | 36941        |\n",
      "|    total_timesteps      | 4108288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051948642 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.8         |\n",
      "|    n_updates            | 20050        |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    reward               | -2.3131206   |\n",
      "|    std                  | 8.61         |\n",
      "|    value_loss           | 78.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2007        |\n",
      "|    time_elapsed         | 36959       |\n",
      "|    total_timesteps      | 4110336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005303329 |\n",
      "|    clip_fraction        | 0.00801     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.6        |\n",
      "|    n_updates            | 20060       |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    reward               | -1.2729064  |\n",
      "|    std                  | 8.62        |\n",
      "|    value_loss           | 78.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2008        |\n",
      "|    time_elapsed         | 36977       |\n",
      "|    total_timesteps      | 4112384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008364866 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 20070       |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    reward               | -1.0904015  |\n",
      "|    std                  | 8.65        |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2009         |\n",
      "|    time_elapsed         | 36996        |\n",
      "|    total_timesteps      | 4114432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037026978 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.8         |\n",
      "|    n_updates            | 20080        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | -0.54160386  |\n",
      "|    std                  | 8.66         |\n",
      "|    value_loss           | 78.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2010         |\n",
      "|    time_elapsed         | 37014        |\n",
      "|    total_timesteps      | 4116480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035535838 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 20090        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | -0.1192616   |\n",
      "|    std                  | 8.66         |\n",
      "|    value_loss           | 73.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2011        |\n",
      "|    time_elapsed         | 37033       |\n",
      "|    total_timesteps      | 4118528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010996493 |\n",
      "|    clip_fraction        | 0.0507      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 20100       |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    reward               | -2.7346709  |\n",
      "|    std                  | 8.66        |\n",
      "|    value_loss           | 62.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2012        |\n",
      "|    time_elapsed         | 37051       |\n",
      "|    total_timesteps      | 4120576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010872321 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.6        |\n",
      "|    n_updates            | 20110       |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    reward               | 0.30137113  |\n",
      "|    std                  | 8.68        |\n",
      "|    value_loss           | 74.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2013        |\n",
      "|    time_elapsed         | 37070       |\n",
      "|    total_timesteps      | 4122624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001287384 |\n",
      "|    clip_fraction        | 0.00171     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 20120       |\n",
      "|    policy_gradient_loss | -0.00166    |\n",
      "|    reward               | -1.9087845  |\n",
      "|    std                  | 8.69        |\n",
      "|    value_loss           | 78.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2014        |\n",
      "|    time_elapsed         | 37088       |\n",
      "|    total_timesteps      | 4124672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001673831 |\n",
      "|    clip_fraction        | 0.000635    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.5        |\n",
      "|    n_updates            | 20130       |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    reward               | 0.22101292  |\n",
      "|    std                  | 8.69        |\n",
      "|    value_loss           | 75.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2015        |\n",
      "|    time_elapsed         | 37107       |\n",
      "|    total_timesteps      | 4126720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008687228 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 20140       |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    reward               | -0.23692378 |\n",
      "|    std                  | 8.7         |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2016        |\n",
      "|    time_elapsed         | 37126       |\n",
      "|    total_timesteps      | 4128768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007471422 |\n",
      "|    clip_fraction        | 0.0279      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.6        |\n",
      "|    n_updates            | 20150       |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    reward               | -0.17428534 |\n",
      "|    std                  | 8.71        |\n",
      "|    value_loss           | 93.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 2017          |\n",
      "|    time_elapsed         | 37144         |\n",
      "|    total_timesteps      | 4130816       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027878306 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -103          |\n",
      "|    explained_variance   | 0.751         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 52.2          |\n",
      "|    n_updates            | 20160         |\n",
      "|    policy_gradient_loss | -0.000584     |\n",
      "|    reward               | -0.59454376   |\n",
      "|    std                  | 8.72          |\n",
      "|    value_loss           | 86.2          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2018        |\n",
      "|    time_elapsed         | 37162       |\n",
      "|    total_timesteps      | 4132864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004684655 |\n",
      "|    clip_fraction        | 0.0248      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 20170       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | 3.3563166   |\n",
      "|    std                  | 8.72        |\n",
      "|    value_loss           | 53.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3549831.91\n",
      "total_reward: 2549831.91\n",
      "total_cost: 179433.66\n",
      "total_trades: 57927\n",
      "Sharpe: 0.585\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2019        |\n",
      "|    time_elapsed         | 37181       |\n",
      "|    total_timesteps      | 4134912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008747162 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 20180       |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    reward               | -2.8180583  |\n",
      "|    std                  | 8.74        |\n",
      "|    value_loss           | 59.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2020         |\n",
      "|    time_elapsed         | 37200        |\n",
      "|    total_timesteps      | 4136960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020981855 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.1         |\n",
      "|    n_updates            | 20190        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    reward               | -6.3591776   |\n",
      "|    std                  | 8.74         |\n",
      "|    value_loss           | 79.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2021        |\n",
      "|    time_elapsed         | 37218       |\n",
      "|    total_timesteps      | 4139008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002889236 |\n",
      "|    clip_fraction        | 0.00254     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 20200       |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    reward               | -0.6085779  |\n",
      "|    std                  | 8.75        |\n",
      "|    value_loss           | 79.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2022        |\n",
      "|    time_elapsed         | 37237       |\n",
      "|    total_timesteps      | 4141056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00970178  |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 20210       |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | -0.31760153 |\n",
      "|    std                  | 8.79        |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2023        |\n",
      "|    time_elapsed         | 37256       |\n",
      "|    total_timesteps      | 4143104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007147681 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 20220       |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    reward               | 1.7693514   |\n",
      "|    std                  | 8.8         |\n",
      "|    value_loss           | 97.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2024         |\n",
      "|    time_elapsed         | 37274        |\n",
      "|    total_timesteps      | 4145152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018205162 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.1         |\n",
      "|    n_updates            | 20230        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | 1.268984     |\n",
      "|    std                  | 8.81         |\n",
      "|    value_loss           | 80.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2025        |\n",
      "|    time_elapsed         | 37294       |\n",
      "|    total_timesteps      | 4147200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011584087 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 20240       |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    reward               | 6.408478    |\n",
      "|    std                  | 8.82        |\n",
      "|    value_loss           | 51          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2026         |\n",
      "|    time_elapsed         | 37312        |\n",
      "|    total_timesteps      | 4149248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028091483 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.3         |\n",
      "|    n_updates            | 20250        |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    reward               | -7.895543    |\n",
      "|    std                  | 8.83         |\n",
      "|    value_loss           | 83.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2027         |\n",
      "|    time_elapsed         | 37331        |\n",
      "|    total_timesteps      | 4151296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020928276 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43           |\n",
      "|    n_updates            | 20260        |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    reward               | -2.1284065   |\n",
      "|    std                  | 8.83         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2028         |\n",
      "|    time_elapsed         | 37351        |\n",
      "|    total_timesteps      | 4153344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039208354 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28           |\n",
      "|    n_updates            | 20270        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    reward               | 1.0175686    |\n",
      "|    std                  | 8.84         |\n",
      "|    value_loss           | 67.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2029         |\n",
      "|    time_elapsed         | 37370        |\n",
      "|    total_timesteps      | 4155392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074616456 |\n",
      "|    clip_fraction        | 0.0397       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.787        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.4         |\n",
      "|    n_updates            | 20280        |\n",
      "|    policy_gradient_loss | -0.00537     |\n",
      "|    reward               | 3.770762     |\n",
      "|    std                  | 8.85         |\n",
      "|    value_loss           | 62.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2030         |\n",
      "|    time_elapsed         | 37389        |\n",
      "|    total_timesteps      | 4157440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038643628 |\n",
      "|    clip_fraction        | 0.00947      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.763        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.4         |\n",
      "|    n_updates            | 20290        |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    reward               | -1.1220484   |\n",
      "|    std                  | 8.85         |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2031         |\n",
      "|    time_elapsed         | 37407        |\n",
      "|    total_timesteps      | 4159488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049161348 |\n",
      "|    clip_fraction        | 0.0286       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.757        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40           |\n",
      "|    n_updates            | 20300        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | -1.6078095   |\n",
      "|    std                  | 8.85         |\n",
      "|    value_loss           | 70.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2032        |\n",
      "|    time_elapsed         | 37427       |\n",
      "|    total_timesteps      | 4161536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011940312 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 20310       |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    reward               | -2.596111   |\n",
      "|    std                  | 8.88        |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3193415.63\n",
      "total_reward: 2193415.63\n",
      "total_cost: 167959.68\n",
      "total_trades: 56837\n",
      "Sharpe: 0.540\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2033        |\n",
      "|    time_elapsed         | 37447       |\n",
      "|    total_timesteps      | 4163584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003714364 |\n",
      "|    clip_fraction        | 0.00635     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 20320       |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    reward               | 3.0745656   |\n",
      "|    std                  | 8.89        |\n",
      "|    value_loss           | 82.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2034         |\n",
      "|    time_elapsed         | 37466        |\n",
      "|    total_timesteps      | 4165632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012667356 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.1         |\n",
      "|    n_updates            | 20330        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    reward               | 1.768328     |\n",
      "|    std                  | 8.89         |\n",
      "|    value_loss           | 82.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2035         |\n",
      "|    time_elapsed         | 37485        |\n",
      "|    total_timesteps      | 4167680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072886217 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.1         |\n",
      "|    n_updates            | 20340        |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    reward               | -2.364133    |\n",
      "|    std                  | 8.9          |\n",
      "|    value_loss           | 60.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2036        |\n",
      "|    time_elapsed         | 37504       |\n",
      "|    total_timesteps      | 4169728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009095051 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 20350       |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    reward               | 0.12308909  |\n",
      "|    std                  | 8.9         |\n",
      "|    value_loss           | 71.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2037         |\n",
      "|    time_elapsed         | 37524        |\n",
      "|    total_timesteps      | 4171776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055369344 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.808        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.4         |\n",
      "|    n_updates            | 20360        |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    reward               | 1.5389915    |\n",
      "|    std                  | 8.9          |\n",
      "|    value_loss           | 83.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2038         |\n",
      "|    time_elapsed         | 37542        |\n",
      "|    total_timesteps      | 4173824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013205094 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.4         |\n",
      "|    n_updates            | 20370        |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    reward               | 0.805703     |\n",
      "|    std                  | 8.91         |\n",
      "|    value_loss           | 79.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2039        |\n",
      "|    time_elapsed         | 37561       |\n",
      "|    total_timesteps      | 4175872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012175016 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 20380       |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    reward               | -5.3971887  |\n",
      "|    std                  | 8.93        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2040         |\n",
      "|    time_elapsed         | 37581        |\n",
      "|    total_timesteps      | 4177920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044100834 |\n",
      "|    clip_fraction        | 0.00923      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.5         |\n",
      "|    n_updates            | 20390        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | 1.3644527    |\n",
      "|    std                  | 8.93         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 2041          |\n",
      "|    time_elapsed         | 37600         |\n",
      "|    total_timesteps      | 4179968       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087416917 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -104          |\n",
      "|    explained_variance   | 0.787         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 33.3          |\n",
      "|    n_updates            | 20400         |\n",
      "|    policy_gradient_loss | -0.00181      |\n",
      "|    reward               | 6.1096444     |\n",
      "|    std                  | 8.93          |\n",
      "|    value_loss           | 75.9          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2042        |\n",
      "|    time_elapsed         | 37619       |\n",
      "|    total_timesteps      | 4182016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009417877 |\n",
      "|    clip_fraction        | 0.0447      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 20410       |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    reward               | 0.27091864  |\n",
      "|    std                  | 8.93        |\n",
      "|    value_loss           | 55.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2043         |\n",
      "|    time_elapsed         | 37638        |\n",
      "|    total_timesteps      | 4184064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029076592 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.809        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.5         |\n",
      "|    n_updates            | 20420        |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    reward               | -2.5609317   |\n",
      "|    std                  | 8.94         |\n",
      "|    value_loss           | 67.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2044         |\n",
      "|    time_elapsed         | 37657        |\n",
      "|    total_timesteps      | 4186112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016650059 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30           |\n",
      "|    n_updates            | 20430        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | 5.235922     |\n",
      "|    std                  | 8.93         |\n",
      "|    value_loss           | 88.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2045        |\n",
      "|    time_elapsed         | 37675       |\n",
      "|    total_timesteps      | 4188160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004154898 |\n",
      "|    clip_fraction        | 0.00825     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.8        |\n",
      "|    n_updates            | 20440       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    reward               | -0.3333636  |\n",
      "|    std                  | 8.94        |\n",
      "|    value_loss           | 71.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2046        |\n",
      "|    time_elapsed         | 37694       |\n",
      "|    total_timesteps      | 4190208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009314443 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 20450       |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | 1.161984    |\n",
      "|    std                  | 8.97        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3331692.12\n",
      "total_reward: 2331692.12\n",
      "total_cost: 154731.84\n",
      "total_trades: 56095\n",
      "Sharpe: 0.559\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2047        |\n",
      "|    time_elapsed         | 37712       |\n",
      "|    total_timesteps      | 4192256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014083123 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 20460       |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    reward               | 1.6412035   |\n",
      "|    std                  | 9           |\n",
      "|    value_loss           | 99.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2048         |\n",
      "|    time_elapsed         | 37730        |\n",
      "|    total_timesteps      | 4194304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012044506 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33           |\n",
      "|    n_updates            | 20470        |\n",
      "|    policy_gradient_loss | -0.00128     |\n",
      "|    reward               | -0.06848502  |\n",
      "|    std                  | 9.01         |\n",
      "|    value_loss           | 90.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2049        |\n",
      "|    time_elapsed         | 37749       |\n",
      "|    total_timesteps      | 4196352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013475105 |\n",
      "|    clip_fraction        | 0.0946      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 20480       |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    reward               | -0.21159102 |\n",
      "|    std                  | 9.02        |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2050         |\n",
      "|    time_elapsed         | 37768        |\n",
      "|    total_timesteps      | 4198400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037388108 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.3         |\n",
      "|    n_updates            | 20490        |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    reward               | 7.472653     |\n",
      "|    std                  | 9.03         |\n",
      "|    value_loss           | 93.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2051         |\n",
      "|    time_elapsed         | 37787        |\n",
      "|    total_timesteps      | 4200448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016686448 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.787        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.3         |\n",
      "|    n_updates            | 20500        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | -7.942949    |\n",
      "|    std                  | 9.03         |\n",
      "|    value_loss           | 74           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2052         |\n",
      "|    time_elapsed         | 37805        |\n",
      "|    total_timesteps      | 4202496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019985782 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.4         |\n",
      "|    n_updates            | 20510        |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    reward               | 0.7854098    |\n",
      "|    std                  | 9.04         |\n",
      "|    value_loss           | 72.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2053        |\n",
      "|    time_elapsed         | 37824       |\n",
      "|    total_timesteps      | 4204544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008057039 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 20520       |\n",
      "|    policy_gradient_loss | -0.00721    |\n",
      "|    reward               | 1.1191003   |\n",
      "|    std                  | 9.05        |\n",
      "|    value_loss           | 70.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2054         |\n",
      "|    time_elapsed         | 37843        |\n",
      "|    total_timesteps      | 4206592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012586087 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.6         |\n",
      "|    n_updates            | 20530        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    reward               | 0.8990637    |\n",
      "|    std                  | 9.06         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2055         |\n",
      "|    time_elapsed         | 37861        |\n",
      "|    total_timesteps      | 4208640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007378416 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.0904       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.2         |\n",
      "|    n_updates            | 20540        |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    reward               | 11.750764    |\n",
      "|    std                  | 9.06         |\n",
      "|    value_loss           | 139          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2056        |\n",
      "|    time_elapsed         | 37881       |\n",
      "|    total_timesteps      | 4210688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009727287 |\n",
      "|    clip_fraction        | 0.0483      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 20550       |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | 2.2424982   |\n",
      "|    std                  | 9.07        |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2057         |\n",
      "|    time_elapsed         | 37900        |\n",
      "|    total_timesteps      | 4212736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045049815 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.759        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41           |\n",
      "|    n_updates            | 20560        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | 2.389837     |\n",
      "|    std                  | 9.08         |\n",
      "|    value_loss           | 87.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2058         |\n",
      "|    time_elapsed         | 37919        |\n",
      "|    total_timesteps      | 4214784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038163892 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.1         |\n",
      "|    n_updates            | 20570        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | 5.5298395    |\n",
      "|    std                  | 9.08         |\n",
      "|    value_loss           | 86.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 2059       |\n",
      "|    time_elapsed         | 37937      |\n",
      "|    total_timesteps      | 4216832    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00975629 |\n",
      "|    clip_fraction        | 0.0664     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -104       |\n",
      "|    explained_variance   | 0.394      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.1       |\n",
      "|    n_updates            | 20580      |\n",
      "|    policy_gradient_loss | -0.00582   |\n",
      "|    reward               | -2.0301702 |\n",
      "|    std                  | 9.1        |\n",
      "|    value_loss           | 65.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2060        |\n",
      "|    time_elapsed         | 37956       |\n",
      "|    total_timesteps      | 4218880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010453226 |\n",
      "|    clip_fraction        | 0.0537      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 20590       |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    reward               | -3.8874981  |\n",
      "|    std                  | 9.11        |\n",
      "|    value_loss           | 69.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3382984.84\n",
      "total_reward: 2382984.84\n",
      "total_cost: 147098.19\n",
      "total_trades: 55873\n",
      "Sharpe: 0.550\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2061        |\n",
      "|    time_elapsed         | 37975       |\n",
      "|    total_timesteps      | 4220928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004512475 |\n",
      "|    clip_fraction        | 0.0131      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 20600       |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    reward               | 0.7528822   |\n",
      "|    std                  | 9.12        |\n",
      "|    value_loss           | 93.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2062         |\n",
      "|    time_elapsed         | 37995        |\n",
      "|    total_timesteps      | 4222976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020603207 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.755        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.8         |\n",
      "|    n_updates            | 20610        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | -1.1815556   |\n",
      "|    std                  | 9.13         |\n",
      "|    value_loss           | 81.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 2063       |\n",
      "|    time_elapsed         | 38014      |\n",
      "|    total_timesteps      | 4225024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01594453 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -105       |\n",
      "|    explained_variance   | 0.555      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.5       |\n",
      "|    n_updates            | 20620      |\n",
      "|    policy_gradient_loss | -0.00758   |\n",
      "|    reward               | -3.3488045 |\n",
      "|    std                  | 9.16       |\n",
      "|    value_loss           | 44.9       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2064         |\n",
      "|    time_elapsed         | 38033        |\n",
      "|    total_timesteps      | 4227072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025714305 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.9         |\n",
      "|    n_updates            | 20630        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 0.55505127   |\n",
      "|    std                  | 9.16         |\n",
      "|    value_loss           | 89.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 2065          |\n",
      "|    time_elapsed         | 38052         |\n",
      "|    total_timesteps      | 4229120       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020662285 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -105          |\n",
      "|    explained_variance   | 0.777         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 42.2          |\n",
      "|    n_updates            | 20640         |\n",
      "|    policy_gradient_loss | -0.000801     |\n",
      "|    reward               | 0.19274743    |\n",
      "|    std                  | 9.16          |\n",
      "|    value_loss           | 95.6          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2066        |\n",
      "|    time_elapsed         | 38072       |\n",
      "|    total_timesteps      | 4231168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012668277 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 20650       |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | -1.0676198  |\n",
      "|    std                  | 9.17        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2067        |\n",
      "|    time_elapsed         | 38092       |\n",
      "|    total_timesteps      | 4233216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004218394 |\n",
      "|    clip_fraction        | 0.00854     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 20660       |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    reward               | 1.0196713   |\n",
      "|    std                  | 9.18        |\n",
      "|    value_loss           | 72.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2068         |\n",
      "|    time_elapsed         | 38111        |\n",
      "|    total_timesteps      | 4235264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007087871 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.797        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.2         |\n",
      "|    n_updates            | 20670        |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    reward               | -5.0896945   |\n",
      "|    std                  | 9.18         |\n",
      "|    value_loss           | 88.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2069         |\n",
      "|    time_elapsed         | 38131        |\n",
      "|    total_timesteps      | 4237312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013372274 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.3         |\n",
      "|    n_updates            | 20680        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | -0.84494084  |\n",
      "|    std                  | 9.19         |\n",
      "|    value_loss           | 72.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2070        |\n",
      "|    time_elapsed         | 38149       |\n",
      "|    total_timesteps      | 4239360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010027673 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 20690       |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    reward               | -0.70458853 |\n",
      "|    std                  | 9.2         |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2071         |\n",
      "|    time_elapsed         | 38168        |\n",
      "|    total_timesteps      | 4241408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021041231 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31           |\n",
      "|    n_updates            | 20700        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    reward               | -0.06943728  |\n",
      "|    std                  | 9.2          |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2072         |\n",
      "|    time_elapsed         | 38186        |\n",
      "|    total_timesteps      | 4243456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002107356 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.9         |\n",
      "|    n_updates            | 20710        |\n",
      "|    policy_gradient_loss | -0.000804    |\n",
      "|    reward               | 2.45251      |\n",
      "|    std                  | 9.2          |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2073        |\n",
      "|    time_elapsed         | 38204       |\n",
      "|    total_timesteps      | 4245504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006736895 |\n",
      "|    clip_fraction        | 0.0275      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 20720       |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    reward               | 1.586588    |\n",
      "|    std                  | 9.24        |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2074        |\n",
      "|    time_elapsed         | 38223       |\n",
      "|    total_timesteps      | 4247552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009643905 |\n",
      "|    clip_fraction        | 0.0609      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32          |\n",
      "|    n_updates            | 20730       |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    reward               | 4.611225    |\n",
      "|    std                  | 9.27        |\n",
      "|    value_loss           | 92.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2075         |\n",
      "|    time_elapsed         | 38242        |\n",
      "|    total_timesteps      | 4249600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018101109 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.3         |\n",
      "|    n_updates            | 20740        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | 3.0321205    |\n",
      "|    std                  | 9.27         |\n",
      "|    value_loss           | 88.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3483898.87\n",
      "total_reward: 2483898.87\n",
      "total_cost: 144797.14\n",
      "total_trades: 56115\n",
      "Sharpe: 0.581\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2076         |\n",
      "|    time_elapsed         | 38260        |\n",
      "|    total_timesteps      | 4251648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011026727 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.6         |\n",
      "|    n_updates            | 20750        |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    reward               | 5.8888283    |\n",
      "|    std                  | 9.27         |\n",
      "|    value_loss           | 78.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2077        |\n",
      "|    time_elapsed         | 38279       |\n",
      "|    total_timesteps      | 4253696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007259355 |\n",
      "|    clip_fraction        | 0.0242      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 20760       |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | -0.9094015  |\n",
      "|    std                  | 9.27        |\n",
      "|    value_loss           | 73.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2078        |\n",
      "|    time_elapsed         | 38298       |\n",
      "|    total_timesteps      | 4255744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002970024 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.4        |\n",
      "|    n_updates            | 20770       |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    reward               | 0.2883751   |\n",
      "|    std                  | 9.27        |\n",
      "|    value_loss           | 97.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2079         |\n",
      "|    time_elapsed         | 38316        |\n",
      "|    total_timesteps      | 4257792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026371903 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.3         |\n",
      "|    n_updates            | 20780        |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    reward               | -1.957712    |\n",
      "|    std                  | 9.27         |\n",
      "|    value_loss           | 78.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2080        |\n",
      "|    time_elapsed         | 38335       |\n",
      "|    total_timesteps      | 4259840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007403708 |\n",
      "|    clip_fraction        | 0.0773      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 20790       |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | 3.189468    |\n",
      "|    std                  | 9.34        |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2081        |\n",
      "|    time_elapsed         | 38354       |\n",
      "|    total_timesteps      | 4261888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003245023 |\n",
      "|    clip_fraction        | 0.00381     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.5        |\n",
      "|    n_updates            | 20800       |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    reward               | -0.14600797 |\n",
      "|    std                  | 9.34        |\n",
      "|    value_loss           | 73.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2082         |\n",
      "|    time_elapsed         | 38373        |\n",
      "|    total_timesteps      | 4263936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003937235 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.7         |\n",
      "|    n_updates            | 20810        |\n",
      "|    policy_gradient_loss | -0.000534    |\n",
      "|    reward               | 5.9539375    |\n",
      "|    std                  | 9.34         |\n",
      "|    value_loss           | 93.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2083         |\n",
      "|    time_elapsed         | 38393        |\n",
      "|    total_timesteps      | 4265984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045228535 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 20820        |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    reward               | 0.12486583   |\n",
      "|    std                  | 9.34         |\n",
      "|    value_loss           | 54.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2084         |\n",
      "|    time_elapsed         | 38413        |\n",
      "|    total_timesteps      | 4268032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023029908 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.825        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 20830        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | 3.9500513    |\n",
      "|    std                  | 9.35         |\n",
      "|    value_loss           | 64.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 2085       |\n",
      "|    time_elapsed         | 38431      |\n",
      "|    total_timesteps      | 4270080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00841575 |\n",
      "|    clip_fraction        | 0.0335     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -105       |\n",
      "|    explained_variance   | 0.686      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 39.8       |\n",
      "|    n_updates            | 20840      |\n",
      "|    policy_gradient_loss | -0.00562   |\n",
      "|    reward               | 0.9866957  |\n",
      "|    std                  | 9.36       |\n",
      "|    value_loss           | 83.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2086         |\n",
      "|    time_elapsed         | 38450        |\n",
      "|    total_timesteps      | 4272128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014790228 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 20850        |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    reward               | -0.060594484 |\n",
      "|    std                  | 9.36         |\n",
      "|    value_loss           | 87.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2087        |\n",
      "|    time_elapsed         | 38469       |\n",
      "|    total_timesteps      | 4274176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007863159 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 20860       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -1.3379891  |\n",
      "|    std                  | 9.36        |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2088         |\n",
      "|    time_elapsed         | 38489        |\n",
      "|    total_timesteps      | 4276224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021930304 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.8         |\n",
      "|    n_updates            | 20870        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | 0.49012956   |\n",
      "|    std                  | 9.37         |\n",
      "|    value_loss           | 76.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2089         |\n",
      "|    time_elapsed         | 38508        |\n",
      "|    total_timesteps      | 4278272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.939151e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.761        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.7         |\n",
      "|    n_updates            | 20880        |\n",
      "|    policy_gradient_loss | -0.000603    |\n",
      "|    reward               | -5.995427    |\n",
      "|    std                  | 9.37         |\n",
      "|    value_loss           | 98.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3674830.25\n",
      "total_reward: 2674830.25\n",
      "total_cost: 154074.48\n",
      "total_trades: 56579\n",
      "Sharpe: 0.595\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2090         |\n",
      "|    time_elapsed         | 38526        |\n",
      "|    total_timesteps      | 4280320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078007034 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.222        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.6         |\n",
      "|    n_updates            | 20890        |\n",
      "|    policy_gradient_loss | -0.00622     |\n",
      "|    reward               | 1.3342096    |\n",
      "|    std                  | 9.38         |\n",
      "|    value_loss           | 60.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2091        |\n",
      "|    time_elapsed         | 38544       |\n",
      "|    total_timesteps      | 4282368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001667538 |\n",
      "|    clip_fraction        | 0.000195    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 20900       |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    reward               | -4.2561154  |\n",
      "|    std                  | 9.38        |\n",
      "|    value_loss           | 72          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2092         |\n",
      "|    time_elapsed         | 38563        |\n",
      "|    total_timesteps      | 4284416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010206553 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37           |\n",
      "|    n_updates            | 20910        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | 0.4035179    |\n",
      "|    std                  | 9.38         |\n",
      "|    value_loss           | 89.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2093         |\n",
      "|    time_elapsed         | 38581        |\n",
      "|    total_timesteps      | 4286464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073675024 |\n",
      "|    clip_fraction        | 0.0378       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.4         |\n",
      "|    n_updates            | 20920        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    reward               | 0.7717977    |\n",
      "|    std                  | 9.4          |\n",
      "|    value_loss           | 61.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2094        |\n",
      "|    time_elapsed         | 38601       |\n",
      "|    total_timesteps      | 4288512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012338868 |\n",
      "|    clip_fraction        | 0.0686      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 20930       |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    reward               | 0.13453953  |\n",
      "|    std                  | 9.43        |\n",
      "|    value_loss           | 53.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2095         |\n",
      "|    time_elapsed         | 38620        |\n",
      "|    total_timesteps      | 4290560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00245864   |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.7         |\n",
      "|    n_updates            | 20940        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    reward               | -0.018038932 |\n",
      "|    std                  | 9.43         |\n",
      "|    value_loss           | 82.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2096         |\n",
      "|    time_elapsed         | 38639        |\n",
      "|    total_timesteps      | 4292608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010734135 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.5         |\n",
      "|    n_updates            | 20950        |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | 10.899382    |\n",
      "|    std                  | 9.44         |\n",
      "|    value_loss           | 77.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2097         |\n",
      "|    time_elapsed         | 38657        |\n",
      "|    total_timesteps      | 4294656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022697407 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 20960        |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    reward               | -1.2127601   |\n",
      "|    std                  | 9.44         |\n",
      "|    value_loss           | 45.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2098        |\n",
      "|    time_elapsed         | 38675       |\n",
      "|    total_timesteps      | 4296704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007510232 |\n",
      "|    clip_fraction        | 0.0263      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.5        |\n",
      "|    n_updates            | 20970       |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    reward               | 0.71670336  |\n",
      "|    std                  | 9.45        |\n",
      "|    value_loss           | 73.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2099        |\n",
      "|    time_elapsed         | 38694       |\n",
      "|    total_timesteps      | 4298752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008639233 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 20980       |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    reward               | 2.7968354   |\n",
      "|    std                  | 9.45        |\n",
      "|    value_loss           | 71.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2100         |\n",
      "|    time_elapsed         | 38712        |\n",
      "|    total_timesteps      | 4300800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035383143 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.538        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.8         |\n",
      "|    n_updates            | 20990        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    reward               | 0.8430868    |\n",
      "|    std                  | 9.45         |\n",
      "|    value_loss           | 73.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2101        |\n",
      "|    time_elapsed         | 38731       |\n",
      "|    total_timesteps      | 4302848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008740249 |\n",
      "|    clip_fraction        | 0.0493      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 21000       |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    reward               | -1.2279707  |\n",
      "|    std                  | 9.47        |\n",
      "|    value_loss           | 60.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2102         |\n",
      "|    time_elapsed         | 38749        |\n",
      "|    total_timesteps      | 4304896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013310253 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.775        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.7         |\n",
      "|    n_updates            | 21010        |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    reward               | -1.2640558   |\n",
      "|    std                  | 9.47         |\n",
      "|    value_loss           | 89.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2103        |\n",
      "|    time_elapsed         | 38767       |\n",
      "|    total_timesteps      | 4306944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004077129 |\n",
      "|    clip_fraction        | 0.0101      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 21020       |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | -0.27966392 |\n",
      "|    std                  | 9.48        |\n",
      "|    value_loss           | 87.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3034560.46\n",
      "total_reward: 2034560.46\n",
      "total_cost: 154147.84\n",
      "total_trades: 56876\n",
      "Sharpe: 0.517\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2104        |\n",
      "|    time_elapsed         | 38785       |\n",
      "|    total_timesteps      | 4308992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005171543 |\n",
      "|    clip_fraction        | 0.0188      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 21030       |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    reward               | -2.542167   |\n",
      "|    std                  | 9.49        |\n",
      "|    value_loss           | 44.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2105         |\n",
      "|    time_elapsed         | 38803        |\n",
      "|    total_timesteps      | 4311040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021552774 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.795        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 21040        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | -2.2761939   |\n",
      "|    std                  | 9.49         |\n",
      "|    value_loss           | 97           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2106         |\n",
      "|    time_elapsed         | 38822        |\n",
      "|    total_timesteps      | 4313088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049558417 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.2         |\n",
      "|    n_updates            | 21050        |\n",
      "|    policy_gradient_loss | -0.00583     |\n",
      "|    reward               | 15.317415    |\n",
      "|    std                  | 9.5          |\n",
      "|    value_loss           | 87.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2107         |\n",
      "|    time_elapsed         | 38840        |\n",
      "|    total_timesteps      | 4315136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126020685 |\n",
      "|    clip_fraction        | 0.0649       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 21060        |\n",
      "|    policy_gradient_loss | -0.00845     |\n",
      "|    reward               | 5.426231     |\n",
      "|    std                  | 9.51         |\n",
      "|    value_loss           | 53.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2108         |\n",
      "|    time_elapsed         | 38858        |\n",
      "|    total_timesteps      | 4317184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016613436 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.6         |\n",
      "|    n_updates            | 21070        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | 2.5185874    |\n",
      "|    std                  | 9.53         |\n",
      "|    value_loss           | 71.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2109         |\n",
      "|    time_elapsed         | 38877        |\n",
      "|    total_timesteps      | 4319232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027740756 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.4         |\n",
      "|    n_updates            | 21080        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    reward               | 9.996604     |\n",
      "|    std                  | 9.54         |\n",
      "|    value_loss           | 83.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2110         |\n",
      "|    time_elapsed         | 38895        |\n",
      "|    total_timesteps      | 4321280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025922223 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.805        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43           |\n",
      "|    n_updates            | 21090        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | 2.7363303    |\n",
      "|    std                  | 9.54         |\n",
      "|    value_loss           | 81.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2111        |\n",
      "|    time_elapsed         | 38913       |\n",
      "|    total_timesteps      | 4323328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010982651 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 21100       |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | -0.18726274 |\n",
      "|    std                  | 9.58        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2112        |\n",
      "|    time_elapsed         | 38932       |\n",
      "|    total_timesteps      | 4325376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002909253 |\n",
      "|    clip_fraction        | 0.00469     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.81        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 21110       |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    reward               | 2.8847523   |\n",
      "|    std                  | 9.58        |\n",
      "|    value_loss           | 69.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 2113          |\n",
      "|    time_elapsed         | 38950         |\n",
      "|    total_timesteps      | 4327424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020813238 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -106          |\n",
      "|    explained_variance   | 0.839         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 36.9          |\n",
      "|    n_updates            | 21120         |\n",
      "|    policy_gradient_loss | -0.00152      |\n",
      "|    reward               | 1.4345744     |\n",
      "|    std                  | 9.58          |\n",
      "|    value_loss           | 90.6          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2114        |\n",
      "|    time_elapsed         | 38969       |\n",
      "|    total_timesteps      | 4329472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008756485 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 21130       |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    reward               | -0.42825982 |\n",
      "|    std                  | 9.6         |\n",
      "|    value_loss           | 46.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2115         |\n",
      "|    time_elapsed         | 38987        |\n",
      "|    total_timesteps      | 4331520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064786323 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.1         |\n",
      "|    n_updates            | 21140        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    reward               | 2.449156     |\n",
      "|    std                  | 9.61         |\n",
      "|    value_loss           | 78.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2116        |\n",
      "|    time_elapsed         | 39005       |\n",
      "|    total_timesteps      | 4333568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004548223 |\n",
      "|    clip_fraction        | 0.0127      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.1        |\n",
      "|    n_updates            | 21150       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | -7.424485   |\n",
      "|    std                  | 9.62        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2117         |\n",
      "|    time_elapsed         | 39023        |\n",
      "|    total_timesteps      | 4335616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020241574 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.9         |\n",
      "|    n_updates            | 21160        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    reward               | -0.6731292   |\n",
      "|    std                  | 9.62         |\n",
      "|    value_loss           | 67.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3140696.99\n",
      "total_reward: 2140696.99\n",
      "total_cost: 154918.57\n",
      "total_trades: 58029\n",
      "Sharpe: 0.527\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2118        |\n",
      "|    time_elapsed         | 39042       |\n",
      "|    total_timesteps      | 4337664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010054046 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.3        |\n",
      "|    n_updates            | 21170       |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | 0.33431497  |\n",
      "|    std                  | 9.66        |\n",
      "|    value_loss           | 71.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2119         |\n",
      "|    time_elapsed         | 39060        |\n",
      "|    total_timesteps      | 4339712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025734247 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.817        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.3         |\n",
      "|    n_updates            | 21180        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    reward               | 0.19380084   |\n",
      "|    std                  | 9.67         |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 2120          |\n",
      "|    time_elapsed         | 39079         |\n",
      "|    total_timesteps      | 4341760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058456825 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -106          |\n",
      "|    explained_variance   | 0.803         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 46            |\n",
      "|    n_updates            | 21190         |\n",
      "|    policy_gradient_loss | -0.0014       |\n",
      "|    reward               | 1.1620417     |\n",
      "|    std                  | 9.67          |\n",
      "|    value_loss           | 73.9          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2121        |\n",
      "|    time_elapsed         | 39097       |\n",
      "|    total_timesteps      | 4343808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009795163 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 21200       |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | 2.2300081   |\n",
      "|    std                  | 9.69        |\n",
      "|    value_loss           | 36.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2122         |\n",
      "|    time_elapsed         | 39115        |\n",
      "|    total_timesteps      | 4345856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033550977 |\n",
      "|    clip_fraction        | 0.00786      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.2         |\n",
      "|    n_updates            | 21210        |\n",
      "|    policy_gradient_loss | -0.000609    |\n",
      "|    reward               | -1.2350459   |\n",
      "|    std                  | 9.71         |\n",
      "|    value_loss           | 75.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2123        |\n",
      "|    time_elapsed         | 39133       |\n",
      "|    total_timesteps      | 4347904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005655821 |\n",
      "|    clip_fraction        | 0.03        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 21220       |\n",
      "|    policy_gradient_loss | -0.00155    |\n",
      "|    reward               | -0.13193382 |\n",
      "|    std                  | 9.72        |\n",
      "|    value_loss           | 85          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2124        |\n",
      "|    time_elapsed         | 39151       |\n",
      "|    total_timesteps      | 4349952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004110261 |\n",
      "|    clip_fraction        | 0.0061      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 21230       |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    reward               | 0.3993953   |\n",
      "|    std                  | 9.72        |\n",
      "|    value_loss           | 67.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2125        |\n",
      "|    time_elapsed         | 39169       |\n",
      "|    total_timesteps      | 4352000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007670436 |\n",
      "|    clip_fraction        | 0.0413      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 21240       |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    reward               | 4.643222    |\n",
      "|    std                  | 9.75        |\n",
      "|    value_loss           | 64.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2126         |\n",
      "|    time_elapsed         | 39187        |\n",
      "|    total_timesteps      | 4354048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031321952 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.8         |\n",
      "|    n_updates            | 21250        |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    reward               | 1.6045159    |\n",
      "|    std                  | 9.75         |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2127         |\n",
      "|    time_elapsed         | 39205        |\n",
      "|    total_timesteps      | 4356096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019550296 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.9         |\n",
      "|    n_updates            | 21260        |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    reward               | -3.176423    |\n",
      "|    std                  | 9.76         |\n",
      "|    value_loss           | 73.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2128         |\n",
      "|    time_elapsed         | 39224        |\n",
      "|    total_timesteps      | 4358144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123236235 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 21270        |\n",
      "|    policy_gradient_loss | -0.00659     |\n",
      "|    reward               | 2.076629     |\n",
      "|    std                  | 9.78         |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2129         |\n",
      "|    time_elapsed         | 39242        |\n",
      "|    total_timesteps      | 4360192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021145232 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.75         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52           |\n",
      "|    n_updates            | 21280        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | -3.1708672   |\n",
      "|    std                  | 9.79         |\n",
      "|    value_loss           | 89.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2130         |\n",
      "|    time_elapsed         | 39261        |\n",
      "|    total_timesteps      | 4362240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033964005 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.4         |\n",
      "|    n_updates            | 21290        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | -8.187463    |\n",
      "|    std                  | 9.79         |\n",
      "|    value_loss           | 80           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2131        |\n",
      "|    time_elapsed         | 39279       |\n",
      "|    total_timesteps      | 4364288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000576554 |\n",
      "|    clip_fraction        | 0.000293    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.2        |\n",
      "|    n_updates            | 21300       |\n",
      "|    policy_gradient_loss | -0.000619   |\n",
      "|    reward               | 0.99579203  |\n",
      "|    std                  | 9.8         |\n",
      "|    value_loss           | 59.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3161395.48\n",
      "total_reward: 2161395.48\n",
      "total_cost: 168298.61\n",
      "total_trades: 58674\n",
      "Sharpe: 0.531\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2132        |\n",
      "|    time_elapsed         | 39297       |\n",
      "|    total_timesteps      | 4366336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007693963 |\n",
      "|    clip_fraction        | 0.0426      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 21310       |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    reward               | -6.0585346  |\n",
      "|    std                  | 9.81        |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2133         |\n",
      "|    time_elapsed         | 39315        |\n",
      "|    total_timesteps      | 4368384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016835569 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.5         |\n",
      "|    n_updates            | 21320        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | 4.47852      |\n",
      "|    std                  | 9.81         |\n",
      "|    value_loss           | 79.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2134         |\n",
      "|    time_elapsed         | 39333        |\n",
      "|    total_timesteps      | 4370432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016433178 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21           |\n",
      "|    n_updates            | 21330        |\n",
      "|    policy_gradient_loss | -0.000728    |\n",
      "|    reward               | -3.0325258   |\n",
      "|    std                  | 9.82         |\n",
      "|    value_loss           | 72.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2135        |\n",
      "|    time_elapsed         | 39375       |\n",
      "|    total_timesteps      | 4372480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010693373 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 21340       |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    reward               | 3.3249526   |\n",
      "|    std                  | 9.85        |\n",
      "|    value_loss           | 47          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2136        |\n",
      "|    time_elapsed         | 39393       |\n",
      "|    total_timesteps      | 4374528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005094609 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.3        |\n",
      "|    n_updates            | 21350       |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    reward               | -0.46707806 |\n",
      "|    std                  | 9.86        |\n",
      "|    value_loss           | 78.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2137         |\n",
      "|    time_elapsed         | 39411        |\n",
      "|    total_timesteps      | 4376576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015460628 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.8         |\n",
      "|    n_updates            | 21360        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    reward               | 0.60370684   |\n",
      "|    std                  | 9.86         |\n",
      "|    value_loss           | 73.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2138        |\n",
      "|    time_elapsed         | 39429       |\n",
      "|    total_timesteps      | 4378624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011936152 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 21370       |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | -2.9279928  |\n",
      "|    std                  | 9.89        |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2139         |\n",
      "|    time_elapsed         | 39447        |\n",
      "|    total_timesteps      | 4380672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012923895 |\n",
      "|    clip_fraction        | 0.00581      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.8         |\n",
      "|    n_updates            | 21380        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | 1.9895347    |\n",
      "|    std                  | 9.89         |\n",
      "|    value_loss           | 72.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2140         |\n",
      "|    time_elapsed         | 39466        |\n",
      "|    total_timesteps      | 4382720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024207141 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.2         |\n",
      "|    n_updates            | 21390        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | 4.4910545    |\n",
      "|    std                  | 9.9          |\n",
      "|    value_loss           | 85.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2141         |\n",
      "|    time_elapsed         | 39485        |\n",
      "|    total_timesteps      | 4384768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010721993 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.7         |\n",
      "|    n_updates            | 21400        |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    reward               | -2.7645233   |\n",
      "|    std                  | 9.91         |\n",
      "|    value_loss           | 59.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2142        |\n",
      "|    time_elapsed         | 39503       |\n",
      "|    total_timesteps      | 4386816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009279767 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 21410       |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    reward               | -2.049075   |\n",
      "|    std                  | 9.92        |\n",
      "|    value_loss           | 53.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2143         |\n",
      "|    time_elapsed         | 39522        |\n",
      "|    total_timesteps      | 4388864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057231355 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 21420        |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    reward               | -0.34694308  |\n",
      "|    std                  | 9.93         |\n",
      "|    value_loss           | 76.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 2144          |\n",
      "|    time_elapsed         | 39541         |\n",
      "|    total_timesteps      | 4390912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015878328 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -107          |\n",
      "|    explained_variance   | 0.762         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 50.3          |\n",
      "|    n_updates            | 21430         |\n",
      "|    policy_gradient_loss | -0.000608     |\n",
      "|    reward               | 0.7548079     |\n",
      "|    std                  | 9.93          |\n",
      "|    value_loss           | 102           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2145        |\n",
      "|    time_elapsed         | 39560       |\n",
      "|    total_timesteps      | 4392960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012896871 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 21440       |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    reward               | -1.8752927  |\n",
      "|    std                  | 9.97        |\n",
      "|    value_loss           | 31.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3124039.08\n",
      "total_reward: 2124039.08\n",
      "total_cost: 179429.14\n",
      "total_trades: 58563\n",
      "Sharpe: 0.530\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2146         |\n",
      "|    time_elapsed         | 39580        |\n",
      "|    total_timesteps      | 4395008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018706593 |\n",
      "|    clip_fraction        | 0.00376      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.798        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.9         |\n",
      "|    n_updates            | 21450        |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    reward               | 1.7655733    |\n",
      "|    std                  | 9.98         |\n",
      "|    value_loss           | 71.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2147        |\n",
      "|    time_elapsed         | 39599       |\n",
      "|    total_timesteps      | 4397056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003614765 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.3        |\n",
      "|    n_updates            | 21460       |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    reward               | 1.0582386   |\n",
      "|    std                  | 9.99        |\n",
      "|    value_loss           | 84.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2148        |\n",
      "|    time_elapsed         | 39617       |\n",
      "|    total_timesteps      | 4399104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006123552 |\n",
      "|    clip_fraction        | 0.0372      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 21470       |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | -2.883024   |\n",
      "|    std                  | 10          |\n",
      "|    value_loss           | 59.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2149        |\n",
      "|    time_elapsed         | 39635       |\n",
      "|    total_timesteps      | 4401152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009596903 |\n",
      "|    clip_fraction        | 0.0741      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 21480       |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    reward               | 4.1339874   |\n",
      "|    std                  | 10          |\n",
      "|    value_loss           | 61.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2150         |\n",
      "|    time_elapsed         | 39654        |\n",
      "|    total_timesteps      | 4403200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012729357 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.5         |\n",
      "|    n_updates            | 21490        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    reward               | 2.6281466    |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 89.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2151         |\n",
      "|    time_elapsed         | 39672        |\n",
      "|    total_timesteps      | 4405248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023844214 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.4         |\n",
      "|    n_updates            | 21500        |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    reward               | 1.2984337    |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 83.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2152        |\n",
      "|    time_elapsed         | 39691       |\n",
      "|    total_timesteps      | 4407296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011526444 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 21510       |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    reward               | 1.8518552   |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2153         |\n",
      "|    time_elapsed         | 39710        |\n",
      "|    total_timesteps      | 4409344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031508317 |\n",
      "|    clip_fraction        | 0.00532      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.8          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 21520        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | -2.5170515   |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 80.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2154         |\n",
      "|    time_elapsed         | 39729        |\n",
      "|    total_timesteps      | 4411392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015313602 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.9         |\n",
      "|    n_updates            | 21530        |\n",
      "|    policy_gradient_loss | -0.000255    |\n",
      "|    reward               | -11.3428545  |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2155         |\n",
      "|    time_elapsed         | 39749        |\n",
      "|    total_timesteps      | 4413440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036451553 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 21540        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | -2.9295208   |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 46.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2156        |\n",
      "|    time_elapsed         | 39768       |\n",
      "|    total_timesteps      | 4415488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003464073 |\n",
      "|    clip_fraction        | 0.00625     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.5        |\n",
      "|    n_updates            | 21550       |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    reward               | -0.35960114 |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 85.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2157         |\n",
      "|    time_elapsed         | 39787        |\n",
      "|    total_timesteps      | 4417536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018587001 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.3         |\n",
      "|    n_updates            | 21560        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    reward               | -38.437363   |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 91.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2158         |\n",
      "|    time_elapsed         | 39806        |\n",
      "|    total_timesteps      | 4419584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013898255 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 21570        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    reward               | -2.6354873   |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 66.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2159        |\n",
      "|    time_elapsed         | 39825       |\n",
      "|    total_timesteps      | 4421632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010804933 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 21580       |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    reward               | 2.8405337   |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 53.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3038950.58\n",
      "total_reward: 2038950.58\n",
      "total_cost: 158272.70\n",
      "total_trades: 57414\n",
      "Sharpe: 0.502\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 2160       |\n",
      "|    time_elapsed         | 39844      |\n",
      "|    total_timesteps      | 4423680    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00689804 |\n",
      "|    clip_fraction        | 0.0345     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -107       |\n",
      "|    explained_variance   | 0.54       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 48         |\n",
      "|    n_updates            | 21590      |\n",
      "|    policy_gradient_loss | -0.00535   |\n",
      "|    reward               | 0.8432405  |\n",
      "|    std                  | 10.1       |\n",
      "|    value_loss           | 118        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2161        |\n",
      "|    time_elapsed         | 39864       |\n",
      "|    total_timesteps      | 4425728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002403475 |\n",
      "|    clip_fraction        | 0.00977     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.6        |\n",
      "|    n_updates            | 21600       |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    reward               | 0.8266847   |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 88          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2162        |\n",
      "|    time_elapsed         | 39883       |\n",
      "|    total_timesteps      | 4427776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007930586 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 21610       |\n",
      "|    policy_gradient_loss | -0.00573    |\n",
      "|    reward               | -0.2044303  |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2163        |\n",
      "|    time_elapsed         | 39901       |\n",
      "|    total_timesteps      | 4429824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005780636 |\n",
      "|    clip_fraction        | 0.0216      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 21620       |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    reward               | 1.0221133   |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 83.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2164         |\n",
      "|    time_elapsed         | 39920        |\n",
      "|    total_timesteps      | 4431872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025306095 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.3         |\n",
      "|    n_updates            | 21630        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | -6.4925294   |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 94           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2165        |\n",
      "|    time_elapsed         | 39940       |\n",
      "|    total_timesteps      | 4433920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004573521 |\n",
      "|    clip_fraction        | 0.00654     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 21640       |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    reward               | 0.66238683  |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 2166       |\n",
      "|    time_elapsed         | 39959      |\n",
      "|    total_timesteps      | 4435968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00860895 |\n",
      "|    clip_fraction        | 0.0416     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -107       |\n",
      "|    explained_variance   | 0.738      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 44.4       |\n",
      "|    n_updates            | 21650      |\n",
      "|    policy_gradient_loss | -0.0095    |\n",
      "|    reward               | 0.41441202 |\n",
      "|    std                  | 10.2       |\n",
      "|    value_loss           | 80.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2167        |\n",
      "|    time_elapsed         | 39979       |\n",
      "|    total_timesteps      | 4438016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005687832 |\n",
      "|    clip_fraction        | 0.0201      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.7        |\n",
      "|    n_updates            | 21660       |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    reward               | 0.48461717  |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 82.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 2168         |\n",
      "|    time_elapsed         | 39999        |\n",
      "|    total_timesteps      | 4440064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050610607 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.4         |\n",
      "|    n_updates            | 21670        |\n",
      "|    policy_gradient_loss | -0.00567     |\n",
      "|    reward               | 0.25061807   |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 81.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2169        |\n",
      "|    time_elapsed         | 40018       |\n",
      "|    total_timesteps      | 4442112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008197482 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 21680       |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    reward               | 4.1032004   |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 46.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2170         |\n",
      "|    time_elapsed         | 40038        |\n",
      "|    total_timesteps      | 4444160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017433057 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.1         |\n",
      "|    n_updates            | 21690        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    reward               | 0.24439731   |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 86.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2171         |\n",
      "|    time_elapsed         | 40057        |\n",
      "|    total_timesteps      | 4446208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011927325 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.2         |\n",
      "|    n_updates            | 21700        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | -3.9987977   |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2172        |\n",
      "|    time_elapsed         | 40077       |\n",
      "|    total_timesteps      | 4448256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009530302 |\n",
      "|    clip_fraction        | 0.0324      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.3        |\n",
      "|    n_updates            | 21710       |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    reward               | -0.95105463 |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2173         |\n",
      "|    time_elapsed         | 40096        |\n",
      "|    total_timesteps      | 4450304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054730475 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 21720        |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    reward               | 2.7971988    |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 78.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3047250.07\n",
      "total_reward: 2047250.07\n",
      "total_cost: 177801.50\n",
      "total_trades: 58182\n",
      "Sharpe: 0.511\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2174         |\n",
      "|    time_elapsed         | 40116        |\n",
      "|    total_timesteps      | 4452352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036894926 |\n",
      "|    clip_fraction        | 0.00854      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.815        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 21730        |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    reward               | 0.067219466  |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 78.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2175         |\n",
      "|    time_elapsed         | 40135        |\n",
      "|    total_timesteps      | 4454400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029451218 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.4         |\n",
      "|    n_updates            | 21740        |\n",
      "|    policy_gradient_loss | -0.00481     |\n",
      "|    reward               | -1.0401448   |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 83.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2176        |\n",
      "|    time_elapsed         | 40155       |\n",
      "|    total_timesteps      | 4456448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011778543 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 21750       |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    reward               | -0.7018292  |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2177        |\n",
      "|    time_elapsed         | 40174       |\n",
      "|    total_timesteps      | 4458496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006276341 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 21760       |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    reward               | 3.341761    |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 73.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2178         |\n",
      "|    time_elapsed         | 40194        |\n",
      "|    total_timesteps      | 4460544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018487602 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.816        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.6         |\n",
      "|    n_updates            | 21770        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | -1.1425014   |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 80.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2179         |\n",
      "|    time_elapsed         | 40213        |\n",
      "|    total_timesteps      | 4462592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071178433 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 21780        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    reward               | -0.50945115  |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 45.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2180         |\n",
      "|    time_elapsed         | 40232        |\n",
      "|    total_timesteps      | 4464640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074306205 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.839        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 21790        |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | 4.203713     |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 55.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2181         |\n",
      "|    time_elapsed         | 40252        |\n",
      "|    total_timesteps      | 4466688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023056057 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.1         |\n",
      "|    n_updates            | 21800        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    reward               | 2.772629     |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 68.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2182        |\n",
      "|    time_elapsed         | 40271       |\n",
      "|    total_timesteps      | 4468736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004300769 |\n",
      "|    clip_fraction        | 0.00576     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 21810       |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    reward               | 0.7892781   |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 47.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2183        |\n",
      "|    time_elapsed         | 40290       |\n",
      "|    total_timesteps      | 4470784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008651838 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 21820       |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    reward               | -1.4708045  |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 61.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2184        |\n",
      "|    time_elapsed         | 40309       |\n",
      "|    total_timesteps      | 4472832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002857825 |\n",
      "|    clip_fraction        | 0.00269     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 21830       |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | 0.15305048  |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 82.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2185         |\n",
      "|    time_elapsed         | 40328        |\n",
      "|    total_timesteps      | 4474880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019992376 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.9         |\n",
      "|    n_updates            | 21840        |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    reward               | 7.756592     |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 83.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2186        |\n",
      "|    time_elapsed         | 40346       |\n",
      "|    total_timesteps      | 4476928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008416593 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 21850       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -0.20570774 |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2187         |\n",
      "|    time_elapsed         | 40365        |\n",
      "|    total_timesteps      | 4478976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026923544 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.785        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.1         |\n",
      "|    n_updates            | 21860        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    reward               | -2.3463006   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 78.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2188         |\n",
      "|    time_elapsed         | 40383        |\n",
      "|    total_timesteps      | 4481024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016691536 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.7         |\n",
      "|    n_updates            | 21870        |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    reward               | -3.5170815   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 92.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3048389.82\n",
      "total_reward: 2048389.82\n",
      "total_cost: 182401.33\n",
      "total_trades: 58601\n",
      "Sharpe: 0.508\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2189        |\n",
      "|    time_elapsed         | 40401       |\n",
      "|    total_timesteps      | 4483072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010069266 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 21880       |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    reward               | 0.24974541  |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 49.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2190        |\n",
      "|    time_elapsed         | 40420       |\n",
      "|    total_timesteps      | 4485120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006420169 |\n",
      "|    clip_fraction        | 0.0489      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 21890       |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    reward               | -1.0889299  |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 65.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2191        |\n",
      "|    time_elapsed         | 40438       |\n",
      "|    total_timesteps      | 4487168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005666214 |\n",
      "|    clip_fraction        | 0.0201      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 21900       |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    reward               | -3.1550417  |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 71.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2192         |\n",
      "|    time_elapsed         | 40457        |\n",
      "|    total_timesteps      | 4489216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049860356 |\n",
      "|    clip_fraction        | 0.00688      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.5         |\n",
      "|    n_updates            | 21910        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    reward               | -0.37217325  |\n",
      "|    std                  | 10.5         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2193       |\n",
      "|    time_elapsed         | 40476      |\n",
      "|    total_timesteps      | 4491264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00856664 |\n",
      "|    clip_fraction        | 0.0459     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -108       |\n",
      "|    explained_variance   | 0.582      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.1       |\n",
      "|    n_updates            | 21920      |\n",
      "|    policy_gradient_loss | -0.00533   |\n",
      "|    reward               | 2.8922956  |\n",
      "|    std                  | 10.5       |\n",
      "|    value_loss           | 39.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2194        |\n",
      "|    time_elapsed         | 40495       |\n",
      "|    total_timesteps      | 4493312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004242568 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.1        |\n",
      "|    n_updates            | 21930       |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    reward               | 1.6642554   |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 99          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2195         |\n",
      "|    time_elapsed         | 40515        |\n",
      "|    total_timesteps      | 4495360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021677848 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.3         |\n",
      "|    n_updates            | 21940        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | 0.055237748  |\n",
      "|    std                  | 10.5         |\n",
      "|    value_loss           | 93.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2196        |\n",
      "|    time_elapsed         | 40534       |\n",
      "|    total_timesteps      | 4497408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005741165 |\n",
      "|    clip_fraction        | 0.00986     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 21950       |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    reward               | 3.9889011   |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 44.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2197        |\n",
      "|    time_elapsed         | 40553       |\n",
      "|    total_timesteps      | 4499456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008856585 |\n",
      "|    clip_fraction        | 0.053       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 21960       |\n",
      "|    policy_gradient_loss | -0.00943    |\n",
      "|    reward               | -3.0871332  |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 78.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2198         |\n",
      "|    time_elapsed         | 40572        |\n",
      "|    total_timesteps      | 4501504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028144354 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.3         |\n",
      "|    n_updates            | 21970        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | 7.0089974    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 86.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2199        |\n",
      "|    time_elapsed         | 40590       |\n",
      "|    total_timesteps      | 4503552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004076241 |\n",
      "|    clip_fraction        | 0.00801     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.6        |\n",
      "|    n_updates            | 21980       |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    reward               | 0.6945578   |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 88          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2200        |\n",
      "|    time_elapsed         | 40608       |\n",
      "|    total_timesteps      | 4505600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009680862 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 21990       |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    reward               | -1.8243672  |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2201         |\n",
      "|    time_elapsed         | 40627        |\n",
      "|    total_timesteps      | 4507648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036602803 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.3         |\n",
      "|    n_updates            | 22000        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | -1.7229861   |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2202         |\n",
      "|    time_elapsed         | 40646        |\n",
      "|    total_timesteps      | 4509696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012568104 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.8         |\n",
      "|    n_updates            | 22010        |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    reward               | -7.401826    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 87.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3027659.12\n",
      "total_reward: 2027659.12\n",
      "total_cost: 210383.04\n",
      "total_trades: 59917\n",
      "Sharpe: 0.509\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2203         |\n",
      "|    time_elapsed         | 40665        |\n",
      "|    total_timesteps      | 4511744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068905484 |\n",
      "|    clip_fraction        | 0.0482       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 22020        |\n",
      "|    policy_gradient_loss | -0.00729     |\n",
      "|    reward               | 4.5341015    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 38.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2204         |\n",
      "|    time_elapsed         | 40683        |\n",
      "|    total_timesteps      | 4513792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037847443 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37           |\n",
      "|    n_updates            | 22030        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    reward               | 0.7213234    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 76.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2205         |\n",
      "|    time_elapsed         | 40703        |\n",
      "|    total_timesteps      | 4515840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010950444 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.7         |\n",
      "|    n_updates            | 22040        |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    reward               | -1.0120676   |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 76.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2206         |\n",
      "|    time_elapsed         | 40723        |\n",
      "|    total_timesteps      | 4517888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035128873 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 22050        |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    reward               | 2.0969667    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 45.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2207        |\n",
      "|    time_elapsed         | 40742       |\n",
      "|    total_timesteps      | 4519936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011358498 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.5        |\n",
      "|    n_updates            | 22060       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -1.9049196  |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 56.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2208        |\n",
      "|    time_elapsed         | 40762       |\n",
      "|    total_timesteps      | 4521984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000659604 |\n",
      "|    clip_fraction        | 0.000342    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55          |\n",
      "|    n_updates            | 22070       |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    reward               | 1.3296963   |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2209         |\n",
      "|    time_elapsed         | 40782        |\n",
      "|    total_timesteps      | 4524032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.182621e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.753        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 95.8         |\n",
      "|    n_updates            | 22080        |\n",
      "|    policy_gradient_loss | -0.000438    |\n",
      "|    reward               | 1.0522772    |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 182          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2210        |\n",
      "|    time_elapsed         | 40800       |\n",
      "|    total_timesteps      | 4526080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011281133 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 22090       |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    reward               | -0.14305855 |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2211       |\n",
      "|    time_elapsed         | 40819      |\n",
      "|    total_timesteps      | 4528128    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00226153 |\n",
      "|    clip_fraction        | 0.00225    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -109       |\n",
      "|    explained_variance   | 0.705      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 64.7       |\n",
      "|    n_updates            | 22100      |\n",
      "|    policy_gradient_loss | -0.00164   |\n",
      "|    reward               | 1.711834   |\n",
      "|    std                  | 10.7       |\n",
      "|    value_loss           | 111        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2212         |\n",
      "|    time_elapsed         | 40837        |\n",
      "|    total_timesteps      | 4530176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023801625 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 22110        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | 6.2445154    |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 122          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2213        |\n",
      "|    time_elapsed         | 40855       |\n",
      "|    total_timesteps      | 4532224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009386752 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 22120       |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    reward               | -4.459004   |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2214         |\n",
      "|    time_elapsed         | 40874        |\n",
      "|    total_timesteps      | 4534272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073139477 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.2         |\n",
      "|    n_updates            | 22130        |\n",
      "|    policy_gradient_loss | -0.00761     |\n",
      "|    reward               | -1.9460703   |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 96.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2215         |\n",
      "|    time_elapsed         | 40892        |\n",
      "|    total_timesteps      | 4536320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002402997 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 89.5         |\n",
      "|    n_updates            | 22140        |\n",
      "|    policy_gradient_loss | -0.000469    |\n",
      "|    reward               | -0.27967596  |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2216         |\n",
      "|    time_elapsed         | 40912        |\n",
      "|    total_timesteps      | 4538368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008609296 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.2         |\n",
      "|    n_updates            | 22150        |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    reward               | -0.3461166   |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3148976.78\n",
      "total_reward: 2148976.78\n",
      "total_cost: 189112.48\n",
      "total_trades: 58181\n",
      "Sharpe: 0.520\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2217        |\n",
      "|    time_elapsed         | 40931       |\n",
      "|    total_timesteps      | 4540416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011096733 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 22160       |\n",
      "|    policy_gradient_loss | -0.00762    |\n",
      "|    reward               | 6.42144     |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2218        |\n",
      "|    time_elapsed         | 40950       |\n",
      "|    total_timesteps      | 4542464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004631875 |\n",
      "|    clip_fraction        | 0.0169      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.4        |\n",
      "|    n_updates            | 22170       |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    reward               | 0.4012929   |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 97.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2219         |\n",
      "|    time_elapsed         | 40968        |\n",
      "|    total_timesteps      | 4544512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016018376 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.9         |\n",
      "|    n_updates            | 22180        |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    reward               | -1.2598176   |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2220        |\n",
      "|    time_elapsed         | 40987       |\n",
      "|    total_timesteps      | 4546560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00500874  |\n",
      "|    clip_fraction        | 0.00737     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 22190       |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    reward               | -0.84494233 |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 44.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2221        |\n",
      "|    time_elapsed         | 41005       |\n",
      "|    total_timesteps      | 4548608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007359082 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 22200       |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    reward               | 0.8208872   |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2222          |\n",
      "|    time_elapsed         | 41023         |\n",
      "|    total_timesteps      | 4550656       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036443124 |\n",
      "|    clip_fraction        | 0.00298       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -109          |\n",
      "|    explained_variance   | 0.687         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 33            |\n",
      "|    n_updates            | 22210         |\n",
      "|    policy_gradient_loss | -0.000806     |\n",
      "|    reward               | 12.109651     |\n",
      "|    std                  | 10.8          |\n",
      "|    value_loss           | 122           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2223          |\n",
      "|    time_elapsed         | 41042         |\n",
      "|    total_timesteps      | 4552704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00080958277 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -109          |\n",
      "|    explained_variance   | 0.654         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 40.5          |\n",
      "|    n_updates            | 22220         |\n",
      "|    policy_gradient_loss | -0.00108      |\n",
      "|    reward               | 3.0619605     |\n",
      "|    std                  | 10.8          |\n",
      "|    value_loss           | 89            |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2224        |\n",
      "|    time_elapsed         | 41061       |\n",
      "|    total_timesteps      | 4554752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011936635 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 22230       |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    reward               | -3.869509   |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2225         |\n",
      "|    time_elapsed         | 41079        |\n",
      "|    total_timesteps      | 4556800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031328765 |\n",
      "|    clip_fraction        | 0.00542      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.515        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.1         |\n",
      "|    n_updates            | 22240        |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    reward               | -0.27670443  |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2226          |\n",
      "|    time_elapsed         | 41098         |\n",
      "|    total_timesteps      | 4558848       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029192242 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -109          |\n",
      "|    explained_variance   | 0.673         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 42.4          |\n",
      "|    n_updates            | 22250         |\n",
      "|    policy_gradient_loss | -0.000504     |\n",
      "|    reward               | 1.5066057     |\n",
      "|    std                  | 10.9          |\n",
      "|    value_loss           | 113           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2227         |\n",
      "|    time_elapsed         | 41116        |\n",
      "|    total_timesteps      | 4560896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040292153 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 22260        |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    reward               | 0.7543402    |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 41.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2228       |\n",
      "|    time_elapsed         | 41134      |\n",
      "|    total_timesteps      | 4562944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00704919 |\n",
      "|    clip_fraction        | 0.0389     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -109       |\n",
      "|    explained_variance   | 0.794      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.3       |\n",
      "|    n_updates            | 22270      |\n",
      "|    policy_gradient_loss | -0.00817   |\n",
      "|    reward               | -3.2372253 |\n",
      "|    std                  | 10.9       |\n",
      "|    value_loss           | 82.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2229         |\n",
      "|    time_elapsed         | 41153        |\n",
      "|    total_timesteps      | 4564992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010483337 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.7         |\n",
      "|    n_updates            | 22280        |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    reward               | 4.717336     |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2230        |\n",
      "|    time_elapsed         | 41171       |\n",
      "|    total_timesteps      | 4567040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004923404 |\n",
      "|    clip_fraction        | 0.0187      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 22290       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | 3.3640697   |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 55.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2865020.94\n",
      "total_reward: 1865020.94\n",
      "total_cost: 213803.70\n",
      "total_trades: 59481\n",
      "Sharpe: 0.509\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2231        |\n",
      "|    time_elapsed         | 41190       |\n",
      "|    total_timesteps      | 4569088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009041637 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 22300       |\n",
      "|    policy_gradient_loss | -0.00681    |\n",
      "|    reward               | 2.0493386   |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 66.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2232         |\n",
      "|    time_elapsed         | 41208        |\n",
      "|    total_timesteps      | 4571136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038512882 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.3         |\n",
      "|    n_updates            | 22310        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    reward               | -0.4845622   |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 85.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2233         |\n",
      "|    time_elapsed         | 41227        |\n",
      "|    total_timesteps      | 4573184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016403905 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.761        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.9         |\n",
      "|    n_updates            | 22320        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | 4.7247605    |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 94           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2234         |\n",
      "|    time_elapsed         | 41245        |\n",
      "|    total_timesteps      | 4575232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077641327 |\n",
      "|    clip_fraction        | 0.0595       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 22330        |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | -2.4065366   |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 34.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2235         |\n",
      "|    time_elapsed         | 41264        |\n",
      "|    total_timesteps      | 4577280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038259793 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.793        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.5         |\n",
      "|    n_updates            | 22340        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | -3.4621603   |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 80.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2236        |\n",
      "|    time_elapsed         | 41282       |\n",
      "|    total_timesteps      | 4579328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002277436 |\n",
      "|    clip_fraction        | 0.0019      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 22350       |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    reward               | -3.9495535  |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 80.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2237        |\n",
      "|    time_elapsed         | 41301       |\n",
      "|    total_timesteps      | 4581376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005234398 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 22360       |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | 0.1536137   |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 49.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2238        |\n",
      "|    time_elapsed         | 41319       |\n",
      "|    total_timesteps      | 4583424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007041319 |\n",
      "|    clip_fraction        | 0.0295      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51          |\n",
      "|    n_updates            | 22370       |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    reward               | 0.69423157  |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 87          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2239        |\n",
      "|    time_elapsed         | 41338       |\n",
      "|    total_timesteps      | 4585472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011600396 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45          |\n",
      "|    n_updates            | 22380       |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    reward               | 0.84446424  |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2240        |\n",
      "|    time_elapsed         | 41357       |\n",
      "|    total_timesteps      | 4587520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007489319 |\n",
      "|    clip_fraction        | 0.0485      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 22390       |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    reward               | -1.0715117  |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 98.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2241         |\n",
      "|    time_elapsed         | 41375        |\n",
      "|    total_timesteps      | 4589568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093110725 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 22400        |\n",
      "|    policy_gradient_loss | -0.0138      |\n",
      "|    reward               | -1.2203714   |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 36.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2242         |\n",
      "|    time_elapsed         | 41393        |\n",
      "|    total_timesteps      | 4591616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055376287 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 98           |\n",
      "|    n_updates            | 22410        |\n",
      "|    policy_gradient_loss | -0.00548     |\n",
      "|    reward               | 0.28137797   |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 183          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2243        |\n",
      "|    time_elapsed         | 41412       |\n",
      "|    total_timesteps      | 4593664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009953203 |\n",
      "|    clip_fraction        | 0.0645      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.4        |\n",
      "|    n_updates            | 22420       |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    reward               | -0.12171835 |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2244        |\n",
      "|    time_elapsed         | 41431       |\n",
      "|    total_timesteps      | 4595712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008424435 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 22430       |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | 0.4207612   |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3423291.22\n",
      "total_reward: 2423291.22\n",
      "total_cost: 195760.25\n",
      "total_trades: 59437\n",
      "Sharpe: 0.559\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2245        |\n",
      "|    time_elapsed         | 41450       |\n",
      "|    total_timesteps      | 4597760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008888245 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.9        |\n",
      "|    n_updates            | 22440       |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    reward               | -1.2290589  |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 82.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2246        |\n",
      "|    time_elapsed         | 41469       |\n",
      "|    total_timesteps      | 4599808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006200961 |\n",
      "|    clip_fraction        | 0.0206      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 22450       |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    reward               | -0.03394146 |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2247         |\n",
      "|    time_elapsed         | 41487        |\n",
      "|    total_timesteps      | 4601856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024472328 |\n",
      "|    clip_fraction        | 0.00591      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.2         |\n",
      "|    n_updates            | 22460        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    reward               | 1.7377031    |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2248       |\n",
      "|    time_elapsed         | 41506      |\n",
      "|    total_timesteps      | 4603904    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0035213  |\n",
      "|    clip_fraction        | 0.0103     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -110       |\n",
      "|    explained_variance   | 0.599      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.9       |\n",
      "|    n_updates            | 22470      |\n",
      "|    policy_gradient_loss | -0.0034    |\n",
      "|    reward               | -3.7297497 |\n",
      "|    std                  | 11.1       |\n",
      "|    value_loss           | 34         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2249         |\n",
      "|    time_elapsed         | 41524        |\n",
      "|    total_timesteps      | 4605952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025993914 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.261        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.5         |\n",
      "|    n_updates            | 22480        |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    reward               | -0.2005912   |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2250         |\n",
      "|    time_elapsed         | 41543        |\n",
      "|    total_timesteps      | 4608000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011524751 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.3         |\n",
      "|    n_updates            | 22490        |\n",
      "|    policy_gradient_loss | -0.000909    |\n",
      "|    reward               | 4.0329933    |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2251         |\n",
      "|    time_elapsed         | 41561        |\n",
      "|    total_timesteps      | 4610048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019350825 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 22500        |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    reward               | -4.7776437   |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 35.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2252         |\n",
      "|    time_elapsed         | 41579        |\n",
      "|    total_timesteps      | 4612096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006356387 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.707        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 87.3         |\n",
      "|    n_updates            | 22510        |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    reward               | -9.281068    |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 145          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2253         |\n",
      "|    time_elapsed         | 41598        |\n",
      "|    total_timesteps      | 4614144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066341823 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.445        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25           |\n",
      "|    n_updates            | 22520        |\n",
      "|    policy_gradient_loss | -0.00477     |\n",
      "|    reward               | -1.0302391   |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2254        |\n",
      "|    time_elapsed         | 41616       |\n",
      "|    total_timesteps      | 4616192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003502911 |\n",
      "|    clip_fraction        | 0.0154      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 22530       |\n",
      "|    policy_gradient_loss | -0.00203    |\n",
      "|    reward               | -1.9519463  |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 52          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2255        |\n",
      "|    time_elapsed         | 41635       |\n",
      "|    total_timesteps      | 4618240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005914961 |\n",
      "|    clip_fraction        | 0.0224      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.3        |\n",
      "|    n_updates            | 22540       |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    reward               | 1.3168058   |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 74.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2256         |\n",
      "|    time_elapsed         | 41653        |\n",
      "|    total_timesteps      | 4620288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059196497 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.779        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.8         |\n",
      "|    n_updates            | 22550        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | -2.3967965   |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 82.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2257         |\n",
      "|    time_elapsed         | 41671        |\n",
      "|    total_timesteps      | 4622336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033519194 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.6         |\n",
      "|    n_updates            | 22560        |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    reward               | -0.57929415  |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2258        |\n",
      "|    time_elapsed         | 41690       |\n",
      "|    total_timesteps      | 4624384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011467118 |\n",
      "|    clip_fraction        | 0.0761      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 22570       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | 0.20640148  |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3113571.78\n",
      "total_reward: 2113571.78\n",
      "total_cost: 167196.49\n",
      "total_trades: 57767\n",
      "Sharpe: 0.517\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2259         |\n",
      "|    time_elapsed         | 41708        |\n",
      "|    total_timesteps      | 4626432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074583692 |\n",
      "|    clip_fraction        | 0.0337       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.6         |\n",
      "|    n_updates            | 22580        |\n",
      "|    policy_gradient_loss | -0.00622     |\n",
      "|    reward               | 0.1539761    |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2260         |\n",
      "|    time_elapsed         | 41727        |\n",
      "|    total_timesteps      | 4628480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037221103 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.783        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.3         |\n",
      "|    n_updates            | 22590        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | 1.5036427    |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2261        |\n",
      "|    time_elapsed         | 41746       |\n",
      "|    total_timesteps      | 4630528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003454228 |\n",
      "|    clip_fraction        | 0.00488     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 22600       |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    reward               | -3.139916   |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 49.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2262         |\n",
      "|    time_elapsed         | 41764        |\n",
      "|    total_timesteps      | 4632576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055539934 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.789        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.2         |\n",
      "|    n_updates            | 22610        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    reward               | -0.24607907  |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 93.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2263         |\n",
      "|    time_elapsed         | 41783        |\n",
      "|    total_timesteps      | 4634624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007905006  |\n",
      "|    clip_fraction        | 0.0451       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.2         |\n",
      "|    n_updates            | 22620        |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    reward               | -0.085254386 |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 99.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2264         |\n",
      "|    time_elapsed         | 41802        |\n",
      "|    total_timesteps      | 4636672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004115642 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.681        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.3         |\n",
      "|    n_updates            | 22630        |\n",
      "|    policy_gradient_loss | -0.000893    |\n",
      "|    reward               | -2.7617218   |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2265         |\n",
      "|    time_elapsed         | 41822        |\n",
      "|    total_timesteps      | 4638720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049236976 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.9         |\n",
      "|    n_updates            | 22640        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | 4.1229506    |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 41.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2266         |\n",
      "|    time_elapsed         | 41844        |\n",
      "|    total_timesteps      | 4640768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062638074 |\n",
      "|    clip_fraction        | 0.0255       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.6         |\n",
      "|    n_updates            | 22650        |\n",
      "|    policy_gradient_loss | -0.00712     |\n",
      "|    reward               | 0.3062003    |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 95.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2267         |\n",
      "|    time_elapsed         | 41862        |\n",
      "|    total_timesteps      | 4642816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025916824 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.8         |\n",
      "|    n_updates            | 22660        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | 1.5293611    |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2268        |\n",
      "|    time_elapsed         | 41881       |\n",
      "|    total_timesteps      | 4644864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008171461 |\n",
      "|    clip_fraction        | 0.051       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 22670       |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | -1.799541   |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2269        |\n",
      "|    time_elapsed         | 41900       |\n",
      "|    total_timesteps      | 4646912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006418881 |\n",
      "|    clip_fraction        | 0.0247      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60          |\n",
      "|    n_updates            | 22680       |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    reward               | 2.147757    |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 86.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2270          |\n",
      "|    time_elapsed         | 41918         |\n",
      "|    total_timesteps      | 4648960       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027732467 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -111          |\n",
      "|    explained_variance   | 0.764         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 85.1          |\n",
      "|    n_updates            | 22690         |\n",
      "|    policy_gradient_loss | -0.00123      |\n",
      "|    reward               | -5.9193506    |\n",
      "|    std                  | 11.4          |\n",
      "|    value_loss           | 196           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2271         |\n",
      "|    time_elapsed         | 41936        |\n",
      "|    total_timesteps      | 4651008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018942789 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.1         |\n",
      "|    n_updates            | 22700        |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    reward               | -3.1007292   |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 69.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2272        |\n",
      "|    time_elapsed         | 41955       |\n",
      "|    total_timesteps      | 4653056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006702968 |\n",
      "|    clip_fraction        | 0.0446      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.9        |\n",
      "|    n_updates            | 22710       |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | -3.7454612  |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 79          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2900430.62\n",
      "total_reward: 1900430.62\n",
      "total_cost: 189916.94\n",
      "total_trades: 58287\n",
      "Sharpe: 0.494\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2273         |\n",
      "|    time_elapsed         | 41973        |\n",
      "|    total_timesteps      | 4655104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028398195 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.761        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 89.3         |\n",
      "|    n_updates            | 22720        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | 0.6466317    |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 195          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2274          |\n",
      "|    time_elapsed         | 41992         |\n",
      "|    total_timesteps      | 4657152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095808704 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -111          |\n",
      "|    explained_variance   | 0.713         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 68.3          |\n",
      "|    n_updates            | 22730         |\n",
      "|    policy_gradient_loss | -0.00157      |\n",
      "|    reward               | -0.19487883   |\n",
      "|    std                  | 11.4          |\n",
      "|    value_loss           | 166           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2275          |\n",
      "|    time_elapsed         | 42010         |\n",
      "|    total_timesteps      | 4659200       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020403412 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -111          |\n",
      "|    explained_variance   | 0.596         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.8          |\n",
      "|    n_updates            | 22740         |\n",
      "|    policy_gradient_loss | -0.000694     |\n",
      "|    reward               | 0.50015736    |\n",
      "|    std                  | 11.4          |\n",
      "|    value_loss           | 63            |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2276        |\n",
      "|    time_elapsed         | 42029       |\n",
      "|    total_timesteps      | 4661248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004349344 |\n",
      "|    clip_fraction        | 0.013       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.7        |\n",
      "|    n_updates            | 22750       |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    reward               | 2.3753848   |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2277         |\n",
      "|    time_elapsed         | 42047        |\n",
      "|    total_timesteps      | 4663296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010116708 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.821        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.6         |\n",
      "|    n_updates            | 22760        |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    reward               | 6.408182     |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2278         |\n",
      "|    time_elapsed         | 42065        |\n",
      "|    total_timesteps      | 4665344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017461001 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.8         |\n",
      "|    n_updates            | 22770        |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    reward               | 1.8980578    |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 84.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2279        |\n",
      "|    time_elapsed         | 42084       |\n",
      "|    total_timesteps      | 4667392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008457517 |\n",
      "|    clip_fraction        | 0.038       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 22780       |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    reward               | 2.8958848   |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 99.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2280         |\n",
      "|    time_elapsed         | 42102        |\n",
      "|    total_timesteps      | 4669440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061865347 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 22790        |\n",
      "|    policy_gradient_loss | -0.00567     |\n",
      "|    reward               | -0.42613798  |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 85.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2281         |\n",
      "|    time_elapsed         | 42121        |\n",
      "|    total_timesteps      | 4671488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030713687 |\n",
      "|    clip_fraction        | 0.00474      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.6         |\n",
      "|    n_updates            | 22800        |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    reward               | -0.5012405   |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2282        |\n",
      "|    time_elapsed         | 42140       |\n",
      "|    total_timesteps      | 4673536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011554947 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 22810       |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    reward               | 0.18749219  |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2283         |\n",
      "|    time_elapsed         | 42158        |\n",
      "|    total_timesteps      | 4675584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013384924 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.797        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.5         |\n",
      "|    n_updates            | 22820        |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    reward               | 1.681422     |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2284          |\n",
      "|    time_elapsed         | 42177         |\n",
      "|    total_timesteps      | 4677632       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074160047 |\n",
      "|    clip_fraction        | 0.000537      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -111          |\n",
      "|    explained_variance   | 0.759         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 65.7          |\n",
      "|    n_updates            | 22830         |\n",
      "|    policy_gradient_loss | -0.00128      |\n",
      "|    reward               | 4.891798      |\n",
      "|    std                  | 11.5          |\n",
      "|    value_loss           | 115           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2285        |\n",
      "|    time_elapsed         | 42195       |\n",
      "|    total_timesteps      | 4679680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008675486 |\n",
      "|    clip_fraction        | 0.0449      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 22840       |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    reward               | 1.692825    |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2286         |\n",
      "|    time_elapsed         | 42213        |\n",
      "|    total_timesteps      | 4681728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048158253 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.752        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.9         |\n",
      "|    n_updates            | 22850        |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    reward               | -0.06848103  |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 87.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3179441.82\n",
      "total_reward: 2179441.82\n",
      "total_cost: 172273.50\n",
      "total_trades: 57739\n",
      "Sharpe: 0.522\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2287         |\n",
      "|    time_elapsed         | 42231        |\n",
      "|    total_timesteps      | 4683776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005311802  |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.8         |\n",
      "|    n_updates            | 22860        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | -0.045791347 |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 94.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2288        |\n",
      "|    time_elapsed         | 42249       |\n",
      "|    total_timesteps      | 4685824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001042224 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.9        |\n",
      "|    n_updates            | 22870       |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    reward               | 0.1995228   |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2289        |\n",
      "|    time_elapsed         | 42268       |\n",
      "|    total_timesteps      | 4687872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008833678 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 22880       |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | 4.2868214   |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2290         |\n",
      "|    time_elapsed         | 42286        |\n",
      "|    total_timesteps      | 4689920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022789007 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.766        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.6         |\n",
      "|    n_updates            | 22890        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | -0.34550357  |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 93.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2291         |\n",
      "|    time_elapsed         | 42305        |\n",
      "|    total_timesteps      | 4691968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003744637 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.7         |\n",
      "|    n_updates            | 22900        |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    reward               | 3.398628     |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2292        |\n",
      "|    time_elapsed         | 42323       |\n",
      "|    total_timesteps      | 4694016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01007976  |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 22910       |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | -0.10031069 |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 43.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2293        |\n",
      "|    time_elapsed         | 42342       |\n",
      "|    total_timesteps      | 4696064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007630207 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.4        |\n",
      "|    n_updates            | 22920       |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    reward               | -3.989848   |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 81.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2294         |\n",
      "|    time_elapsed         | 42361        |\n",
      "|    total_timesteps      | 4698112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061408565 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59           |\n",
      "|    n_updates            | 22930        |\n",
      "|    policy_gradient_loss | -0.00813     |\n",
      "|    reward               | 7.395832     |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 97.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2295         |\n",
      "|    time_elapsed         | 42379        |\n",
      "|    total_timesteps      | 4700160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010158375 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.361        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.9         |\n",
      "|    n_updates            | 22940        |\n",
      "|    policy_gradient_loss | -0.000653    |\n",
      "|    reward               | -0.23782346  |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 170          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2296         |\n",
      "|    time_elapsed         | 42399        |\n",
      "|    total_timesteps      | 4702208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059966035 |\n",
      "|    clip_fraction        | 0.031        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.805        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.9         |\n",
      "|    n_updates            | 22950        |\n",
      "|    policy_gradient_loss | -0.00752     |\n",
      "|    reward               | -0.7439379   |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 76.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2297        |\n",
      "|    time_elapsed         | 42418       |\n",
      "|    total_timesteps      | 4704256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004949071 |\n",
      "|    clip_fraction        | 0.00825     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 22960       |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    reward               | 0.37109348  |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 195         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2298          |\n",
      "|    time_elapsed         | 42438         |\n",
      "|    total_timesteps      | 4706304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067426334 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -111          |\n",
      "|    explained_variance   | 0.66          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 100           |\n",
      "|    n_updates            | 22970         |\n",
      "|    policy_gradient_loss | -0.000836     |\n",
      "|    reward               | 1.8880607     |\n",
      "|    std                  | 11.7          |\n",
      "|    value_loss           | 130           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2299         |\n",
      "|    time_elapsed         | 42456        |\n",
      "|    total_timesteps      | 4708352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050067496 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.4         |\n",
      "|    n_updates            | 22980        |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    reward               | 1.037806     |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 52.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2300         |\n",
      "|    time_elapsed         | 42475        |\n",
      "|    total_timesteps      | 4710400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013456022 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.8          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.9         |\n",
      "|    n_updates            | 22990        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | 1.0301632    |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2301          |\n",
      "|    time_elapsed         | 42493         |\n",
      "|    total_timesteps      | 4712448       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082494615 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -111          |\n",
      "|    explained_variance   | 0.721         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 36.3          |\n",
      "|    n_updates            | 23000         |\n",
      "|    policy_gradient_loss | -0.00188      |\n",
      "|    reward               | -1.8010331    |\n",
      "|    std                  | 11.7          |\n",
      "|    value_loss           | 107           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3112055.08\n",
      "total_reward: 2112055.08\n",
      "total_cost: 155570.71\n",
      "total_trades: 57285\n",
      "Sharpe: 0.507\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2302         |\n",
      "|    time_elapsed         | 42512        |\n",
      "|    total_timesteps      | 4714496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034137995 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.1         |\n",
      "|    n_updates            | 23010        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    reward               | -0.15654543  |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 58.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2303         |\n",
      "|    time_elapsed         | 42531        |\n",
      "|    total_timesteps      | 4716544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060515935 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82.3         |\n",
      "|    n_updates            | 23020        |\n",
      "|    policy_gradient_loss | -0.00641     |\n",
      "|    reward               | -0.16630216  |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2304         |\n",
      "|    time_elapsed         | 42551        |\n",
      "|    total_timesteps      | 4718592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029766448 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.75         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.1         |\n",
      "|    n_updates            | 23030        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | -0.6346482   |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2305          |\n",
      "|    time_elapsed         | 42569         |\n",
      "|    total_timesteps      | 4720640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.4657164e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -111          |\n",
      "|    explained_variance   | 0.704         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 71.1          |\n",
      "|    n_updates            | 23040         |\n",
      "|    policy_gradient_loss | -0.000301     |\n",
      "|    reward               | 2.982821      |\n",
      "|    std                  | 11.7          |\n",
      "|    value_loss           | 132           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2306        |\n",
      "|    time_elapsed         | 42588       |\n",
      "|    total_timesteps      | 4722688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006968255 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 23050       |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | -0.6156121  |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2307        |\n",
      "|    time_elapsed         | 42607       |\n",
      "|    total_timesteps      | 4724736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008258568 |\n",
      "|    clip_fraction        | 0.0381      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 23060       |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | -1.1462137  |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2308         |\n",
      "|    time_elapsed         | 42626        |\n",
      "|    total_timesteps      | 4726784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051733917 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.5         |\n",
      "|    n_updates            | 23070        |\n",
      "|    policy_gradient_loss | -0.00692     |\n",
      "|    reward               | 3.0896747    |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2309         |\n",
      "|    time_elapsed         | 42644        |\n",
      "|    total_timesteps      | 4728832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024713264 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21           |\n",
      "|    n_updates            | 23080        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | -5.727335    |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 50.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2310         |\n",
      "|    time_elapsed         | 42665        |\n",
      "|    total_timesteps      | 4730880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075958027 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.8          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.4         |\n",
      "|    n_updates            | 23090        |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    reward               | 3.2804854    |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2311        |\n",
      "|    time_elapsed         | 42684       |\n",
      "|    total_timesteps      | 4732928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002264196 |\n",
      "|    clip_fraction        | 0.00146     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 23100       |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    reward               | 20.620201   |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2312         |\n",
      "|    time_elapsed         | 42702        |\n",
      "|    total_timesteps      | 4734976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012826498 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.779        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.3         |\n",
      "|    n_updates            | 23110        |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    reward               | 4.5218744    |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2313         |\n",
      "|    time_elapsed         | 42720        |\n",
      "|    total_timesteps      | 4737024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067166444 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 23120        |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    reward               | 1.088445     |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 46.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2314         |\n",
      "|    time_elapsed         | 42739        |\n",
      "|    total_timesteps      | 4739072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053511052 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.1         |\n",
      "|    n_updates            | 23130        |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    reward               | -3.3988903   |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 96.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2315          |\n",
      "|    time_elapsed         | 42757         |\n",
      "|    total_timesteps      | 4741120       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00078061415 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -112          |\n",
      "|    explained_variance   | 0.649         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 46.2          |\n",
      "|    n_updates            | 23140         |\n",
      "|    policy_gradient_loss | -0.00147      |\n",
      "|    reward               | -1.0474828    |\n",
      "|    std                  | 11.8          |\n",
      "|    value_loss           | 122           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3293034.23\n",
      "total_reward: 2293034.23\n",
      "total_cost: 142157.62\n",
      "total_trades: 56952\n",
      "Sharpe: 0.529\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2316        |\n",
      "|    time_elapsed         | 42776       |\n",
      "|    total_timesteps      | 4743168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012362306 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 23150       |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    reward               | 2.0050848   |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2317        |\n",
      "|    time_elapsed         | 42794       |\n",
      "|    total_timesteps      | 4745216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006471059 |\n",
      "|    clip_fraction        | 0.0189      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.3        |\n",
      "|    n_updates            | 23160       |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | 3.1222541   |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2318        |\n",
      "|    time_elapsed         | 42812       |\n",
      "|    total_timesteps      | 4747264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002489157 |\n",
      "|    clip_fraction        | 0.00161     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54          |\n",
      "|    n_updates            | 23170       |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    reward               | -2.8421416  |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2319         |\n",
      "|    time_elapsed         | 42830        |\n",
      "|    total_timesteps      | 4749312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008945657 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.5         |\n",
      "|    n_updates            | 23180        |\n",
      "|    policy_gradient_loss | -0.00141     |\n",
      "|    reward               | 0.895784     |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 89.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2320        |\n",
      "|    time_elapsed         | 42848       |\n",
      "|    total_timesteps      | 4751360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007727425 |\n",
      "|    clip_fraction        | 0.0378      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.5        |\n",
      "|    n_updates            | 23190       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | 0.03304721  |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2321         |\n",
      "|    time_elapsed         | 42867        |\n",
      "|    total_timesteps      | 4753408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009394721 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.785        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.2         |\n",
      "|    n_updates            | 23200        |\n",
      "|    policy_gradient_loss | -0.000654    |\n",
      "|    reward               | -4.0560846   |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 152          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2322         |\n",
      "|    time_elapsed         | 42885        |\n",
      "|    total_timesteps      | 4755456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015598084 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58           |\n",
      "|    n_updates            | 23210        |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    reward               | -1.6634209   |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2323        |\n",
      "|    time_elapsed         | 42903       |\n",
      "|    total_timesteps      | 4757504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008754997 |\n",
      "|    clip_fraction        | 0.0592      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 23220       |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    reward               | 0.9788413   |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 49          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2324         |\n",
      "|    time_elapsed         | 42921        |\n",
      "|    total_timesteps      | 4759552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017313788 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.1         |\n",
      "|    n_updates            | 23230        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | 0.3408217    |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 128          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2325         |\n",
      "|    time_elapsed         | 42940        |\n",
      "|    total_timesteps      | 4761600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.529301e-05 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.6         |\n",
      "|    n_updates            | 23240        |\n",
      "|    policy_gradient_loss | -0.000731    |\n",
      "|    reward               | 3.8060308    |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 210          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2326         |\n",
      "|    time_elapsed         | 42958        |\n",
      "|    total_timesteps      | 4763648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074557425 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34           |\n",
      "|    n_updates            | 23250        |\n",
      "|    policy_gradient_loss | -0.00719     |\n",
      "|    reward               | 1.4875113    |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 69           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2327        |\n",
      "|    time_elapsed         | 42976       |\n",
      "|    total_timesteps      | 4765696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007550195 |\n",
      "|    clip_fraction        | 0.0191      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.2        |\n",
      "|    n_updates            | 23260       |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    reward               | 0.8546918   |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2328         |\n",
      "|    time_elapsed         | 42994        |\n",
      "|    total_timesteps      | 4767744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006339576 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.827        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.2         |\n",
      "|    n_updates            | 23270        |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    reward               | 0.89230716   |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2329         |\n",
      "|    time_elapsed         | 43013        |\n",
      "|    total_timesteps      | 4769792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015307546 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.783        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 92.2         |\n",
      "|    n_updates            | 23280        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | 1.9839617    |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2796422.33\n",
      "total_reward: 1796422.33\n",
      "total_cost: 159397.14\n",
      "total_trades: 57685\n",
      "Sharpe: 0.477\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2330        |\n",
      "|    time_elapsed         | 43031       |\n",
      "|    total_timesteps      | 4771840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008289708 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 23290       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 4.042211    |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2331        |\n",
      "|    time_elapsed         | 43049       |\n",
      "|    total_timesteps      | 4773888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008281801 |\n",
      "|    clip_fraction        | 0.0492      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.2        |\n",
      "|    n_updates            | 23300       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -1.0553017  |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2332          |\n",
      "|    time_elapsed         | 43067         |\n",
      "|    total_timesteps      | 4775936       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032532698 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -112          |\n",
      "|    explained_variance   | 0.611         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 133           |\n",
      "|    n_updates            | 23310         |\n",
      "|    policy_gradient_loss | -0.000703     |\n",
      "|    reward               | 5.872954      |\n",
      "|    std                  | 12            |\n",
      "|    value_loss           | 136           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2333         |\n",
      "|    time_elapsed         | 43086        |\n",
      "|    total_timesteps      | 4777984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037443694 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.2         |\n",
      "|    n_updates            | 23320        |\n",
      "|    policy_gradient_loss | -0.00134     |\n",
      "|    reward               | 3.4040186    |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 48.3         |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 2334      |\n",
      "|    time_elapsed         | 43105     |\n",
      "|    total_timesteps      | 4780032   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0063282 |\n",
      "|    clip_fraction        | 0.0258    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -112      |\n",
      "|    explained_variance   | 0.776     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 42.4      |\n",
      "|    n_updates            | 23330     |\n",
      "|    policy_gradient_loss | -0.00513  |\n",
      "|    reward               | 0.9474113 |\n",
      "|    std                  | 12        |\n",
      "|    value_loss           | 90.1      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2335         |\n",
      "|    time_elapsed         | 43123        |\n",
      "|    total_timesteps      | 4782080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027906818 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.792        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.3         |\n",
      "|    n_updates            | 23340        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    reward               | 3.2641602    |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2336          |\n",
      "|    time_elapsed         | 43141         |\n",
      "|    total_timesteps      | 4784128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017132473 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -112          |\n",
      "|    explained_variance   | 0.808         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 49.5          |\n",
      "|    n_updates            | 23350         |\n",
      "|    policy_gradient_loss | -0.000743     |\n",
      "|    reward               | -0.4157554    |\n",
      "|    std                  | 12            |\n",
      "|    value_loss           | 155           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2337        |\n",
      "|    time_elapsed         | 43160       |\n",
      "|    total_timesteps      | 4786176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010807278 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.9        |\n",
      "|    n_updates            | 23360       |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    reward               | 0.25361082  |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2338         |\n",
      "|    time_elapsed         | 43178        |\n",
      "|    total_timesteps      | 4788224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057815127 |\n",
      "|    clip_fraction        | 0.0255       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.1         |\n",
      "|    n_updates            | 23370        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | 0.0030464907 |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 97.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2339          |\n",
      "|    time_elapsed         | 43197         |\n",
      "|    total_timesteps      | 4790272       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5807526e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -112          |\n",
      "|    explained_variance   | 0.76          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 67.7          |\n",
      "|    n_updates            | 23380         |\n",
      "|    policy_gradient_loss | -0.000272     |\n",
      "|    reward               | -1.8932402    |\n",
      "|    std                  | 12            |\n",
      "|    value_loss           | 172           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2340         |\n",
      "|    time_elapsed         | 43215        |\n",
      "|    total_timesteps      | 4792320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090411585 |\n",
      "|    clip_fraction        | 0.0639       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 23390        |\n",
      "|    policy_gradient_loss | -0.00695     |\n",
      "|    reward               | -5.756036    |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 54.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2341         |\n",
      "|    time_elapsed         | 43233        |\n",
      "|    total_timesteps      | 4794368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037174616 |\n",
      "|    clip_fraction        | 0.0061       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.464        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.7         |\n",
      "|    n_updates            | 23400        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | -1.5177511   |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2342         |\n",
      "|    time_elapsed         | 43251        |\n",
      "|    total_timesteps      | 4796416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008972351 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.9         |\n",
      "|    n_updates            | 23410        |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    reward               | -0.56406087  |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 97.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2343        |\n",
      "|    time_elapsed         | 43270       |\n",
      "|    total_timesteps      | 4798464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003865461 |\n",
      "|    clip_fraction        | 0.00786     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 23420       |\n",
      "|    policy_gradient_loss | -0.00222    |\n",
      "|    reward               | 1.1846608   |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 59.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3288701.90\n",
      "total_reward: 2288701.90\n",
      "total_cost: 141256.52\n",
      "total_trades: 56434\n",
      "Sharpe: 0.525\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2344        |\n",
      "|    time_elapsed         | 43288       |\n",
      "|    total_timesteps      | 4800512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006673252 |\n",
      "|    clip_fraction        | 0.0318      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.3        |\n",
      "|    n_updates            | 23430       |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | -0.4040104  |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2345         |\n",
      "|    time_elapsed         | 43306        |\n",
      "|    total_timesteps      | 4802560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018897363 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.737        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.9         |\n",
      "|    n_updates            | 23440        |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    reward               | -0.95489603  |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2346         |\n",
      "|    time_elapsed         | 43324        |\n",
      "|    total_timesteps      | 4804608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018173619 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.789        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67           |\n",
      "|    n_updates            | 23450        |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    reward               | -2.7590382   |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2347        |\n",
      "|    time_elapsed         | 43343       |\n",
      "|    total_timesteps      | 4806656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00951408  |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 23460       |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | -0.41069788 |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2348        |\n",
      "|    time_elapsed         | 43362       |\n",
      "|    total_timesteps      | 4808704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004291895 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58          |\n",
      "|    n_updates            | 23470       |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    reward               | -4.1156483  |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2349        |\n",
      "|    time_elapsed         | 43381       |\n",
      "|    total_timesteps      | 4810752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003151084 |\n",
      "|    clip_fraction        | 0.00171     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.1        |\n",
      "|    n_updates            | 23480       |\n",
      "|    policy_gradient_loss | -0.00366    |\n",
      "|    reward               | 3.3001497   |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2350        |\n",
      "|    time_elapsed         | 43400       |\n",
      "|    total_timesteps      | 4812800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003318652 |\n",
      "|    clip_fraction        | 0.00508     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.7        |\n",
      "|    n_updates            | 23490       |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    reward               | -3.5570033  |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 64.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2351         |\n",
      "|    time_elapsed         | 43419        |\n",
      "|    total_timesteps      | 4814848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052660406 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.7         |\n",
      "|    n_updates            | 23500        |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    reward               | -0.6066408   |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2352        |\n",
      "|    time_elapsed         | 43438       |\n",
      "|    total_timesteps      | 4816896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007884179 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 23510       |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    reward               | 1.0117478   |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2353         |\n",
      "|    time_elapsed         | 43457        |\n",
      "|    total_timesteps      | 4818944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003042188 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.3         |\n",
      "|    n_updates            | 23520        |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    reward               | 0.008830641  |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2354       |\n",
      "|    time_elapsed         | 43476      |\n",
      "|    total_timesteps      | 4820992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00943009 |\n",
      "|    clip_fraction        | 0.0744     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -113       |\n",
      "|    explained_variance   | 0.669      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.5       |\n",
      "|    n_updates            | 23530      |\n",
      "|    policy_gradient_loss | -0.00702   |\n",
      "|    reward               | 0.99699455 |\n",
      "|    std                  | 12.2       |\n",
      "|    value_loss           | 43         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2355         |\n",
      "|    time_elapsed         | 43495        |\n",
      "|    total_timesteps      | 4823040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025099176 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.762        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.8         |\n",
      "|    n_updates            | 23540        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | 0.0047772494 |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 94.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2356         |\n",
      "|    time_elapsed         | 43514        |\n",
      "|    total_timesteps      | 4825088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023634594 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.4         |\n",
      "|    n_updates            | 23550        |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    reward               | -1.837321    |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2357        |\n",
      "|    time_elapsed         | 43533       |\n",
      "|    total_timesteps      | 4827136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005342587 |\n",
      "|    clip_fraction        | 0.00889     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 23560       |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    reward               | -0.74095225 |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 54          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3323485.29\n",
      "total_reward: 2323485.29\n",
      "total_cost: 160952.54\n",
      "total_trades: 57813\n",
      "Sharpe: 0.539\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2358         |\n",
      "|    time_elapsed         | 43553        |\n",
      "|    total_timesteps      | 4829184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028951778 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.2         |\n",
      "|    n_updates            | 23570        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | 1.4620159    |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 93.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2359        |\n",
      "|    time_elapsed         | 43572       |\n",
      "|    total_timesteps      | 4831232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001435717 |\n",
      "|    clip_fraction        | 0.000537    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.3        |\n",
      "|    n_updates            | 23580       |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    reward               | -26.505383  |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2360         |\n",
      "|    time_elapsed         | 43591        |\n",
      "|    total_timesteps      | 4833280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007979756 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.818        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.1         |\n",
      "|    n_updates            | 23590        |\n",
      "|    policy_gradient_loss | -0.000505    |\n",
      "|    reward               | -1.5593803   |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2361         |\n",
      "|    time_elapsed         | 43610        |\n",
      "|    total_timesteps      | 4835328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017795563 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.5         |\n",
      "|    n_updates            | 23600        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | -4.074713    |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 73.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2362         |\n",
      "|    time_elapsed         | 43630        |\n",
      "|    total_timesteps      | 4837376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017569753 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 23610        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | -1.025933    |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2363         |\n",
      "|    time_elapsed         | 43649        |\n",
      "|    total_timesteps      | 4839424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038043857 |\n",
      "|    clip_fraction        | 0.00894      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.3         |\n",
      "|    n_updates            | 23620        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    reward               | 2.6462584    |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2364         |\n",
      "|    time_elapsed         | 43669        |\n",
      "|    total_timesteps      | 4841472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068528326 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.6         |\n",
      "|    n_updates            | 23630        |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    reward               | -0.4508199   |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 54.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2365         |\n",
      "|    time_elapsed         | 43688        |\n",
      "|    total_timesteps      | 4843520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034464537 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.85         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.4         |\n",
      "|    n_updates            | 23640        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    reward               | 1.9218731    |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2366          |\n",
      "|    time_elapsed         | 43706         |\n",
      "|    total_timesteps      | 4845568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028288524 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -113          |\n",
      "|    explained_variance   | 0.8           |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 56.5          |\n",
      "|    n_updates            | 23650         |\n",
      "|    policy_gradient_loss | -0.00117      |\n",
      "|    reward               | 7.7528453     |\n",
      "|    std                  | 12.4          |\n",
      "|    value_loss           | 164           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2367         |\n",
      "|    time_elapsed         | 43725        |\n",
      "|    total_timesteps      | 4847616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012465676 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.9         |\n",
      "|    n_updates            | 23660        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | 0.009430299  |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 64.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2368        |\n",
      "|    time_elapsed         | 43745       |\n",
      "|    total_timesteps      | 4849664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010254287 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 23670       |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    reward               | 1.8589154   |\n",
      "|    std                  | 12.4        |\n",
      "|    value_loss           | 89.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2369         |\n",
      "|    time_elapsed         | 43764        |\n",
      "|    total_timesteps      | 4851712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031435797 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.795        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.8         |\n",
      "|    n_updates            | 23680        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    reward               | -0.8835816   |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2370         |\n",
      "|    time_elapsed         | 43782        |\n",
      "|    total_timesteps      | 4853760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013117892 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.2         |\n",
      "|    n_updates            | 23690        |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | 2.82757      |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2371         |\n",
      "|    time_elapsed         | 43801        |\n",
      "|    total_timesteps      | 4855808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077507556 |\n",
      "|    clip_fraction        | 0.0383       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 23700        |\n",
      "|    policy_gradient_loss | -0.00718     |\n",
      "|    reward               | 2.2715423    |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 52.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3360415.66\n",
      "total_reward: 2360415.66\n",
      "total_cost: 155364.65\n",
      "total_trades: 57667\n",
      "Sharpe: 0.540\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2372        |\n",
      "|    time_elapsed         | 43820       |\n",
      "|    total_timesteps      | 4857856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007698681 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.4        |\n",
      "|    n_updates            | 23710       |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | 0.066748396 |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2373        |\n",
      "|    time_elapsed         | 43838       |\n",
      "|    total_timesteps      | 4859904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 8.10019e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 23720       |\n",
      "|    policy_gradient_loss | -0.000311   |\n",
      "|    reward               | 0.22894336  |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2374          |\n",
      "|    time_elapsed         | 43857         |\n",
      "|    total_timesteps      | 4861952       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6604226e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -113          |\n",
      "|    explained_variance   | 0.375         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 39.3          |\n",
      "|    n_updates            | 23730         |\n",
      "|    policy_gradient_loss | -0.000305     |\n",
      "|    reward               | -1.4064502    |\n",
      "|    std                  | 12.5          |\n",
      "|    value_loss           | 95.8          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2375        |\n",
      "|    time_elapsed         | 43877       |\n",
      "|    total_timesteps      | 4864000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005182992 |\n",
      "|    clip_fraction        | 0.0112      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85          |\n",
      "|    n_updates            | 23740       |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    reward               | 4.0905805   |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2376         |\n",
      "|    time_elapsed         | 43897        |\n",
      "|    total_timesteps      | 4866048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003152434 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.5         |\n",
      "|    n_updates            | 23750        |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    reward               | 0.0035266287 |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2377         |\n",
      "|    time_elapsed         | 43915        |\n",
      "|    total_timesteps      | 4868096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020627053 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.766        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.5         |\n",
      "|    n_updates            | 23760        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    reward               | 1.121416     |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2378        |\n",
      "|    time_elapsed         | 43934       |\n",
      "|    total_timesteps      | 4870144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012090674 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 23770       |\n",
      "|    policy_gradient_loss | -0.00881    |\n",
      "|    reward               | 1.3012134   |\n",
      "|    std                  | 12.6        |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2379         |\n",
      "|    time_elapsed         | 43954        |\n",
      "|    total_timesteps      | 4872192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017287189 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.5         |\n",
      "|    n_updates            | 23780        |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    reward               | 1.1713724    |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2380         |\n",
      "|    time_elapsed         | 43972        |\n",
      "|    total_timesteps      | 4874240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014366322 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.3         |\n",
      "|    n_updates            | 23790        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | 1.289084     |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2381        |\n",
      "|    time_elapsed         | 43991       |\n",
      "|    total_timesteps      | 4876288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009291805 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 23800       |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    reward               | -0.13306786 |\n",
      "|    std                  | 12.6        |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2382        |\n",
      "|    time_elapsed         | 44009       |\n",
      "|    total_timesteps      | 4878336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007140837 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.6        |\n",
      "|    n_updates            | 23810       |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    reward               | -0.7619562  |\n",
      "|    std                  | 12.6        |\n",
      "|    value_loss           | 98.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2383        |\n",
      "|    time_elapsed         | 44028       |\n",
      "|    total_timesteps      | 4880384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004224321 |\n",
      "|    clip_fraction        | 0.00513     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.9        |\n",
      "|    n_updates            | 23820       |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | -2.3635428  |\n",
      "|    std                  | 12.6        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2384         |\n",
      "|    time_elapsed         | 44046        |\n",
      "|    total_timesteps      | 4882432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.355866e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.6         |\n",
      "|    n_updates            | 23830        |\n",
      "|    policy_gradient_loss | -0.00054     |\n",
      "|    reward               | 1.1976187    |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2385         |\n",
      "|    time_elapsed         | 44065        |\n",
      "|    total_timesteps      | 4884480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032616057 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.9         |\n",
      "|    n_updates            | 23840        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    reward               | -0.7137053   |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 87.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3049578.52\n",
      "total_reward: 2049578.52\n",
      "total_cost: 136681.71\n",
      "total_trades: 56275\n",
      "Sharpe: 0.503\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2386         |\n",
      "|    time_elapsed         | 44083        |\n",
      "|    total_timesteps      | 4886528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026092161 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.7         |\n",
      "|    n_updates            | 23850        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    reward               | -1.2899661   |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 94.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2387          |\n",
      "|    time_elapsed         | 44102         |\n",
      "|    total_timesteps      | 4888576       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033154857 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -114          |\n",
      "|    explained_variance   | 0.807         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 76.7          |\n",
      "|    n_updates            | 23860         |\n",
      "|    policy_gradient_loss | -0.000708     |\n",
      "|    reward               | 0.9791916     |\n",
      "|    std                  | 12.7          |\n",
      "|    value_loss           | 121           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2388        |\n",
      "|    time_elapsed         | 44121       |\n",
      "|    total_timesteps      | 4890624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011006689 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 23870       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -6.354445   |\n",
      "|    std                  | 12.7        |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2389        |\n",
      "|    time_elapsed         | 44139       |\n",
      "|    total_timesteps      | 4892672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000499177 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 23880       |\n",
      "|    policy_gradient_loss | -0.000852   |\n",
      "|    reward               | -2.003046   |\n",
      "|    std                  | 12.7        |\n",
      "|    value_loss           | 93.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2390          |\n",
      "|    time_elapsed         | 44158         |\n",
      "|    total_timesteps      | 4894720       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043193746 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -114          |\n",
      "|    explained_variance   | 0.782         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 75.5          |\n",
      "|    n_updates            | 23890         |\n",
      "|    policy_gradient_loss | -0.0011       |\n",
      "|    reward               | -2.8173006    |\n",
      "|    std                  | 12.7          |\n",
      "|    value_loss           | 146           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2391        |\n",
      "|    time_elapsed         | 44177       |\n",
      "|    total_timesteps      | 4896768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008880467 |\n",
      "|    clip_fraction        | 0.0494      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.2        |\n",
      "|    n_updates            | 23900       |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | 1.621376    |\n",
      "|    std                  | 12.7        |\n",
      "|    value_loss           | 76.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2392        |\n",
      "|    time_elapsed         | 44195       |\n",
      "|    total_timesteps      | 4898816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003980452 |\n",
      "|    clip_fraction        | 0.00522     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.6        |\n",
      "|    n_updates            | 23910       |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    reward               | -0.5171765  |\n",
      "|    std                  | 12.7        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2393         |\n",
      "|    time_elapsed         | 44214        |\n",
      "|    total_timesteps      | 4900864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038604112 |\n",
      "|    clip_fraction        | 0.00776      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.2         |\n",
      "|    n_updates            | 23920        |\n",
      "|    policy_gradient_loss | -0.00802     |\n",
      "|    reward               | 0.8547398    |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2394          |\n",
      "|    time_elapsed         | 44233         |\n",
      "|    total_timesteps      | 4902912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037891598 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -114          |\n",
      "|    explained_variance   | 0.803         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 57.4          |\n",
      "|    n_updates            | 23930         |\n",
      "|    policy_gradient_loss | -0.000447     |\n",
      "|    reward               | 2.0024056     |\n",
      "|    std                  | 12.7          |\n",
      "|    value_loss           | 164           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2395        |\n",
      "|    time_elapsed         | 44251       |\n",
      "|    total_timesteps      | 4904960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009797844 |\n",
      "|    clip_fraction        | 0.0848      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 23940       |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    reward               | 6.93356     |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2396         |\n",
      "|    time_elapsed         | 44270        |\n",
      "|    total_timesteps      | 4907008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018776366 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.2         |\n",
      "|    n_updates            | 23950        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | 0.5240011    |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 123          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2397          |\n",
      "|    time_elapsed         | 44288         |\n",
      "|    total_timesteps      | 4909056       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022818719 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -114          |\n",
      "|    explained_variance   | 0.784         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 42.4          |\n",
      "|    n_updates            | 23960         |\n",
      "|    policy_gradient_loss | -0.000449     |\n",
      "|    reward               | 3.243834      |\n",
      "|    std                  | 12.8          |\n",
      "|    value_loss           | 143           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2398          |\n",
      "|    time_elapsed         | 44307         |\n",
      "|    total_timesteps      | 4911104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063133345 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -114          |\n",
      "|    explained_variance   | 0.634         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 33.2          |\n",
      "|    n_updates            | 23970         |\n",
      "|    policy_gradient_loss | -0.00195      |\n",
      "|    reward               | 0.5234219     |\n",
      "|    std                  | 12.8          |\n",
      "|    value_loss           | 64.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2399         |\n",
      "|    time_elapsed         | 44326        |\n",
      "|    total_timesteps      | 4913152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047107763 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.814        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.6         |\n",
      "|    n_updates            | 23980        |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    reward               | 2.0055606    |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2400          |\n",
      "|    time_elapsed         | 44344         |\n",
      "|    total_timesteps      | 4915200       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069437415 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -114          |\n",
      "|    explained_variance   | 0.761         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 75.5          |\n",
      "|    n_updates            | 23990         |\n",
      "|    policy_gradient_loss | 0.000173      |\n",
      "|    reward               | -5.385016     |\n",
      "|    std                  | 12.8          |\n",
      "|    value_loss           | 131           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3557571.41\n",
      "total_reward: 2557571.41\n",
      "total_cost: 136381.15\n",
      "total_trades: 55502\n",
      "Sharpe: 0.551\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2401         |\n",
      "|    time_elapsed         | 44363        |\n",
      "|    total_timesteps      | 4917248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007707428 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.7         |\n",
      "|    n_updates            | 24000        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    reward               | 0.9896456    |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2402        |\n",
      "|    time_elapsed         | 44383       |\n",
      "|    total_timesteps      | 4919296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012226023 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 24010       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -1.711503   |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2403        |\n",
      "|    time_elapsed         | 44402       |\n",
      "|    total_timesteps      | 4921344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003841162 |\n",
      "|    clip_fraction        | 0.0063      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.8        |\n",
      "|    n_updates            | 24020       |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    reward               | -1.3730104  |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2404         |\n",
      "|    time_elapsed         | 44421        |\n",
      "|    total_timesteps      | 4923392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.304771e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.4         |\n",
      "|    n_updates            | 24030        |\n",
      "|    policy_gradient_loss | -0.000355    |\n",
      "|    reward               | 0.59929675   |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 195          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2405         |\n",
      "|    time_elapsed         | 44439        |\n",
      "|    total_timesteps      | 4925440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021301904 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.8         |\n",
      "|    n_updates            | 24040        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | 0.63281506   |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 59.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2406        |\n",
      "|    time_elapsed         | 44459       |\n",
      "|    total_timesteps      | 4927488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002148868 |\n",
      "|    clip_fraction        | 0.000781    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 24050       |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    reward               | -2.2544572  |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2407          |\n",
      "|    time_elapsed         | 44477         |\n",
      "|    total_timesteps      | 4929536       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033090124 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -114          |\n",
      "|    explained_variance   | 0.753         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 46.8          |\n",
      "|    n_updates            | 24060         |\n",
      "|    policy_gradient_loss | -0.000873     |\n",
      "|    reward               | -3.7184167    |\n",
      "|    std                  | 12.9          |\n",
      "|    value_loss           | 131           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2408         |\n",
      "|    time_elapsed         | 44496        |\n",
      "|    total_timesteps      | 4931584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012020178 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.4         |\n",
      "|    n_updates            | 24070        |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    reward               | 0.63565123   |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 73.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2409         |\n",
      "|    time_elapsed         | 44515        |\n",
      "|    total_timesteps      | 4933632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050285757 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.9         |\n",
      "|    n_updates            | 24080        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | 0.9838919    |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2410          |\n",
      "|    time_elapsed         | 44534         |\n",
      "|    total_timesteps      | 4935680       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043016634 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -114          |\n",
      "|    explained_variance   | 0.744         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 142           |\n",
      "|    n_updates            | 24090         |\n",
      "|    policy_gradient_loss | -0.00103      |\n",
      "|    reward               | 0.17758213    |\n",
      "|    std                  | 13            |\n",
      "|    value_loss           | 182           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2411          |\n",
      "|    time_elapsed         | 44553         |\n",
      "|    total_timesteps      | 4937728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033800895 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -114          |\n",
      "|    explained_variance   | 0.726         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 62.2          |\n",
      "|    n_updates            | 24100         |\n",
      "|    policy_gradient_loss | -0.000871     |\n",
      "|    reward               | 1.1390135     |\n",
      "|    std                  | 13            |\n",
      "|    value_loss           | 156           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2412        |\n",
      "|    time_elapsed         | 44572       |\n",
      "|    total_timesteps      | 4939776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008248888 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 24110       |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    reward               | 0.3914722   |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 43          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2413         |\n",
      "|    time_elapsed         | 44590        |\n",
      "|    total_timesteps      | 4941824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025326288 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.798        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.2         |\n",
      "|    n_updates            | 24120        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | 0.5518465    |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2414         |\n",
      "|    time_elapsed         | 44608        |\n",
      "|    total_timesteps      | 4943872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021056077 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.2         |\n",
      "|    n_updates            | 24130        |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    reward               | -0.5917703   |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3294270.77\n",
      "total_reward: 2294270.77\n",
      "total_cost: 142098.55\n",
      "total_trades: 56817\n",
      "Sharpe: 0.532\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2415         |\n",
      "|    time_elapsed         | 44626        |\n",
      "|    total_timesteps      | 4945920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010459434 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.5         |\n",
      "|    n_updates            | 24140        |\n",
      "|    policy_gradient_loss | -0.00149     |\n",
      "|    reward               | 1.0207068    |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 65.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2416        |\n",
      "|    time_elapsed         | 44645       |\n",
      "|    total_timesteps      | 4947968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006947372 |\n",
      "|    clip_fraction        | 0.0356      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 24150       |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    reward               | -1.4676073  |\n",
      "|    std                  | 13          |\n",
      "|    value_loss           | 96.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2417        |\n",
      "|    time_elapsed         | 44664       |\n",
      "|    total_timesteps      | 4950016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001143882 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.7        |\n",
      "|    n_updates            | 24160       |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    reward               | 3.1266587   |\n",
      "|    std                  | 13          |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2418         |\n",
      "|    time_elapsed         | 44682        |\n",
      "|    total_timesteps      | 4952064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015823597 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.4         |\n",
      "|    n_updates            | 24170        |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    reward               | -3.8497999   |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2419        |\n",
      "|    time_elapsed         | 44702       |\n",
      "|    total_timesteps      | 4954112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011593292 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 24180       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 1.7293031   |\n",
      "|    std                  | 13          |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2420         |\n",
      "|    time_elapsed         | 44720        |\n",
      "|    total_timesteps      | 4956160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017446539 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.8         |\n",
      "|    n_updates            | 24190        |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    reward               | 1.0590056    |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2421          |\n",
      "|    time_elapsed         | 44738         |\n",
      "|    total_timesteps      | 4958208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039633748 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -114          |\n",
      "|    explained_variance   | 0.784         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 52.9          |\n",
      "|    n_updates            | 24200         |\n",
      "|    policy_gradient_loss | -0.000581     |\n",
      "|    reward               | 1.7139152     |\n",
      "|    std                  | 13            |\n",
      "|    value_loss           | 121           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2422         |\n",
      "|    time_elapsed         | 44757        |\n",
      "|    total_timesteps      | 4960256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016118705 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.5         |\n",
      "|    n_updates            | 24210        |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    reward               | 1.4523857    |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 80.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2423        |\n",
      "|    time_elapsed         | 44775       |\n",
      "|    total_timesteps      | 4962304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007251183 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 24220       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | -1.6002917  |\n",
      "|    std                  | 13.1        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2424          |\n",
      "|    time_elapsed         | 44793         |\n",
      "|    total_timesteps      | 4964352       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00057367794 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -115          |\n",
      "|    explained_variance   | 0.36          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 128           |\n",
      "|    n_updates            | 24230         |\n",
      "|    policy_gradient_loss | -0.00107      |\n",
      "|    reward               | -14.644096    |\n",
      "|    std                  | 13.1          |\n",
      "|    value_loss           | 198           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2425         |\n",
      "|    time_elapsed         | 44812        |\n",
      "|    total_timesteps      | 4966400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004362155 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.464        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.7         |\n",
      "|    n_updates            | 24240        |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    reward               | -1.3472606   |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 170          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2426        |\n",
      "|    time_elapsed         | 44831       |\n",
      "|    total_timesteps      | 4968448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006237614 |\n",
      "|    clip_fraction        | 0.0245      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40          |\n",
      "|    n_updates            | 24250       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | 1.368121    |\n",
      "|    std                  | 13.1        |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2427        |\n",
      "|    time_elapsed         | 44849       |\n",
      "|    total_timesteps      | 4970496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006498856 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 24260       |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | 0.52487344  |\n",
      "|    std                  | 13.1        |\n",
      "|    value_loss           | 76          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2428         |\n",
      "|    time_elapsed         | 44868        |\n",
      "|    total_timesteps      | 4972544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007844227 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.7         |\n",
      "|    n_updates            | 24270        |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    reward               | 3.9603817    |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 174          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3150293.76\n",
      "total_reward: 2150293.76\n",
      "total_cost: 136826.10\n",
      "total_trades: 56692\n",
      "Sharpe: 0.516\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2429         |\n",
      "|    time_elapsed         | 44887        |\n",
      "|    total_timesteps      | 4974592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062582716 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 24280        |\n",
      "|    policy_gradient_loss | -0.00524     |\n",
      "|    reward               | -2.4517193   |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 47.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2430        |\n",
      "|    time_elapsed         | 44906       |\n",
      "|    total_timesteps      | 4976640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005580709 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52          |\n",
      "|    n_updates            | 24290       |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    reward               | 1.3774191   |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 95.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2431         |\n",
      "|    time_elapsed         | 44924        |\n",
      "|    total_timesteps      | 4978688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044356147 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.2         |\n",
      "|    n_updates            | 24300        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    reward               | 1.6614631    |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2432          |\n",
      "|    time_elapsed         | 44943         |\n",
      "|    total_timesteps      | 4980736       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00080497377 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -115          |\n",
      "|    explained_variance   | 0.697         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 51.6          |\n",
      "|    n_updates            | 24310         |\n",
      "|    policy_gradient_loss | -0.00184      |\n",
      "|    reward               | -7.360319     |\n",
      "|    std                  | 13.2          |\n",
      "|    value_loss           | 71.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2433         |\n",
      "|    time_elapsed         | 44962        |\n",
      "|    total_timesteps      | 4982784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064583234 |\n",
      "|    clip_fraction        | 0.0305       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.8         |\n",
      "|    n_updates            | 24320        |\n",
      "|    policy_gradient_loss | -0.00779     |\n",
      "|    reward               | 1.3436689    |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2434          |\n",
      "|    time_elapsed         | 44981         |\n",
      "|    total_timesteps      | 4984832       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025016745 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -115          |\n",
      "|    explained_variance   | 0.646         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 49.8          |\n",
      "|    n_updates            | 24330         |\n",
      "|    policy_gradient_loss | -0.000716     |\n",
      "|    reward               | 0.608405      |\n",
      "|    std                  | 13.3          |\n",
      "|    value_loss           | 135           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2435          |\n",
      "|    time_elapsed         | 44999         |\n",
      "|    total_timesteps      | 4986880       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2496377e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -115          |\n",
      "|    explained_variance   | 0.672         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 44.6          |\n",
      "|    n_updates            | 24340         |\n",
      "|    policy_gradient_loss | -0.00052      |\n",
      "|    reward               | -0.015594041  |\n",
      "|    std                  | 13.3          |\n",
      "|    value_loss           | 125           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2436        |\n",
      "|    time_elapsed         | 45018       |\n",
      "|    total_timesteps      | 4988928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004979247 |\n",
      "|    clip_fraction        | 0.00874     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 24350       |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    reward               | 1.504902    |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2437         |\n",
      "|    time_elapsed         | 45036        |\n",
      "|    total_timesteps      | 4990976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022161715 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.3         |\n",
      "|    n_updates            | 24360        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | 1.3921672    |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 94.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2438        |\n",
      "|    time_elapsed         | 45055       |\n",
      "|    total_timesteps      | 4993024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002649321 |\n",
      "|    clip_fraction        | 0.00171     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.3        |\n",
      "|    n_updates            | 24370       |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    reward               | 0.72600347  |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2439        |\n",
      "|    time_elapsed         | 45073       |\n",
      "|    total_timesteps      | 4995072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005140899 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 24380       |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    reward               | 1.761184    |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 66.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2440        |\n",
      "|    time_elapsed         | 45092       |\n",
      "|    total_timesteps      | 4997120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005919203 |\n",
      "|    clip_fraction        | 0.0158      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.4        |\n",
      "|    n_updates            | 24390       |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    reward               | -1.4018642  |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 92.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2441        |\n",
      "|    time_elapsed         | 45110       |\n",
      "|    total_timesteps      | 4999168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007601396 |\n",
      "|    clip_fraction        | 0.0351      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67          |\n",
      "|    n_updates            | 24400       |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    reward               | -0.60313064 |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2442          |\n",
      "|    time_elapsed         | 45130         |\n",
      "|    total_timesteps      | 5001216       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037901034 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -115          |\n",
      "|    explained_variance   | 0.778         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 45.5          |\n",
      "|    n_updates            | 24410         |\n",
      "|    policy_gradient_loss | -0.000665     |\n",
      "|    reward               | -0.2552523    |\n",
      "|    std                  | 13.4          |\n",
      "|    value_loss           | 148           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3516975.98\n",
      "total_reward: 2516975.98\n",
      "total_cost: 139011.45\n",
      "total_trades: 56958\n",
      "Sharpe: 0.545\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2443         |\n",
      "|    time_elapsed         | 45149        |\n",
      "|    total_timesteps      | 5003264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078051165 |\n",
      "|    clip_fraction        | 0.0586       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.5         |\n",
      "|    n_updates            | 24420        |\n",
      "|    policy_gradient_loss | -0.00757     |\n",
      "|    reward               | 3.4657824    |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 51.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2444        |\n",
      "|    time_elapsed         | 45167       |\n",
      "|    total_timesteps      | 5005312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004280322 |\n",
      "|    clip_fraction        | 0.00967     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.2        |\n",
      "|    n_updates            | 24430       |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | -2.503378   |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2445        |\n",
      "|    time_elapsed         | 45186       |\n",
      "|    total_timesteps      | 5007360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 5.73773e-05 |\n",
      "|    clip_fraction        | 0.000244    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.7        |\n",
      "|    n_updates            | 24440       |\n",
      "|    policy_gradient_loss | -0.000353   |\n",
      "|    reward               | -7.0014834  |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2446          |\n",
      "|    time_elapsed         | 45205         |\n",
      "|    total_timesteps      | 5009408       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073018135 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -115          |\n",
      "|    explained_variance   | 0.532         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 34.2          |\n",
      "|    n_updates            | 24450         |\n",
      "|    policy_gradient_loss | -0.000997     |\n",
      "|    reward               | 1.4060067     |\n",
      "|    std                  | 13.4          |\n",
      "|    value_loss           | 91.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2447         |\n",
      "|    time_elapsed         | 45223        |\n",
      "|    total_timesteps      | 5011456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021678791 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.7         |\n",
      "|    n_updates            | 24460        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | 0.34824926   |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 98.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2448        |\n",
      "|    time_elapsed         | 45242       |\n",
      "|    total_timesteps      | 5013504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002308588 |\n",
      "|    clip_fraction        | 0.00112     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.5        |\n",
      "|    n_updates            | 24470       |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    reward               | 5.5047574   |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2449         |\n",
      "|    time_elapsed         | 45260        |\n",
      "|    total_timesteps      | 5015552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022926566 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.2         |\n",
      "|    n_updates            | 24480        |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    reward               | -2.229279    |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 99.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2450         |\n",
      "|    time_elapsed         | 45279        |\n",
      "|    total_timesteps      | 5017600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052046226 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.9         |\n",
      "|    n_updates            | 24490        |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    reward               | 3.9677804    |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 55.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2451         |\n",
      "|    time_elapsed         | 45297        |\n",
      "|    total_timesteps      | 5019648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061611454 |\n",
      "|    clip_fraction        | 0.031        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.785        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.2         |\n",
      "|    n_updates            | 24500        |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    reward               | 0.67533857   |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2452          |\n",
      "|    time_elapsed         | 45315         |\n",
      "|    total_timesteps      | 5021696       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050587207 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -115          |\n",
      "|    explained_variance   | 0.699         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 31            |\n",
      "|    n_updates            | 24510         |\n",
      "|    policy_gradient_loss | -0.00128      |\n",
      "|    reward               | -0.49169898   |\n",
      "|    std                  | 13.5          |\n",
      "|    value_loss           | 99.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2453         |\n",
      "|    time_elapsed         | 45333        |\n",
      "|    total_timesteps      | 5023744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036105937 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 24520        |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    reward               | 1.2883651    |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 38.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2454        |\n",
      "|    time_elapsed         | 45351       |\n",
      "|    total_timesteps      | 5025792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004723929 |\n",
      "|    clip_fraction        | 0.00864     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52          |\n",
      "|    n_updates            | 24530       |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    reward               | -0.21230398 |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 84.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2455         |\n",
      "|    time_elapsed         | 45369        |\n",
      "|    total_timesteps      | 5027840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048370236 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.1         |\n",
      "|    n_updates            | 24540        |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    reward               | -0.251391    |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 88.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2456          |\n",
      "|    time_elapsed         | 45387         |\n",
      "|    total_timesteps      | 5029888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015118803 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -116          |\n",
      "|    explained_variance   | 0.661         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 46.7          |\n",
      "|    n_updates            | 24550         |\n",
      "|    policy_gradient_loss | -0.000988     |\n",
      "|    reward               | -0.098607235  |\n",
      "|    std                  | 13.6          |\n",
      "|    value_loss           | 73.5          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2968941.02\n",
      "total_reward: 1968941.02\n",
      "total_cost: 137900.85\n",
      "total_trades: 56970\n",
      "Sharpe: 0.492\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2457        |\n",
      "|    time_elapsed         | 45406       |\n",
      "|    total_timesteps      | 5031936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006066536 |\n",
      "|    clip_fraction        | 0.0452      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 24560       |\n",
      "|    policy_gradient_loss | -0.00818    |\n",
      "|    reward               | 0.7119412   |\n",
      "|    std                  | 13.6        |\n",
      "|    value_loss           | 72.4        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2458          |\n",
      "|    time_elapsed         | 45424         |\n",
      "|    total_timesteps      | 5033984       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011813184 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -116          |\n",
      "|    explained_variance   | 0.783         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 68.3          |\n",
      "|    n_updates            | 24570         |\n",
      "|    policy_gradient_loss | -0.000737     |\n",
      "|    reward               | 0.63654       |\n",
      "|    std                  | 13.6          |\n",
      "|    value_loss           | 110           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2459          |\n",
      "|    time_elapsed         | 45443         |\n",
      "|    total_timesteps      | 5036032       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027258528 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -116          |\n",
      "|    explained_variance   | 0.705         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 91.3          |\n",
      "|    n_updates            | 24580         |\n",
      "|    policy_gradient_loss | -0.000841     |\n",
      "|    reward               | -2.9805882    |\n",
      "|    std                  | 13.6          |\n",
      "|    value_loss           | 123           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2460        |\n",
      "|    time_elapsed         | 45462       |\n",
      "|    total_timesteps      | 5038080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007953645 |\n",
      "|    clip_fraction        | 0.0502      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 24590       |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    reward               | -0.7961364  |\n",
      "|    std                  | 13.6        |\n",
      "|    value_loss           | 48.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2461          |\n",
      "|    time_elapsed         | 45481         |\n",
      "|    total_timesteps      | 5040128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073700305 |\n",
      "|    clip_fraction        | 0.000928      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -116          |\n",
      "|    explained_variance   | 0.793         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 35            |\n",
      "|    n_updates            | 24600         |\n",
      "|    policy_gradient_loss | -0.00181      |\n",
      "|    reward               | -1.9574459    |\n",
      "|    std                  | 13.6          |\n",
      "|    value_loss           | 99.9          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2462         |\n",
      "|    time_elapsed         | 45499        |\n",
      "|    total_timesteps      | 5042176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057999045 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.2         |\n",
      "|    n_updates            | 24610        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | 3.480811     |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2463        |\n",
      "|    time_elapsed         | 45518       |\n",
      "|    total_timesteps      | 5044224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008669902 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 24620       |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    reward               | -2.9296863  |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 74.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2464        |\n",
      "|    time_elapsed         | 45537       |\n",
      "|    total_timesteps      | 5046272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005861515 |\n",
      "|    clip_fraction        | 0.0246      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.4        |\n",
      "|    n_updates            | 24630       |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    reward               | 4.074179    |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2465         |\n",
      "|    time_elapsed         | 45555        |\n",
      "|    total_timesteps      | 5048320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017830324 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.9         |\n",
      "|    n_updates            | 24640        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | 1.3644742    |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2466          |\n",
      "|    time_elapsed         | 45574         |\n",
      "|    total_timesteps      | 5050368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061287195 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -116          |\n",
      "|    explained_variance   | 0.76          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 55.4          |\n",
      "|    n_updates            | 24650         |\n",
      "|    policy_gradient_loss | -0.0011       |\n",
      "|    reward               | -1.8931996    |\n",
      "|    std                  | 13.7          |\n",
      "|    value_loss           | 120           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2467         |\n",
      "|    time_elapsed         | 45592        |\n",
      "|    total_timesteps      | 5052416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066672997 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.647        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.9         |\n",
      "|    n_updates            | 24660        |\n",
      "|    policy_gradient_loss | -0.00713     |\n",
      "|    reward               | -1.9646873   |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 43.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2468          |\n",
      "|    time_elapsed         | 45610         |\n",
      "|    total_timesteps      | 5054464       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031587807 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -116          |\n",
      "|    explained_variance   | 0.689         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 36.3          |\n",
      "|    n_updates            | 24670         |\n",
      "|    policy_gradient_loss | -0.000799     |\n",
      "|    reward               | -1.5913905    |\n",
      "|    std                  | 13.7          |\n",
      "|    value_loss           | 134           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2469          |\n",
      "|    time_elapsed         | 45628         |\n",
      "|    total_timesteps      | 5056512       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042008018 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -116          |\n",
      "|    explained_variance   | 0.71          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 32.2          |\n",
      "|    n_updates            | 24680         |\n",
      "|    policy_gradient_loss | -0.00114      |\n",
      "|    reward               | 2.526841      |\n",
      "|    std                  | 13.7          |\n",
      "|    value_loss           | 141           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2470         |\n",
      "|    time_elapsed         | 45647        |\n",
      "|    total_timesteps      | 5058560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030068373 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.1         |\n",
      "|    n_updates            | 24690        |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    reward               | 1.8715       |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 59.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3321441.32\n",
      "total_reward: 2321441.32\n",
      "total_cost: 125989.45\n",
      "total_trades: 56395\n",
      "Sharpe: 0.528\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2471        |\n",
      "|    time_elapsed         | 45665       |\n",
      "|    total_timesteps      | 5060608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002409565 |\n",
      "|    clip_fraction        | 0.00107     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.1        |\n",
      "|    n_updates            | 24700       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    reward               | 1.0363817   |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2472         |\n",
      "|    time_elapsed         | 45684        |\n",
      "|    total_timesteps      | 5062656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003234073 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.797        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.4         |\n",
      "|    n_updates            | 24710        |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    reward               | -0.95361435  |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 122          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2473         |\n",
      "|    time_elapsed         | 45702        |\n",
      "|    total_timesteps      | 5064704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007325488 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.3         |\n",
      "|    n_updates            | 24720        |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    reward               | -8.117285    |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 86.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2474        |\n",
      "|    time_elapsed         | 45721       |\n",
      "|    total_timesteps      | 5066752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006887202 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.1        |\n",
      "|    n_updates            | 24730       |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    reward               | -1.4437985  |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 94.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2475         |\n",
      "|    time_elapsed         | 45740        |\n",
      "|    total_timesteps      | 5068800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014310785 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 118          |\n",
      "|    n_updates            | 24740        |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    reward               | -2.760309    |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 165          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2476          |\n",
      "|    time_elapsed         | 45759         |\n",
      "|    total_timesteps      | 5070848       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040667134 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -116          |\n",
      "|    explained_variance   | 0.748         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 62.8          |\n",
      "|    n_updates            | 24750         |\n",
      "|    policy_gradient_loss | -0.00191      |\n",
      "|    reward               | -4.4943647    |\n",
      "|    std                  | 13.8          |\n",
      "|    value_loss           | 156           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2477         |\n",
      "|    time_elapsed         | 45777        |\n",
      "|    total_timesteps      | 5072896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042061387 |\n",
      "|    clip_fraction        | 0.00811      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.719        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 24760        |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | 1.3814422    |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 51.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2478         |\n",
      "|    time_elapsed         | 45795        |\n",
      "|    total_timesteps      | 5074944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014024173 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.2         |\n",
      "|    n_updates            | 24770        |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    reward               | -0.43166387  |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 151          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2479         |\n",
      "|    time_elapsed         | 45814        |\n",
      "|    total_timesteps      | 5076992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027698465 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.4         |\n",
      "|    n_updates            | 24780        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    reward               | 8.6923065    |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2480        |\n",
      "|    time_elapsed         | 45834       |\n",
      "|    total_timesteps      | 5079040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002044247 |\n",
      "|    clip_fraction        | 0.00195     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.3        |\n",
      "|    n_updates            | 24790       |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | -1.5915512  |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 81.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2481        |\n",
      "|    time_elapsed         | 45853       |\n",
      "|    total_timesteps      | 5081088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005201433 |\n",
      "|    clip_fraction        | 0.0168      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.4        |\n",
      "|    n_updates            | 24800       |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    reward               | 0.64101106  |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2482        |\n",
      "|    time_elapsed         | 45872       |\n",
      "|    total_timesteps      | 5083136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00529347  |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.9        |\n",
      "|    n_updates            | 24810       |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    reward               | 0.049826454 |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2483         |\n",
      "|    time_elapsed         | 45890        |\n",
      "|    total_timesteps      | 5085184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.230806e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81           |\n",
      "|    n_updates            | 24820        |\n",
      "|    policy_gradient_loss | -0.000367    |\n",
      "|    reward               | -2.74626     |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 252          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2484        |\n",
      "|    time_elapsed         | 45910       |\n",
      "|    total_timesteps      | 5087232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004917888 |\n",
      "|    clip_fraction        | 0.0111      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 24830       |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    reward               | 2.2060096   |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 59.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3179186.13\n",
      "total_reward: 2179186.13\n",
      "total_cost: 112750.30\n",
      "total_trades: 55285\n",
      "Sharpe: 0.515\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2485         |\n",
      "|    time_elapsed         | 45930        |\n",
      "|    total_timesteps      | 5089280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012596056 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.787        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 161          |\n",
      "|    n_updates            | 24840        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    reward               | -2.6053207   |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 222          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2486        |\n",
      "|    time_elapsed         | 45948       |\n",
      "|    total_timesteps      | 5091328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.36966e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 24850       |\n",
      "|    policy_gradient_loss | -0.000506   |\n",
      "|    reward               | -1.9232937  |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2487        |\n",
      "|    time_elapsed         | 45967       |\n",
      "|    total_timesteps      | 5093376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00936034  |\n",
      "|    clip_fraction        | 0.0485      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.5        |\n",
      "|    n_updates            | 24860       |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | -0.62596405 |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 58.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2488        |\n",
      "|    time_elapsed         | 45986       |\n",
      "|    total_timesteps      | 5095424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006934044 |\n",
      "|    clip_fraction        | 0.0284      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40          |\n",
      "|    n_updates            | 24870       |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    reward               | -0.50766444 |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2489         |\n",
      "|    time_elapsed         | 46006        |\n",
      "|    total_timesteps      | 5097472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024702745 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.7         |\n",
      "|    n_updates            | 24880        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | -0.35493356  |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2490         |\n",
      "|    time_elapsed         | 46025        |\n",
      "|    total_timesteps      | 5099520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030816304 |\n",
      "|    clip_fraction        | 0.00659      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.5         |\n",
      "|    n_updates            | 24890        |\n",
      "|    policy_gradient_loss | -0.00473     |\n",
      "|    reward               | -6.2770467   |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 239          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2491         |\n",
      "|    time_elapsed         | 46045        |\n",
      "|    total_timesteps      | 5101568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092391595 |\n",
      "|    clip_fraction        | 0.0593       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 24900        |\n",
      "|    policy_gradient_loss | -0.00755     |\n",
      "|    reward               | 1.8897688    |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 48           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2492         |\n",
      "|    time_elapsed         | 46064        |\n",
      "|    total_timesteps      | 5103616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028315894 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48           |\n",
      "|    n_updates            | 24910        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | 3.729976     |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2493         |\n",
      "|    time_elapsed         | 46082        |\n",
      "|    total_timesteps      | 5105664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.998724e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.783        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.6         |\n",
      "|    n_updates            | 24920        |\n",
      "|    policy_gradient_loss | -0.000591    |\n",
      "|    reward               | 0.4732736    |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2494        |\n",
      "|    time_elapsed         | 46101       |\n",
      "|    total_timesteps      | 5107712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003211652 |\n",
      "|    clip_fraction        | 0.00122     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 24930       |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    reward               | -4.8034005  |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2495        |\n",
      "|    time_elapsed         | 46119       |\n",
      "|    total_timesteps      | 5109760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004312998 |\n",
      "|    clip_fraction        | 0.00723     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 24940       |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    reward               | 5.015691    |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2496         |\n",
      "|    time_elapsed         | 46137        |\n",
      "|    total_timesteps      | 5111808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003774363 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.6         |\n",
      "|    n_updates            | 24950        |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    reward               | -1.7342879   |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2497          |\n",
      "|    time_elapsed         | 46156         |\n",
      "|    total_timesteps      | 5113856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014826635 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -117          |\n",
      "|    explained_variance   | 0.729         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 28.7          |\n",
      "|    n_updates            | 24960         |\n",
      "|    policy_gradient_loss | -0.000642     |\n",
      "|    reward               | -0.5306829    |\n",
      "|    std                  | 14.1          |\n",
      "|    value_loss           | 71.9          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2498        |\n",
      "|    time_elapsed         | 46174       |\n",
      "|    total_timesteps      | 5115904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010685854 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.2        |\n",
      "|    n_updates            | 24970       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 5.4629254   |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 90          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3301819.72\n",
      "total_reward: 2301819.72\n",
      "total_cost: 115651.82\n",
      "total_trades: 55793\n",
      "Sharpe: 0.532\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2499         |\n",
      "|    time_elapsed         | 46193        |\n",
      "|    total_timesteps      | 5117952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032064277 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.5         |\n",
      "|    n_updates            | 24980        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | -1.2622951   |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2500         |\n",
      "|    time_elapsed         | 46211        |\n",
      "|    total_timesteps      | 5120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008454396 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.776        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.9         |\n",
      "|    n_updates            | 24990        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | -0.9075097   |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2501        |\n",
      "|    time_elapsed         | 46230       |\n",
      "|    total_timesteps      | 5122048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008452734 |\n",
      "|    clip_fraction        | 0.0602      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 25000       |\n",
      "|    policy_gradient_loss | -0.00895    |\n",
      "|    reward               | -0.48303235 |\n",
      "|    std                  | 14.2        |\n",
      "|    value_loss           | 58.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2502         |\n",
      "|    time_elapsed         | 46248        |\n",
      "|    total_timesteps      | 5124096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022314566 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.459        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71           |\n",
      "|    n_updates            | 25010        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    reward               | -1.2639756   |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2503         |\n",
      "|    time_elapsed         | 46267        |\n",
      "|    total_timesteps      | 5126144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004631574 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 171          |\n",
      "|    n_updates            | 25020        |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    reward               | 0.9220706    |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 180          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2504        |\n",
      "|    time_elapsed         | 46285       |\n",
      "|    total_timesteps      | 5128192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000407021 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.3        |\n",
      "|    n_updates            | 25030       |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    reward               | -1.6791534  |\n",
      "|    std                  | 14.2        |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2505         |\n",
      "|    time_elapsed         | 46304        |\n",
      "|    total_timesteps      | 5130240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056832414 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.852        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.5         |\n",
      "|    n_updates            | 25040        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    reward               | -1.495801    |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 97           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2506          |\n",
      "|    time_elapsed         | 46322         |\n",
      "|    total_timesteps      | 5132288       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032375622 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -117          |\n",
      "|    explained_variance   | 0.736         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 53.9          |\n",
      "|    n_updates            | 25050         |\n",
      "|    policy_gradient_loss | -0.00148      |\n",
      "|    reward               | -0.05597637   |\n",
      "|    std                  | 14.2          |\n",
      "|    value_loss           | 174           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2507          |\n",
      "|    time_elapsed         | 46340         |\n",
      "|    total_timesteps      | 5134336       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038245282 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -117          |\n",
      "|    explained_variance   | 0.741         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 41.9          |\n",
      "|    n_updates            | 25060         |\n",
      "|    policy_gradient_loss | -0.00139      |\n",
      "|    reward               | 1.0963697     |\n",
      "|    std                  | 14.2          |\n",
      "|    value_loss           | 155           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2508        |\n",
      "|    time_elapsed         | 46358       |\n",
      "|    total_timesteps      | 5136384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010290676 |\n",
      "|    clip_fraction        | 0.0883      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 25070       |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | 0.72394234  |\n",
      "|    std                  | 14.2        |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2509         |\n",
      "|    time_elapsed         | 46376        |\n",
      "|    total_timesteps      | 5138432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012141047 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.4         |\n",
      "|    n_updates            | 25080        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    reward               | 4.701928     |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2510         |\n",
      "|    time_elapsed         | 46394        |\n",
      "|    total_timesteps      | 5140480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046352083 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.3         |\n",
      "|    n_updates            | 25090        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | 13.594437    |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2511         |\n",
      "|    time_elapsed         | 46413        |\n",
      "|    total_timesteps      | 5142528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007212659 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 25100        |\n",
      "|    policy_gradient_loss | -0.00134     |\n",
      "|    reward               | -0.24754514  |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 53           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2512         |\n",
      "|    time_elapsed         | 46431        |\n",
      "|    total_timesteps      | 5144576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030654543 |\n",
      "|    clip_fraction        | 0.00493      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.4         |\n",
      "|    n_updates            | 25110        |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    reward               | -2.6818774   |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2513         |\n",
      "|    time_elapsed         | 46449        |\n",
      "|    total_timesteps      | 5146624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013794182 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.5         |\n",
      "|    n_updates            | 25120        |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    reward               | -3.6205578   |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 96.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3497519.93\n",
      "total_reward: 2497519.93\n",
      "total_cost: 118971.13\n",
      "total_trades: 56330\n",
      "Sharpe: 0.610\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2514          |\n",
      "|    time_elapsed         | 46467         |\n",
      "|    total_timesteps      | 5148672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054972275 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -117          |\n",
      "|    explained_variance   | 0.736         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 48.3          |\n",
      "|    n_updates            | 25130         |\n",
      "|    policy_gradient_loss | -0.00169      |\n",
      "|    reward               | -2.3471184    |\n",
      "|    std                  | 14.3          |\n",
      "|    value_loss           | 83.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2515         |\n",
      "|    time_elapsed         | 46485        |\n",
      "|    total_timesteps      | 5150720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030564975 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 25140        |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    reward               | 0.39309895   |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2516         |\n",
      "|    time_elapsed         | 46503        |\n",
      "|    total_timesteps      | 5152768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014546881 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.6         |\n",
      "|    n_updates            | 25150        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | -3.7523627   |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 95.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2517        |\n",
      "|    time_elapsed         | 46521       |\n",
      "|    total_timesteps      | 5154816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001081927 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.1        |\n",
      "|    n_updates            | 25160       |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    reward               | -0.15384634 |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 97.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2518         |\n",
      "|    time_elapsed         | 46539        |\n",
      "|    total_timesteps      | 5156864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018613535 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.3         |\n",
      "|    n_updates            | 25170        |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | -14.756404   |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 43.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2519         |\n",
      "|    time_elapsed         | 46557        |\n",
      "|    total_timesteps      | 5158912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013968933 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 25180        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    reward               | -4.941076    |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2520          |\n",
      "|    time_elapsed         | 46575         |\n",
      "|    total_timesteps      | 5160960       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040445678 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -117          |\n",
      "|    explained_variance   | 0.567         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16            |\n",
      "|    n_updates            | 25190         |\n",
      "|    policy_gradient_loss | -0.0015       |\n",
      "|    reward               | -1.3916419    |\n",
      "|    std                  | 14.3          |\n",
      "|    value_loss           | 94.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2521         |\n",
      "|    time_elapsed         | 46594        |\n",
      "|    total_timesteps      | 5163008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014319473 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 25200        |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    reward               | 0.37002727   |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 45.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2522         |\n",
      "|    time_elapsed         | 46612        |\n",
      "|    total_timesteps      | 5165056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060491413 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.6         |\n",
      "|    n_updates            | 25210        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | 0.75933254   |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 74.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2523         |\n",
      "|    time_elapsed         | 46631        |\n",
      "|    total_timesteps      | 5167104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034887898 |\n",
      "|    clip_fraction        | 0.00596      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 25220        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    reward               | 0.42640242   |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 68.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2524          |\n",
      "|    time_elapsed         | 46649         |\n",
      "|    total_timesteps      | 5169152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010521556 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -117          |\n",
      "|    explained_variance   | 0.78          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 31.5          |\n",
      "|    n_updates            | 25230         |\n",
      "|    policy_gradient_loss | -0.00112      |\n",
      "|    reward               | -2.481864     |\n",
      "|    std                  | 14.4          |\n",
      "|    value_loss           | 88            |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2525        |\n",
      "|    time_elapsed         | 46667       |\n",
      "|    total_timesteps      | 5171200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006146075 |\n",
      "|    clip_fraction        | 0.0185      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 25240       |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    reward               | 4.089837    |\n",
      "|    std                  | 14.5        |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2526         |\n",
      "|    time_elapsed         | 46686        |\n",
      "|    total_timesteps      | 5173248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023416704 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.6         |\n",
      "|    n_updates            | 25250        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    reward               | 1.2272594    |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 89.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2527        |\n",
      "|    time_elapsed         | 46705       |\n",
      "|    total_timesteps      | 5175296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002432434 |\n",
      "|    clip_fraction        | 0.00176     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.6        |\n",
      "|    n_updates            | 25260       |\n",
      "|    policy_gradient_loss | -0.0021     |\n",
      "|    reward               | 1.6764778   |\n",
      "|    std                  | 14.5        |\n",
      "|    value_loss           | 81          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3111071.46\n",
      "total_reward: 2111071.46\n",
      "total_cost: 144996.42\n",
      "total_trades: 57602\n",
      "Sharpe: 0.534\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2528         |\n",
      "|    time_elapsed         | 46724        |\n",
      "|    total_timesteps      | 5177344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002845783 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.4         |\n",
      "|    n_updates            | 25270        |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    reward               | 1.2317352    |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 61.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2529         |\n",
      "|    time_elapsed         | 46744        |\n",
      "|    total_timesteps      | 5179392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055437842 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.794        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.1         |\n",
      "|    n_updates            | 25280        |\n",
      "|    policy_gradient_loss | -0.00473     |\n",
      "|    reward               | -0.29220235  |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 79.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2530         |\n",
      "|    time_elapsed         | 46763        |\n",
      "|    total_timesteps      | 5181440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047940006 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.5         |\n",
      "|    n_updates            | 25290        |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    reward               | 1.1814467    |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2531          |\n",
      "|    time_elapsed         | 46781         |\n",
      "|    total_timesteps      | 5183488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016256102 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -118          |\n",
      "|    explained_variance   | 0.84          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 46.9          |\n",
      "|    n_updates            | 25300         |\n",
      "|    policy_gradient_loss | -0.000599     |\n",
      "|    reward               | 1.111947      |\n",
      "|    std                  | 14.5          |\n",
      "|    value_loss           | 88.1          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2532         |\n",
      "|    time_elapsed         | 46800        |\n",
      "|    total_timesteps      | 5185536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017766106 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 25310        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | 0.7686188    |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2533         |\n",
      "|    time_elapsed         | 46818        |\n",
      "|    total_timesteps      | 5187584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017568305 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.86         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 25320        |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    reward               | 3.4231238    |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 76.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2534          |\n",
      "|    time_elapsed         | 46836         |\n",
      "|    total_timesteps      | 5189632       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017418078 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -118          |\n",
      "|    explained_variance   | 0.817         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 47.6          |\n",
      "|    n_updates            | 25330         |\n",
      "|    policy_gradient_loss | -0.000807     |\n",
      "|    reward               | -5.153426     |\n",
      "|    std                  | 14.6          |\n",
      "|    value_loss           | 86            |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2535        |\n",
      "|    time_elapsed         | 46854       |\n",
      "|    total_timesteps      | 5191680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004240222 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 25340       |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | -4.6105857  |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2536        |\n",
      "|    time_elapsed         | 46873       |\n",
      "|    total_timesteps      | 5193728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004838884 |\n",
      "|    clip_fraction        | 0.0158      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 25350       |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    reward               | 1.0146185   |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 65.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2537         |\n",
      "|    time_elapsed         | 46891        |\n",
      "|    total_timesteps      | 5195776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024784342 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.816        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 25360        |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    reward               | 16.922161    |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 74.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2538         |\n",
      "|    time_elapsed         | 46909        |\n",
      "|    total_timesteps      | 5197824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007133086 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 25370        |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    reward               | 0.70893556   |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 75.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2539         |\n",
      "|    time_elapsed         | 46929        |\n",
      "|    total_timesteps      | 5199872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048832297 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 25380        |\n",
      "|    policy_gradient_loss | -0.00771     |\n",
      "|    reward               | -3.2035272   |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 39.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2540         |\n",
      "|    time_elapsed         | 46947        |\n",
      "|    total_timesteps      | 5201920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065137274 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.845        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.3         |\n",
      "|    n_updates            | 25390        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    reward               | 2.1172113    |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 64           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2541         |\n",
      "|    time_elapsed         | 46965        |\n",
      "|    total_timesteps      | 5203968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013631068 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.763        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.7         |\n",
      "|    n_updates            | 25400        |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    reward               | 3.3605227    |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 75.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3488739.81\n",
      "total_reward: 2488739.81\n",
      "total_cost: 158241.55\n",
      "total_trades: 59017\n",
      "Sharpe: 0.589\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2542        |\n",
      "|    time_elapsed         | 46984       |\n",
      "|    total_timesteps      | 5206016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009255033 |\n",
      "|    clip_fraction        | 0.0771      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 25410       |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | -3.2155638  |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2543        |\n",
      "|    time_elapsed         | 47003       |\n",
      "|    total_timesteps      | 5208064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002489959 |\n",
      "|    clip_fraction        | 0.00293     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 25420       |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    reward               | 0.37485966  |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 64.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2544         |\n",
      "|    time_elapsed         | 47021        |\n",
      "|    total_timesteps      | 5210112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019182889 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.823        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.2         |\n",
      "|    n_updates            | 25430        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    reward               | 5.3267174    |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 64           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2545         |\n",
      "|    time_elapsed         | 47041        |\n",
      "|    total_timesteps      | 5212160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048568333 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.362        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 25440        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | -1.9502226   |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 53.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2546         |\n",
      "|    time_elapsed         | 47060        |\n",
      "|    total_timesteps      | 5214208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059084687 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.811        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 25450        |\n",
      "|    policy_gradient_loss | -0.00788     |\n",
      "|    reward               | -0.13710113  |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 50.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2547         |\n",
      "|    time_elapsed         | 47079        |\n",
      "|    total_timesteps      | 5216256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039628893 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.795        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.5         |\n",
      "|    n_updates            | 25460        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | 1.4230771    |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 73.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2548          |\n",
      "|    time_elapsed         | 47098         |\n",
      "|    total_timesteps      | 5218304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051424396 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -118          |\n",
      "|    explained_variance   | 0.403         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 110           |\n",
      "|    n_updates            | 25470         |\n",
      "|    policy_gradient_loss | -0.00143      |\n",
      "|    reward               | 0.26365548    |\n",
      "|    std                  | 14.8          |\n",
      "|    value_loss           | 123           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2549        |\n",
      "|    time_elapsed         | 47117       |\n",
      "|    total_timesteps      | 5220352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008443831 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 25480       |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    reward               | 0.4523558   |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2550         |\n",
      "|    time_elapsed         | 47136        |\n",
      "|    total_timesteps      | 5222400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024408675 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 25490        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | 1.2525544    |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 60.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2551        |\n",
      "|    time_elapsed         | 47154       |\n",
      "|    total_timesteps      | 5224448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004469914 |\n",
      "|    clip_fraction        | 0.0123      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 25500       |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    reward               | -2.5313668  |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 81.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2552         |\n",
      "|    time_elapsed         | 47174        |\n",
      "|    total_timesteps      | 5226496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014289913 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.5         |\n",
      "|    n_updates            | 25510        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | 0.37104756   |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 40.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2553         |\n",
      "|    time_elapsed         | 47194        |\n",
      "|    total_timesteps      | 5228544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048495964 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.1         |\n",
      "|    n_updates            | 25520        |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    reward               | -2.7012851   |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 70.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2554         |\n",
      "|    time_elapsed         | 47213        |\n",
      "|    total_timesteps      | 5230592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033021998 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.434        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.4         |\n",
      "|    n_updates            | 25530        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | 0.38029343   |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 125          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2555        |\n",
      "|    time_elapsed         | 47232       |\n",
      "|    total_timesteps      | 5232640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002030822 |\n",
      "|    clip_fraction        | 0.000732    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51          |\n",
      "|    n_updates            | 25540       |\n",
      "|    policy_gradient_loss | -0.00187    |\n",
      "|    reward               | 0.5940369   |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 90.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3188803.72\n",
      "total_reward: 2188803.72\n",
      "total_cost: 194131.26\n",
      "total_trades: 60378\n",
      "Sharpe: 0.542\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2556          |\n",
      "|    time_elapsed         | 47251         |\n",
      "|    total_timesteps      | 5234688       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086198415 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -118          |\n",
      "|    explained_variance   | 0.674         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.4          |\n",
      "|    n_updates            | 25550         |\n",
      "|    policy_gradient_loss | -0.0024       |\n",
      "|    reward               | 2.8699627     |\n",
      "|    std                  | 14.9          |\n",
      "|    value_loss           | 36.1          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2557        |\n",
      "|    time_elapsed         | 47270       |\n",
      "|    total_timesteps      | 5236736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00217812  |\n",
      "|    clip_fraction        | 0.000781    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 25560       |\n",
      "|    policy_gradient_loss | -0.00345    |\n",
      "|    reward               | 0.000192529 |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 71.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2558          |\n",
      "|    time_elapsed         | 47288         |\n",
      "|    total_timesteps      | 5238784       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00049825513 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -118          |\n",
      "|    explained_variance   | 0.81          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 27.3          |\n",
      "|    n_updates            | 25570         |\n",
      "|    policy_gradient_loss | -0.00193      |\n",
      "|    reward               | 1.6217197     |\n",
      "|    std                  | 14.9          |\n",
      "|    value_loss           | 70.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2559         |\n",
      "|    time_elapsed         | 47307        |\n",
      "|    total_timesteps      | 5240832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018167874 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 25580        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    reward               | 0.03478123   |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2560        |\n",
      "|    time_elapsed         | 47326       |\n",
      "|    total_timesteps      | 5242880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005193907 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.9        |\n",
      "|    n_updates            | 25590       |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    reward               | 0.30154824  |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 72.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2561        |\n",
      "|    time_elapsed         | 47345       |\n",
      "|    total_timesteps      | 5244928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004925212 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36          |\n",
      "|    n_updates            | 25600       |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    reward               | -7.012481   |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 71.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2562         |\n",
      "|    time_elapsed         | 47364        |\n",
      "|    total_timesteps      | 5246976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016460582 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.1         |\n",
      "|    n_updates            | 25610        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | -1.0476389   |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 69.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2563        |\n",
      "|    time_elapsed         | 47383       |\n",
      "|    total_timesteps      | 5249024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008255428 |\n",
      "|    clip_fraction        | 0.0487      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.99        |\n",
      "|    n_updates            | 25620       |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | -1.9589989  |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 47.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2564         |\n",
      "|    time_elapsed         | 47401        |\n",
      "|    total_timesteps      | 5251072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022031786 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.8         |\n",
      "|    n_updates            | 25630        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | 2.460033     |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 62.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2565          |\n",
      "|    time_elapsed         | 47420         |\n",
      "|    total_timesteps      | 5253120       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044510743 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -119          |\n",
      "|    explained_variance   | 0.735         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22            |\n",
      "|    n_updates            | 25640         |\n",
      "|    policy_gradient_loss | -0.0015       |\n",
      "|    reward               | 3.0933676     |\n",
      "|    std                  | 15            |\n",
      "|    value_loss           | 77.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2566         |\n",
      "|    time_elapsed         | 47439        |\n",
      "|    total_timesteps      | 5255168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064990716 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 25650        |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    reward               | 0.83996534   |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2567         |\n",
      "|    time_elapsed         | 47457        |\n",
      "|    total_timesteps      | 5257216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017958008 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.814        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.8         |\n",
      "|    n_updates            | 25660        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | -0.67762965  |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 69.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2568         |\n",
      "|    time_elapsed         | 47475        |\n",
      "|    total_timesteps      | 5259264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037140334 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.9         |\n",
      "|    n_updates            | 25670        |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    reward               | -0.9718249   |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2569         |\n",
      "|    time_elapsed         | 47493        |\n",
      "|    total_timesteps      | 5261312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021960598 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 25680        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    reward               | 0.715113     |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 49           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3263511.26\n",
      "total_reward: 2263511.26\n",
      "total_cost: 191864.63\n",
      "total_trades: 60414\n",
      "Sharpe: 0.548\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2570        |\n",
      "|    time_elapsed         | 47512       |\n",
      "|    total_timesteps      | 5263360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007468713 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 25690       |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    reward               | 1.4315172   |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 66.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2571         |\n",
      "|    time_elapsed         | 47530        |\n",
      "|    total_timesteps      | 5265408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059268316 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.6         |\n",
      "|    n_updates            | 25700        |\n",
      "|    policy_gradient_loss | -0.00681     |\n",
      "|    reward               | 0.120364346  |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 86.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2572          |\n",
      "|    time_elapsed         | 47550         |\n",
      "|    total_timesteps      | 5267456       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3529744e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -119          |\n",
      "|    explained_variance   | 0.814         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 49.9          |\n",
      "|    n_updates            | 25710         |\n",
      "|    policy_gradient_loss | -0.000311     |\n",
      "|    reward               | -0.27106002   |\n",
      "|    std                  | 15.2          |\n",
      "|    value_loss           | 103           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2573         |\n",
      "|    time_elapsed         | 47568        |\n",
      "|    total_timesteps      | 5269504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011997903 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 25720        |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    reward               | 0.51962054   |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 38.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2574         |\n",
      "|    time_elapsed         | 47586        |\n",
      "|    total_timesteps      | 5271552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030714576 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.6         |\n",
      "|    n_updates            | 25730        |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    reward               | 1.9219581    |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2575         |\n",
      "|    time_elapsed         | 47606        |\n",
      "|    total_timesteps      | 5273600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025123737 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.808        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.7         |\n",
      "|    n_updates            | 25740        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | 1.24357      |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 78.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2576          |\n",
      "|    time_elapsed         | 47625         |\n",
      "|    total_timesteps      | 5275648       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050321885 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -119          |\n",
      "|    explained_variance   | 0.726         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 24.1          |\n",
      "|    n_updates            | 25750         |\n",
      "|    policy_gradient_loss | -0.00191      |\n",
      "|    reward               | 1.5837762     |\n",
      "|    std                  | 15.2          |\n",
      "|    value_loss           | 44.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2577         |\n",
      "|    time_elapsed         | 47645        |\n",
      "|    total_timesteps      | 5277696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016490726 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.8          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 25760        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    reward               | 0.31326118   |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 66.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2578         |\n",
      "|    time_elapsed         | 47665        |\n",
      "|    total_timesteps      | 5279744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038503627 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.7         |\n",
      "|    n_updates            | 25770        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    reward               | -0.29907158  |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 68.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2579         |\n",
      "|    time_elapsed         | 47684        |\n",
      "|    total_timesteps      | 5281792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014240602 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.4         |\n",
      "|    n_updates            | 25780        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | -3.9275274   |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 82           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2580         |\n",
      "|    time_elapsed         | 47703        |\n",
      "|    total_timesteps      | 5283840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028680414 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 25790        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    reward               | 1.6445869    |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2581         |\n",
      "|    time_elapsed         | 47721        |\n",
      "|    total_timesteps      | 5285888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037589842 |\n",
      "|    clip_fraction        | 0.00913      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.6         |\n",
      "|    n_updates            | 25800        |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    reward               | -0.79315656  |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 71.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2582         |\n",
      "|    time_elapsed         | 47741        |\n",
      "|    total_timesteps      | 5287936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009630313 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.797        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.3         |\n",
      "|    n_updates            | 25810        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | 0.09651542   |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 73.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2583         |\n",
      "|    time_elapsed         | 47761        |\n",
      "|    total_timesteps      | 5289984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079100905 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.86         |\n",
      "|    n_updates            | 25820        |\n",
      "|    policy_gradient_loss | -0.0073      |\n",
      "|    reward               | -0.28011927  |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 24.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3734053.16\n",
      "total_reward: 2734053.16\n",
      "total_cost: 221038.04\n",
      "total_trades: 61454\n",
      "Sharpe: 0.668\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2584        |\n",
      "|    time_elapsed         | 47780       |\n",
      "|    total_timesteps      | 5292032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007800244 |\n",
      "|    clip_fraction        | 0.0409      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.5        |\n",
      "|    n_updates            | 25830       |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    reward               | -1.0511333  |\n",
      "|    std                  | 15.3        |\n",
      "|    value_loss           | 68.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2585         |\n",
      "|    time_elapsed         | 47800        |\n",
      "|    total_timesteps      | 5294080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024134135 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.5         |\n",
      "|    n_updates            | 25840        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    reward               | 9.464969     |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 89.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2586          |\n",
      "|    time_elapsed         | 47820         |\n",
      "|    total_timesteps      | 5296128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095998263 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -119          |\n",
      "|    explained_variance   | 0.483         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 25.2          |\n",
      "|    n_updates            | 25850         |\n",
      "|    policy_gradient_loss | -0.00226      |\n",
      "|    reward               | -1.650535     |\n",
      "|    std                  | 15.3          |\n",
      "|    value_loss           | 59.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2587         |\n",
      "|    time_elapsed         | 47840        |\n",
      "|    total_timesteps      | 5298176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039300313 |\n",
      "|    clip_fraction        | 0.00957      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 25860        |\n",
      "|    policy_gradient_loss | -0.00783     |\n",
      "|    reward               | -0.09488507  |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 54.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2588        |\n",
      "|    time_elapsed         | 47858       |\n",
      "|    total_timesteps      | 5300224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004506705 |\n",
      "|    clip_fraction        | 0.00981     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.4        |\n",
      "|    n_updates            | 25870       |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    reward               | 0.015401391 |\n",
      "|    std                  | 15.3        |\n",
      "|    value_loss           | 97.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2589         |\n",
      "|    time_elapsed         | 47877        |\n",
      "|    total_timesteps      | 5302272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017160128 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.9         |\n",
      "|    n_updates            | 25880        |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    reward               | 3.344036     |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 90           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2590        |\n",
      "|    time_elapsed         | 47896       |\n",
      "|    total_timesteps      | 5304320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009104975 |\n",
      "|    clip_fraction        | 0.0537      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 25890       |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    reward               | 5.207817    |\n",
      "|    std                  | 15.3        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2591         |\n",
      "|    time_elapsed         | 47915        |\n",
      "|    total_timesteps      | 5306368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027877202 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31           |\n",
      "|    n_updates            | 25900        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | 1.470575     |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 93.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2592          |\n",
      "|    time_elapsed         | 47934         |\n",
      "|    total_timesteps      | 5308416       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021346938 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -119          |\n",
      "|    explained_variance   | 0.767         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 74.6          |\n",
      "|    n_updates            | 25910         |\n",
      "|    policy_gradient_loss | -0.000722     |\n",
      "|    reward               | 1.6333685     |\n",
      "|    std                  | 15.4          |\n",
      "|    value_loss           | 122           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2593         |\n",
      "|    time_elapsed         | 47953        |\n",
      "|    total_timesteps      | 5310464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001613305 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.7         |\n",
      "|    n_updates            | 25920        |\n",
      "|    policy_gradient_loss | -0.000744    |\n",
      "|    reward               | 2.6406915    |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 80.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2594         |\n",
      "|    time_elapsed         | 47972        |\n",
      "|    total_timesteps      | 5312512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067198686 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.7         |\n",
      "|    n_updates            | 25930        |\n",
      "|    policy_gradient_loss | -0.00594     |\n",
      "|    reward               | 0.5085464    |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 74.9         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2595       |\n",
      "|    time_elapsed         | 47991      |\n",
      "|    total_timesteps      | 5314560    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00433483 |\n",
      "|    clip_fraction        | 0.00757    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -119       |\n",
      "|    explained_variance   | 0.758      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 46.6       |\n",
      "|    n_updates            | 25940      |\n",
      "|    policy_gradient_loss | -0.00337   |\n",
      "|    reward               | 0.14306097 |\n",
      "|    std                  | 15.4       |\n",
      "|    value_loss           | 65         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2596         |\n",
      "|    time_elapsed         | 48010        |\n",
      "|    total_timesteps      | 5316608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009371883 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.75         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.2         |\n",
      "|    n_updates            | 25950        |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    reward               | -0.56082743  |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 87.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2597        |\n",
      "|    time_elapsed         | 48029       |\n",
      "|    total_timesteps      | 5318656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010354314 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.54        |\n",
      "|    n_updates            | 25960       |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | -2.2552185  |\n",
      "|    std                  | 15.5        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3376375.79\n",
      "total_reward: 2376375.79\n",
      "total_cost: 258561.91\n",
      "total_trades: 63665\n",
      "Sharpe: 0.619\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2598          |\n",
      "|    time_elapsed         | 48049         |\n",
      "|    total_timesteps      | 5320704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069096027 |\n",
      "|    clip_fraction        | 0.00132       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -119          |\n",
      "|    explained_variance   | 0.8           |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.9          |\n",
      "|    n_updates            | 25970         |\n",
      "|    policy_gradient_loss | -0.0024       |\n",
      "|    reward               | -1.8058462    |\n",
      "|    std                  | 15.5          |\n",
      "|    value_loss           | 68            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2599         |\n",
      "|    time_elapsed         | 48067        |\n",
      "|    total_timesteps      | 5322752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012960581 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 25980        |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    reward               | -1.0460434   |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 61.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2600         |\n",
      "|    time_elapsed         | 48087        |\n",
      "|    total_timesteps      | 5324800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014710522 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.2         |\n",
      "|    n_updates            | 25990        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    reward               | -5.5937796   |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 45.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2601         |\n",
      "|    time_elapsed         | 48105        |\n",
      "|    total_timesteps      | 5326848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044276984 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 26000        |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    reward               | 1.6828706    |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 60.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2602         |\n",
      "|    time_elapsed         | 48124        |\n",
      "|    total_timesteps      | 5328896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023090374 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 26010        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | -2.1289508   |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 69.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2603         |\n",
      "|    time_elapsed         | 48142        |\n",
      "|    total_timesteps      | 5330944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013163504 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.5         |\n",
      "|    n_updates            | 26020        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | 0.08937114   |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 67.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2604        |\n",
      "|    time_elapsed         | 48161       |\n",
      "|    total_timesteps      | 5332992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009617776 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.75        |\n",
      "|    n_updates            | 26030       |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    reward               | -1.2676628  |\n",
      "|    std                  | 15.6        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2605        |\n",
      "|    time_elapsed         | 48180       |\n",
      "|    total_timesteps      | 5335040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008395826 |\n",
      "|    clip_fraction        | 0.0341      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 26040       |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    reward               | 1.6168132   |\n",
      "|    std                  | 15.6        |\n",
      "|    value_loss           | 72.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2606         |\n",
      "|    time_elapsed         | 48199        |\n",
      "|    total_timesteps      | 5337088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017232137 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 26050        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | -2.996403    |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 58.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2607         |\n",
      "|    time_elapsed         | 48218        |\n",
      "|    total_timesteps      | 5339136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055756858 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 26060        |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    reward               | -1.9463902   |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2608         |\n",
      "|    time_elapsed         | 48238        |\n",
      "|    total_timesteps      | 5341184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020530461 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.752        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 26070        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    reward               | 0.5492844    |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 61.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2609         |\n",
      "|    time_elapsed         | 48257        |\n",
      "|    total_timesteps      | 5343232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014001703 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48           |\n",
      "|    n_updates            | 26080        |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    reward               | -0.2985703   |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 73.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2610         |\n",
      "|    time_elapsed         | 48277        |\n",
      "|    total_timesteps      | 5345280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065708277 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 26090        |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | 0.6919734    |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 30.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2611         |\n",
      "|    time_elapsed         | 48296        |\n",
      "|    total_timesteps      | 5347328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092755975 |\n",
      "|    clip_fraction        | 0.0575       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.823        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 26100        |\n",
      "|    policy_gradient_loss | -0.00866     |\n",
      "|    reward               | -0.05499961  |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 35           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3092714.14\n",
      "total_reward: 2092714.14\n",
      "total_cost: 269303.11\n",
      "total_trades: 63349\n",
      "Sharpe: 0.574\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2612         |\n",
      "|    time_elapsed         | 48316        |\n",
      "|    total_timesteps      | 5349376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027501686 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.787        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.5         |\n",
      "|    n_updates            | 26110        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    reward               | 0.15550621   |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 66.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2613        |\n",
      "|    time_elapsed         | 48334       |\n",
      "|    total_timesteps      | 5351424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001164706 |\n",
      "|    clip_fraction        | 0.000586    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 26120       |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    reward               | 3.9427888   |\n",
      "|    std                  | 15.7        |\n",
      "|    value_loss           | 72.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2614        |\n",
      "|    time_elapsed         | 48353       |\n",
      "|    total_timesteps      | 5353472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010687332 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 26130       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 0.7804914   |\n",
      "|    std                  | 15.6        |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2615        |\n",
      "|    time_elapsed         | 48372       |\n",
      "|    total_timesteps      | 5355520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004777013 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41          |\n",
      "|    n_updates            | 26140       |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    reward               | -3.1984947  |\n",
      "|    std                  | 15.7        |\n",
      "|    value_loss           | 54.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2616        |\n",
      "|    time_elapsed         | 48391       |\n",
      "|    total_timesteps      | 5357568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002230376 |\n",
      "|    clip_fraction        | 0.00107     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 26150       |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    reward               | 2.3888497   |\n",
      "|    std                  | 15.7        |\n",
      "|    value_loss           | 65          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2617         |\n",
      "|    time_elapsed         | 48410        |\n",
      "|    total_timesteps      | 5359616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029278658 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.412        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.1         |\n",
      "|    n_updates            | 26160        |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    reward               | 1.5598243    |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 51.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2618         |\n",
      "|    time_elapsed         | 48428        |\n",
      "|    total_timesteps      | 5361664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031280275 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 26170        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    reward               | 0.7401853    |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 51.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2619         |\n",
      "|    time_elapsed         | 48448        |\n",
      "|    total_timesteps      | 5363712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025832006 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.606        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 26180        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | -1.7075204   |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 56.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2620          |\n",
      "|    time_elapsed         | 48467         |\n",
      "|    total_timesteps      | 5365760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00083065755 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -120          |\n",
      "|    explained_variance   | 0.73          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.2          |\n",
      "|    n_updates            | 26190         |\n",
      "|    policy_gradient_loss | -0.00162      |\n",
      "|    reward               | 1.180299      |\n",
      "|    std                  | 15.8          |\n",
      "|    value_loss           | 52.5          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2621        |\n",
      "|    time_elapsed         | 48486       |\n",
      "|    total_timesteps      | 5367808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009605134 |\n",
      "|    clip_fraction        | 0.0735      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.39        |\n",
      "|    n_updates            | 26200       |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    reward               | 1.2232835   |\n",
      "|    std                  | 15.8        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2622         |\n",
      "|    time_elapsed         | 48505        |\n",
      "|    total_timesteps      | 5369856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019379909 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 26210        |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    reward               | 1.1187819    |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 47.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2623          |\n",
      "|    time_elapsed         | 48523         |\n",
      "|    total_timesteps      | 5371904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027669515 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -120          |\n",
      "|    explained_variance   | 0.765         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.3          |\n",
      "|    n_updates            | 26220         |\n",
      "|    policy_gradient_loss | -0.000811     |\n",
      "|    reward               | 5.926062      |\n",
      "|    std                  | 15.8          |\n",
      "|    value_loss           | 71.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2624         |\n",
      "|    time_elapsed         | 48542        |\n",
      "|    total_timesteps      | 5373952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035458119 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 26230        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | -1.7385083   |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 25.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2625        |\n",
      "|    time_elapsed         | 48560       |\n",
      "|    total_timesteps      | 5376000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004839381 |\n",
      "|    clip_fraction        | 0.00913     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 26240       |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    reward               | 1.4431357   |\n",
      "|    std                  | 15.8        |\n",
      "|    value_loss           | 46.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2626         |\n",
      "|    time_elapsed         | 48579        |\n",
      "|    total_timesteps      | 5378048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037336238 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.9         |\n",
      "|    n_updates            | 26250        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | -5.1259217   |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 63           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3283517.64\n",
      "total_reward: 2283517.64\n",
      "total_cost: 292552.72\n",
      "total_trades: 65442\n",
      "Sharpe: 0.589\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2627          |\n",
      "|    time_elapsed         | 48597         |\n",
      "|    total_timesteps      | 5380096       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089603337 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -120          |\n",
      "|    explained_variance   | 0.755         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.3          |\n",
      "|    n_updates            | 26260         |\n",
      "|    policy_gradient_loss | -0.00155      |\n",
      "|    reward               | 0.625779      |\n",
      "|    std                  | 15.9          |\n",
      "|    value_loss           | 59.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2628         |\n",
      "|    time_elapsed         | 48616        |\n",
      "|    total_timesteps      | 5382144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090185935 |\n",
      "|    clip_fraction        | 0.0832       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 26270        |\n",
      "|    policy_gradient_loss | -0.00944     |\n",
      "|    reward               | -1.3989764   |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 28           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2629         |\n",
      "|    time_elapsed         | 48634        |\n",
      "|    total_timesteps      | 5384192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012517921 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 26280        |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    reward               | 0.883401     |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 52.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2630          |\n",
      "|    time_elapsed         | 48653         |\n",
      "|    total_timesteps      | 5386240       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023816049 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -120          |\n",
      "|    explained_variance   | 0.819         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.7          |\n",
      "|    n_updates            | 26290         |\n",
      "|    policy_gradient_loss | -0.00132      |\n",
      "|    reward               | 3.6373394     |\n",
      "|    std                  | 16            |\n",
      "|    value_loss           | 56.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2631         |\n",
      "|    time_elapsed         | 48672        |\n",
      "|    total_timesteps      | 5388288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022821222 |\n",
      "|    clip_fraction        | 0.00376      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.14         |\n",
      "|    n_updates            | 26300        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    reward               | 1.0758381    |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2632         |\n",
      "|    time_elapsed         | 48691        |\n",
      "|    total_timesteps      | 5390336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023564207 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.823        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.4         |\n",
      "|    n_updates            | 26310        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | -4.844924    |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 58.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2633          |\n",
      "|    time_elapsed         | 48711         |\n",
      "|    total_timesteps      | 5392384       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067388534 |\n",
      "|    clip_fraction        | 0.00112       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -120          |\n",
      "|    explained_variance   | 0.777         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.4          |\n",
      "|    n_updates            | 26320         |\n",
      "|    policy_gradient_loss | -0.00169      |\n",
      "|    reward               | 2.5567808     |\n",
      "|    std                  | 16            |\n",
      "|    value_loss           | 63.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2634         |\n",
      "|    time_elapsed         | 48730        |\n",
      "|    total_timesteps      | 5394432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028064381 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 26330        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | -1.0354016   |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 39.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2635        |\n",
      "|    time_elapsed         | 48749       |\n",
      "|    total_timesteps      | 5396480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006987593 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 26340       |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    reward               | -0.75397885 |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 37.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2636        |\n",
      "|    time_elapsed         | 48768       |\n",
      "|    total_timesteps      | 5398528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002703071 |\n",
      "|    clip_fraction        | 0.00537     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 26350       |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    reward               | 1.5121439   |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 52.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2637          |\n",
      "|    time_elapsed         | 48786         |\n",
      "|    total_timesteps      | 5400576       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028046977 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -120          |\n",
      "|    explained_variance   | 0.76          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 55.3          |\n",
      "|    n_updates            | 26360         |\n",
      "|    policy_gradient_loss | -0.00132      |\n",
      "|    reward               | 1.231037      |\n",
      "|    std                  | 16.1          |\n",
      "|    value_loss           | 73.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2638         |\n",
      "|    time_elapsed         | 48805        |\n",
      "|    total_timesteps      | 5402624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089430455 |\n",
      "|    clip_fraction        | 0.0755       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.92         |\n",
      "|    n_updates            | 26370        |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    reward               | -3.4130328   |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 19.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2639         |\n",
      "|    time_elapsed         | 48824        |\n",
      "|    total_timesteps      | 5404672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010791699 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.759        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 26380        |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    reward               | 2.5582619    |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 70.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2640         |\n",
      "|    time_elapsed         | 48842        |\n",
      "|    total_timesteps      | 5406720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011080473 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 26390        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | -1.8538283   |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 58.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2692449.17\n",
      "total_reward: 1692449.17\n",
      "total_cost: 279417.43\n",
      "total_trades: 65300\n",
      "Sharpe: 0.484\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2641        |\n",
      "|    time_elapsed         | 48861       |\n",
      "|    total_timesteps      | 5408768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003341564 |\n",
      "|    clip_fraction        | 0.00532     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 26400       |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    reward               | 1.7344606   |\n",
      "|    std                  | 16.2        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2642         |\n",
      "|    time_elapsed         | 48879        |\n",
      "|    total_timesteps      | 5410816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036962947 |\n",
      "|    clip_fraction        | 0.00474      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.788        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 26410        |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    reward               | 1.2801908    |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 57.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2643         |\n",
      "|    time_elapsed         | 48898        |\n",
      "|    total_timesteps      | 5412864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016789313 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.5         |\n",
      "|    n_updates            | 26420        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | 1.4283715    |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 55.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2644         |\n",
      "|    time_elapsed         | 48917        |\n",
      "|    total_timesteps      | 5414912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015566106 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.3         |\n",
      "|    n_updates            | 26430        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    reward               | 2.1856694    |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 63           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2645        |\n",
      "|    time_elapsed         | 48936       |\n",
      "|    total_timesteps      | 5416960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009196285 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 26440       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 0.15953058  |\n",
      "|    std                  | 16.3        |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2646         |\n",
      "|    time_elapsed         | 48955        |\n",
      "|    total_timesteps      | 5419008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021642812 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 26450        |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    reward               | 3.905838     |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 58.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2647          |\n",
      "|    time_elapsed         | 48975         |\n",
      "|    total_timesteps      | 5421056       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047903706 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -121          |\n",
      "|    explained_variance   | 0.724         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 24.5          |\n",
      "|    n_updates            | 26460         |\n",
      "|    policy_gradient_loss | -0.00109      |\n",
      "|    reward               | 2.2252686     |\n",
      "|    std                  | 16.3          |\n",
      "|    value_loss           | 69.3          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2648        |\n",
      "|    time_elapsed         | 48994       |\n",
      "|    total_timesteps      | 5423104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008420715 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 26470       |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | -1.5664202  |\n",
      "|    std                  | 16.3        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2649         |\n",
      "|    time_elapsed         | 49014        |\n",
      "|    total_timesteps      | 5425152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027101631 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 26480        |\n",
      "|    policy_gradient_loss | -0.00551     |\n",
      "|    reward               | 0.017072953  |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 57.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2650         |\n",
      "|    time_elapsed         | 49032        |\n",
      "|    total_timesteps      | 5427200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016316373 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.716        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.1         |\n",
      "|    n_updates            | 26490        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | 7.310317     |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 95.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2651         |\n",
      "|    time_elapsed         | 49051        |\n",
      "|    total_timesteps      | 5429248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016981605 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 26500        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | -0.7062081   |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 58.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2652         |\n",
      "|    time_elapsed         | 49069        |\n",
      "|    total_timesteps      | 5431296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075475303 |\n",
      "|    clip_fraction        | 0.0401       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 26510        |\n",
      "|    policy_gradient_loss | -0.00857     |\n",
      "|    reward               | 2.297087     |\n",
      "|    std                  | 16.4         |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2653         |\n",
      "|    time_elapsed         | 49088        |\n",
      "|    total_timesteps      | 5433344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044104117 |\n",
      "|    clip_fraction        | 0.00835      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 26520        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | 1.0040762    |\n",
      "|    std                  | 16.4         |\n",
      "|    value_loss           | 62.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2654         |\n",
      "|    time_elapsed         | 49106        |\n",
      "|    total_timesteps      | 5435392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024330858 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 26530        |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    reward               | 4.0390644    |\n",
      "|    std                  | 16.4         |\n",
      "|    value_loss           | 55.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3703537.58\n",
      "total_reward: 2703537.58\n",
      "total_cost: 310521.18\n",
      "total_trades: 67190\n",
      "Sharpe: 0.642\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2655        |\n",
      "|    time_elapsed         | 49125       |\n",
      "|    total_timesteps      | 5437440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009089036 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 26540       |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    reward               | -2.365373   |\n",
      "|    std                  | 16.4        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2656          |\n",
      "|    time_elapsed         | 49143         |\n",
      "|    total_timesteps      | 5439488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087279035 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -121          |\n",
      "|    explained_variance   | 0.579         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.2          |\n",
      "|    n_updates            | 26550         |\n",
      "|    policy_gradient_loss | -0.00261      |\n",
      "|    reward               | -1.2715709    |\n",
      "|    std                  | 16.4          |\n",
      "|    value_loss           | 75            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2657         |\n",
      "|    time_elapsed         | 49163        |\n",
      "|    total_timesteps      | 5441536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006699888 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.5         |\n",
      "|    n_updates            | 26560        |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    reward               | -2.4644806   |\n",
      "|    std                  | 16.4         |\n",
      "|    value_loss           | 79           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2658        |\n",
      "|    time_elapsed         | 49182       |\n",
      "|    total_timesteps      | 5443584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001413044 |\n",
      "|    clip_fraction        | 0.00239     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 26570       |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    reward               | -2.3289094  |\n",
      "|    std                  | 16.5        |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2659         |\n",
      "|    time_elapsed         | 49202        |\n",
      "|    total_timesteps      | 5445632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037954762 |\n",
      "|    clip_fraction        | 0.00581      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.757        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 26580        |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | 4.96153      |\n",
      "|    std                  | 16.4         |\n",
      "|    value_loss           | 48.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2660         |\n",
      "|    time_elapsed         | 49222        |\n",
      "|    total_timesteps      | 5447680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076149674 |\n",
      "|    clip_fraction        | 0.0444       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 26590        |\n",
      "|    policy_gradient_loss | -0.00766     |\n",
      "|    reward               | 0.022766411  |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 70           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2661         |\n",
      "|    time_elapsed         | 49241        |\n",
      "|    total_timesteps      | 5449728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027357251 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 26600        |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    reward               | 1.6161495    |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 57.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2662        |\n",
      "|    time_elapsed         | 49259       |\n",
      "|    total_timesteps      | 5451776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008137592 |\n",
      "|    clip_fraction        | 0.0583      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.65        |\n",
      "|    n_updates            | 26610       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 1.8301344   |\n",
      "|    std                  | 16.5        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2663         |\n",
      "|    time_elapsed         | 49278        |\n",
      "|    total_timesteps      | 5453824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014514711 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.733        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.9         |\n",
      "|    n_updates            | 26620        |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    reward               | -0.201868    |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 63.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2664         |\n",
      "|    time_elapsed         | 49297        |\n",
      "|    total_timesteps      | 5455872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039711026 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.0577       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.5         |\n",
      "|    n_updates            | 26630        |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    reward               | 0.9454301    |\n",
      "|    std                  | 16.6         |\n",
      "|    value_loss           | 146          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2665        |\n",
      "|    time_elapsed         | 49316       |\n",
      "|    total_timesteps      | 5457920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004179205 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 26640       |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    reward               | -0.2602321  |\n",
      "|    std                  | 16.6        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2666        |\n",
      "|    time_elapsed         | 49334       |\n",
      "|    total_timesteps      | 5459968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005340329 |\n",
      "|    clip_fraction        | 0.0298      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 26650       |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    reward               | 0.6815256   |\n",
      "|    std                  | 16.6        |\n",
      "|    value_loss           | 60.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2667         |\n",
      "|    time_elapsed         | 49352        |\n",
      "|    total_timesteps      | 5462016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015748685 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.26         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.1         |\n",
      "|    n_updates            | 26660        |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    reward               | -0.15681751  |\n",
      "|    std                  | 16.6         |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2668        |\n",
      "|    time_elapsed         | 49371       |\n",
      "|    total_timesteps      | 5464064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000279365 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 26670       |\n",
      "|    policy_gradient_loss | -0.000422   |\n",
      "|    reward               | -0.95806104 |\n",
      "|    std                  | 16.6        |\n",
      "|    value_loss           | 73.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3201181.91\n",
      "total_reward: 2201181.91\n",
      "total_cost: 290828.67\n",
      "total_trades: 66517\n",
      "Sharpe: 0.584\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2669         |\n",
      "|    time_elapsed         | 49389        |\n",
      "|    total_timesteps      | 5466112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075447867 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.39         |\n",
      "|    n_updates            | 26680        |\n",
      "|    policy_gradient_loss | -0.00779     |\n",
      "|    reward               | 1.0348964    |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 18.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2670         |\n",
      "|    time_elapsed         | 49408        |\n",
      "|    total_timesteps      | 5468160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022403626 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.5         |\n",
      "|    n_updates            | 26690        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    reward               | 1.8660784    |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 58.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2671         |\n",
      "|    time_elapsed         | 49428        |\n",
      "|    total_timesteps      | 5470208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010390701 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.9         |\n",
      "|    n_updates            | 26700        |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    reward               | 2.8383715    |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 63.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2672        |\n",
      "|    time_elapsed         | 49446       |\n",
      "|    total_timesteps      | 5472256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003359526 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.09        |\n",
      "|    n_updates            | 26710       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    reward               | 0.35781434  |\n",
      "|    std                  | 16.7        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2673         |\n",
      "|    time_elapsed         | 49465        |\n",
      "|    total_timesteps      | 5474304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027865781 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.815        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 26720        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | 5.8237867    |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 50.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2674         |\n",
      "|    time_elapsed         | 49484        |\n",
      "|    total_timesteps      | 5476352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015899248 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.2         |\n",
      "|    n_updates            | 26730        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    reward               | 2.3941677    |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 79.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2675          |\n",
      "|    time_elapsed         | 49504         |\n",
      "|    total_timesteps      | 5478400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070172007 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -122          |\n",
      "|    explained_variance   | 0.722         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.7          |\n",
      "|    n_updates            | 26740         |\n",
      "|    policy_gradient_loss | -0.00152      |\n",
      "|    reward               | -1.1135778    |\n",
      "|    std                  | 16.8          |\n",
      "|    value_loss           | 37.2          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2676        |\n",
      "|    time_elapsed         | 49524       |\n",
      "|    total_timesteps      | 5480448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008648059 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 26750       |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    reward               | 1.6080093   |\n",
      "|    std                  | 16.8        |\n",
      "|    value_loss           | 36.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2677         |\n",
      "|    time_elapsed         | 49543        |\n",
      "|    total_timesteps      | 5482496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028513037 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 26760        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | -1.1068574   |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 59.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2678          |\n",
      "|    time_elapsed         | 49562         |\n",
      "|    total_timesteps      | 5484544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017301389 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -122          |\n",
      "|    explained_variance   | 0.741         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 51.6          |\n",
      "|    n_updates            | 26770         |\n",
      "|    policy_gradient_loss | -0.000377     |\n",
      "|    reward               | -0.83424807   |\n",
      "|    std                  | 16.8          |\n",
      "|    value_loss           | 102           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2679         |\n",
      "|    time_elapsed         | 49582        |\n",
      "|    total_timesteps      | 5486592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047952207 |\n",
      "|    clip_fraction        | 0.00933      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.79         |\n",
      "|    n_updates            | 26780        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    reward               | -0.42595622  |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 26.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2680         |\n",
      "|    time_elapsed         | 49601        |\n",
      "|    total_timesteps      | 5488640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005828603 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.9         |\n",
      "|    n_updates            | 26790        |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    reward               | 0.47392577   |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 77.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2681          |\n",
      "|    time_elapsed         | 49619         |\n",
      "|    total_timesteps      | 5490688       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095294026 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -122          |\n",
      "|    explained_variance   | 0.569         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 43.2          |\n",
      "|    n_updates            | 26800         |\n",
      "|    policy_gradient_loss | -0.00247      |\n",
      "|    reward               | 5.191342      |\n",
      "|    std                  | 16.9          |\n",
      "|    value_loss           | 92.5          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2682         |\n",
      "|    time_elapsed         | 49638        |\n",
      "|    total_timesteps      | 5492736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010112296 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 26810        |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    reward               | 2.2960758    |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 31.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3815910.79\n",
      "total_reward: 2815910.79\n",
      "total_cost: 279138.72\n",
      "total_trades: 65620\n",
      "Sharpe: 0.627\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2683        |\n",
      "|    time_elapsed         | 49658       |\n",
      "|    total_timesteps      | 5494784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004440626 |\n",
      "|    clip_fraction        | 0.0115      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.7        |\n",
      "|    n_updates            | 26820       |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    reward               | 3.030801    |\n",
      "|    std                  | 16.9        |\n",
      "|    value_loss           | 80.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2684         |\n",
      "|    time_elapsed         | 49677        |\n",
      "|    total_timesteps      | 5496832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010019871 |\n",
      "|    clip_fraction        | 0.00493      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.5         |\n",
      "|    n_updates            | 26830        |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    reward               | -0.030678801 |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 95           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2685          |\n",
      "|    time_elapsed         | 49697         |\n",
      "|    total_timesteps      | 5498880       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051986147 |\n",
      "|    clip_fraction        | 0.000928      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -122          |\n",
      "|    explained_variance   | 0.681         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 44.1          |\n",
      "|    n_updates            | 26840         |\n",
      "|    policy_gradient_loss | -0.00105      |\n",
      "|    reward               | 0.71261036    |\n",
      "|    std                  | 16.9          |\n",
      "|    value_loss           | 100           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2686        |\n",
      "|    time_elapsed         | 49715       |\n",
      "|    total_timesteps      | 5500928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011414737 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.63        |\n",
      "|    n_updates            | 26850       |\n",
      "|    policy_gradient_loss | -0.00955    |\n",
      "|    reward               | 1.0758697   |\n",
      "|    std                  | 17          |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2687         |\n",
      "|    time_elapsed         | 49734        |\n",
      "|    total_timesteps      | 5502976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010207896 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.9         |\n",
      "|    n_updates            | 26860        |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    reward               | 1.3453641    |\n",
      "|    std                  | 17           |\n",
      "|    value_loss           | 83.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2688         |\n",
      "|    time_elapsed         | 49784        |\n",
      "|    total_timesteps      | 5505024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018462297 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.779        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 26870        |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    reward               | 1.6317145    |\n",
      "|    std                  | 17           |\n",
      "|    value_loss           | 73.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2689         |\n",
      "|    time_elapsed         | 49802        |\n",
      "|    total_timesteps      | 5507072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027356825 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 26880        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | -2.5729322   |\n",
      "|    std                  | 17           |\n",
      "|    value_loss           | 40.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2690         |\n",
      "|    time_elapsed         | 49821        |\n",
      "|    total_timesteps      | 5509120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059619527 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.811        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 26890        |\n",
      "|    policy_gradient_loss | -0.00714     |\n",
      "|    reward               | -1.2450794   |\n",
      "|    std                  | 17           |\n",
      "|    value_loss           | 60.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2691         |\n",
      "|    time_elapsed         | 49839        |\n",
      "|    total_timesteps      | 5511168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011955781 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 26900        |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    reward               | -0.10067186  |\n",
      "|    std                  | 17           |\n",
      "|    value_loss           | 68.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2692          |\n",
      "|    time_elapsed         | 49857         |\n",
      "|    total_timesteps      | 5513216       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062754675 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -122          |\n",
      "|    explained_variance   | 0.823         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.8          |\n",
      "|    n_updates            | 26910         |\n",
      "|    policy_gradient_loss | -0.00139      |\n",
      "|    reward               | -0.087943844  |\n",
      "|    std                  | 17            |\n",
      "|    value_loss           | 74.3          |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2693       |\n",
      "|    time_elapsed         | 49876      |\n",
      "|    total_timesteps      | 5515264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00905255 |\n",
      "|    clip_fraction        | 0.0719     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -122       |\n",
      "|    explained_variance   | 0.535      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.07       |\n",
      "|    n_updates            | 26920      |\n",
      "|    policy_gradient_loss | -0.00906   |\n",
      "|    reward               | 4.6285996  |\n",
      "|    std                  | 17         |\n",
      "|    value_loss           | 20.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2694         |\n",
      "|    time_elapsed         | 49894        |\n",
      "|    total_timesteps      | 5517312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029160986 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38           |\n",
      "|    n_updates            | 26930        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | 3.5759168    |\n",
      "|    std                  | 17.1         |\n",
      "|    value_loss           | 75.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2695         |\n",
      "|    time_elapsed         | 49913        |\n",
      "|    total_timesteps      | 5519360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016608088 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.4         |\n",
      "|    n_updates            | 26940        |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    reward               | -8.486957    |\n",
      "|    std                  | 17.1         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2696         |\n",
      "|    time_elapsed         | 49932        |\n",
      "|    total_timesteps      | 5521408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034205716 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 26950        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    reward               | -0.5866299   |\n",
      "|    std                  | 17.1         |\n",
      "|    value_loss           | 37.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3084134.19\n",
      "total_reward: 2084134.19\n",
      "total_cost: 297683.27\n",
      "total_trades: 66707\n",
      "Sharpe: 0.540\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2697          |\n",
      "|    time_elapsed         | 49951         |\n",
      "|    total_timesteps      | 5523456       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031976736 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -122          |\n",
      "|    explained_variance   | 0.686         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 38.9          |\n",
      "|    n_updates            | 26960         |\n",
      "|    policy_gradient_loss | -0.00162      |\n",
      "|    reward               | 1.0171075     |\n",
      "|    std                  | 17.1          |\n",
      "|    value_loss           | 74.3          |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2698       |\n",
      "|    time_elapsed         | 49970      |\n",
      "|    total_timesteps      | 5525504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00030872 |\n",
      "|    clip_fraction        | 0.000146   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -122       |\n",
      "|    explained_variance   | 0.787      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.2       |\n",
      "|    n_updates            | 26970      |\n",
      "|    policy_gradient_loss | -0.00103   |\n",
      "|    reward               | 0.8484363  |\n",
      "|    std                  | 17.1       |\n",
      "|    value_loss           | 98.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2699        |\n",
      "|    time_elapsed         | 49989       |\n",
      "|    total_timesteps      | 5527552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002221895 |\n",
      "|    clip_fraction        | 0.00557     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 26980       |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    reward               | -0.412001   |\n",
      "|    std                  | 17.1        |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2700         |\n",
      "|    time_elapsed         | 50008        |\n",
      "|    total_timesteps      | 5529600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041128816 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.807        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.4         |\n",
      "|    n_updates            | 26990        |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    reward               | 1.3213621    |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 48.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2701        |\n",
      "|    time_elapsed         | 50028       |\n",
      "|    total_timesteps      | 5531648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000358743 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 27000       |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    reward               | -1.5254602  |\n",
      "|    std                  | 17.2        |\n",
      "|    value_loss           | 98.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2702         |\n",
      "|    time_elapsed         | 50047        |\n",
      "|    total_timesteps      | 5533696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003785579 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.3         |\n",
      "|    n_updates            | 27010        |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    reward               | 2.1719644    |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 92.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2703        |\n",
      "|    time_elapsed         | 50066       |\n",
      "|    total_timesteps      | 5535744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007256698 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 27020       |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    reward               | 1.9459639   |\n",
      "|    std                  | 17.2        |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2704         |\n",
      "|    time_elapsed         | 50084        |\n",
      "|    total_timesteps      | 5537792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008418069 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.842        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 27030        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | 1.1580346    |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 62.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2705         |\n",
      "|    time_elapsed         | 50102        |\n",
      "|    total_timesteps      | 5539840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046314085 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.291        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 85           |\n",
      "|    n_updates            | 27040        |\n",
      "|    policy_gradient_loss | -0.00856     |\n",
      "|    reward               | 1.0575528    |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2706         |\n",
      "|    time_elapsed         | 50121        |\n",
      "|    total_timesteps      | 5541888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013589908 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.405        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 27050        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    reward               | 1.1245198    |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 54.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2707         |\n",
      "|    time_elapsed         | 50139        |\n",
      "|    total_timesteps      | 5543936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025691225 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.2         |\n",
      "|    n_updates            | 27060        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | -0.2522076   |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 68.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2708         |\n",
      "|    time_elapsed         | 50158        |\n",
      "|    total_timesteps      | 5545984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014462987 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 27070        |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    reward               | 0.29662442   |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 79.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2709         |\n",
      "|    time_elapsed         | 50176        |\n",
      "|    total_timesteps      | 5548032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013975188 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.4         |\n",
      "|    n_updates            | 27080        |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    reward               | -1.2594495   |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 80.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2710         |\n",
      "|    time_elapsed         | 50195        |\n",
      "|    total_timesteps      | 5550080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030715019 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 27090        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | -5.164179    |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 26.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3196101.47\n",
      "total_reward: 2196101.47\n",
      "total_cost: 297681.81\n",
      "total_trades: 67093\n",
      "Sharpe: 0.556\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2711        |\n",
      "|    time_elapsed         | 50213       |\n",
      "|    total_timesteps      | 5552128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000649019 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.803       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.2        |\n",
      "|    n_updates            | 27100       |\n",
      "|    policy_gradient_loss | -0.00129    |\n",
      "|    reward               | 0.28845838  |\n",
      "|    std                  | 17.3        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2712        |\n",
      "|    time_elapsed         | 50231       |\n",
      "|    total_timesteps      | 5554176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002270344 |\n",
      "|    clip_fraction        | 0.00396     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 27110       |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    reward               | -9.308324   |\n",
      "|    std                  | 17.3        |\n",
      "|    value_loss           | 61.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2713         |\n",
      "|    time_elapsed         | 50250        |\n",
      "|    total_timesteps      | 5556224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004180501  |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.9         |\n",
      "|    n_updates            | 27120        |\n",
      "|    policy_gradient_loss | -0.00504     |\n",
      "|    reward               | -0.080474384 |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 28.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2714         |\n",
      "|    time_elapsed         | 50268        |\n",
      "|    total_timesteps      | 5558272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063187154 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 27130        |\n",
      "|    policy_gradient_loss | -0.00665     |\n",
      "|    reward               | 0.021981748  |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 62.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2715         |\n",
      "|    time_elapsed         | 50286        |\n",
      "|    total_timesteps      | 5560320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030425438 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.853        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 27140        |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    reward               | 12.76368     |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 60.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2716          |\n",
      "|    time_elapsed         | 50305         |\n",
      "|    total_timesteps      | 5562368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030782924 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -123          |\n",
      "|    explained_variance   | 0.811         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 27.5          |\n",
      "|    n_updates            | 27150         |\n",
      "|    policy_gradient_loss | -0.000925     |\n",
      "|    reward               | -0.6403673    |\n",
      "|    std                  | 17.4          |\n",
      "|    value_loss           | 63.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2717         |\n",
      "|    time_elapsed         | 50323        |\n",
      "|    total_timesteps      | 5564416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066913757 |\n",
      "|    clip_fraction        | 0.0287       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.76         |\n",
      "|    n_updates            | 27160        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    reward               | -0.6462564   |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2718         |\n",
      "|    time_elapsed         | 50342        |\n",
      "|    total_timesteps      | 5566464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019801324 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.858        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 27170        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | 2.616583     |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 58.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2719         |\n",
      "|    time_elapsed         | 50361        |\n",
      "|    total_timesteps      | 5568512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021978396 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.7         |\n",
      "|    n_updates            | 27180        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    reward               | -2.25987     |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 71.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2720        |\n",
      "|    time_elapsed         | 50379       |\n",
      "|    total_timesteps      | 5570560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007350559 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 27190       |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    reward               | -0.45180574 |\n",
      "|    std                  | 17.4        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2721         |\n",
      "|    time_elapsed         | 50398        |\n",
      "|    total_timesteps      | 5572608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057180533 |\n",
      "|    clip_fraction        | 0.0252       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.6         |\n",
      "|    n_updates            | 27200        |\n",
      "|    policy_gradient_loss | -0.00757     |\n",
      "|    reward               | -2.9714139   |\n",
      "|    std                  | 17.5         |\n",
      "|    value_loss           | 56.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2722          |\n",
      "|    time_elapsed         | 50417         |\n",
      "|    total_timesteps      | 5574656       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00088640396 |\n",
      "|    clip_fraction        | 0.000732      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -123          |\n",
      "|    explained_variance   | 0.654         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.6          |\n",
      "|    n_updates            | 27210         |\n",
      "|    policy_gradient_loss | -0.00161      |\n",
      "|    reward               | -1.9060024    |\n",
      "|    std                  | 17.5          |\n",
      "|    value_loss           | 63.1          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2723        |\n",
      "|    time_elapsed         | 50435       |\n",
      "|    total_timesteps      | 5576704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002521948 |\n",
      "|    clip_fraction        | 0.00386     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 27220       |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    reward               | 1.7235221   |\n",
      "|    std                  | 17.5        |\n",
      "|    value_loss           | 42.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2724        |\n",
      "|    time_elapsed         | 50454       |\n",
      "|    total_timesteps      | 5578752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008763427 |\n",
      "|    clip_fraction        | 0.0441      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 27230       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 1.48878     |\n",
      "|    std                  | 17.6        |\n",
      "|    value_loss           | 49.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3959070.84\n",
      "total_reward: 2959070.84\n",
      "total_cost: 344689.15\n",
      "total_trades: 68593\n",
      "Sharpe: 0.759\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2725         |\n",
      "|    time_elapsed         | 50473        |\n",
      "|    total_timesteps      | 5580800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035974374 |\n",
      "|    clip_fraction        | 0.00962      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 27240        |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    reward               | 2.1370192    |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 60.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2726         |\n",
      "|    time_elapsed         | 50491        |\n",
      "|    total_timesteps      | 5582848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028533693 |\n",
      "|    clip_fraction        | 0.00962      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.4         |\n",
      "|    n_updates            | 27250        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | 1.3145471    |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 60.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2727        |\n",
      "|    time_elapsed         | 50509       |\n",
      "|    total_timesteps      | 5584896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008966835 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.41        |\n",
      "|    n_updates            | 27260       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -2.4069586  |\n",
      "|    std                  | 17.5        |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2728         |\n",
      "|    time_elapsed         | 50528        |\n",
      "|    total_timesteps      | 5586944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064874757 |\n",
      "|    clip_fraction        | 0.0283       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.752        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 27270        |\n",
      "|    policy_gradient_loss | -0.00926     |\n",
      "|    reward               | 0.52284914   |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 41.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2729         |\n",
      "|    time_elapsed         | 50546        |\n",
      "|    total_timesteps      | 5588992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026246859 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.348        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.9         |\n",
      "|    n_updates            | 27280        |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    reward               | 0.46196225   |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 80.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2730        |\n",
      "|    time_elapsed         | 50565       |\n",
      "|    total_timesteps      | 5591040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004606113 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 27290       |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    reward               | -2.9567206  |\n",
      "|    std                  | 17.6        |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2731        |\n",
      "|    time_elapsed         | 50583       |\n",
      "|    total_timesteps      | 5593088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004456235 |\n",
      "|    clip_fraction        | 0.0214      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 27300       |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    reward               | 0.7988274   |\n",
      "|    std                  | 17.6        |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2732         |\n",
      "|    time_elapsed         | 50601        |\n",
      "|    total_timesteps      | 5595136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061479546 |\n",
      "|    clip_fraction        | 0.0421       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.243        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 27310        |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    reward               | 1.4253724    |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 58.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2733        |\n",
      "|    time_elapsed         | 50620       |\n",
      "|    total_timesteps      | 5597184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004149631 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 27320       |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    reward               | 1.1764867   |\n",
      "|    std                  | 17.7        |\n",
      "|    value_loss           | 69.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2734        |\n",
      "|    time_elapsed         | 50638       |\n",
      "|    total_timesteps      | 5599232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010140337 |\n",
      "|    clip_fraction        | 0.098       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | -0.0382     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 27330       |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    reward               | 5.152972    |\n",
      "|    std                  | 17.7        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2735         |\n",
      "|    time_elapsed         | 50656        |\n",
      "|    total_timesteps      | 5601280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048261303 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.0208       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.8         |\n",
      "|    n_updates            | 27340        |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    reward               | 0.75991374   |\n",
      "|    std                  | 17.7         |\n",
      "|    value_loss           | 139          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2736          |\n",
      "|    time_elapsed         | 50675         |\n",
      "|    total_timesteps      | 5603328       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081527093 |\n",
      "|    clip_fraction        | 0.0019        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -123          |\n",
      "|    explained_variance   | 0.374         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 52.9          |\n",
      "|    n_updates            | 27350         |\n",
      "|    policy_gradient_loss | -0.000641     |\n",
      "|    reward               | 7.886141      |\n",
      "|    std                  | 17.8          |\n",
      "|    value_loss           | 97.4          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2737        |\n",
      "|    time_elapsed         | 50693       |\n",
      "|    total_timesteps      | 5605376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005848461 |\n",
      "|    clip_fraction        | 0.0323      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 27360       |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    reward               | 0.15085174  |\n",
      "|    std                  | 17.8        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2738        |\n",
      "|    time_elapsed         | 50711       |\n",
      "|    total_timesteps      | 5607424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001894682 |\n",
      "|    clip_fraction        | 0.00483     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 27370       |\n",
      "|    policy_gradient_loss | -0.00224    |\n",
      "|    reward               | 0.44265276  |\n",
      "|    std                  | 17.8        |\n",
      "|    value_loss           | 60.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2739          |\n",
      "|    time_elapsed         | 50729         |\n",
      "|    total_timesteps      | 5609472       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00065218733 |\n",
      "|    clip_fraction        | 0.00137       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -123          |\n",
      "|    explained_variance   | 0.713         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29            |\n",
      "|    n_updates            | 27380         |\n",
      "|    policy_gradient_loss | -0.00165      |\n",
      "|    reward               | 6.734258      |\n",
      "|    std                  | 17.8          |\n",
      "|    value_loss           | 70            |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3201880.50\n",
      "total_reward: 2201880.50\n",
      "total_cost: 363081.42\n",
      "total_trades: 69737\n",
      "Sharpe: 0.604\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2740         |\n",
      "|    time_elapsed         | 50748        |\n",
      "|    total_timesteps      | 5611520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024780193 |\n",
      "|    clip_fraction        | 0.00713      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 27390        |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    reward               | 0.07380597   |\n",
      "|    std                  | 17.8         |\n",
      "|    value_loss           | 46.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2741        |\n",
      "|    time_elapsed         | 50767       |\n",
      "|    total_timesteps      | 5613568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008923352 |\n",
      "|    clip_fraction        | 0.0599      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.73        |\n",
      "|    n_updates            | 27400       |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    reward               | 0.19546914  |\n",
      "|    std                  | 17.8        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2742         |\n",
      "|    time_elapsed         | 50786        |\n",
      "|    total_timesteps      | 5615616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060406197 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 27410        |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    reward               | 0.2842074    |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 43.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2743         |\n",
      "|    time_elapsed         | 50804        |\n",
      "|    total_timesteps      | 5617664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018892514 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 27420        |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    reward               | 4.315609     |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2744         |\n",
      "|    time_elapsed         | 50823        |\n",
      "|    total_timesteps      | 5619712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047457917 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.32         |\n",
      "|    n_updates            | 27430        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | 1.0480144    |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 26.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2745         |\n",
      "|    time_elapsed         | 50841        |\n",
      "|    total_timesteps      | 5621760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029400277 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.9         |\n",
      "|    n_updates            | 27440        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | -0.40233216  |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 57.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2746         |\n",
      "|    time_elapsed         | 50859        |\n",
      "|    total_timesteps      | 5623808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037674978 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.707        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.9         |\n",
      "|    n_updates            | 27450        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    reward               | -6.2424507   |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 45.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2747         |\n",
      "|    time_elapsed         | 50878        |\n",
      "|    total_timesteps      | 5625856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036230977 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.15         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 27460        |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    reward               | -0.027008358 |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 47.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2748         |\n",
      "|    time_elapsed         | 50896        |\n",
      "|    total_timesteps      | 5627904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049733752 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.252        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.4         |\n",
      "|    n_updates            | 27470        |\n",
      "|    policy_gradient_loss | -0.00711     |\n",
      "|    reward               | -0.50448096  |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 85           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2749         |\n",
      "|    time_elapsed         | 50914        |\n",
      "|    total_timesteps      | 5629952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037651567 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 27480        |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    reward               | -0.12921417  |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 64.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2750        |\n",
      "|    time_elapsed         | 50933       |\n",
      "|    total_timesteps      | 5632000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004435123 |\n",
      "|    clip_fraction        | 0.028       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62          |\n",
      "|    n_updates            | 27490       |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    reward               | -2.198467   |\n",
      "|    std                  | 18          |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2751       |\n",
      "|    time_elapsed         | 50952      |\n",
      "|    total_timesteps      | 5634048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01449191 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -124       |\n",
      "|    explained_variance   | 0.00489    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.3       |\n",
      "|    n_updates            | 27500      |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    reward               | -1.5370592 |\n",
      "|    std                  | 18         |\n",
      "|    value_loss           | 32.1       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2752         |\n",
      "|    time_elapsed         | 50970        |\n",
      "|    total_timesteps      | 5636096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051956093 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.249        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.2         |\n",
      "|    n_updates            | 27510        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | 2.2898278    |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2753        |\n",
      "|    time_elapsed         | 50989       |\n",
      "|    total_timesteps      | 5638144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006261096 |\n",
      "|    clip_fraction        | 0.0338      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 27520       |\n",
      "|    policy_gradient_loss | -0.00545    |\n",
      "|    reward               | -1.0588809  |\n",
      "|    std                  | 18.1        |\n",
      "|    value_loss           | 96.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3654047.76\n",
      "total_reward: 2654047.76\n",
      "total_cost: 374858.96\n",
      "total_trades: 70345\n",
      "Sharpe: 0.672\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2754         |\n",
      "|    time_elapsed         | 51007        |\n",
      "|    total_timesteps      | 5640192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031323996 |\n",
      "|    clip_fraction        | 0.00913      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.412        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 27530        |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    reward               | -0.015961813 |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 43           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2755         |\n",
      "|    time_elapsed         | 51026        |\n",
      "|    total_timesteps      | 5642240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037018824 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.8         |\n",
      "|    n_updates            | 27540        |\n",
      "|    policy_gradient_loss | -0.0064      |\n",
      "|    reward               | -0.67750466  |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 56.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2756         |\n",
      "|    time_elapsed         | 51044        |\n",
      "|    total_timesteps      | 5644288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027249043 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.1         |\n",
      "|    n_updates            | 27550        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    reward               | 2.7149758    |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 65.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2757         |\n",
      "|    time_elapsed         | 51064        |\n",
      "|    total_timesteps      | 5646336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048555927 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 27560        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    reward               | -2.7064939   |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 50.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2758        |\n",
      "|    time_elapsed         | 51082       |\n",
      "|    total_timesteps      | 5648384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007972149 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.0856      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 27570       |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    reward               | -0.24087854 |\n",
      "|    std                  | 18.2        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2759        |\n",
      "|    time_elapsed         | 51101       |\n",
      "|    total_timesteps      | 5650432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002088332 |\n",
      "|    clip_fraction        | 0.00376     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 27580       |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | -0.9299078  |\n",
      "|    std                  | 18.2        |\n",
      "|    value_loss           | 96.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2760         |\n",
      "|    time_elapsed         | 51120        |\n",
      "|    total_timesteps      | 5652480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012556595 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 27590        |\n",
      "|    policy_gradient_loss | -0.000976    |\n",
      "|    reward               | 0.8242405    |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 56.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2761         |\n",
      "|    time_elapsed         | 51138        |\n",
      "|    total_timesteps      | 5654528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036533428 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 27600        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    reward               | 1.9328122    |\n",
      "|    std                  | 18.3         |\n",
      "|    value_loss           | 25           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2762         |\n",
      "|    time_elapsed         | 51157        |\n",
      "|    total_timesteps      | 5656576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038893071 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.6         |\n",
      "|    n_updates            | 27610        |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | 2.4114087    |\n",
      "|    std                  | 18.3         |\n",
      "|    value_loss           | 50.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2763         |\n",
      "|    time_elapsed         | 51176        |\n",
      "|    total_timesteps      | 5658624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038036183 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.6         |\n",
      "|    n_updates            | 27620        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | -9.146898    |\n",
      "|    std                  | 18.3         |\n",
      "|    value_loss           | 49           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2764         |\n",
      "|    time_elapsed         | 51195        |\n",
      "|    total_timesteps      | 5660672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016790854 |\n",
      "|    clip_fraction        | 0.00947      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 27630        |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    reward               | -0.41671467  |\n",
      "|    std                  | 18.3         |\n",
      "|    value_loss           | 48.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2765        |\n",
      "|    time_elapsed         | 51214       |\n",
      "|    total_timesteps      | 5662720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008162885 |\n",
      "|    clip_fraction        | 0.0396      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 27640       |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    reward               | -1.5436689  |\n",
      "|    std                  | 18.4        |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2766        |\n",
      "|    time_elapsed         | 51232       |\n",
      "|    total_timesteps      | 5664768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003529165 |\n",
      "|    clip_fraction        | 0.0183      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 27650       |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    reward               | -3.1430008  |\n",
      "|    std                  | 18.4        |\n",
      "|    value_loss           | 56.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2767          |\n",
      "|    time_elapsed         | 51251         |\n",
      "|    total_timesteps      | 5666816       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025135608 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -124          |\n",
      "|    explained_variance   | 0.638         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.3          |\n",
      "|    n_updates            | 27660         |\n",
      "|    policy_gradient_loss | -0.0013       |\n",
      "|    reward               | 10.272075     |\n",
      "|    std                  | 18.4          |\n",
      "|    value_loss           | 52.1          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3481662.84\n",
      "total_reward: 2481662.84\n",
      "total_cost: 309377.63\n",
      "total_trades: 67037\n",
      "Sharpe: 0.607\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2768        |\n",
      "|    time_elapsed         | 51269       |\n",
      "|    total_timesteps      | 5668864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004466231 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 27670       |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    reward               | -1.3796314  |\n",
      "|    std                  | 18.4        |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2769          |\n",
      "|    time_elapsed         | 51288         |\n",
      "|    total_timesteps      | 5670912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00078055635 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -124          |\n",
      "|    explained_variance   | 0.723         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 35.6          |\n",
      "|    n_updates            | 27680         |\n",
      "|    policy_gradient_loss | -0.000537     |\n",
      "|    reward               | 1.8399367     |\n",
      "|    std                  | 18.4          |\n",
      "|    value_loss           | 72.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2770         |\n",
      "|    time_elapsed         | 51306        |\n",
      "|    total_timesteps      | 5672960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019120873 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.6         |\n",
      "|    n_updates            | 27690        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | -6.59624     |\n",
      "|    std                  | 18.4         |\n",
      "|    value_loss           | 79.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2771         |\n",
      "|    time_elapsed         | 51325        |\n",
      "|    total_timesteps      | 5675008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015569736 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.189        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 27700        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | 1.7676835    |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 45.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2772         |\n",
      "|    time_elapsed         | 51343        |\n",
      "|    total_timesteps      | 5677056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065937703 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 27710        |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    reward               | 0.8604445    |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 42.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2773         |\n",
      "|    time_elapsed         | 51363        |\n",
      "|    total_timesteps      | 5679104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027177578 |\n",
      "|    clip_fraction        | 0.00811      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 27720        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | 0.36006087   |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 53           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2774         |\n",
      "|    time_elapsed         | 51382        |\n",
      "|    total_timesteps      | 5681152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008844723 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19           |\n",
      "|    n_updates            | 27730        |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    reward               | 1.7141647    |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 71.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2775        |\n",
      "|    time_elapsed         | 51400       |\n",
      "|    total_timesteps      | 5683200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009907881 |\n",
      "|    clip_fraction        | 0.0871      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.49        |\n",
      "|    n_updates            | 27740       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 1.0276326   |\n",
      "|    std                  | 18.6        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2776         |\n",
      "|    time_elapsed         | 51419        |\n",
      "|    total_timesteps      | 5685248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011581107 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.7         |\n",
      "|    n_updates            | 27750        |\n",
      "|    policy_gradient_loss | -0.000898    |\n",
      "|    reward               | 0.068428375  |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 68.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2777         |\n",
      "|    time_elapsed         | 51438        |\n",
      "|    total_timesteps      | 5687296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010579638 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 27760        |\n",
      "|    policy_gradient_loss | -0.000822    |\n",
      "|    reward               | 1.2145405    |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 65.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2778        |\n",
      "|    time_elapsed         | 51457       |\n",
      "|    total_timesteps      | 5689344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004693582 |\n",
      "|    clip_fraction        | 0.0228      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 27770       |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    reward               | -1.5937766  |\n",
      "|    std                  | 18.7        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2779        |\n",
      "|    time_elapsed         | 51476       |\n",
      "|    total_timesteps      | 5691392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008590678 |\n",
      "|    clip_fraction        | 0.0337      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 27780       |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    reward               | -1.8004413  |\n",
      "|    std                  | 18.7        |\n",
      "|    value_loss           | 37.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2780         |\n",
      "|    time_elapsed         | 51494        |\n",
      "|    total_timesteps      | 5693440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015383426 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.2         |\n",
      "|    n_updates            | 27790        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    reward               | 0.2738288    |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 60.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2781          |\n",
      "|    time_elapsed         | 51513         |\n",
      "|    total_timesteps      | 5695488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00083325675 |\n",
      "|    clip_fraction        | 0.00215       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -125          |\n",
      "|    explained_variance   | 0.63          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.7          |\n",
      "|    n_updates            | 27800         |\n",
      "|    policy_gradient_loss | -0.00168      |\n",
      "|    reward               | -1.0563041    |\n",
      "|    std                  | 18.7          |\n",
      "|    value_loss           | 60.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2972996.36\n",
      "total_reward: 1972996.36\n",
      "total_cost: 308811.39\n",
      "total_trades: 66948\n",
      "Sharpe: 0.538\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2782        |\n",
      "|    time_elapsed         | 51533       |\n",
      "|    total_timesteps      | 5697536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006975171 |\n",
      "|    clip_fraction        | 0.0279      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 27810       |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    reward               | -0.23072648 |\n",
      "|    std                  | 18.7        |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2783         |\n",
      "|    time_elapsed         | 51552        |\n",
      "|    total_timesteps      | 5699584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014661397 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 27820        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    reward               | -5.050238    |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 53.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2784         |\n",
      "|    time_elapsed         | 51572        |\n",
      "|    total_timesteps      | 5701632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007241467 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.681        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.9         |\n",
      "|    n_updates            | 27830        |\n",
      "|    policy_gradient_loss | -0.000943    |\n",
      "|    reward               | 9.663675     |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 59.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2785         |\n",
      "|    time_elapsed         | 51591        |\n",
      "|    total_timesteps      | 5703680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019065463 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.104        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 27840        |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    reward               | 2.777576     |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2786         |\n",
      "|    time_elapsed         | 51610        |\n",
      "|    total_timesteps      | 5705728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019300099 |\n",
      "|    clip_fraction        | 0.00474      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.336        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.9         |\n",
      "|    n_updates            | 27850        |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    reward               | 6.1723404    |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 83.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2787         |\n",
      "|    time_elapsed         | 51630        |\n",
      "|    total_timesteps      | 5707776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026241108 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.5         |\n",
      "|    n_updates            | 27860        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | -5.1965795   |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 73.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2788         |\n",
      "|    time_elapsed         | 51649        |\n",
      "|    total_timesteps      | 5709824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007181231 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.646        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27           |\n",
      "|    n_updates            | 27870        |\n",
      "|    policy_gradient_loss | -0.000727    |\n",
      "|    reward               | -5.1102567   |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 61.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2789        |\n",
      "|    time_elapsed         | 51668       |\n",
      "|    total_timesteps      | 5711872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009702003 |\n",
      "|    clip_fraction        | 0.0644      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 27880       |\n",
      "|    policy_gradient_loss | -0.00814    |\n",
      "|    reward               | 2.6466007   |\n",
      "|    std                  | 18.8        |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2790         |\n",
      "|    time_elapsed         | 51687        |\n",
      "|    total_timesteps      | 5713920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013175902 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 27890        |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    reward               | 0.4243827    |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 60.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2791         |\n",
      "|    time_elapsed         | 51706        |\n",
      "|    total_timesteps      | 5715968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030524256 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.1         |\n",
      "|    n_updates            | 27900        |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    reward               | 6.087703     |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 55.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2792        |\n",
      "|    time_elapsed         | 51726       |\n",
      "|    total_timesteps      | 5718016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008028707 |\n",
      "|    clip_fraction        | 0.0386      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 27910       |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    reward               | 1.065977    |\n",
      "|    std                  | 18.9        |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2793         |\n",
      "|    time_elapsed         | 51746        |\n",
      "|    total_timesteps      | 5720064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025277943 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 27920        |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    reward               | 0.75790644   |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 57.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2794         |\n",
      "|    time_elapsed         | 51765        |\n",
      "|    total_timesteps      | 5722112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018081525 |\n",
      "|    clip_fraction        | 0.00542      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 27930        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | -3.9810052   |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 59.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2795         |\n",
      "|    time_elapsed         | 51784        |\n",
      "|    total_timesteps      | 5724160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024858923 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 27940        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | -4.400263    |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 37.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2826273.29\n",
      "total_reward: 1826273.29\n",
      "total_cost: 314712.78\n",
      "total_trades: 67373\n",
      "Sharpe: 0.518\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2796         |\n",
      "|    time_elapsed         | 51803        |\n",
      "|    total_timesteps      | 5726208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055562323 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 27950        |\n",
      "|    policy_gradient_loss | -0.00713     |\n",
      "|    reward               | -1.0749141   |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 37.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2797         |\n",
      "|    time_elapsed         | 51821        |\n",
      "|    total_timesteps      | 5728256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024682302 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.9         |\n",
      "|    n_updates            | 27960        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | -0.1486137   |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 62.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2798          |\n",
      "|    time_elapsed         | 51841         |\n",
      "|    total_timesteps      | 5730304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061974674 |\n",
      "|    clip_fraction        | 0.00122       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -125          |\n",
      "|    explained_variance   | 0.672         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 33.4          |\n",
      "|    n_updates            | 27970         |\n",
      "|    policy_gradient_loss | -0.000226     |\n",
      "|    reward               | -0.80393964   |\n",
      "|    std                  | 19            |\n",
      "|    value_loss           | 63.8          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2799        |\n",
      "|    time_elapsed         | 51860       |\n",
      "|    total_timesteps      | 5732352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008299398 |\n",
      "|    clip_fraction        | 0.0402      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 27980       |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    reward               | 0.81628895  |\n",
      "|    std                  | 19          |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2800         |\n",
      "|    time_elapsed         | 51879        |\n",
      "|    total_timesteps      | 5734400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035203032 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.1         |\n",
      "|    n_updates            | 27990        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    reward               | 2.4928675    |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 57.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2801         |\n",
      "|    time_elapsed         | 51898        |\n",
      "|    total_timesteps      | 5736448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007045857 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.4         |\n",
      "|    n_updates            | 28000        |\n",
      "|    policy_gradient_loss | -0.00071     |\n",
      "|    reward               | 3.420739     |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 82.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2802         |\n",
      "|    time_elapsed         | 51916        |\n",
      "|    total_timesteps      | 5738496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018905805 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 28010        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    reward               | -4.702526    |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 40.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2803        |\n",
      "|    time_elapsed         | 51935       |\n",
      "|    total_timesteps      | 5740544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007838609 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.784       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 28020       |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    reward               | -1.2307241  |\n",
      "|    std                  | 19.1        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2804         |\n",
      "|    time_elapsed         | 51954        |\n",
      "|    total_timesteps      | 5742592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028495467 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 28030        |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    reward               | -0.49320322  |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 51.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2805         |\n",
      "|    time_elapsed         | 51973        |\n",
      "|    total_timesteps      | 5744640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014842725 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.2         |\n",
      "|    n_updates            | 28040        |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    reward               | -1.0179305   |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 50.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2806        |\n",
      "|    time_elapsed         | 51991       |\n",
      "|    total_timesteps      | 5746688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00836591  |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 28050       |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    reward               | -0.82508844 |\n",
      "|    std                  | 19.1        |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2807          |\n",
      "|    time_elapsed         | 52010         |\n",
      "|    total_timesteps      | 5748736       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046869303 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -125          |\n",
      "|    explained_variance   | 0.645         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 35.2          |\n",
      "|    n_updates            | 28060         |\n",
      "|    policy_gradient_loss | -0.000835     |\n",
      "|    reward               | -1.2224444    |\n",
      "|    std                  | 19.1          |\n",
      "|    value_loss           | 66.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2808          |\n",
      "|    time_elapsed         | 52028         |\n",
      "|    total_timesteps      | 5750784       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038189668 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -125          |\n",
      "|    explained_variance   | 0.592         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 34.1          |\n",
      "|    n_updates            | 28070         |\n",
      "|    policy_gradient_loss | -0.00141      |\n",
      "|    reward               | 0.15736835    |\n",
      "|    std                  | 19.1          |\n",
      "|    value_loss           | 71.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2809         |\n",
      "|    time_elapsed         | 52048        |\n",
      "|    total_timesteps      | 5752832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055231387 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.332        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 28080        |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    reward               | -2.1112864   |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 28.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3445225.11\n",
      "total_reward: 2445225.11\n",
      "total_cost: 314929.61\n",
      "total_trades: 67274\n",
      "Sharpe: 0.582\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2810         |\n",
      "|    time_elapsed         | 52067        |\n",
      "|    total_timesteps      | 5754880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053436467 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 28090        |\n",
      "|    policy_gradient_loss | -0.00603     |\n",
      "|    reward               | -4.2727304   |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2811         |\n",
      "|    time_elapsed         | 52087        |\n",
      "|    total_timesteps      | 5756928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029146038 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.152        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.1         |\n",
      "|    n_updates            | 28100        |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    reward               | 3.341025     |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2812         |\n",
      "|    time_elapsed         | 52105        |\n",
      "|    total_timesteps      | 5758976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009291206 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.364        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 28110        |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    reward               | 0.1126692    |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 51.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2813         |\n",
      "|    time_elapsed         | 52125        |\n",
      "|    total_timesteps      | 5761024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048030773 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22           |\n",
      "|    n_updates            | 28120        |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    reward               | 1.3524289    |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 43.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2814         |\n",
      "|    time_elapsed         | 52144        |\n",
      "|    total_timesteps      | 5763072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021710005 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 28130        |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    reward               | 0.13278052   |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 39.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2815          |\n",
      "|    time_elapsed         | 52162         |\n",
      "|    total_timesteps      | 5765120       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047152583 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -125          |\n",
      "|    explained_variance   | 0.627         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 31            |\n",
      "|    n_updates            | 28140         |\n",
      "|    policy_gradient_loss | -0.00206      |\n",
      "|    reward               | -1.7835252    |\n",
      "|    std                  | 19.2          |\n",
      "|    value_loss           | 61.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2816         |\n",
      "|    time_elapsed         | 52182        |\n",
      "|    total_timesteps      | 5767168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070018647 |\n",
      "|    clip_fraction        | 0.0405       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.429        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 28150        |\n",
      "|    policy_gradient_loss | -0.00839     |\n",
      "|    reward               | 1.5349834    |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2817         |\n",
      "|    time_elapsed         | 52202        |\n",
      "|    total_timesteps      | 5769216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007281779 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.6         |\n",
      "|    n_updates            | 28160        |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    reward               | 1.1487545    |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 60.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2818        |\n",
      "|    time_elapsed         | 52222       |\n",
      "|    total_timesteps      | 5771264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001017998 |\n",
      "|    clip_fraction        | 9.77e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.5        |\n",
      "|    n_updates            | 28170       |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    reward               | 2.4589543   |\n",
      "|    std                  | 19.3        |\n",
      "|    value_loss           | 58.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2819         |\n",
      "|    time_elapsed         | 52241        |\n",
      "|    total_timesteps      | 5773312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009591001 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.7         |\n",
      "|    n_updates            | 28180        |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    reward               | 2.4342198    |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 56           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2820         |\n",
      "|    time_elapsed         | 52261        |\n",
      "|    total_timesteps      | 5775360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047165705 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.755        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 28190        |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    reward               | 2.8223364    |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 44.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2821         |\n",
      "|    time_elapsed         | 52280        |\n",
      "|    total_timesteps      | 5777408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010659974 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.3         |\n",
      "|    n_updates            | 28200        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | 2.1695108    |\n",
      "|    std                  | 19.4         |\n",
      "|    value_loss           | 51.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2822         |\n",
      "|    time_elapsed         | 52299        |\n",
      "|    total_timesteps      | 5779456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033489307 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 28210        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | -1.0865418   |\n",
      "|    std                  | 19.4         |\n",
      "|    value_loss           | 48.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2823       |\n",
      "|    time_elapsed         | 52318      |\n",
      "|    total_timesteps      | 5781504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00823847 |\n",
      "|    clip_fraction        | 0.0267     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -126       |\n",
      "|    explained_variance   | 0.554      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.84       |\n",
      "|    n_updates            | 28220      |\n",
      "|    policy_gradient_loss | -0.00361   |\n",
      "|    reward               | -1.5913559 |\n",
      "|    std                  | 19.4       |\n",
      "|    value_loss           | 26.2       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 2000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3641644.27\n",
      "total_reward: 2641644.27\n",
      "total_cost: 279576.68\n",
      "total_trades: 65037\n",
      "Sharpe: 0.599\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2824         |\n",
      "|    time_elapsed         | 52336        |\n",
      "|    total_timesteps      | 5783552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024145169 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22           |\n",
      "|    n_updates            | 28230        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | 1.3007948    |\n",
      "|    std                  | 19.4         |\n",
      "|    value_loss           | 58.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2825         |\n",
      "|    time_elapsed         | 52356        |\n",
      "|    total_timesteps      | 5785600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014080671 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.4         |\n",
      "|    n_updates            | 28240        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    reward               | 1.5731585    |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 74.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2826         |\n",
      "|    time_elapsed         | 52375        |\n",
      "|    total_timesteps      | 5787648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051039187 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.8         |\n",
      "|    n_updates            | 28250        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    reward               | -3.9406374   |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 46.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2827         |\n",
      "|    time_elapsed         | 52395        |\n",
      "|    total_timesteps      | 5789696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028349508 |\n",
      "|    clip_fraction        | 0.00591      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 28260        |\n",
      "|    policy_gradient_loss | -0.00497     |\n",
      "|    reward               | -0.9315728   |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 59.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2828         |\n",
      "|    time_elapsed         | 52415        |\n",
      "|    total_timesteps      | 5791744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031634506 |\n",
      "|    clip_fraction        | 0.00908      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 28270        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | -10.889317   |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 49.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2829         |\n",
      "|    time_elapsed         | 52434        |\n",
      "|    total_timesteps      | 5793792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007719032 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 28280        |\n",
      "|    policy_gradient_loss | -0.00137     |\n",
      "|    reward               | 1.3987837    |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 52.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2830         |\n",
      "|    time_elapsed         | 52452        |\n",
      "|    total_timesteps      | 5795840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063456404 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.88         |\n",
      "|    n_updates            | 28290        |\n",
      "|    policy_gradient_loss | -0.00487     |\n",
      "|    reward               | -0.9896937   |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 24.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2831         |\n",
      "|    time_elapsed         | 52472        |\n",
      "|    total_timesteps      | 5797888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024203593 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 28300        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | -1.0855538   |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 55.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2832          |\n",
      "|    time_elapsed         | 52491         |\n",
      "|    total_timesteps      | 5799936       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030362938 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -126          |\n",
      "|    explained_variance   | 0.692         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.4          |\n",
      "|    n_updates            | 28310         |\n",
      "|    policy_gradient_loss | -0.00131      |\n",
      "|    reward               | -0.17710957   |\n",
      "|    std                  | 19.6          |\n",
      "|    value_loss           | 57.2          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2833        |\n",
      "|    time_elapsed         | 52511       |\n",
      "|    total_timesteps      | 5801984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003526819 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 28320       |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    reward               | -2.8924417  |\n",
      "|    std                  | 19.6        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2834         |\n",
      "|    time_elapsed         | 52530        |\n",
      "|    total_timesteps      | 5804032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010261068 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.1         |\n",
      "|    n_updates            | 28330        |\n",
      "|    policy_gradient_loss | -0.000493    |\n",
      "|    reward               | -0.2547004   |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 61.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2835         |\n",
      "|    time_elapsed         | 52550        |\n",
      "|    total_timesteps      | 5806080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012385538 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.3         |\n",
      "|    n_updates            | 28340        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | 10.022022    |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 65.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2836         |\n",
      "|    time_elapsed         | 52568        |\n",
      "|    total_timesteps      | 5808128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023132013 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.205        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.4         |\n",
      "|    n_updates            | 28350        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    reward               | -1.8014591   |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 74.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2837         |\n",
      "|    time_elapsed         | 52587        |\n",
      "|    total_timesteps      | 5810176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045249956 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.47         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 28360        |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    reward               | 0.8862635    |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 54           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3393333.83\n",
      "total_reward: 2393333.83\n",
      "total_cost: 272108.37\n",
      "total_trades: 65300\n",
      "Sharpe: 0.610\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2838        |\n",
      "|    time_elapsed         | 52606       |\n",
      "|    total_timesteps      | 5812224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004335369 |\n",
      "|    clip_fraction        | 0.0117      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 28370       |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    reward               | -0.18666588 |\n",
      "|    std                  | 19.7        |\n",
      "|    value_loss           | 58.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2839         |\n",
      "|    time_elapsed         | 52625        |\n",
      "|    total_timesteps      | 5814272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015332454 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 28380        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | 4.9122477    |\n",
      "|    std                  | 19.7         |\n",
      "|    value_loss           | 60.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2840        |\n",
      "|    time_elapsed         | 52645       |\n",
      "|    total_timesteps      | 5816320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007568891 |\n",
      "|    clip_fraction        | 0.0305      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 28390       |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    reward               | 0.14154708  |\n",
      "|    std                  | 19.7        |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2841         |\n",
      "|    time_elapsed         | 52664        |\n",
      "|    total_timesteps      | 5818368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009123408 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.2         |\n",
      "|    n_updates            | 28400        |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    reward               | 3.4727323    |\n",
      "|    std                  | 19.7         |\n",
      "|    value_loss           | 76.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2842         |\n",
      "|    time_elapsed         | 52684        |\n",
      "|    total_timesteps      | 5820416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016293616 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 28410        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | -5.708328    |\n",
      "|    std                  | 19.7         |\n",
      "|    value_loss           | 53.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2843         |\n",
      "|    time_elapsed         | 52703        |\n",
      "|    total_timesteps      | 5822464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010434424 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.1         |\n",
      "|    n_updates            | 28420        |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    reward               | -3.5229003   |\n",
      "|    std                  | 19.7         |\n",
      "|    value_loss           | 43.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2844         |\n",
      "|    time_elapsed         | 52722        |\n",
      "|    total_timesteps      | 5824512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057321126 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.5         |\n",
      "|    n_updates            | 28430        |\n",
      "|    policy_gradient_loss | -0.00796     |\n",
      "|    reward               | -0.45919573  |\n",
      "|    std                  | 19.7         |\n",
      "|    value_loss           | 41           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2845         |\n",
      "|    time_elapsed         | 52740        |\n",
      "|    total_timesteps      | 5826560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037593185 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.2         |\n",
      "|    n_updates            | 28440        |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    reward               | -1.0220962   |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 64.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2846          |\n",
      "|    time_elapsed         | 52760         |\n",
      "|    total_timesteps      | 5828608       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082769454 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -126          |\n",
      "|    explained_variance   | 0.776         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.8          |\n",
      "|    n_updates            | 28450         |\n",
      "|    policy_gradient_loss | -0.00193      |\n",
      "|    reward               | 0.1825224     |\n",
      "|    std                  | 19.8          |\n",
      "|    value_loss           | 48.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2847         |\n",
      "|    time_elapsed         | 52778        |\n",
      "|    total_timesteps      | 5830656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097017465 |\n",
      "|    clip_fraction        | 0.0424       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.462        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 28460        |\n",
      "|    policy_gradient_loss | -0.00957     |\n",
      "|    reward               | 0.5596805    |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 27.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2848         |\n",
      "|    time_elapsed         | 52798        |\n",
      "|    total_timesteps      | 5832704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009908195 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 28470        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | 2.477698     |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 52.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2849         |\n",
      "|    time_elapsed         | 52817        |\n",
      "|    total_timesteps      | 5834752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013705463 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24           |\n",
      "|    n_updates            | 28480        |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    reward               | 4.9304633    |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 67.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2850        |\n",
      "|    time_elapsed         | 52836       |\n",
      "|    total_timesteps      | 5836800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005184295 |\n",
      "|    clip_fraction        | 0.0189      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 28490       |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    reward               | 3.075187    |\n",
      "|    std                  | 19.9        |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2851        |\n",
      "|    time_elapsed         | 52854       |\n",
      "|    total_timesteps      | 5838848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005561429 |\n",
      "|    clip_fraction        | 0.0284      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 28500       |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    reward               | -0.707714   |\n",
      "|    std                  | 19.9        |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2852          |\n",
      "|    time_elapsed         | 52873         |\n",
      "|    total_timesteps      | 5840896       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00094764656 |\n",
      "|    clip_fraction        | 0.00137       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -126          |\n",
      "|    explained_variance   | 0.786         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.1          |\n",
      "|    n_updates            | 28510         |\n",
      "|    policy_gradient_loss | -0.00267      |\n",
      "|    reward               | -10.744199    |\n",
      "|    std                  | 19.9          |\n",
      "|    value_loss           | 49.1          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2747817.77\n",
      "total_reward: 1747817.77\n",
      "total_cost: 267077.75\n",
      "total_trades: 64126\n",
      "Sharpe: 0.542\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2853        |\n",
      "|    time_elapsed         | 52893       |\n",
      "|    total_timesteps      | 5842944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000728513 |\n",
      "|    clip_fraction        | 0.00327     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 28520       |\n",
      "|    policy_gradient_loss | -0.000696   |\n",
      "|    reward               | 1.7816164   |\n",
      "|    std                  | 19.9        |\n",
      "|    value_loss           | 55.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2854        |\n",
      "|    time_elapsed         | 52911       |\n",
      "|    total_timesteps      | 5844992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006188318 |\n",
      "|    clip_fraction        | 0.0213      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 28530       |\n",
      "|    policy_gradient_loss | -0.00894    |\n",
      "|    reward               | -0.53921735 |\n",
      "|    std                  | 19.9        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2855       |\n",
      "|    time_elapsed         | 52931      |\n",
      "|    total_timesteps      | 5847040    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00201485 |\n",
      "|    clip_fraction        | 0.00122    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -127       |\n",
      "|    explained_variance   | 0.527      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.2       |\n",
      "|    n_updates            | 28540      |\n",
      "|    policy_gradient_loss | -0.004     |\n",
      "|    reward               | 1.149079   |\n",
      "|    std                  | 20         |\n",
      "|    value_loss           | 55.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2856         |\n",
      "|    time_elapsed         | 52950        |\n",
      "|    total_timesteps      | 5849088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010234187 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.793        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 28550        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | 0.45298484   |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 38.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2857        |\n",
      "|    time_elapsed         | 52969       |\n",
      "|    total_timesteps      | 5851136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007001877 |\n",
      "|    clip_fraction        | 0.031       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 28560       |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    reward               | -0.7250166  |\n",
      "|    std                  | 20          |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2858         |\n",
      "|    time_elapsed         | 52988        |\n",
      "|    total_timesteps      | 5853184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010515761 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 28570        |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    reward               | -0.55124146  |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2859         |\n",
      "|    time_elapsed         | 53007        |\n",
      "|    total_timesteps      | 5855232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018974472 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 28580        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    reward               | -2.5933905   |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 51.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2860         |\n",
      "|    time_elapsed         | 53026        |\n",
      "|    total_timesteps      | 5857280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018257825 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.0935       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 28590        |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    reward               | 0.42523104   |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 54.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2861        |\n",
      "|    time_elapsed         | 53044       |\n",
      "|    total_timesteps      | 5859328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008419409 |\n",
      "|    clip_fraction        | 0.0519      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 28600       |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    reward               | -0.31219238 |\n",
      "|    std                  | 20.2        |\n",
      "|    value_loss           | 56.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2862         |\n",
      "|    time_elapsed         | 53063        |\n",
      "|    total_timesteps      | 5861376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013833443 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.73         |\n",
      "|    n_updates            | 28610        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | 0.48658493   |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2863         |\n",
      "|    time_elapsed         | 53083        |\n",
      "|    total_timesteps      | 5863424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021011508 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 28620        |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    reward               | 0.80573285   |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2864         |\n",
      "|    time_elapsed         | 53102        |\n",
      "|    total_timesteps      | 5865472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075262915 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.45         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.76         |\n",
      "|    n_updates            | 28630        |\n",
      "|    policy_gradient_loss | -0.00894     |\n",
      "|    reward               | 2.1650167    |\n",
      "|    std                  | 20.3         |\n",
      "|    value_loss           | 27           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2865         |\n",
      "|    time_elapsed         | 53120        |\n",
      "|    total_timesteps      | 5867520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017696905 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.3         |\n",
      "|    n_updates            | 28640        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | -1.435522    |\n",
      "|    std                  | 20.3         |\n",
      "|    value_loss           | 54.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2866         |\n",
      "|    time_elapsed         | 53140        |\n",
      "|    total_timesteps      | 5869568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010198854 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 28650        |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    reward               | 1.6735694    |\n",
      "|    std                  | 20.3         |\n",
      "|    value_loss           | 48.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2685067.51\n",
      "total_reward: 1685067.51\n",
      "total_cost: 274422.64\n",
      "total_trades: 64668\n",
      "Sharpe: 0.512\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2867          |\n",
      "|    time_elapsed         | 53160         |\n",
      "|    total_timesteps      | 5871616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00093629723 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.592         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.5          |\n",
      "|    n_updates            | 28660         |\n",
      "|    policy_gradient_loss | -0.00171      |\n",
      "|    reward               | 0.33574843    |\n",
      "|    std                  | 20.3          |\n",
      "|    value_loss           | 35.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2868         |\n",
      "|    time_elapsed         | 53179        |\n",
      "|    total_timesteps      | 5873664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058180075 |\n",
      "|    clip_fraction        | 0.0305       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.47         |\n",
      "|    n_updates            | 28670        |\n",
      "|    policy_gradient_loss | -0.00765     |\n",
      "|    reward               | -2.5528479   |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2869         |\n",
      "|    time_elapsed         | 53198        |\n",
      "|    total_timesteps      | 5875712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022182278 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 28680        |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    reward               | -0.25101626  |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 38.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2870         |\n",
      "|    time_elapsed         | 53218        |\n",
      "|    total_timesteps      | 5877760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005974225 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.6         |\n",
      "|    n_updates            | 28690        |\n",
      "|    policy_gradient_loss | -0.00141     |\n",
      "|    reward               | 3.0554628    |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 43           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2871        |\n",
      "|    time_elapsed         | 53237       |\n",
      "|    total_timesteps      | 5879808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009742521 |\n",
      "|    clip_fraction        | 0.0781      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.43        |\n",
      "|    n_updates            | 28700       |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    reward               | 1.244507    |\n",
      "|    std                  | 20.4        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2872         |\n",
      "|    time_elapsed         | 53257        |\n",
      "|    total_timesteps      | 5881856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015433178 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 28710        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | 0.7420295    |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 51.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2873          |\n",
      "|    time_elapsed         | 53276         |\n",
      "|    total_timesteps      | 5883904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025450956 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.727         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 24.2          |\n",
      "|    n_updates            | 28720         |\n",
      "|    policy_gradient_loss | -0.00109      |\n",
      "|    reward               | 4.342092      |\n",
      "|    std                  | 20.4          |\n",
      "|    value_loss           | 46.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2874         |\n",
      "|    time_elapsed         | 53294        |\n",
      "|    total_timesteps      | 5885952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025371576 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.58         |\n",
      "|    n_updates            | 28730        |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    reward               | 0.8972632    |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 29.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2875         |\n",
      "|    time_elapsed         | 53313        |\n",
      "|    total_timesteps      | 5888000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006605296 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 28740        |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    reward               | 0.99116397   |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2876         |\n",
      "|    time_elapsed         | 53332        |\n",
      "|    total_timesteps      | 5890048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022262381 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.719        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19           |\n",
      "|    n_updates            | 28750        |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    reward               | -5.931954    |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 38.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2877         |\n",
      "|    time_elapsed         | 53351        |\n",
      "|    total_timesteps      | 5892096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017592143 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 28760        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | 5.1452684    |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 40           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2878        |\n",
      "|    time_elapsed         | 53369       |\n",
      "|    total_timesteps      | 5894144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008556476 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 28770       |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    reward               | -1.2857451  |\n",
      "|    std                  | 20.6        |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2879        |\n",
      "|    time_elapsed         | 53388       |\n",
      "|    total_timesteps      | 5896192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001769014 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 28780       |\n",
      "|    policy_gradient_loss | -0.0021     |\n",
      "|    reward               | -1.8805723  |\n",
      "|    std                  | 20.6        |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2880         |\n",
      "|    time_elapsed         | 53408        |\n",
      "|    total_timesteps      | 5898240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012402587 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.9         |\n",
      "|    n_updates            | 28790        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    reward               | -5.406337    |\n",
      "|    std                  | 20.6         |\n",
      "|    value_loss           | 45           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2982264.48\n",
      "total_reward: 1982264.48\n",
      "total_cost: 303873.05\n",
      "total_trades: 66379\n",
      "Sharpe: 0.534\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2881         |\n",
      "|    time_elapsed         | 53427        |\n",
      "|    total_timesteps      | 5900288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068607125 |\n",
      "|    clip_fraction        | 0.0286       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.4         |\n",
      "|    n_updates            | 28800        |\n",
      "|    policy_gradient_loss | -0.00804     |\n",
      "|    reward               | -1.8715584   |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 33.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2882         |\n",
      "|    time_elapsed         | 53446        |\n",
      "|    total_timesteps      | 5902336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007818778 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22           |\n",
      "|    n_updates            | 28810        |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | 2.3415       |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 54.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2883          |\n",
      "|    time_elapsed         | 53466         |\n",
      "|    total_timesteps      | 5904384       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050669856 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.656         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 30.9          |\n",
      "|    n_updates            | 28820         |\n",
      "|    policy_gradient_loss | -0.00152      |\n",
      "|    reward               | -6.6790385    |\n",
      "|    std                  | 20.7          |\n",
      "|    value_loss           | 56            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2884         |\n",
      "|    time_elapsed         | 53486        |\n",
      "|    total_timesteps      | 5906432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023996718 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 28830        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    reward               | -0.1412898   |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 40.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2885         |\n",
      "|    time_elapsed         | 53504        |\n",
      "|    total_timesteps      | 5908480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058380263 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.5         |\n",
      "|    n_updates            | 28840        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    reward               | -3.11408     |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2886         |\n",
      "|    time_elapsed         | 53523        |\n",
      "|    total_timesteps      | 5910528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016781375 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 28850        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | 0.37801936   |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 43.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2887         |\n",
      "|    time_elapsed         | 53542        |\n",
      "|    total_timesteps      | 5912576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001500698 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.716        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 28860        |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    reward               | 1.1387527    |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 43.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2888        |\n",
      "|    time_elapsed         | 53560       |\n",
      "|    total_timesteps      | 5914624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009232141 |\n",
      "|    clip_fraction        | 0.0356      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 28870       |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    reward               | 0.636666    |\n",
      "|    std                  | 20.8        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2889          |\n",
      "|    time_elapsed         | 53579         |\n",
      "|    total_timesteps      | 5916672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023645165 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.608         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 27.8          |\n",
      "|    n_updates            | 28880         |\n",
      "|    policy_gradient_loss | -0.00116      |\n",
      "|    reward               | 0.20370126    |\n",
      "|    std                  | 20.8          |\n",
      "|    value_loss           | 61            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2890          |\n",
      "|    time_elapsed         | 53598         |\n",
      "|    total_timesteps      | 5918720       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027691564 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.753         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.4          |\n",
      "|    n_updates            | 28890         |\n",
      "|    policy_gradient_loss | -0.0012       |\n",
      "|    reward               | 5.089648      |\n",
      "|    std                  | 20.8          |\n",
      "|    value_loss           | 42.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2891         |\n",
      "|    time_elapsed         | 53616        |\n",
      "|    total_timesteps      | 5920768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026886591 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 28900        |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    reward               | -1.3197594   |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2892         |\n",
      "|    time_elapsed         | 53636        |\n",
      "|    total_timesteps      | 5922816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044739856 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.753        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 28910        |\n",
      "|    policy_gradient_loss | -0.00686     |\n",
      "|    reward               | -0.37460226  |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2893         |\n",
      "|    time_elapsed         | 53654        |\n",
      "|    total_timesteps      | 5924864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020583784 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.686        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 28920        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    reward               | 3.4639456    |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 47.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2894         |\n",
      "|    time_elapsed         | 53673        |\n",
      "|    total_timesteps      | 5926912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012764159 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.681        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.6         |\n",
      "|    n_updates            | 28930        |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    reward               | -0.07296903  |\n",
      "|    std                  | 20.9         |\n",
      "|    value_loss           | 50           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2773741.88\n",
      "total_reward: 1773741.88\n",
      "total_cost: 286167.11\n",
      "total_trades: 65127\n",
      "Sharpe: 0.511\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2895        |\n",
      "|    time_elapsed         | 53692       |\n",
      "|    total_timesteps      | 5928960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006905256 |\n",
      "|    clip_fraction        | 0.039       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9           |\n",
      "|    n_updates            | 28940       |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | 0.37324953  |\n",
      "|    std                  | 20.9        |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2896         |\n",
      "|    time_elapsed         | 53710        |\n",
      "|    total_timesteps      | 5931008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010474089 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 28950        |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    reward               | -2.0916746   |\n",
      "|    std                  | 20.9         |\n",
      "|    value_loss           | 46.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2897          |\n",
      "|    time_elapsed         | 53729         |\n",
      "|    total_timesteps      | 5933056       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.7273126e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.734         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.4          |\n",
      "|    n_updates            | 28960         |\n",
      "|    policy_gradient_loss | -0.000593     |\n",
      "|    reward               | 4.6467557     |\n",
      "|    std                  | 20.9          |\n",
      "|    value_loss           | 49.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2898         |\n",
      "|    time_elapsed         | 53748        |\n",
      "|    total_timesteps      | 5935104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010579368 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.515        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 28970        |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    reward               | 4.6142683    |\n",
      "|    std                  | 20.9         |\n",
      "|    value_loss           | 33.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2899         |\n",
      "|    time_elapsed         | 53767        |\n",
      "|    total_timesteps      | 5937152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022665558 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 28980        |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    reward               | 2.976722     |\n",
      "|    std                  | 21           |\n",
      "|    value_loss           | 39.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2900         |\n",
      "|    time_elapsed         | 53787        |\n",
      "|    total_timesteps      | 5939200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009507324 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 28990        |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    reward               | 0.895349     |\n",
      "|    std                  | 21           |\n",
      "|    value_loss           | 49.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2901          |\n",
      "|    time_elapsed         | 53807         |\n",
      "|    total_timesteps      | 5941248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066220446 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.659         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.5          |\n",
      "|    n_updates            | 29000         |\n",
      "|    policy_gradient_loss | -0.00114      |\n",
      "|    reward               | 0.38607052    |\n",
      "|    std                  | 21            |\n",
      "|    value_loss           | 40.5          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2902         |\n",
      "|    time_elapsed         | 53827        |\n",
      "|    total_timesteps      | 5943296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055336338 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.9         |\n",
      "|    n_updates            | 29010        |\n",
      "|    policy_gradient_loss | -0.00682     |\n",
      "|    reward               | -0.60662407  |\n",
      "|    std                  | 21           |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2903         |\n",
      "|    time_elapsed         | 53846        |\n",
      "|    total_timesteps      | 5945344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017475149 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.8         |\n",
      "|    n_updates            | 29020        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    reward               | 1.0399027    |\n",
      "|    std                  | 21.1         |\n",
      "|    value_loss           | 49.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2904          |\n",
      "|    time_elapsed         | 53865         |\n",
      "|    total_timesteps      | 5947392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079608697 |\n",
      "|    clip_fraction        | 0.00127       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.773         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.7          |\n",
      "|    n_updates            | 29030         |\n",
      "|    policy_gradient_loss | -0.00138      |\n",
      "|    reward               | 2.5507314     |\n",
      "|    std                  | 21.1          |\n",
      "|    value_loss           | 44.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2905         |\n",
      "|    time_elapsed         | 53883        |\n",
      "|    total_timesteps      | 5949440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065677837 |\n",
      "|    clip_fraction        | 0.0411       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.21         |\n",
      "|    n_updates            | 29040        |\n",
      "|    policy_gradient_loss | -0.00991     |\n",
      "|    reward               | -0.62674725  |\n",
      "|    std                  | 21.1         |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2906         |\n",
      "|    time_elapsed         | 53902        |\n",
      "|    total_timesteps      | 5951488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010801565 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 29050        |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    reward               | -1.0656557   |\n",
      "|    std                  | 21.1         |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2907         |\n",
      "|    time_elapsed         | 53921        |\n",
      "|    total_timesteps      | 5953536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010758133 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 29060        |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    reward               | 1.0653396    |\n",
      "|    std                  | 21.1         |\n",
      "|    value_loss           | 45.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2908        |\n",
      "|    time_elapsed         | 53940       |\n",
      "|    total_timesteps      | 5955584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001257967 |\n",
      "|    clip_fraction        | 0.00308     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 29070       |\n",
      "|    policy_gradient_loss | -0.00145    |\n",
      "|    reward               | 2.5097704   |\n",
      "|    std                  | 21.1        |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2648422.05\n",
      "total_reward: 1648422.05\n",
      "total_cost: 310248.53\n",
      "total_trades: 66931\n",
      "Sharpe: 0.509\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2909        |\n",
      "|    time_elapsed         | 53960       |\n",
      "|    total_timesteps      | 5957632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002868648 |\n",
      "|    clip_fraction        | 0.00532     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 29080       |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    reward               | 0.24391016  |\n",
      "|    std                  | 21.2        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2910         |\n",
      "|    time_elapsed         | 53980        |\n",
      "|    total_timesteps      | 5959680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014661073 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.3         |\n",
      "|    n_updates            | 29090        |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    reward               | 0.48657635   |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 38.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2911        |\n",
      "|    time_elapsed         | 53999       |\n",
      "|    total_timesteps      | 5961728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000543997 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 29100       |\n",
      "|    policy_gradient_loss | -0.0014     |\n",
      "|    reward               | -0.12530646 |\n",
      "|    std                  | 21.2        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2912        |\n",
      "|    time_elapsed         | 54019       |\n",
      "|    total_timesteps      | 5963776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006603513 |\n",
      "|    clip_fraction        | 0.0367      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 29110       |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    reward               | -0.7046789  |\n",
      "|    std                  | 21.3        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2913         |\n",
      "|    time_elapsed         | 54038        |\n",
      "|    total_timesteps      | 5965824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007080391 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 29120        |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    reward               | -0.8463826   |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2914          |\n",
      "|    time_elapsed         | 54057         |\n",
      "|    total_timesteps      | 5967872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027496618 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.605         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.3          |\n",
      "|    n_updates            | 29130         |\n",
      "|    policy_gradient_loss | -0.000959     |\n",
      "|    reward               | -5.1140027    |\n",
      "|    std                  | 21.3          |\n",
      "|    value_loss           | 45.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2915         |\n",
      "|    time_elapsed         | 54077        |\n",
      "|    total_timesteps      | 5969920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013524427 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.7         |\n",
      "|    n_updates            | 29140        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | 4.422849     |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 43.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2916         |\n",
      "|    time_elapsed         | 54096        |\n",
      "|    total_timesteps      | 5971968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033952403 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 29150        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    reward               | 0.87785953   |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 43.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2917          |\n",
      "|    time_elapsed         | 54115         |\n",
      "|    total_timesteps      | 5974016       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058774604 |\n",
      "|    clip_fraction        | 0.000928      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.747         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.9          |\n",
      "|    n_updates            | 29160         |\n",
      "|    policy_gradient_loss | -0.00169      |\n",
      "|    reward               | 4.351706      |\n",
      "|    std                  | 21.4          |\n",
      "|    value_loss           | 50.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2918         |\n",
      "|    time_elapsed         | 54134        |\n",
      "|    total_timesteps      | 5976064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011021611 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.9         |\n",
      "|    n_updates            | 29170        |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    reward               | 1.7719558    |\n",
      "|    std                  | 21.4         |\n",
      "|    value_loss           | 40.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2919         |\n",
      "|    time_elapsed         | 54152        |\n",
      "|    total_timesteps      | 5978112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080468375 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 29180        |\n",
      "|    policy_gradient_loss | -0.00716     |\n",
      "|    reward               | 0.2923989    |\n",
      "|    std                  | 21.4         |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2920         |\n",
      "|    time_elapsed         | 54171        |\n",
      "|    total_timesteps      | 5980160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004416475 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.8         |\n",
      "|    n_updates            | 29190        |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    reward               | 1.2500645    |\n",
      "|    std                  | 21.4         |\n",
      "|    value_loss           | 64           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2921         |\n",
      "|    time_elapsed         | 54189        |\n",
      "|    total_timesteps      | 5982208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007256466 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.9         |\n",
      "|    n_updates            | 29200        |\n",
      "|    policy_gradient_loss | -0.000879    |\n",
      "|    reward               | -4.690035    |\n",
      "|    std                  | 21.4         |\n",
      "|    value_loss           | 72.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2922        |\n",
      "|    time_elapsed         | 54207       |\n",
      "|    total_timesteps      | 5984256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004431003 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 29210       |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    reward               | -4.4904103  |\n",
      "|    std                  | 21.5        |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2997807.33\n",
      "total_reward: 1997807.33\n",
      "total_cost: 301111.96\n",
      "total_trades: 66748\n",
      "Sharpe: 0.536\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2923         |\n",
      "|    time_elapsed         | 54225        |\n",
      "|    total_timesteps      | 5986304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012330355 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 29220        |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    reward               | 0.15397522   |\n",
      "|    std                  | 21.5         |\n",
      "|    value_loss           | 61.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2924        |\n",
      "|    time_elapsed         | 54244       |\n",
      "|    total_timesteps      | 5988352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001458388 |\n",
      "|    clip_fraction        | 0.00444     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 29230       |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    reward               | -2.8757596  |\n",
      "|    std                  | 21.5        |\n",
      "|    value_loss           | 58.1        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2925          |\n",
      "|    time_elapsed         | 54262         |\n",
      "|    total_timesteps      | 5990400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026858653 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.648         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.6          |\n",
      "|    n_updates            | 29240         |\n",
      "|    policy_gradient_loss | -0.000955     |\n",
      "|    reward               | -0.13600552   |\n",
      "|    std                  | 21.5          |\n",
      "|    value_loss           | 57.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2926         |\n",
      "|    time_elapsed         | 54280        |\n",
      "|    total_timesteps      | 5992448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069181854 |\n",
      "|    clip_fraction        | 0.0417       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 29250        |\n",
      "|    policy_gradient_loss | -0.00637     |\n",
      "|    reward               | -0.25776714  |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2927         |\n",
      "|    time_elapsed         | 54298        |\n",
      "|    total_timesteps      | 5994496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016975835 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 29260        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | 1.5647786    |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 46.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2928         |\n",
      "|    time_elapsed         | 54317        |\n",
      "|    total_timesteps      | 5996544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009833792 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.4         |\n",
      "|    n_updates            | 29270        |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    reward               | -1.4388216   |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 68.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2929         |\n",
      "|    time_elapsed         | 54336        |\n",
      "|    total_timesteps      | 5998592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054591065 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 29280        |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    reward               | -5.519613    |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 25.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2930          |\n",
      "|    time_elapsed         | 54354         |\n",
      "|    total_timesteps      | 6000640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00083097524 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.473         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.6          |\n",
      "|    n_updates            | 29290         |\n",
      "|    policy_gradient_loss | -0.00164      |\n",
      "|    reward               | -0.73498946   |\n",
      "|    std                  | 21.6          |\n",
      "|    value_loss           | 53.4          |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# model_ppo2.load('42')\n",
    "print('load')\n",
    "trained_ppo2 = agent_con.train_model(model=model_ppo2, \n",
    "                             tb_log_name=\"8\",\n",
    "                             total_timesteps=3000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Model 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xwOhVjqRkCdM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "K8RSdKCckJyH"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23766/4244563930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_sac = agent.train_model(model=model_sac, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sac'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              total_timesteps=60000)\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         )\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;31m# Special case when the user passes `gradient_steps=0`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgradient_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# Select action according to policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                 \u001b[0mnext_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# Compute the next Q values: min over all critics targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mnext_q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/policies.py\u001b[0m in \u001b[0;36maction_log_prob\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_dist_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# return action and associated log prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mlog_prob_from_params\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mactions_from_params\u001b[0;34m(self, mean_actions, log_std, deterministic)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Update the proba distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"SquashedDiagGaussianDistribution\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSquashedDiagGaussianDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m    151\u001b[0m         \u001b[0maction_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     raise ValueError(\n\u001b[1;32m     56\u001b[0m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at 2020-07-01. We use the DDPG model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEv5KGC8h1jE"
   },
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be greater than the maximum of insample turbulence data, if current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "efwBi84ch1jE"
   },
   "outputs": [],
   "source": [
    "data_risk_indicator = processed_full[(processed_full.date<'2020-07-01') & (processed_full.date>='2009-01-01')]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n",
    "\n",
    "trained_ppo2.save('83')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "VHZMBpSqh1jG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       18.824245\n",
       "std         8.489311\n",
       "min         9.140000\n",
       "25%        13.330000\n",
       "50%        16.139999\n",
       "75%        21.309999\n",
       "max        82.690002\n",
       "Name: vix, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "BDkszkMloRWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.40400183105453"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.quantile(0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "AL7hs7svnNWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       34.574233\n",
       "std        43.787150\n",
       "min         0.000000\n",
       "25%        14.966105\n",
       "50%        24.124290\n",
       "75%        39.162080\n",
       "max       652.505555\n",
       "Name: turbulence, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "N78hfHckoqJ9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276.45132359815483"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.quantile(0.996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trade\n",
    "\n",
    "DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "cIqoV0GSI52v"
   },
   "outputs": [],
   "source": [
    "#trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "W_XNgGsBMeVw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "eLOnL5eYh1jR"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trained_ppo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33280/536458364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     environment = e_trade_gym)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m df_account_value, df_actions = DRLAgent.DRL_prediction(\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_ppo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     environment = e_trade_gym)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trained_ppo' is not defined"
     ]
    }
   ],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "ERxw3KqLkcP4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33280/1680983300.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "2yRkNguY5yvp"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33280/2509563385.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "nFlK5hNbWVFk"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_actions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33280/1118186915.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_actions' is not defined"
     ]
    }
   ],
   "source": [
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Nzkr9yv-AdV_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33280/2746174370.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%d-%Hh%M'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mperf_stats_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbacktest_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_account_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mperf_stats_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf_stats_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mperf_stats_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESULTS_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/perf_stats_all_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "QkV-LB66iwhD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33280/57827447.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m baseline_df = get_baseline(\n\u001b[1;32m      4\u001b[0m         \u001b[0mticker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"^DJI\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         end = df_account_value.loc[len(df_account_value)-1,'date'])\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "qg1kvfemrrQH"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33280/2351900042.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value.loc[0,'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "tt1bzL5OrsTa"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33280/1309470278.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_account_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value.loc[len(df_account_value)-1,'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "lKRGftSS7pNM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to DJIA===========\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33280/2064601725.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Dow Jones Index: ^DJI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# NASDAQ 100: ^NDX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m backtest_plot(df_account_value, \n\u001b[0m\u001b[1;32m      7\u001b[0m              \u001b[0mbaseline_ticker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'^DJI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m              \u001b[0mbaseline_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "BzBaE63H3RLc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value2, df_actions2 = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo2, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ZYeOjax-7H_5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.353082\n",
      "Cumulative returns     0.496576\n",
      "Annual volatility      0.156380\n",
      "Sharpe ratio           2.018457\n",
      "Calmar ratio           4.141427\n",
      "Stability              0.910061\n",
      "Max drawdown          -0.085256\n",
      "Omega ratio            1.385657\n",
      "Sortino ratio          3.140165\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.104091\n",
      "Daily value at risk   -0.018449\n",
      "dtype: float64\n",
      "==============Get Baseline Stats===========\n",
      "Annual return          0.269722\n",
      "Cumulative returns     0.374922\n",
      "Annual volatility      0.139083\n",
      "Sharpe ratio           1.792302\n",
      "Calmar ratio           3.020136\n",
      "Stability              0.919220\n",
      "Max drawdown          -0.089308\n",
      "Omega ratio            1.347571\n",
      "Sortino ratio          2.655481\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.052781\n",
      "Daily value at risk   -0.016534\n",
      "dtype: float64\n",
      "==============Compare to DJIA===========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2020-07-01</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2021-10-28</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>16</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>35.308%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>49.658%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>15.638%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>4.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-8.526%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-1.845%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.53</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.02</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.66</td>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.56</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>2021-06-18</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.79</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>2021-03-24</td>\n",
       "      <td>2021-04-15</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stress Events</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Normal</th>\n",
       "      <td>0.13%</td>\n",
       "      <td>-3.22%</td>\n",
       "      <td>4.70%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x5184 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value2)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'2.csv')\n",
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value2.loc[0,'date'],\n",
    "        end = df_account_value2.loc[len(df_account_value2)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n",
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value2, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value2.loc[0,'date'],\n",
    "             baseline_end = df_account_value2.loc[len(df_account_value2)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Uy5_PTmOh1hj",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_StockTrading_NeurIPS_2018.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
