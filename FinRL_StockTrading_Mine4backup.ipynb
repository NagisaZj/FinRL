{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/FinRL_StockTrading_NeurIPS_2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
    "\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)   \n",
    "* [RLlib Section](#7)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "ef0ba8d0-f57a-4c74-bb0b-46737762677d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
      "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to /tmp/pip-req-build-8i1_yu6g\n",
      "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-8i1_yu6g\n",
      "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
      "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
      "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "  Running command git clone -q https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.19.5)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.1.5)\n",
      "Collecting stockstats\n",
      "  Downloading stockstats-0.3.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.1.67-py2.py3-none-any.whl (25 kB)\n",
      "Collecting elegantrl\n",
      "  Downloading elegantrl-0.3.2-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 2.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.17.3)\n",
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-1.3.0-py3-none-any.whl (174 kB)\n",
      "\u001b[K     |████████████████████████████████| 174 kB 65.2 MB/s \n",
      "\u001b[?25hCollecting ray[default]\n",
      "  Downloading ray-1.9.1-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 57.6 MB 1.4 MB/s \n",
      "\u001b[?25hCollecting lz4\n",
      "  Downloading lz4-3.1.10-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 42.9 MB/s \n",
      "\u001b[?25hCollecting tensorboardX\n",
      "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 71.5 MB/s \n",
      "\u001b[?25hCollecting gputil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "Collecting exchange_calendars\n",
      "  Downloading exchange_calendars-3.5.tar.gz (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 35.6 MB/s \n",
      "\u001b[?25hCollecting alpaca_trade_api\n",
      "  Downloading alpaca_trade_api-1.4.3-py3-none-any.whl (36 kB)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting jqdatasdk\n",
      "  Downloading jqdatasdk-1.8.10-py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 57.3 MB/s \n",
      "\u001b[?25hCollecting wrds\n",
      "  Downloading wrds-3.1.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.6.4)\n",
      "Requirement already satisfied: setuptools>=41.4.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (57.4.0)\n",
      "Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.37.0)\n",
      "Collecting pre-commit\n",
      "  Downloading pre_commit-2.16.0-py2.py3-none-any.whl (191 kB)\n",
      "\u001b[K     |████████████████████████████████| 191 kB 55.1 MB/s \n",
      "\u001b[?25hCollecting pybullet\n",
      "  Downloading pybullet-3.2.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (90.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 90.8 MB 244 bytes/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (1.10.0+cu111)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (4.1.2.30)\n",
      "Collecting box2d-py\n",
      "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 50.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.5.0)\n",
      "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2018.9)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.4.1)\n",
      "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.11.2)\n",
      "Collecting empyrical>=0.5.0\n",
      "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.9.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.0.18)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.4.2)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.6.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (0.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.23.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.2.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.2.5)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.3.3) (0.16.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (1.1.0)\n",
      "Collecting websocket-client<2,>=0.56.0\n",
      "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
      "\u001b[?25hCollecting PyYAML==5.4.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 52.7 MB/s \n",
      "\u001b[?25hCollecting msgpack==1.0.2\n",
      "  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
      "\u001b[K     |████████████████████████████████| 273 kB 60.4 MB/s \n",
      "\u001b[?25hCollecting aiohttp==3.7.4\n",
      "  Downloading aiohttp-3.7.4-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 55.5 MB/s \n",
      "\u001b[?25hCollecting websockets<10,>=8.0\n",
      "  Downloading websockets-9.1-cp37-cp37m-manylinux2010_x86_64.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 48.7 MB/s \n",
      "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (3.10.0.2)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 56.6 MB/s \n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 57.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (21.2.0)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 68.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 28.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 21.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 11.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 70.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 24.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 14.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 65.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.85-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 59.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.84-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.83-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.82-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.81-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.80-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 35.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.79-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.78-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 20.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.77-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.76-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.75-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.74-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 34.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.73-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.72-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.71-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.70-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.69-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.68-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 60.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.67-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.66-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.65-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.64-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.63-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.62-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.61-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.60-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 57.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.59-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.58-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.57-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.56-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.55-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.54-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.53-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.52-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.51-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.6 MB/s \n",
      "\u001b[?25hCollecting aiodns>=1.1.1\n",
      "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 60.7 MB/s \n",
      "\u001b[?25hCollecting cryptography>=2.6.1\n",
      "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 42.6 MB/s \n",
      "\u001b[?25hCollecting pycares>=4.0.0\n",
      "  Downloading pycares-4.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (291 kB)\n",
      "\u001b[K     |████████████████████████████████| 291 kB 44.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt->finrl==0.3.3) (2.21)\n",
      "Collecting pyluach\n",
      "  Downloading pyluach-1.3.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.11.2)\n",
      "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.2.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.3) (1.4.27)\n",
      "Collecting thriftpy2>=0.3.9\n",
      "  Downloading thriftpy2-0.4.14.tar.gz (361 kB)\n",
      "\u001b[K     |████████████████████████████████| 361 kB 50.4 MB/s \n",
      "\u001b[?25hCollecting pymysql>=0.7.6\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (1.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (4.8.2)\n",
      "Collecting ply<4.0,>=3.4\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (3.6.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.0)\n",
      "Collecting cfgv>=2.0.0\n",
      "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (0.10.2)\n",
      "Collecting identify>=1.0.0\n",
      "  Downloading identify-2.4.1-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 7.2 MB/s \n",
      "\u001b[?25hCollecting virtualenv>=20.0.8\n",
      "  Downloading virtualenv-20.11.0-py2.py3-none-any.whl (6.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5 MB 39.6 MB/s \n",
      "\u001b[?25hCollecting nodeenv>=0.11.1\n",
      "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (3.4.0)\n",
      "Collecting distlib<1,>=0.3.1\n",
      "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
      "\u001b[K     |████████████████████████████████| 461 kB 32.3 MB/s \n",
      "\u001b[?25hCollecting platformdirs<3,>=2\n",
      "  Downloading platformdirs-2.4.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (0.7.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.11.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (8.12.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.42.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (3.17.3)\n",
      "Collecting redis>=3.5.0\n",
      "  Downloading redis-4.1.0-py3-none-any.whl (171 kB)\n",
      "\u001b[K     |████████████████████████████████| 171 kB 57.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (2.6.0)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.12.0)\n",
      "Collecting aioredis<2\n",
      "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.6 MB/s \n",
      "\u001b[?25hCollecting py-spy>=0.2.0\n",
      "  Downloading py_spy-0.3.11-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 50.8 MB/s \n",
      "\u001b[?25hCollecting colorful\n",
      "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[K     |████████████████████████████████| 201 kB 70.8 MB/s \n",
      "\u001b[?25hCollecting aiohttp-cors\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (5.2.1)\n",
      "Collecting aiosignal\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist\n",
      "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
      "\u001b[K     |████████████████████████████████| 192 kB 7.1 MB/s \n",
      "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
      "  Downloading gpustat-1.0.0b1.tar.gz (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 213 kB/s \n",
      "\u001b[?25hCollecting opencensus\n",
      "  Downloading opencensus-0.8.0-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 53.5 MB/s \n",
      "\u001b[?25hCollecting hiredis\n",
      "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 2.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (7.352.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (5.4.8)\n",
      "Collecting blessed>=1.17.1\n",
      "  Downloading blessed-1.19.0-py2.py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 4.8 MB/s \n",
      "\u001b[?25hCollecting deprecated>=1.2.3\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]->finrl==0.3.3) (21.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[default]->finrl==0.3.3) (1.13.3)\n",
      "Collecting opencensus-context==0.1.2\n",
      "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.3) (1.26.3)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.35.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.53.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.4.8)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.8.9)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (2.7.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (0.2.9)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.1.1)\n",
      "Collecting int-date>=0.1.7\n",
      "  Downloading int_date-0.1.8-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting mock\n",
      "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.4 MB 45.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.3) (0.0.10)\n",
      "Building wheels for collected packages: finrl, elegantrl, pyfolio, empyrical, exchange-calendars, gputil, thriftpy2, gpustat\n",
      "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for finrl: filename=finrl-0.3.3-py3-none-any.whl size=3885640 sha256=1667a85b9c8c0a7a8efbf04d5ebf154d5d1ea119a32e922d094820030ce0e7e4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/17/ff/bd/1bc602a0352762b0b24041b88536d803ae343ed0a711fcf55e\n",
      "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for elegantrl: filename=elegantrl-0.3.2-py3-none-any.whl size=168744 sha256=7773813204e1a2954730bd149444640d5155458fc82b6910ec4e661879797016\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/99/85/5e/86cb3a9f47adfca5e248295e93113e1b298d60883126d62c84\n",
      "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75775 sha256=e3753b24d032afc5ef0b133c50557002ca9fed8416e2205e1547fc81af5c124a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/ef/09/e5/2c1bf37c050d22557c080deb1be986d06424627c04aeca19b9\n",
      "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39777 sha256=6cc78a6b3f88187e2798221487acba0361bb1d094b6c82496348fb4c85f7686b\n",
      "  Stored in directory: /root/.cache/pip/wheels/d9/91/4b/654fcff57477efcf149eaca236da2fce991526cbab431bf312\n",
      "  Building wheel for exchange-calendars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for exchange-calendars: filename=exchange_calendars-3.5-py3-none-any.whl size=179487 sha256=3d877d78e29a28c4b098f4a0b1d0106458d7f73b52f6c7a43d0757d55c11d44b\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/21/43/b6ae2605dd767f6cd5a5b0b70c93a9a75823e44b3ccb92bce7\n",
      "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=33dcd980f1b32f0582d029fcef126ae53327fb90724eee8c33bc3b4dbebda4b1\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
      "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for thriftpy2: filename=thriftpy2-0.4.14-cp37-cp37m-linux_x86_64.whl size=940507 sha256=429244bf5fd89014c79f01bf0e4a59477258cd2b88978e3125b54f4bd62a88f5\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/f5/49/9c0d851aa64b58db72883cf9393cc824d536bdf13f5c83cff4\n",
      "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gpustat: filename=gpustat-1.0.0b1-py3-none-any.whl size=15979 sha256=b831a9dba6682b3e0a7ae05d7c2ba465918426c72474917e56e0850ac8c73263\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/16/e2/3e2437fba4c4b6a97a97bd96fce5d14e66cff5c4966fb1cc8c\n",
      "Successfully built finrl elegantrl pyfolio empyrical exchange-calendars gputil thriftpy2 gpustat\n",
      "Installing collected packages: multidict, yarl, lxml, deprecated, async-timeout, redis, PyYAML, pycares, ply, platformdirs, opencensus-context, msgpack, hiredis, frozenlist, distlib, blessed, aiohttp, websockets, websocket-client, virtualenv, thriftpy2, tensorboardX, stable-baselines3, ray, pymysql, pyluach, pybullet, py-spy, psycopg2-binary, opencensus, nodeenv, mock, int-date, identify, gpustat, empyrical, cryptography, colorful, cfgv, box2d-py, aiosignal, aioredis, aiohttp-cors, aiodns, yfinance, wrds, stockstats, pyfolio, pre-commit, lz4, jqdatasdk, gputil, exchange-calendars, elegantrl, ccxt, alpaca-trade-api, finrl\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.2.6\n",
      "    Uninstalling lxml-4.2.6:\n",
      "      Successfully uninstalled lxml-4.2.6\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.3\n",
      "    Uninstalling msgpack-1.0.3:\n",
      "      Successfully uninstalled msgpack-1.0.3\n",
      "Successfully installed PyYAML-5.4.1 aiodns-3.0.0 aiohttp-3.7.4 aiohttp-cors-0.7.0 aioredis-1.3.1 aiosignal-1.2.0 alpaca-trade-api-1.4.3 async-timeout-3.0.1 blessed-1.19.0 box2d-py-2.3.8 ccxt-1.61.51 cfgv-3.3.1 colorful-0.5.4 cryptography-36.0.1 deprecated-1.2.13 distlib-0.3.4 elegantrl-0.3.2 empyrical-0.5.5 exchange-calendars-3.5 finrl-0.3.3 frozenlist-1.2.0 gpustat-1.0.0b1 gputil-1.4.0 hiredis-2.0.0 identify-2.4.1 int-date-0.1.8 jqdatasdk-1.8.10 lxml-4.7.1 lz4-3.1.10 mock-4.0.3 msgpack-1.0.2 multidict-5.2.0 nodeenv-1.6.0 opencensus-0.8.0 opencensus-context-0.1.2 platformdirs-2.4.1 ply-3.11 pre-commit-2.16.0 psycopg2-binary-2.9.2 py-spy-0.3.11 pybullet-3.2.1 pycares-4.1.2 pyfolio-0.9.2+75.g4b901f6 pyluach-1.3.0 pymysql-1.0.2 ray-1.9.1 redis-4.1.0 stable-baselines3-1.3.0 stockstats-0.3.2 tensorboardX-2.4.1 thriftpy2-0.4.14 virtualenv-20.11.0 websocket-client-1.2.3 websockets-9.1 wrds-3.1.1 yarl-1.6.3 yfinance-0.1.67\n"
     ]
    }
   ],
   "source": [
    "## install finrl library\n",
    "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "10b08480-3a0c-4826-8e51-f94ce97ab84a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zj/anaconda3/envs/finrl/lib/python3.7/site-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.finrl_meta.preprocessor.tusharedownloader import TushareDownloader\n",
    "from finrl.finrl_meta.data_processors.processor_alpaca import AlpacaProcessor\n",
    "from finrl.finrl_meta.data_processors.processor_wrds import WrdsProcessor\n",
    "from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading_conservative import StockTradingEnvCon\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.finrl_meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot2 import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "5302d7c0-1c68-4c6e-b30e-b1395bdc109e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-01-01'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py TRAIN_START_DATE is a string\n",
    "config.TRAIN_START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FUnY8WEfLq3C",
    "outputId": "35dd8c5b-d58f-49b8-e4df-ae7e122448cd"
   },
   "outputs": [],
   "source": [
    "# from config.py TRAIN_END_DATE is a string\n",
    "# config.TRAIN_END_DATE\n",
    "# df2=TushareDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "83c7f894-3757-473b-8afb-a904e6caabda",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = YahooDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "7a991dfe-f39c-40db-ec44-7c416cdce7dc"
   },
   "outputs": [],
   "source": [
    "# print(config_tickers.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "5267773c-399c-4ec9-d4d5-13ab1e4cced0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94360, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./1.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "210fade5-e912-40df-be99-4ad00bdb9d2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600</td>\n",
       "      <td>AXP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100</td>\n",
       "      <td>BA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400</td>\n",
       "      <td>CAT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date       open       high        low      close  \\\n",
       "0           0  2008-12-31   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31  43.700001  45.099998  43.700001  30.628819   \n",
       "\n",
       "      volume   tic  day  \n",
       "0  607541200  AAPL    2  \n",
       "1    6287200  AMGN    2  \n",
       "2    9625600   AXP    2  \n",
       "3    5443100    BA    2  \n",
       "4    6277400   CAT    2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmKP-1ii3RLS",
    "outputId": "0708badb-77ef-4c86-f77c-6525f0e8934d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fe = FeatureEngineer(\n",
    "#                     use_technical_indicator=True,\n",
    "#                     tech_indicator_list = config.INDICATORS,\n",
    "#                     use_vix=True,\n",
    "#                     use_turbulence=True,\n",
    "#                     user_defined_feature = False)\n",
    "\n",
    "# processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Kixon2tR3RLT"
   },
   "outputs": [],
   "source": [
    "# list_ticker = processed[\"tic\"].unique().tolist()\n",
    "# list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "# combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "# processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "# processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "# processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "# processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "grvhGJJII3Xn",
    "outputId": "733758c3-3552-4aa5-e1f9-789bd4ce0c92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AXP</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>BA</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CAT</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CRM</td>\n",
       "      <td>7.712500</td>\n",
       "      <td>8.130000</td>\n",
       "      <td>7.707500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>5367600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>16.180000</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.120001</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>37513700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CVX</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>74.629997</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>9964300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>DIS</td>\n",
       "      <td>22.570000</td>\n",
       "      <td>22.950001</td>\n",
       "      <td>22.520000</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>9012100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>GS</td>\n",
       "      <td>82.239998</td>\n",
       "      <td>86.150002</td>\n",
       "      <td>81.120003</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>14894100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic       open       high        low      close  \\\n",
       "0           0  2008-12-31  AAPL   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  AMGN  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31   AXP  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31    BA  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31   CAT  43.700001  45.099998  43.700001  30.628819   \n",
       "5           5  2008-12-31   CRM   7.712500   8.130000   7.707500   8.002500   \n",
       "6           6  2008-12-31  CSCO  16.180000  16.549999  16.120001  11.787783   \n",
       "7           7  2008-12-31   CVX  72.900002  74.629997  72.900002  43.314438   \n",
       "8           8  2008-12-31   DIS  22.570000  22.950001  22.520000  19.538342   \n",
       "9           9  2008-12-31    GS  82.239998  86.150002  81.120003  69.224182   \n",
       "\n",
       "        volume  day  macd   boll_ub   boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0  607541200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "1    6287200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "2    9625600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "3    5443100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "4    6277400.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "5    5367600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "6   37513700.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "7    9964300.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "8    9012100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "9   14894100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma   vix  turbulence  \n",
       "0      2.606277      2.606277  40.0         0.0  \n",
       "1     43.924454     43.924454  40.0         0.0  \n",
       "2     14.908465     14.908465  40.0         0.0  \n",
       "3     32.005894     32.005894  40.0         0.0  \n",
       "4     30.628819     30.628819  40.0         0.0  \n",
       "5      8.002500      8.002500  40.0         0.0  \n",
       "6     11.787783     11.787783  40.0         0.0  \n",
       "7     43.314438     43.314438  40.0         0.0  \n",
       "8     19.538342     19.538342  40.0         0.0  \n",
       "9     69.224182     69.224182  40.0         0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full=pd.read_csv('./2.csv')\n",
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TOhcryx44bb"
   },
   "source": [
    "## Training data split: 2009-01-01 to 2020-07-01\n",
    "## Trade data split: 2020-07-01 to 2021-10-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "ca8d1a43-ffc3-4fc3-efa9-4de9a9065842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83897\n",
      "9744\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, '2009-01-01','2020-07-01')\n",
    "trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "p52zNCOhTtLR",
    "outputId": "b3ad3e10-376f-4186-f875-0331708c5e14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121795</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>UNH</td>\n",
       "      <td>288.570007</td>\n",
       "      <td>296.450012</td>\n",
       "      <td>287.660004</td>\n",
       "      <td>287.776794</td>\n",
       "      <td>2932900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>303.925869</td>\n",
       "      <td>271.251255</td>\n",
       "      <td>52.413046</td>\n",
       "      <td>-25.838431</td>\n",
       "      <td>1.846804</td>\n",
       "      <td>288.020689</td>\n",
       "      <td>281.001438</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121796</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>V</td>\n",
       "      <td>191.490005</td>\n",
       "      <td>193.750000</td>\n",
       "      <td>190.160004</td>\n",
       "      <td>190.737244</td>\n",
       "      <td>9040100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.048786</td>\n",
       "      <td>198.750528</td>\n",
       "      <td>185.041391</td>\n",
       "      <td>53.021033</td>\n",
       "      <td>-51.550760</td>\n",
       "      <td>2.013358</td>\n",
       "      <td>191.485037</td>\n",
       "      <td>181.677683</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121797</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>VZ</td>\n",
       "      <td>54.919998</td>\n",
       "      <td>55.290001</td>\n",
       "      <td>54.360001</td>\n",
       "      <td>50.376743</td>\n",
       "      <td>17414800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.437111</td>\n",
       "      <td>53.918425</td>\n",
       "      <td>48.729324</td>\n",
       "      <td>48.097044</td>\n",
       "      <td>-51.018262</td>\n",
       "      <td>8.508886</td>\n",
       "      <td>51.012123</td>\n",
       "      <td>51.464679</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121798</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WBA</td>\n",
       "      <td>42.119999</td>\n",
       "      <td>42.580002</td>\n",
       "      <td>41.759998</td>\n",
       "      <td>39.035732</td>\n",
       "      <td>4782100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.083986</td>\n",
       "      <td>42.609305</td>\n",
       "      <td>36.487095</td>\n",
       "      <td>48.830181</td>\n",
       "      <td>-14.508130</td>\n",
       "      <td>1.500723</td>\n",
       "      <td>39.135190</td>\n",
       "      <td>38.935129</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121799</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WMT</td>\n",
       "      <td>119.220001</td>\n",
       "      <td>120.129997</td>\n",
       "      <td>118.540001</td>\n",
       "      <td>116.121765</td>\n",
       "      <td>6836400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.886569</td>\n",
       "      <td>119.473758</td>\n",
       "      <td>113.510454</td>\n",
       "      <td>48.159665</td>\n",
       "      <td>-69.938795</td>\n",
       "      <td>3.847271</td>\n",
       "      <td>117.787627</td>\n",
       "      <td>119.723273</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        date  tic        open        high         low  \\\n",
       "2892      121795  2020-06-30  UNH  288.570007  296.450012  287.660004   \n",
       "2892      121796  2020-06-30    V  191.490005  193.750000  190.160004   \n",
       "2892      121797  2020-06-30   VZ   54.919998   55.290001   54.360001   \n",
       "2892      121798  2020-06-30  WBA   42.119999   42.580002   41.759998   \n",
       "2892      121799  2020-06-30  WMT  119.220001  120.129997  118.540001   \n",
       "\n",
       "           close      volume  day      macd     boll_ub     boll_lb  \\\n",
       "2892  287.776794   2932900.0  1.0 -0.019475  303.925869  271.251255   \n",
       "2892  190.737244   9040100.0  1.0  1.048786  198.750528  185.041391   \n",
       "2892   50.376743  17414800.0  1.0 -0.437111   53.918425   48.729324   \n",
       "2892   39.035732   4782100.0  1.0 -0.083986   42.609305   36.487095   \n",
       "2892  116.121765   6836400.0  1.0 -0.886569  119.473758  113.510454   \n",
       "\n",
       "         rsi_30     cci_30     dx_30  close_30_sma  close_60_sma    vix  \\\n",
       "2892  52.413046 -25.838431  1.846804    288.020689    281.001438  30.43   \n",
       "2892  53.021033 -51.550760  2.013358    191.485037    181.677683  30.43   \n",
       "2892  48.097044 -51.018262  8.508886     51.012123     51.464679  30.43   \n",
       "2892  48.830181 -14.508130  1.500723     39.135190     38.935129  30.43   \n",
       "2892  48.159665 -69.938795  3.847271    117.787627    119.723273  30.43   \n",
       "\n",
       "      turbulence  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "k9zU9YaTTvFq",
    "outputId": "72213585-39a3-4bff-c031-874ec0ca06f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "7f228183-abe3-4477-f574-3c9b25c62cd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "1f54d044-e2d3-4a34-c041-e913d686654e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "e_train_gym_conservative = StockTradingEnvCon(df = train, **env_kwargs)\n",
    "e_train_gym_conservative.value_history.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64EoqOrQjiVf"
   },
   "source": [
    "## Environment for Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "deeaef07-afda-4ca1-fea8-99384224c7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))\n",
    "env_train_con, _ = e_train_gym_conservative.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "364PsqckttcQ"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "agent_con = DRLAgent(env = env_train_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Model 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "a90a7a60-21a5-47e1-b683-1f7cbb4b8bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0GVpkWGqH4-D",
    "outputId": "570d540f-abe9-402b-e0cc-f9b007228e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 67         |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | -1.41      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -72.8      |\n",
      "|    reward             | 0.19451597 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.68       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 68         |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | -0.115     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -70.2      |\n",
      "|    reward             | -1.4624771 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.55       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0.198    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -167     |\n",
      "|    reward             | 5.02583  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 21.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -30.9    |\n",
      "|    reward             | 5.606354 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 368       |\n",
      "|    reward             | -7.546301 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 164       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0.0793    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 145       |\n",
      "|    reward             | 0.4507672 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 15        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | -0.0998    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -78.4      |\n",
      "|    reward             | -2.1521304 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 5.52       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0.00557     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 10.6        |\n",
      "|    reward             | -0.80710465 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 2.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 70.3        |\n",
      "|    reward             | -0.11950674 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 3.94        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -35.7      |\n",
      "|    reward             | -4.1389766 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.35       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -245     |\n",
      "|    reward             | 6.363784 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 38.5     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -63.1      |\n",
      "|    reward             | 0.07753525 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.93       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | -0.000831 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 48.9      |\n",
      "|    reward             | -4.088032 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 8         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 179       |\n",
      "|    reward             | 2.0626597 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 40.8      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 169       |\n",
      "|    reward             | 4.8591986 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 21.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 85.1       |\n",
      "|    reward             | 0.85958314 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 6.29       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -141     |\n",
      "|    reward             | 5.65319  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 51.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -41       |\n",
      "|    reward             | 1.1973313 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.57      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -26.6      |\n",
      "|    reward             | 0.36287376 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.68       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40         |\n",
      "|    explained_variance | -0.0091     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -83.6       |\n",
      "|    reward             | -0.30971453 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 13.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 204       |\n",
      "|    reward             | 1.7650424 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 30.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 158        |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | -153       |\n",
      "|    reward             | -7.5710273 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 23.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | -2.04e+03  |\n",
      "|    reward             | -14.886115 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3e+03      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 51        |\n",
      "|    reward             | 0.0559524 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.94      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -46.7     |\n",
      "|    reward             | -0.434364 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 5.71      |\n",
      "|    reward             | 4.8586307 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.131     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 194        |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -13.8      |\n",
      "|    reward             | -0.4118847 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.392      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 201       |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 328       |\n",
      "|    reward             | 1.0554261 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 66.3      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 209       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0.88      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -116      |\n",
      "|    reward             | 2.3091433 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 9.5       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 216        |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | -20.7      |\n",
      "|    reward             | 0.38583377 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.509      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 223        |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | 43.7       |\n",
      "|    reward             | -0.3664559 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 230        |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -38.8      |\n",
      "|    reward             | -0.4616701 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 11.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 237        |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | 96.4       |\n",
      "|    reward             | 0.11014476 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.58       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 245       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -3.93     |\n",
      "|    reward             | 2.1390972 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 30.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | 76.4       |\n",
      "|    reward             | 0.16336557 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.35       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 259       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -85.2     |\n",
      "|    reward             | 1.0221922 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.59      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 266       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 225       |\n",
      "|    reward             | 1.1701288 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 38.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 273       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 33.2      |\n",
      "|    reward             | 2.4472284 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.27      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 281        |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 41.3       |\n",
      "|    reward             | -1.2081411 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.04       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 288       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | -0.481    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -5.13     |\n",
      "|    reward             | 1.3224076 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2         |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | 1.15        |\n",
      "|    reward             | -0.25540048 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.837       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 302       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0.000881  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -119      |\n",
      "|    reward             | 1.3826902 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 10.9      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 309       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -64       |\n",
      "|    reward             | 3.9822705 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.59      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 63.9       |\n",
      "|    reward             | 0.95108056 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 4.87       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 324        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | 86.2       |\n",
      "|    reward             | -2.1539907 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 331       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 102       |\n",
      "|    reward             | 4.8509326 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0.00948     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | -105        |\n",
      "|    reward             | -0.22313617 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 8.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 346         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | -104        |\n",
      "|    reward             | -0.99914765 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 7.87        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 353        |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -33.2      |\n",
      "|    reward             | 0.20132123 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.946      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 360        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | -7.57e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 46.2       |\n",
      "|    reward             | 0.26696855 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.03       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 367        |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | -83.4      |\n",
      "|    reward             | -1.8360271 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 374       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -359      |\n",
      "|    reward             | 3.2874866 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 92.2      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3161472.69\n",
      "total_reward: 2161472.69\n",
      "total_cost: 19221.41\n",
      "total_trades: 41334\n",
      "Sharpe: 0.663\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 382       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -7.54     |\n",
      "|    reward             | 0.2828299 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.173     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 389         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | 26.5        |\n",
      "|    reward             | -0.19252001 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.14        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 396       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -15       |\n",
      "|    reward             | 2.0577734 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.6       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 403         |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -46.9       |\n",
      "|    reward             | -0.06746031 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.12        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 411        |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0.00117    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | -37.6      |\n",
      "|    reward             | 0.18157594 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.34       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 418       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0.0166    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -31.3     |\n",
      "|    reward             | 0.6473793 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.72      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 425        |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | 7.13       |\n",
      "|    reward             | 0.22656512 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.251      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 432        |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | 59.9       |\n",
      "|    reward             | -0.8028962 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.88       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 439        |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | -10.2      |\n",
      "|    reward             | -1.7693416 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.89       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 446         |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 20.2        |\n",
      "|    reward             | -0.10761352 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 454      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 203      |\n",
      "|    reward             | 3.869458 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 34.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 461       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -0.0428   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 110       |\n",
      "|    reward             | 1.2343621 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.67      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 468       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    reward             | -2.028344 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.83      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 475        |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | -66.8      |\n",
      "|    reward             | 0.33169752 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.98       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 483      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | 0.00675  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -869     |\n",
      "|    reward             | -8.09732 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 536      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 490        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 28.9       |\n",
      "|    reward             | 0.56556416 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 13         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 497        |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -176       |\n",
      "|    reward             | -2.9329143 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 88.1       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 504        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 72.3       |\n",
      "|    reward             | 0.22214015 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 3.11       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 511        |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 105        |\n",
      "|    reward             | -0.6425189 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 12         |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 519         |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | -360        |\n",
      "|    reward             | -0.22756429 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 80.8        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 526         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | -430        |\n",
      "|    reward             | -0.44158605 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 131         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 533        |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | 404        |\n",
      "|    reward             | -5.8487034 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 111        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 540       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 1.07e+03  |\n",
      "|    reward             | -14.82644 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 832       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 548       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -141      |\n",
      "|    reward             | 1.4826734 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 555        |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | -0.0473    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | -184       |\n",
      "|    reward             | 0.34629944 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 25.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 562       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -42       |\n",
      "|    reward             | -2.415951 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 6         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 569       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 55.1      |\n",
      "|    reward             | 5.0485888 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 42.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 576        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | -207       |\n",
      "|    reward             | -3.2154734 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 56.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 584       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | 257       |\n",
      "|    reward             | 5.370093  |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 56.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 591        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -160       |\n",
      "|    reward             | 0.03019213 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 16.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 598        |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 118        |\n",
      "|    reward             | -1.1561224 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 12.6       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 605         |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -214        |\n",
      "|    reward             | -0.94865924 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 30.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 613       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -250      |\n",
      "|    reward             | 1.1797212 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 41.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 620        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 411        |\n",
      "|    reward             | -22.785406 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 144        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 627       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 72.4      |\n",
      "|    reward             | 3.2164123 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.27      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 634         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | 87          |\n",
      "|    reward             | -0.17441794 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 6.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 642         |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | 262         |\n",
      "|    reward             | -0.85795397 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 48.9        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 649        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | 72.7       |\n",
      "|    reward             | -2.2230675 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 22.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 656       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -49.2     |\n",
      "|    reward             | 2.6728501 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.66      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 663      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -238     |\n",
      "|    reward             | 8.656925 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 86.3     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 670         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0.000219    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | -187        |\n",
      "|    reward             | -0.62001467 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 27.3        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 678       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 55.6      |\n",
      "|    reward             | 1.1713017 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.79      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 685       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 139       |\n",
      "|    reward             | 1.3898315 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 14.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 692       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -52.5     |\n",
      "|    reward             | -6.044222 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.49      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 699       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 67.7      |\n",
      "|    reward             | 1.8213228 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 9.97      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 706      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 177      |\n",
      "|    reward             | 8.957433 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 58.6     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 714         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 14.2        |\n",
      "|    reward             | -0.26523116 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.559       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 721        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | -0.00926   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | 1.12       |\n",
      "|    reward             | -0.6623605 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.953      |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2YadjfnLwgt"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCDa78rqfO_a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "y5D5PFUhMzSV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Gt8eIQKYM4G3",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ppo/1_1\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 124       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 0.5073655 |\n",
      "----------------------------------\n",
      "day: 2892, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3946387.70\n",
      "total_reward: 2946387.70\n",
      "total_cost: 357438.48\n",
      "total_trades: 81024\n",
      "Sharpe: 0.793\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015788507 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.00723     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.41        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    reward               | 0.3435485   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012375185 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.7        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | -1.1157341  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 65.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016662188 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.00193    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 2.2809894   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017038994 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00886    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    reward               | 3.2505164   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 105        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01701039 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.4      |\n",
      "|    explained_variance   | 0.0063     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17         |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    reward               | 1.8685282  |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 32.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02486872 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.5      |\n",
      "|    explained_variance   | -0.0142    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.5       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    reward               | 0.39857626 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 46.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020911664 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | -0.0215     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | 1.3883617   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7870/2360990771.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_ppo = agent.train_model(model=model_ppo, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              total_timesteps=3000000)\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             )\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/zj/FinRL/finrl/finrl_meta/env_stock_trading/env_stocktrading.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    321\u001b[0m             )\n\u001b[1;32m    322\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_total_asset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_total_asset\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbegin_total_asset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/zj/FinRL/finrl/finrl_meta/env_stock_trading/env_stocktrading.py\u001b[0m in \u001b[0;36m_get_date\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2037\u001b[0m         \u001b[0mCategories\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'b'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2038\u001b[0m         \"\"\"\n\u001b[0;32m-> 2039\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0mhtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_hashtable_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_get_hashtable_algo\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mndtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_object_for_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0mhtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_hashtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mndtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_check_object_for_strings\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# including nulls because that is the only difference between\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# StringHashTable and ObjectHashtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0mndtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mndtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name=\"1\",\n",
    "                             total_timesteps=3000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JSAHhV4Xc-bh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent_con = DRLAgent(env = env_train_con)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo2 = agent_con.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "OSRxNYAxdKpU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load\n",
      "Logging to ppo/6_1\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 117        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 17         |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.24282552 |\n",
      "-----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012917281 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.0051     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.28        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    reward               | 1.0803783   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016816532 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.00395     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    reward               | -1.1497328  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 82.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02171574  |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | 0.00122     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | -0.87502307 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015519448 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.0197     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    reward               | 2.131135    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018762695 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.0156     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    reward               | 2.1767464   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015986675 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | 0.00434     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | 0.3857683   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 65.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022182118 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | -0.023      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 0.5203031   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020969791 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | -0.0105     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.93        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | 0.4874323   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024956549 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | 0.00299     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    reward               | 0.47337115  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018741768 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.00915     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    reward               | 0.51879203  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024812344 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | -0.000251   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    reward               | -0.29524308 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3078606.73\n",
      "total_reward: 2078606.73\n",
      "total_cost: 302121.29\n",
      "total_trades: 77532\n",
      "Sharpe: 0.684\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020196842 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | -0.0175     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.1        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    reward               | 0.4135789   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 88.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 251         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024681233 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.0026      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    reward               | -0.2564199  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 269        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02140002 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.8      |\n",
      "|    explained_variance   | -0.0495    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.35       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    reward               | 2.7875042  |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 23.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 287          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.021912374  |\n",
      "|    clip_fraction        | 0.24         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.8        |\n",
      "|    explained_variance   | -0.011       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.18         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0158      |\n",
      "|    reward               | -0.025143187 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 39.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027498793 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | -0.0109     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.16        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | 1.0610969   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 323         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026587004 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | -0.0109     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    reward               | -0.22079863 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024261089 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | -0.031      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.66        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | -0.3031798  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.87        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 359         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0214406   |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.0205      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -0.73822117 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 377         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028308954 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.0169      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -5.2171445  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 395         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033195082 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.0107      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.06        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | 1.4417834   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 413          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.031710528  |\n",
      "|    clip_fraction        | 0.295        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.2        |\n",
      "|    explained_variance   | 0.00927      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0127      |\n",
      "|    reward               | -0.012119165 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 432         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031391133 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0.0157      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    reward               | 4.572089    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 451         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030075017 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | -0.00441    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | -0.53036475 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 44.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 470         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027426941 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.00961     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.58        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    reward               | 1.2741197   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4451720.54\n",
      "total_reward: 3451720.54\n",
      "total_cost: 313338.22\n",
      "total_trades: 77417\n",
      "Sharpe: 0.879\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 488         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029013425 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.000976    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | -0.7930358  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 507         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022623435 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.00161     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | -0.91208553 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 77.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 526         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02370232  |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | -0.0253     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.46        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    reward               | -0.71907586 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 545         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027711628 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.5       |\n",
      "|    explained_variance   | 0.00245     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | 0.37181202  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 61.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 564         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028266571 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.5       |\n",
      "|    explained_variance   | -0.00157    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -0.81220883 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 75.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 582         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020327464 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0194      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    reward               | -1.8078364  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 601         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021571279 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.00547     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.3        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -0.7086571  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 619         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013550609 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0166      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00947    |\n",
      "|    reward               | 1.2801489   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 638        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01747491 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | 0.00843    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 56.5       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    reward               | 0.10552413 |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 91.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 657        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02599952 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | 0.0284     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.4       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    reward               | -5.183511  |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 20.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 675         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029568814 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.00382     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.9        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    reward               | -1.1630645  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 98.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 694         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027656324 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0158      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.2        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    reward               | -9.975688   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 713         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021797009 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0684     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    reward               | -2.3513696  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 731         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028473783 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0327      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    reward               | -0.24282922 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 46.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4356606.52\n",
      "total_reward: 3356606.52\n",
      "total_cost: 267765.21\n",
      "total_trades: 74775\n",
      "Sharpe: 0.805\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 749         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015823891 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0229      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48          |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 0.23195338  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 92.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 767         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025868943 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0278      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    reward               | 0.44194233  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 79.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 786         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025642134 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0729     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.79        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    reward               | -0.84687066 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 804         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025888477 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0316      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.4        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    reward               | 0.115877226 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 79.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 822         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027293984 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.037       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    reward               | -0.5544342  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 840         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033088576 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.032       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    reward               | -5.316308   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 858         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031150293 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0161      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 0.8712763   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 877         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027172796 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.00826    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.5        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    reward               | 18.715992   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 90.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 895         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020142186 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0388      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.4        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    reward               | -2.48227    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 84.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 913         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041973002 |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.19        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | 0.00407     |\n",
      "|    reward               | 0.5615356   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 931         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029714102 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.6        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | 0.23281227  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 70.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 949        |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03932433 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0279     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.3       |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | 0.0012     |\n",
      "|    reward               | -6.074378  |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 94.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 967         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024112009 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0113      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    reward               | 1.8687892   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 985        |\n",
      "|    total_timesteps      | 110592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03030406 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0247     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 33.2       |\n",
      "|    n_updates            | 530        |\n",
      "|    policy_gradient_loss | -5.18e-05  |\n",
      "|    reward               | 1.188641   |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 96.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1004        |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034168474 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0554      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.1        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    reward               | -2.1425433  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4946155.45\n",
      "total_reward: 3946155.45\n",
      "total_cost: 244750.35\n",
      "total_trades: 72877\n",
      "Sharpe: 0.917\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1022        |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021115704 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    reward               | 1.9635811   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 1040        |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026688732 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0969      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -7.49e-05   |\n",
      "|    reward               | 0.25071162  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 52.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 1058       |\n",
      "|    total_timesteps      | 118784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01993679 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.141      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 41.3       |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | 0.00302    |\n",
      "|    reward               | 0.28801808 |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 73.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1076        |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012911438 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.000328   |\n",
      "|    reward               | 0.721471    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 67.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1095        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033392195 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.2         |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    reward               | 1.759718    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1113        |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029757481 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0815      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 1.1328418   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 85.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1131        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028248373 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    reward               | -0.7624097  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 81.1        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 112       |\n",
      "|    iterations           | 63        |\n",
      "|    time_elapsed         | 1149      |\n",
      "|    total_timesteps      | 129024    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0339016 |\n",
      "|    clip_fraction        | 0.309     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44       |\n",
      "|    explained_variance   | 0.0508    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 14.3      |\n",
      "|    n_updates            | 620       |\n",
      "|    policy_gradient_loss | -0.0125   |\n",
      "|    reward               | 4.888803  |\n",
      "|    std                  | 1.1       |\n",
      "|    value_loss           | 42.1      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 1168        |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034558564 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0646      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.00134    |\n",
      "|    reward               | -0.20332865 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 78.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1186        |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027227808 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0934      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.9        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    reward               | -1.0294285  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 66         |\n",
      "|    time_elapsed         | 1204       |\n",
      "|    total_timesteps      | 135168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02246198 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.214      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 53         |\n",
      "|    n_updates            | 650        |\n",
      "|    policy_gradient_loss | -0.00572   |\n",
      "|    reward               | 4.691887   |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 83.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 1222        |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022454398 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.17        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -1.3808625  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1240        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033994604 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0601      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50          |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0022     |\n",
      "|    reward               | -0.43157592 |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 1258       |\n",
      "|    total_timesteps      | 141312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03565123 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | -0.00926   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 33.6       |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.0062    |\n",
      "|    reward               | -2.5327685 |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 121        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3523864.91\n",
      "total_reward: 2523864.91\n",
      "total_cost: 314291.63\n",
      "total_trades: 77321\n",
      "Sharpe: 0.718\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1277        |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035897158 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0533      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.87        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | 0.89879984  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1296        |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038831145 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.023       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.7        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 0.2657774   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 75          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1314        |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024467569 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0765      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.5        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    reward               | -17.590876  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 67.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1332        |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03440751  |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.05        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    reward               | 0.055868212 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1351        |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043280054 |\n",
      "|    clip_fraction        | 0.392       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0151      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    reward               | -2.118531   |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 75         |\n",
      "|    time_elapsed         | 1369       |\n",
      "|    total_timesteps      | 153600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03163029 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.0855     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 55.1       |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | -0.00525   |\n",
      "|    reward               | 1.3671199  |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 109        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1387        |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039466888 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0198      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.9        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    reward               | -1.5644168  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 63.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1406        |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034980923 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | -0.0865     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.36        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | 0.000451    |\n",
      "|    reward               | 1.095521    |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1424        |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029807188 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | -0.037      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | 0.000871    |\n",
      "|    reward               | 2.2785912   |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 74          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1443        |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032922246 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0267      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    reward               | -1.0490274  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 69.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 1461       |\n",
      "|    total_timesteps      | 163840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03149209 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | -0.16      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.1       |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | 0.000419   |\n",
      "|    reward               | 0.44367918 |\n",
      "|    std                  | 1.14       |\n",
      "|    value_loss           | 22.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1479        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03879675  |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0602      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    reward               | -0.25378513 |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 50.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 1497       |\n",
      "|    total_timesteps      | 167936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05540983 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.9      |\n",
      "|    explained_variance   | 0.00367    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 42.8       |\n",
      "|    n_updates            | 810        |\n",
      "|    policy_gradient_loss | -0.00278   |\n",
      "|    reward               | 0.12408859 |\n",
      "|    std                  | 1.14       |\n",
      "|    value_loss           | 66.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 1515        |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029985389 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.00934     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.5        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    reward               | 0.14446366  |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5620028.49\n",
      "total_reward: 4620028.49\n",
      "total_cost: 296711.84\n",
      "total_trades: 75215\n",
      "Sharpe: 0.964\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1533        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042750858 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.0255      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.8         |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    reward               | 0.3659951   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 1552         |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.020878632  |\n",
      "|    clip_fraction        | 0.198        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.1        |\n",
      "|    explained_variance   | 0.0266       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    reward               | -0.012951351 |\n",
      "|    std                  | 1.15         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1570        |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039298683 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0047      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    reward               | -0.7776401  |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 61          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1588        |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031459197 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.0734      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    reward               | 2.3967865   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 88         |\n",
      "|    time_elapsed         | 1606       |\n",
      "|    total_timesteps      | 180224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03508892 |\n",
      "|    clip_fraction        | 0.275      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.3      |\n",
      "|    explained_variance   | 0.0249     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.7       |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | -0.00947   |\n",
      "|    reward               | -1.7896043 |\n",
      "|    std                  | 1.16       |\n",
      "|    value_loss           | 57.3       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 1624         |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.029418942  |\n",
      "|    clip_fraction        | 0.226        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.4        |\n",
      "|    explained_variance   | -0.0202      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.9         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00727     |\n",
      "|    reward               | -0.037055016 |\n",
      "|    std                  | 1.16         |\n",
      "|    value_loss           | 84.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1642        |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026190467 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0148      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.000539   |\n",
      "|    reward               | 0.7028297   |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 80          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1660        |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025205834 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.0781      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.93        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | 0.00106     |\n",
      "|    reward               | -1.1275359  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 1679        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017805528 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.033       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.6        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -1.6508435  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 60.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1697        |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020032357 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.00602     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.4        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00917    |\n",
      "|    reward               | -4.0849795  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1716        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029677806 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | -0.00197    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | 0.00345     |\n",
      "|    reward               | 0.7339076   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1734        |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017475868 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.0418      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39          |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | -0.44906136 |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 88.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1752        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018138118 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.0141      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.4        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.00873    |\n",
      "|    reward               | -1.736966   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1771        |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012940976 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | 0.0381      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    reward               | -0.48589337 |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3864803.85\n",
      "total_reward: 2864803.85\n",
      "total_cost: 251516.68\n",
      "total_trades: 71140\n",
      "Sharpe: 0.735\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 1789        |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033302598 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | 0.0397      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    reward               | 1.0058252   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 64.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 99         |\n",
      "|    time_elapsed         | 1808       |\n",
      "|    total_timesteps      | 202752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01876717 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.8      |\n",
      "|    explained_variance   | 0.0186     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.3       |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | -0.00376   |\n",
      "|    reward               | -2.0182958 |\n",
      "|    std                  | 1.18       |\n",
      "|    value_loss           | 83.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1826        |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021967407 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | 0.0146      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.3        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | 0.000481    |\n",
      "|    reward               | 0.89961714  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 101        |\n",
      "|    time_elapsed         | 1845       |\n",
      "|    total_timesteps      | 206848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02918652 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.9      |\n",
      "|    explained_variance   | 0.0217     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22         |\n",
      "|    n_updates            | 1000       |\n",
      "|    policy_gradient_loss | -0.00171   |\n",
      "|    reward               | -0.2743407 |\n",
      "|    std                  | 1.18       |\n",
      "|    value_loss           | 35.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 1863        |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026721885 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | -0.000584   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.3        |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -1.7270198  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 1881        |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019406548 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | 0.0583      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.9        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | 0.000151    |\n",
      "|    reward               | -1.8091345  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 87.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 1900        |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03617752  |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | 0.0613      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | -0.32962373 |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 1918        |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021232396 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | 0.00738     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.9        |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -2.2533731  |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 92          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 1937        |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016409904 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | 0.021       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.8        |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.8680453  |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 1955        |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028855506 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | 0.0243      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.5        |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    reward               | 1.0871234   |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 95.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 108        |\n",
      "|    time_elapsed         | 1973       |\n",
      "|    total_timesteps      | 221184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03554119 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.1      |\n",
      "|    explained_variance   | 0.125      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.88       |\n",
      "|    n_updates            | 1070       |\n",
      "|    policy_gradient_loss | -0.00189   |\n",
      "|    reward               | 0.10530215 |\n",
      "|    std                  | 1.19       |\n",
      "|    value_loss           | 14.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 1992        |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030310418 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.2       |\n",
      "|    explained_variance   | 0.0232      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | 0.04043836  |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 63.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 2010        |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041029826 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.3       |\n",
      "|    explained_variance   | 0.00372     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.4        |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.000522   |\n",
      "|    reward               | 0.11199934  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 2029        |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037121147 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.4       |\n",
      "|    explained_variance   | 0.0138      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | 0.00689     |\n",
      "|    reward               | 4.735103    |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5075340.30\n",
      "total_reward: 4075340.30\n",
      "total_cost: 286799.27\n",
      "total_trades: 73797\n",
      "Sharpe: 0.845\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 2047        |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028879724 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.4       |\n",
      "|    explained_variance   | 0.055       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    reward               | -1.0922635  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 113        |\n",
      "|    time_elapsed         | 2065       |\n",
      "|    total_timesteps      | 231424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03784876 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.5      |\n",
      "|    explained_variance   | 0.0632     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34         |\n",
      "|    n_updates            | 1120       |\n",
      "|    policy_gradient_loss | -0.00294   |\n",
      "|    reward               | -4.4557157 |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 125        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 114        |\n",
      "|    time_elapsed         | 2084       |\n",
      "|    total_timesteps      | 233472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03411755 |\n",
      "|    clip_fraction        | 0.236      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.5      |\n",
      "|    explained_variance   | 0.0183     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 35.7       |\n",
      "|    n_updates            | 1130       |\n",
      "|    policy_gradient_loss | -0.00999   |\n",
      "|    reward               | -2.0530336 |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 110        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 2103        |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054676063 |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.6       |\n",
      "|    explained_variance   | 0.064       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.09        |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | 0.000323    |\n",
      "|    reward               | -1.6844655  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 2121        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029828005 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | 0.0298      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.5        |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    reward               | -2.5538075  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 2139        |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019625157 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | 0.0297      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.9        |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    reward               | 3.4392097   |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 2157        |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042847782 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | 0.0514      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | 0.000407    |\n",
      "|    reward               | 1.4177212   |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 2176        |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030656517 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.8       |\n",
      "|    explained_variance   | 0.0251      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    reward               | 0.71404225  |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 120        |\n",
      "|    time_elapsed         | 2194       |\n",
      "|    total_timesteps      | 245760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04137466 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.8      |\n",
      "|    explained_variance   | 0.0497     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 78.6       |\n",
      "|    n_updates            | 1190       |\n",
      "|    policy_gradient_loss | 0.0035     |\n",
      "|    reward               | -3.7379363 |\n",
      "|    std                  | 1.22       |\n",
      "|    value_loss           | 180        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 2213        |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040563013 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.9       |\n",
      "|    explained_variance   | 0.00683     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | 0.00516     |\n",
      "|    reward               | -0.81115186 |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 122        |\n",
      "|    time_elapsed         | 2231       |\n",
      "|    total_timesteps      | 249856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02953684 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.9      |\n",
      "|    explained_variance   | 0.0525     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 55.5       |\n",
      "|    n_updates            | 1210       |\n",
      "|    policy_gradient_loss | -0.0109    |\n",
      "|    reward               | -0.2871872 |\n",
      "|    std                  | 1.22       |\n",
      "|    value_loss           | 85.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 123        |\n",
      "|    time_elapsed         | 2251       |\n",
      "|    total_timesteps      | 251904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02321096 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47        |\n",
      "|    explained_variance   | 0.0563     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 50.3       |\n",
      "|    n_updates            | 1220       |\n",
      "|    policy_gradient_loss | -0.00651   |\n",
      "|    reward               | 3.3047984  |\n",
      "|    std                  | 1.22       |\n",
      "|    value_loss           | 134        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 2270        |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038490627 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.0234      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.5        |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | 0.00229     |\n",
      "|    reward               | -0.47010526 |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 2288        |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044729963 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | -0.00397    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.62        |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    reward               | 1.6819971   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4879759.77\n",
      "total_reward: 3879759.77\n",
      "total_cost: 273220.72\n",
      "total_trades: 73257\n",
      "Sharpe: 0.807\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 126        |\n",
      "|    time_elapsed         | 2306       |\n",
      "|    total_timesteps      | 258048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03202133 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.2      |\n",
      "|    explained_variance   | 0.0206     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.6       |\n",
      "|    n_updates            | 1250       |\n",
      "|    policy_gradient_loss | -0.00559   |\n",
      "|    reward               | -0.3900422 |\n",
      "|    std                  | 1.24       |\n",
      "|    value_loss           | 148        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 2325        |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028280884 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | 0.0677      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    reward               | -6.442069   |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 96.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 128        |\n",
      "|    time_elapsed         | 2343       |\n",
      "|    total_timesteps      | 262144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03649691 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.3      |\n",
      "|    explained_variance   | 0.17       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.7       |\n",
      "|    n_updates            | 1270       |\n",
      "|    policy_gradient_loss | 0.00165    |\n",
      "|    reward               | 0.74985904 |\n",
      "|    std                  | 1.24       |\n",
      "|    value_loss           | 34.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 2361        |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024047814 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | 0.0706      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.4        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | -0.6516999  |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 98.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 2380        |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030909453 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | -0.00158    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | -0.30875483 |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 131        |\n",
      "|    time_elapsed         | 2398       |\n",
      "|    total_timesteps      | 268288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03392508 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.4      |\n",
      "|    explained_variance   | 0.00293    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 71.6       |\n",
      "|    n_updates            | 1300       |\n",
      "|    policy_gradient_loss | -0.00424   |\n",
      "|    reward               | 0.2902988  |\n",
      "|    std                  | 1.25       |\n",
      "|    value_loss           | 114        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 2416        |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030467816 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.59        |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 0.17711093  |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 2434        |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037839375 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | 0.00135     |\n",
      "|    reward               | 1.3326731   |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 2453        |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045392416 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.0728      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.7        |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | 0.0017      |\n",
      "|    reward               | 2.648214    |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 2471        |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029597435 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | 0.0161      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | 0.00935     |\n",
      "|    reward               | -0.09274554 |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 136       |\n",
      "|    time_elapsed         | 2489      |\n",
      "|    total_timesteps      | 278528    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0323171 |\n",
      "|    clip_fraction        | 0.346     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -47.7     |\n",
      "|    explained_variance   | 0.0685    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 54.3      |\n",
      "|    n_updates            | 1350      |\n",
      "|    policy_gradient_loss | 0.000648  |\n",
      "|    reward               | 1.0169847 |\n",
      "|    std                  | 1.26      |\n",
      "|    value_loss           | 111       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 137        |\n",
      "|    time_elapsed         | 2508       |\n",
      "|    total_timesteps      | 280576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02221106 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.8      |\n",
      "|    explained_variance   | 0.0406     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 92.1       |\n",
      "|    n_updates            | 1360       |\n",
      "|    policy_gradient_loss | -0.00882   |\n",
      "|    reward               | -8.592286  |\n",
      "|    std                  | 1.26       |\n",
      "|    value_loss           | 116        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 2526        |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018741129 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.8       |\n",
      "|    explained_variance   | 0.0828      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.2        |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.00169    |\n",
      "|    reward               | 0.61853176  |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 2544        |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028604545 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.8       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    reward               | -1.2811594  |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6599768.08\n",
      "total_reward: 5599768.08\n",
      "total_cost: 256895.64\n",
      "total_trades: 71970\n",
      "Sharpe: 0.939\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 2562        |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021609297 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.9       |\n",
      "|    explained_variance   | 0.089       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    reward               | 0.8478836   |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 2581        |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044878837 |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | 0.0219      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 204         |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | 0.00226     |\n",
      "|    reward               | 4.1931977   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 2599        |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027496496 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.0109      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | 0.00205     |\n",
      "|    reward               | -2.3196766  |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 143          |\n",
      "|    time_elapsed         | 2617         |\n",
      "|    total_timesteps      | 292864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0144985765 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.1        |\n",
      "|    explained_variance   | 0.116        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 134          |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.00875     |\n",
      "|    reward               | 1.865615     |\n",
      "|    std                  | 1.27         |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 2635        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008443048 |\n",
      "|    clip_fraction        | 0.0623      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.0266      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63          |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    reward               | -5.545021   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 2654        |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027737321 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.9        |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    reward               | -5.664069   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 78.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 2672        |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035203535 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.0568      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.9        |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.00173    |\n",
      "|    reward               | 2.2662416   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 2690        |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020984307 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.0457      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.6        |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.000933   |\n",
      "|    reward               | -1.4749335  |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 2709        |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027788848 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.0197      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76          |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | 0.00287     |\n",
      "|    reward               | 0.8621663   |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 186         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 2727        |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022255205 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | -0.0958     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | 0.00643     |\n",
      "|    reward               | 0.7591817   |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 31.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 2746        |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028139528 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | 0.00884     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32          |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | 0.00181     |\n",
      "|    reward               | 0.8383347   |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 2764        |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027904358 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | 0.00491     |\n",
      "|    reward               | 6.790686    |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 2782        |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035046868 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | 0.00786     |\n",
      "|    reward               | -1.5402803  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 46          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 2801        |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037353367 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | 0.0816      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.1        |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | 0.00193     |\n",
      "|    reward               | -0.3272377  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5041579.90\n",
      "total_reward: 4041579.90\n",
      "total_cost: 294973.90\n",
      "total_trades: 74666\n",
      "Sharpe: 0.840\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 2819        |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037313167 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.4       |\n",
      "|    explained_variance   | 0.035       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.7        |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | 0.00114     |\n",
      "|    reward               | -0.85883355 |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 155        |\n",
      "|    time_elapsed         | 2837       |\n",
      "|    total_timesteps      | 317440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03202887 |\n",
      "|    clip_fraction        | 0.362      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.5      |\n",
      "|    explained_variance   | 0.0163     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 71.4       |\n",
      "|    n_updates            | 1540       |\n",
      "|    policy_gradient_loss | -0.00424   |\n",
      "|    reward               | -1.4664232 |\n",
      "|    std                  | 1.29       |\n",
      "|    value_loss           | 114        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 2855        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030909855 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.5       |\n",
      "|    explained_variance   | 0.0168      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    reward               | -1.8599191  |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 2874        |\n",
      "|    total_timesteps      | 321536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035614036 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.6       |\n",
      "|    explained_variance   | 0.049       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.7        |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    reward               | -1.8765408  |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 158        |\n",
      "|    time_elapsed         | 2892       |\n",
      "|    total_timesteps      | 323584     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03241655 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.6      |\n",
      "|    explained_variance   | 0.0716     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 127        |\n",
      "|    n_updates            | 1570       |\n",
      "|    policy_gradient_loss | -0.00581   |\n",
      "|    reward               | -6.996782  |\n",
      "|    std                  | 1.3        |\n",
      "|    value_loss           | 231        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 2910        |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034485746 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | 0.00632     |\n",
      "|    reward               | -0.47418746 |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 2929        |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024070684 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | -0.00851    |\n",
      "|    reward               | 2.0845897   |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 161        |\n",
      "|    time_elapsed         | 2947       |\n",
      "|    total_timesteps      | 329728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04358983 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.8      |\n",
      "|    explained_variance   | 0.125      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.4       |\n",
      "|    n_updates            | 1600       |\n",
      "|    policy_gradient_loss | -0.00318   |\n",
      "|    reward               | 30.124952  |\n",
      "|    std                  | 1.3        |\n",
      "|    value_loss           | 125        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 2965        |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035148673 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | -0.0167     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.7        |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.00719    |\n",
      "|    reward               | -0.5946616  |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 94.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 2983        |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039197654 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.22        |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.00109    |\n",
      "|    reward               | -1.3655676  |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 44          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 164          |\n",
      "|    time_elapsed         | 3002         |\n",
      "|    total_timesteps      | 335872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.025760934  |\n",
      "|    clip_fraction        | 0.25         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49          |\n",
      "|    explained_variance   | 0.0754       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 1630         |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    reward               | -0.039324906 |\n",
      "|    std                  | 1.31         |\n",
      "|    value_loss           | 88           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 3020        |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036594577 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49         |\n",
      "|    explained_variance   | 0.0777      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.1        |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | 7.2409186   |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 166        |\n",
      "|    time_elapsed         | 3038       |\n",
      "|    total_timesteps      | 339968     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05092687 |\n",
      "|    clip_fraction        | 0.413      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.1      |\n",
      "|    explained_variance   | 0.0944     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.6       |\n",
      "|    n_updates            | 1650       |\n",
      "|    policy_gradient_loss | -0.00209   |\n",
      "|    reward               | 1.5132806  |\n",
      "|    std                  | 1.32       |\n",
      "|    value_loss           | 29.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 3056        |\n",
      "|    total_timesteps      | 342016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027293492 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.2        |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | 0.6064313   |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 3074        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018640898 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 2.8523684   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6959818.66\n",
      "total_reward: 5959818.66\n",
      "total_cost: 291379.82\n",
      "total_trades: 74189\n",
      "Sharpe: 0.971\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 3092        |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027423816 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    reward               | -2.156313   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 55.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 3111        |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033223465 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    reward               | -1.8210796  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 3129        |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035882086 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.00719    |\n",
      "|    reward               | -0.34880304 |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 3147        |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026976692 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.0021     |\n",
      "|    reward               | 1.3380725   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 90.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 3165        |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039137606 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    reward               | -1.0104115  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 3184        |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036252536 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.9        |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    reward               | 1.5645907   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 175        |\n",
      "|    time_elapsed         | 3202       |\n",
      "|    total_timesteps      | 358400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02824137 |\n",
      "|    clip_fraction        | 0.275      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.5      |\n",
      "|    explained_variance   | 0.17       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.5       |\n",
      "|    n_updates            | 1740       |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    reward               | 0.8133085  |\n",
      "|    std                  | 1.33       |\n",
      "|    value_loss           | 123        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 3220        |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018163923 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    reward               | 1.5561658   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 177        |\n",
      "|    time_elapsed         | 3239       |\n",
      "|    total_timesteps      | 362496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02734628 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.5      |\n",
      "|    explained_variance   | 0.148      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 53.5       |\n",
      "|    n_updates            | 1760       |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    reward               | -0.6451467 |\n",
      "|    std                  | 1.34       |\n",
      "|    value_loss           | 63.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 3257        |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019327551 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54          |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    reward               | -0.92219234 |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 93.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 179        |\n",
      "|    time_elapsed         | 3276       |\n",
      "|    total_timesteps      | 366592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03000871 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.5      |\n",
      "|    explained_variance   | 0.174      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38.8       |\n",
      "|    n_updates            | 1780       |\n",
      "|    policy_gradient_loss | -0.00767   |\n",
      "|    reward               | 1.9291624  |\n",
      "|    std                  | 1.34       |\n",
      "|    value_loss           | 68.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 3294        |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029240536 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.64        |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    reward               | 0.46162722  |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 3312        |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038365357 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    reward               | -0.444538   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 3330        |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026555514 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.7       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | -0.000491   |\n",
      "|    reward               | -0.21923085 |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3146955.02\n",
      "total_reward: 2146955.02\n",
      "total_cost: 267109.87\n",
      "total_trades: 70182\n",
      "Sharpe: 0.626\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 3349        |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03387268  |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.7       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    reward               | -0.13810028 |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 184        |\n",
      "|    time_elapsed         | 3367       |\n",
      "|    total_timesteps      | 376832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02206011 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.8      |\n",
      "|    explained_variance   | 0.137      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.6       |\n",
      "|    n_updates            | 1830       |\n",
      "|    policy_gradient_loss | -0.0109    |\n",
      "|    reward               | -2.000418  |\n",
      "|    std                  | 1.35       |\n",
      "|    value_loss           | 29.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 3385        |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023233928 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | 3.250465    |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 39.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 3404        |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025631143 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.96        |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    reward               | -1.1183274  |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 187        |\n",
      "|    time_elapsed         | 3424       |\n",
      "|    total_timesteps      | 382976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02343915 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.9      |\n",
      "|    explained_variance   | 0.231      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.8        |\n",
      "|    n_updates            | 1860       |\n",
      "|    policy_gradient_loss | -0.0161    |\n",
      "|    reward               | 0.97330934 |\n",
      "|    std                  | 1.36       |\n",
      "|    value_loss           | 19.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 3443        |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024051026 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50         |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | 0.9793983   |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 3461        |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028253961 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50         |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.000762   |\n",
      "|    reward               | -3.0649726  |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 3480        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024590552 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.1       |\n",
      "|    explained_variance   | 0.0702      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.08        |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | 4.2015386   |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 191        |\n",
      "|    time_elapsed         | 3498       |\n",
      "|    total_timesteps      | 391168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06552029 |\n",
      "|    clip_fraction        | 0.354      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.2      |\n",
      "|    explained_variance   | 0.239      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.3       |\n",
      "|    n_updates            | 1900       |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    reward               | 1.1895111  |\n",
      "|    std                  | 1.37       |\n",
      "|    value_loss           | 21.9       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 192        |\n",
      "|    time_elapsed         | 3516       |\n",
      "|    total_timesteps      | 393216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03419194 |\n",
      "|    clip_fraction        | 0.294      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.3      |\n",
      "|    explained_variance   | 0.0502     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 54.2       |\n",
      "|    n_updates            | 1910       |\n",
      "|    policy_gradient_loss | -0.00292   |\n",
      "|    reward               | -4.326287  |\n",
      "|    std                  | 1.37       |\n",
      "|    value_loss           | 80         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 3535        |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044206023 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.4       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.2         |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | -0.3732452  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 3553        |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.04270438  |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | 0.0601      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | 0.00176     |\n",
      "|    reward               | 0.053775616 |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 3571        |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026479183 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | 0.9232647   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 45.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 196        |\n",
      "|    time_elapsed         | 3590       |\n",
      "|    total_timesteps      | 401408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03742563 |\n",
      "|    clip_fraction        | 0.357      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.6      |\n",
      "|    explained_variance   | 0.0239     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 35.6       |\n",
      "|    n_updates            | 1950       |\n",
      "|    policy_gradient_loss | 0.00104    |\n",
      "|    reward               | 2.9756315  |\n",
      "|    std                  | 1.39       |\n",
      "|    value_loss           | 120        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3825540.94\n",
      "total_reward: 2825540.94\n",
      "total_cost: 267771.48\n",
      "total_trades: 69840\n",
      "Sharpe: 0.684\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 3608        |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022868108 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.22        |\n",
      "|    n_updates            | 1960        |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    reward               | 0.60503405  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 3626        |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037823886 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.0969      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.1        |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    reward               | 0.22868687  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 63.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 3645        |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042371206 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.0498      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 1980        |\n",
      "|    policy_gradient_loss | 0.00152     |\n",
      "|    reward               | 0.1734119   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 66.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 3663        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029485594 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.0712      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | 0.82681715  |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 201        |\n",
      "|    time_elapsed         | 3681       |\n",
      "|    total_timesteps      | 411648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03607551 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.8      |\n",
      "|    explained_variance   | 0.129      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.9       |\n",
      "|    n_updates            | 2000       |\n",
      "|    policy_gradient_loss | -0.0093    |\n",
      "|    reward               | 0.59685546 |\n",
      "|    std                  | 1.4        |\n",
      "|    value_loss           | 31.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 3699        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026044969 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.9       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | -9.057119   |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 3718        |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039860934 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.9       |\n",
      "|    explained_variance   | 0.017       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 2020        |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    reward               | 0.96625024  |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 3736        |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038006958 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.89        |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    reward               | -0.78810394 |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 3754        |\n",
      "|    total_timesteps      | 419840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022168323 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.7        |\n",
      "|    n_updates            | 2040        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 2.3663619   |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 3772        |\n",
      "|    total_timesteps      | 421888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018063635 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.1       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    reward               | -0.08111283 |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 3791        |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033712275 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.1       |\n",
      "|    explained_variance   | -0.0436     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.03        |\n",
      "|    n_updates            | 2060        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -1.8677788  |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 3809        |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036883246 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.0734      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 2070        |\n",
      "|    policy_gradient_loss | 0.000224    |\n",
      "|    reward               | -2.979928   |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 209        |\n",
      "|    time_elapsed         | 3827       |\n",
      "|    total_timesteps      | 428032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02137193 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.2      |\n",
      "|    explained_variance   | 0.0848     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16         |\n",
      "|    n_updates            | 2080       |\n",
      "|    policy_gradient_loss | -0.00735   |\n",
      "|    reward               | 0.5503793  |\n",
      "|    std                  | 1.42       |\n",
      "|    value_loss           | 43         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 3846        |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032486238 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.08        |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    reward               | -0.3308416  |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 15.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4358552.26\n",
      "total_reward: 3358552.26\n",
      "total_cost: 250917.01\n",
      "total_trades: 69395\n",
      "Sharpe: 0.810\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 3864        |\n",
      "|    total_timesteps      | 432128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044691175 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.35        |\n",
      "|    n_updates            | 2100        |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | 0.69847023  |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 3882        |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016640894 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.07        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.6        |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    reward               | 0.22706656  |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 73.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 3901        |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029184021 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.0297      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.2        |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    reward               | 1.6132404   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 72.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 3920        |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042099297 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.29        |\n",
      "|    n_updates            | 2130        |\n",
      "|    policy_gradient_loss | 0.00192     |\n",
      "|    reward               | 0.37546092  |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 215         |\n",
      "|    time_elapsed         | 3938        |\n",
      "|    total_timesteps      | 440320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024659468 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.1        |\n",
      "|    n_updates            | 2140        |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    reward               | 1.1742618   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 3956        |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024005894 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.0789      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 2150        |\n",
      "|    policy_gradient_loss | 0.00371     |\n",
      "|    reward               | 5.0003357   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 75.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 3974        |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020908002 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    reward               | 0.5022837   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 49.2        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 218       |\n",
      "|    time_elapsed         | 3992      |\n",
      "|    total_timesteps      | 446464    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0464019 |\n",
      "|    clip_fraction        | 0.289     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -51.5     |\n",
      "|    explained_variance   | 0.139     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 79.7      |\n",
      "|    n_updates            | 2170      |\n",
      "|    policy_gradient_loss | 0.00341   |\n",
      "|    reward               | 0.9479255 |\n",
      "|    std                  | 1.43      |\n",
      "|    value_loss           | 117       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 4011        |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039821498 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.6       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 2180        |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    reward               | -0.24875788 |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 67.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 220         |\n",
      "|    time_elapsed         | 4029        |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032492332 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.6       |\n",
      "|    explained_variance   | 0.0704      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    reward               | 1.7463938   |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 71.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 221        |\n",
      "|    time_elapsed         | 4047       |\n",
      "|    total_timesteps      | 452608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0471527  |\n",
      "|    clip_fraction        | 0.393      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.7      |\n",
      "|    explained_variance   | 0.182      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.11       |\n",
      "|    n_updates            | 2200       |\n",
      "|    policy_gradient_loss | 0.000753   |\n",
      "|    reward               | -0.9427003 |\n",
      "|    std                  | 1.44       |\n",
      "|    value_loss           | 12.4       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 4066        |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056594484 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.8       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 2210        |\n",
      "|    policy_gradient_loss | 0.000563    |\n",
      "|    reward               | 0.042779986 |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 54.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 223        |\n",
      "|    time_elapsed         | 4084       |\n",
      "|    total_timesteps      | 456704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02108685 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.8      |\n",
      "|    explained_variance   | 0.0506     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.4       |\n",
      "|    n_updates            | 2220       |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    reward               | 0.33279756 |\n",
      "|    std                  | 1.45       |\n",
      "|    value_loss           | 67.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 4102        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029717147 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.9       |\n",
      "|    explained_variance   | 0.0294      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 2230        |\n",
      "|    policy_gradient_loss | -0.000593   |\n",
      "|    reward               | 2.5204113   |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3724022.28\n",
      "total_reward: 2724022.28\n",
      "total_cost: 270329.81\n",
      "total_trades: 70265\n",
      "Sharpe: 0.735\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 225         |\n",
      "|    time_elapsed         | 4120        |\n",
      "|    total_timesteps      | 460800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036003232 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.9       |\n",
      "|    explained_variance   | 0.0649      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 2240        |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    reward               | 1.5179955   |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 53.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 4139        |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039928738 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52         |\n",
      "|    explained_variance   | 0.032       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.000247   |\n",
      "|    reward               | 5.604173    |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 42          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 4157        |\n",
      "|    total_timesteps      | 464896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02287368  |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52         |\n",
      "|    explained_variance   | 0.0606      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    reward               | -0.49143177 |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 66.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 4175        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026570797 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.1       |\n",
      "|    explained_variance   | -0.0829     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | 0.00388     |\n",
      "|    reward               | -0.3886414  |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 4193        |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019618623 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.2       |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.0093     |\n",
      "|    reward               | -0.90352184 |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 60.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 4212        |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027189443 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.2       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.2        |\n",
      "|    n_updates            | 2290        |\n",
      "|    policy_gradient_loss | -0.000785   |\n",
      "|    reward               | 1.0694648   |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 60.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 231        |\n",
      "|    time_elapsed         | 4230       |\n",
      "|    total_timesteps      | 473088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02985245 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.2      |\n",
      "|    explained_variance   | 0.00983    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.03       |\n",
      "|    n_updates            | 2300       |\n",
      "|    policy_gradient_loss | -0.00606   |\n",
      "|    reward               | -8.288378  |\n",
      "|    std                  | 1.47       |\n",
      "|    value_loss           | 32.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 4248        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034284886 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.2       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.4        |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | 0.0077      |\n",
      "|    reward               | 0.08712525  |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 59.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 4266        |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025269661 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | 0.0699      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62          |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | 0.00791     |\n",
      "|    reward               | -0.92082256 |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 95.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 4284        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037833452 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | 0.0755      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    reward               | 0.22571588  |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 4303        |\n",
      "|    total_timesteps      | 481280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030579636 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.4       |\n",
      "|    explained_variance   | 0.0529      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.7        |\n",
      "|    n_updates            | 2340        |\n",
      "|    policy_gradient_loss | 0.00403     |\n",
      "|    reward               | 0.4749078   |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 53.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 4321        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026920483 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.4       |\n",
      "|    explained_variance   | 0.0876      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.6        |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | 0.000347    |\n",
      "|    reward               | 0.6876642   |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 87.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 4339        |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033297904 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.4       |\n",
      "|    explained_variance   | 0.0622      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.4        |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    reward               | -1.7821391  |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 96.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 4357        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023409009 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.5       |\n",
      "|    explained_variance   | 0.0908      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 2370        |\n",
      "|    policy_gradient_loss | 0.00845     |\n",
      "|    reward               | 1.8613558   |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6858438.93\n",
      "total_reward: 5858438.93\n",
      "total_cost: 208909.19\n",
      "total_trades: 63847\n",
      "Sharpe: 0.925\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 4375        |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024893083 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.5       |\n",
      "|    explained_variance   | 0.0624      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.5        |\n",
      "|    n_updates            | 2380        |\n",
      "|    policy_gradient_loss | 0.000617    |\n",
      "|    reward               | 1.3973978   |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 4394        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038178865 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.5       |\n",
      "|    explained_variance   | 0.0346      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.1        |\n",
      "|    n_updates            | 2390        |\n",
      "|    policy_gradient_loss | 0.00333     |\n",
      "|    reward               | -1.7805784  |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 216         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 241        |\n",
      "|    time_elapsed         | 4412       |\n",
      "|    total_timesteps      | 493568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02893503 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.6      |\n",
      "|    explained_variance   | 0.0363     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.1       |\n",
      "|    n_updates            | 2400       |\n",
      "|    policy_gradient_loss | 0.000215   |\n",
      "|    reward               | -0.1279352 |\n",
      "|    std                  | 1.49       |\n",
      "|    value_loss           | 51.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 4430        |\n",
      "|    total_timesteps      | 495616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020768475 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 2410        |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    reward               | 0.34687155  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 61.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 4448        |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010955168 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.082       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.2        |\n",
      "|    n_updates            | 2420        |\n",
      "|    policy_gradient_loss | -0.00267    |\n",
      "|    reward               | 0.12013227  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 4467        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009762571 |\n",
      "|    clip_fraction        | 0.0426      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.0719      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    reward               | -2.0782504  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 258         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 4485        |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036198482 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | 0.00301     |\n",
      "|    reward               | 0.39757976  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 4503        |\n",
      "|    total_timesteps      | 503808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018546565 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.3        |\n",
      "|    n_updates            | 2450        |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    reward               | 1.16272     |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 247         |\n",
      "|    time_elapsed         | 4521        |\n",
      "|    total_timesteps      | 505856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012046961 |\n",
      "|    clip_fraction        | 0.0671      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.8        |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    reward               | 6.6994886   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 286         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 4540        |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036961727 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.8       |\n",
      "|    explained_variance   | -0.0181     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 2470        |\n",
      "|    policy_gradient_loss | 0.00571     |\n",
      "|    reward               | -8.518022   |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 249          |\n",
      "|    time_elapsed         | 4558         |\n",
      "|    total_timesteps      | 509952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0145472055 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -52.8        |\n",
      "|    explained_variance   | 0.149        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.3         |\n",
      "|    n_updates            | 2480         |\n",
      "|    policy_gradient_loss | -0.00707     |\n",
      "|    reward               | 1.129497     |\n",
      "|    std                  | 1.5          |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 250         |\n",
      "|    time_elapsed         | 4576        |\n",
      "|    total_timesteps      | 512000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017674318 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.8       |\n",
      "|    explained_variance   | 0.0319      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 246         |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | -0.00225    |\n",
      "|    reward               | -28.682419  |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 387         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 251          |\n",
      "|    time_elapsed         | 4595         |\n",
      "|    total_timesteps      | 514048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063051064 |\n",
      "|    clip_fraction        | 0.0589       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -52.8        |\n",
      "|    explained_variance   | 0.0321       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 193          |\n",
      "|    n_updates            | 2500         |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    reward               | 4.2411437    |\n",
      "|    std                  | 1.5          |\n",
      "|    value_loss           | 368          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 252         |\n",
      "|    time_elapsed         | 4613        |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015238994 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.8       |\n",
      "|    explained_variance   | 0.18        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    reward               | 8.828226    |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 56.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8487400.28\n",
      "total_reward: 7487400.28\n",
      "total_cost: 177025.41\n",
      "total_trades: 60716\n",
      "Sharpe: 0.944\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 4631        |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012331307 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    reward               | 0.11817342  |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 316         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 254          |\n",
      "|    time_elapsed         | 4649         |\n",
      "|    total_timesteps      | 520192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061127124 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -52.9        |\n",
      "|    explained_variance   | 0.139        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 184          |\n",
      "|    n_updates            | 2530         |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    reward               | 6.4253116    |\n",
      "|    std                  | 1.5          |\n",
      "|    value_loss           | 389          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 4667        |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021757852 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.0805      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 2540        |\n",
      "|    policy_gradient_loss | -0.000215   |\n",
      "|    reward               | 7.56887     |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 57.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 256        |\n",
      "|    time_elapsed         | 4685       |\n",
      "|    total_timesteps      | 524288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02881795 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53        |\n",
      "|    explained_variance   | 0.0802     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 158        |\n",
      "|    n_updates            | 2550       |\n",
      "|    policy_gradient_loss | -0.00185   |\n",
      "|    reward               | 7.008919   |\n",
      "|    std                  | 1.51       |\n",
      "|    value_loss           | 247        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 257         |\n",
      "|    time_elapsed         | 4703        |\n",
      "|    total_timesteps      | 526336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014188835 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53         |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 193         |\n",
      "|    n_updates            | 2560        |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    reward               | 4.59697     |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 369         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 4721        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026100118 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53         |\n",
      "|    explained_variance   | -0.0059     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.7        |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | 0.00756     |\n",
      "|    reward               | 2.753408    |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 4739        |\n",
      "|    total_timesteps      | 530432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017450107 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.0606      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58          |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | -0.20153314 |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 260         |\n",
      "|    time_elapsed         | 4757        |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009263232 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.0291      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 190         |\n",
      "|    n_updates            | 2590        |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | 0.3422479   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 340         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 4775        |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011214193 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.0814      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    reward               | 9.742179    |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 234         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 262        |\n",
      "|    time_elapsed         | 4793       |\n",
      "|    total_timesteps      | 536576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0232923  |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.1      |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.8       |\n",
      "|    n_updates            | 2610       |\n",
      "|    policy_gradient_loss | -0.00125   |\n",
      "|    reward               | -1.5778716 |\n",
      "|    std                  | 1.51       |\n",
      "|    value_loss           | 33.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 263         |\n",
      "|    time_elapsed         | 4811        |\n",
      "|    total_timesteps      | 538624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039544612 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.0796      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 2620        |\n",
      "|    policy_gradient_loss | 0.00225     |\n",
      "|    reward               | 1.0470539   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 261         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 264         |\n",
      "|    time_elapsed         | 4833        |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017344192 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.0466      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.5        |\n",
      "|    n_updates            | 2630        |\n",
      "|    policy_gradient_loss | 0.00165     |\n",
      "|    reward               | -3.9493456  |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 265         |\n",
      "|    time_elapsed         | 4851        |\n",
      "|    total_timesteps      | 542720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021431267 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.0405      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 2640        |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | -3.1743028  |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 65.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 4869        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03888788  |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.2       |\n",
      "|    explained_variance   | 0.0439      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.6        |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | 0.00035     |\n",
      "|    reward               | -0.09760524 |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6718608.67\n",
      "total_reward: 5718608.67\n",
      "total_cost: 141314.58\n",
      "total_trades: 57466\n",
      "Sharpe: 0.914\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 267         |\n",
      "|    time_elapsed         | 4887        |\n",
      "|    total_timesteps      | 546816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020370668 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.2       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.3        |\n",
      "|    n_updates            | 2660        |\n",
      "|    policy_gradient_loss | 0.000507    |\n",
      "|    reward               | -1.1641369  |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 268        |\n",
      "|    time_elapsed         | 4905       |\n",
      "|    total_timesteps      | 548864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01903063 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.2      |\n",
      "|    explained_variance   | 0.0961     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 95.7       |\n",
      "|    n_updates            | 2670       |\n",
      "|    policy_gradient_loss | -0.00135   |\n",
      "|    reward               | 1.3668758  |\n",
      "|    std                  | 1.52       |\n",
      "|    value_loss           | 219        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 269       |\n",
      "|    time_elapsed         | 4923      |\n",
      "|    total_timesteps      | 550912    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0495096 |\n",
      "|    clip_fraction        | 0.41      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -53.3     |\n",
      "|    explained_variance   | 0.472     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 9.56      |\n",
      "|    n_updates            | 2680      |\n",
      "|    policy_gradient_loss | -0.000547 |\n",
      "|    reward               | 0.6192563 |\n",
      "|    std                  | 1.53      |\n",
      "|    value_loss           | 22.7      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 4941        |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018549914 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.4       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.7        |\n",
      "|    n_updates            | 2690        |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    reward               | 2.1089168   |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 217         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 271        |\n",
      "|    time_elapsed         | 4960       |\n",
      "|    total_timesteps      | 555008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02258736 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.4      |\n",
      "|    explained_variance   | 0.0618     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 374        |\n",
      "|    n_updates            | 2700       |\n",
      "|    policy_gradient_loss | 0.00645    |\n",
      "|    reward               | 5.954144   |\n",
      "|    std                  | 1.53       |\n",
      "|    value_loss           | 414        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 272           |\n",
      "|    time_elapsed         | 4978          |\n",
      "|    total_timesteps      | 557056        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.018395226   |\n",
      "|    clip_fraction        | 0.16          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -53.5         |\n",
      "|    explained_variance   | -0.0264       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 35.8          |\n",
      "|    n_updates            | 2710          |\n",
      "|    policy_gradient_loss | -0.00017      |\n",
      "|    reward               | -0.0123887705 |\n",
      "|    std                  | 1.53          |\n",
      "|    value_loss           | 91.5          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 273         |\n",
      "|    time_elapsed         | 4996        |\n",
      "|    total_timesteps      | 559104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012351275 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.5       |\n",
      "|    explained_variance   | 0.0731      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 166         |\n",
      "|    n_updates            | 2720        |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | -0.93108594 |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 385         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 274         |\n",
      "|    time_elapsed         | 5014        |\n",
      "|    total_timesteps      | 561152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023321439 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | -0.00256    |\n",
      "|    reward               | -55.809303  |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 349         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 5032        |\n",
      "|    total_timesteps      | 563200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019873181 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 2740        |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    reward               | 1.0038774   |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 5050        |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027369823 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.00062    |\n",
      "|    reward               | 1.194506    |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 277       |\n",
      "|    time_elapsed         | 5068      |\n",
      "|    total_timesteps      | 567296    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0305404 |\n",
      "|    clip_fraction        | 0.245     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -53.7     |\n",
      "|    explained_variance   | 0.149     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 152       |\n",
      "|    n_updates            | 2760      |\n",
      "|    policy_gradient_loss | -0.000725 |\n",
      "|    reward               | 1.1343527 |\n",
      "|    std                  | 1.55      |\n",
      "|    value_loss           | 412       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 278         |\n",
      "|    time_elapsed         | 5086        |\n",
      "|    total_timesteps      | 569344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008094907 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.8       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 262         |\n",
      "|    n_updates            | 2770        |\n",
      "|    policy_gradient_loss | -0.00117    |\n",
      "|    reward               | -1.6549445  |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 270         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 279         |\n",
      "|    time_elapsed         | 5105        |\n",
      "|    total_timesteps      | 571392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013297701 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.8       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 2780        |\n",
      "|    policy_gradient_loss | 0.00291     |\n",
      "|    reward               | 2.2664967   |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 5122        |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019406676 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.8       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 194         |\n",
      "|    n_updates            | 2790        |\n",
      "|    policy_gradient_loss | 0.00145     |\n",
      "|    reward               | 1.7268884   |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 198         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 5140        |\n",
      "|    total_timesteps      | 575488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013950868 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 167         |\n",
      "|    n_updates            | 2800        |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    reward               | -1.0024405  |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 253         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7960326.81\n",
      "total_reward: 6960326.81\n",
      "total_cost: 166812.96\n",
      "total_trades: 58064\n",
      "Sharpe: 0.971\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 282          |\n",
      "|    time_elapsed         | 5159         |\n",
      "|    total_timesteps      | 577536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049794344 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -53.9        |\n",
      "|    explained_variance   | 0.178        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.2         |\n",
      "|    n_updates            | 2810         |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    reward               | 0.42800766   |\n",
      "|    std                  | 1.55         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 283         |\n",
      "|    time_elapsed         | 5177        |\n",
      "|    total_timesteps      | 579584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016132105 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84          |\n",
      "|    n_updates            | 2820        |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    reward               | 2.9422314   |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 284         |\n",
      "|    time_elapsed         | 5195        |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020762281 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.6        |\n",
      "|    n_updates            | 2830        |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    reward               | 1.2034302   |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 5213        |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008586588 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 256         |\n",
      "|    n_updates            | 2840        |\n",
      "|    policy_gradient_loss | -0.00116    |\n",
      "|    reward               | 4.641172    |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 289         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 5231        |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018853325 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    reward               | -0.05977823 |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 39.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 5249        |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022919755 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | 3.14e-05    |\n",
      "|    reward               | 0.23742403  |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 299         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 5267        |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019272815 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.3        |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    reward               | 1.2276014   |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 231         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 289         |\n",
      "|    time_elapsed         | 5285        |\n",
      "|    total_timesteps      | 591872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030289525 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 2880        |\n",
      "|    policy_gradient_loss | 0.000352    |\n",
      "|    reward               | 0.5010389   |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 69.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 5304        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014779866 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.9        |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    reward               | 1.6663651   |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 291         |\n",
      "|    time_elapsed         | 5322        |\n",
      "|    total_timesteps      | 595968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008845679 |\n",
      "|    clip_fraction        | 0.0525      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.4        |\n",
      "|    n_updates            | 2900        |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    reward               | 0.030115573 |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 274         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 292       |\n",
      "|    time_elapsed         | 5341      |\n",
      "|    total_timesteps      | 598016    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0119645 |\n",
      "|    clip_fraction        | 0.0437    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -53.9     |\n",
      "|    explained_variance   | 0.201     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 121       |\n",
      "|    n_updates            | 2910      |\n",
      "|    policy_gradient_loss | -0.00564  |\n",
      "|    reward               | 1.6130822 |\n",
      "|    std                  | 1.56      |\n",
      "|    value_loss           | 340       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 293        |\n",
      "|    time_elapsed         | 5359       |\n",
      "|    total_timesteps      | 600064     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04211592 |\n",
      "|    clip_fraction        | 0.377      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54        |\n",
      "|    explained_variance   | 0.196      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.56       |\n",
      "|    n_updates            | 2920       |\n",
      "|    policy_gradient_loss | 0.00571    |\n",
      "|    reward               | -0.8890716 |\n",
      "|    std                  | 1.56       |\n",
      "|    value_loss           | 21.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 5377        |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021846455 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54         |\n",
      "|    explained_variance   | 0.0871      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 2930        |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    reward               | -0.6362868  |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 256         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 5395        |\n",
      "|    total_timesteps      | 604160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033572003 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54         |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    reward               | 3.3470337   |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 248         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9077234.71\n",
      "total_reward: 8077234.71\n",
      "total_cost: 186196.82\n",
      "total_trades: 61139\n",
      "Sharpe: 0.958\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 5414        |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025381323 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54         |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.5        |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | -0.000154   |\n",
      "|    reward               | -2.3054488  |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 84.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 5432        |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009728205 |\n",
      "|    clip_fraction        | 0.0649      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 274         |\n",
      "|    n_updates            | 2960        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -1.4932553  |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 366         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 298         |\n",
      "|    time_elapsed         | 5450        |\n",
      "|    total_timesteps      | 610304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012301203 |\n",
      "|    clip_fraction        | 0.0816      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 162         |\n",
      "|    n_updates            | 2970        |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    reward               | 1.9407492   |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 437         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 5469        |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014979459 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.7        |\n",
      "|    n_updates            | 2980        |\n",
      "|    policy_gradient_loss | -0.00155    |\n",
      "|    reward               | -1.9043223  |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 5487        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023852728 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | 7e-05       |\n",
      "|    reward               | 1.9050554   |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 301         |\n",
      "|    time_elapsed         | 5505        |\n",
      "|    total_timesteps      | 616448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010938062 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.00185    |\n",
      "|    reward               | 1.0069591   |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 313         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 5523        |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016971111 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 3010        |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    reward               | -8.797205   |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 293         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 303        |\n",
      "|    time_elapsed         | 5541       |\n",
      "|    total_timesteps      | 620544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03500551 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.1      |\n",
      "|    explained_variance   | 0.142      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.4       |\n",
      "|    n_updates            | 3020       |\n",
      "|    policy_gradient_loss | -0.00189   |\n",
      "|    reward               | -5.266092  |\n",
      "|    std                  | 1.57       |\n",
      "|    value_loss           | 46.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 5560        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014715482 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.2       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 3030        |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    reward               | -0.58958524 |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 5578        |\n",
      "|    total_timesteps      | 624640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023731634 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.2       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 166         |\n",
      "|    n_updates            | 3040        |\n",
      "|    policy_gradient_loss | 0.00538     |\n",
      "|    reward               | -3.6332612  |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 296         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 5596        |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013771101 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.2       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.6        |\n",
      "|    n_updates            | 3050        |\n",
      "|    policy_gradient_loss | 0.00258     |\n",
      "|    reward               | -5.105081   |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 95.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 5614        |\n",
      "|    total_timesteps      | 628736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031510066 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.2       |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.7        |\n",
      "|    n_updates            | 3060        |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    reward               | -0.81138206 |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 308         |\n",
      "|    time_elapsed         | 5632        |\n",
      "|    total_timesteps      | 630784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027485222 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.4        |\n",
      "|    n_updates            | 3070        |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    reward               | -0.6004437  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 309        |\n",
      "|    time_elapsed         | 5651       |\n",
      "|    total_timesteps      | 632832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00909812 |\n",
      "|    clip_fraction        | 0.0252     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.3      |\n",
      "|    explained_variance   | 0.249      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 141        |\n",
      "|    n_updates            | 3080       |\n",
      "|    policy_gradient_loss | -0.00426   |\n",
      "|    reward               | 1.6746107  |\n",
      "|    std                  | 1.58       |\n",
      "|    value_loss           | 304        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7573561.08\n",
      "total_reward: 6573561.08\n",
      "total_cost: 233868.11\n",
      "total_trades: 65385\n",
      "Sharpe: 0.937\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 5669        |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025340267 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | -0.0169     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 3090        |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    reward               | 0.135525    |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 5687        |\n",
      "|    total_timesteps      | 636928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017216237 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 229         |\n",
      "|    n_updates            | 3100        |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    reward               | 0.11371796  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 229         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 5705        |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041834764 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 218         |\n",
      "|    n_updates            | 3110        |\n",
      "|    policy_gradient_loss | 0.0121      |\n",
      "|    reward               | -14.434402  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 251         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 313         |\n",
      "|    time_elapsed         | 5723        |\n",
      "|    total_timesteps      | 641024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014835468 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.2        |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    reward               | -14.980546  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 91.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 5741        |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009431658 |\n",
      "|    clip_fraction        | 0.0484      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 224         |\n",
      "|    n_updates            | 3130        |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    reward               | -1.3571616  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 255         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 5759        |\n",
      "|    total_timesteps      | 645120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015160531 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 3140        |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    reward               | -17.479292  |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 276         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 5778        |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014081723 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 160         |\n",
      "|    n_updates            | 3150        |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    reward               | 2.25345     |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 332         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 317        |\n",
      "|    time_elapsed         | 5796       |\n",
      "|    total_timesteps      | 649216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04981593 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.5      |\n",
      "|    explained_variance   | 0.411      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.6       |\n",
      "|    n_updates            | 3160       |\n",
      "|    policy_gradient_loss | 0.00341    |\n",
      "|    reward               | -1.1267049 |\n",
      "|    std                  | 1.59       |\n",
      "|    value_loss           | 31.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 318         |\n",
      "|    time_elapsed         | 5814        |\n",
      "|    total_timesteps      | 651264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008354181 |\n",
      "|    clip_fraction        | 0.0519      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.6       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.7        |\n",
      "|    n_updates            | 3170        |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    reward               | 3.7425325   |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 259         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 319        |\n",
      "|    time_elapsed         | 5832       |\n",
      "|    total_timesteps      | 653312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01437385 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.6      |\n",
      "|    explained_variance   | 0.11       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 107        |\n",
      "|    n_updates            | 3180       |\n",
      "|    policy_gradient_loss | -0.00321   |\n",
      "|    reward               | -3.5406    |\n",
      "|    std                  | 1.59       |\n",
      "|    value_loss           | 333        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 320        |\n",
      "|    time_elapsed         | 5850       |\n",
      "|    total_timesteps      | 655360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08266876 |\n",
      "|    clip_fraction        | 0.487      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.7      |\n",
      "|    explained_variance   | 0.0261     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.7       |\n",
      "|    n_updates            | 3190       |\n",
      "|    policy_gradient_loss | 0.022      |\n",
      "|    reward               | 1.0090153  |\n",
      "|    std                  | 1.61       |\n",
      "|    value_loss           | 42.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 321         |\n",
      "|    time_elapsed         | 5868        |\n",
      "|    total_timesteps      | 657408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025360087 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.9       |\n",
      "|    explained_variance   | 0.0106      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.3        |\n",
      "|    n_updates            | 3200        |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | 0.07549812  |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 322         |\n",
      "|    time_elapsed         | 5887        |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017506856 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55         |\n",
      "|    explained_variance   | -0.00425    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.8        |\n",
      "|    n_updates            | 3210        |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    reward               | -0.2335499  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 323         |\n",
      "|    time_elapsed         | 5905        |\n",
      "|    total_timesteps      | 661504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012307854 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55         |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | -0.00896    |\n",
      "|    reward               | -0.8017093  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 79.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5897008.74\n",
      "total_reward: 4897008.74\n",
      "total_cost: 255170.01\n",
      "total_trades: 66009\n",
      "Sharpe: 0.931\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 5923        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013509728 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55         |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.9        |\n",
      "|    n_updates            | 3230        |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    reward               | 0.78602624  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 90.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 5941        |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010769799 |\n",
      "|    clip_fraction        | 0.0772      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.5        |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    reward               | 1.0072752   |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 326          |\n",
      "|    time_elapsed         | 5959         |\n",
      "|    total_timesteps      | 667648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073678624 |\n",
      "|    clip_fraction        | 0.043        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -55.1        |\n",
      "|    explained_variance   | 0.308        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 122          |\n",
      "|    n_updates            | 3250         |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    reward               | 0.5329353    |\n",
      "|    std                  | 1.62         |\n",
      "|    value_loss           | 201          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 5978        |\n",
      "|    total_timesteps      | 669696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009861732 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 3260        |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    reward               | 0.92784315  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 328         |\n",
      "|    time_elapsed         | 5996        |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020909835 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 3270        |\n",
      "|    policy_gradient_loss | 0.0115      |\n",
      "|    reward               | -0.8386382  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 257         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 6014        |\n",
      "|    total_timesteps      | 673792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006413054 |\n",
      "|    clip_fraction        | 0.0407      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 271         |\n",
      "|    n_updates            | 3280        |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    reward               | -14.230945  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 240         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 330        |\n",
      "|    time_elapsed         | 6033       |\n",
      "|    total_timesteps      | 675840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02110141 |\n",
      "|    clip_fraction        | 0.0697     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.1      |\n",
      "|    explained_variance   | 0.349      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 33.2       |\n",
      "|    n_updates            | 3290       |\n",
      "|    policy_gradient_loss | -0.00438   |\n",
      "|    reward               | -4.6477365 |\n",
      "|    std                  | 1.62       |\n",
      "|    value_loss           | 111        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 6051        |\n",
      "|    total_timesteps      | 677888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009584201 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 3300        |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    reward               | -0.6555175  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 332          |\n",
      "|    time_elapsed         | 6069         |\n",
      "|    total_timesteps      | 679936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048370017 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -55.1        |\n",
      "|    explained_variance   | 0.308        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 172          |\n",
      "|    n_updates            | 3310         |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | 0.5169662    |\n",
      "|    std                  | 1.62         |\n",
      "|    value_loss           | 345          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 333          |\n",
      "|    time_elapsed         | 6088         |\n",
      "|    total_timesteps      | 681984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035837686 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -55.1        |\n",
      "|    explained_variance   | 0.262        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 175          |\n",
      "|    n_updates            | 3320         |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    reward               | 3.821316     |\n",
      "|    std                  | 1.62         |\n",
      "|    value_loss           | 366          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 6106        |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010610988 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 3330        |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | -2.806923   |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 335         |\n",
      "|    time_elapsed         | 6125        |\n",
      "|    total_timesteps      | 686080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011624604 |\n",
      "|    clip_fraction        | 0.0931      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98.6        |\n",
      "|    n_updates            | 3340        |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | -0.47879204 |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 306         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 6143        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010308641 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 3350        |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    reward               | 13.706995   |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 280         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 337        |\n",
      "|    time_elapsed         | 6162       |\n",
      "|    total_timesteps      | 690176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01904281 |\n",
      "|    clip_fraction        | 0.0883     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.2      |\n",
      "|    explained_variance   | 0.207      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.8       |\n",
      "|    n_updates            | 3360       |\n",
      "|    policy_gradient_loss | -0.00447   |\n",
      "|    reward               | 5.479428   |\n",
      "|    std                  | 1.63       |\n",
      "|    value_loss           | 63         |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7992799.76\n",
      "total_reward: 6992799.76\n",
      "total_cost: 263261.98\n",
      "total_trades: 66415\n",
      "Sharpe: 0.989\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 6180        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017875727 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98.3        |\n",
      "|    n_updates            | 3370        |\n",
      "|    policy_gradient_loss | -0.00942    |\n",
      "|    reward               | -0.34411734 |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 225         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 339       |\n",
      "|    time_elapsed         | 6199      |\n",
      "|    total_timesteps      | 694272    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0115708 |\n",
      "|    clip_fraction        | 0.0889    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -55.2     |\n",
      "|    explained_variance   | 0.193     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 99.6      |\n",
      "|    n_updates            | 3380      |\n",
      "|    policy_gradient_loss | -0.0102   |\n",
      "|    reward               | 18.177479 |\n",
      "|    std                  | 1.63      |\n",
      "|    value_loss           | 266       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 340         |\n",
      "|    time_elapsed         | 6217        |\n",
      "|    total_timesteps      | 696320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011556283 |\n",
      "|    clip_fraction        | 0.0906      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 3390        |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | -1.3748858  |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 273         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 6235        |\n",
      "|    total_timesteps      | 698368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038310584 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.3       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 3400        |\n",
      "|    policy_gradient_loss | 0.000823    |\n",
      "|    reward               | -0.75153387 |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 342         |\n",
      "|    time_elapsed         | 6254        |\n",
      "|    total_timesteps      | 700416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016306862 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.3       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 149         |\n",
      "|    n_updates            | 3410        |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    reward               | 0.7085312   |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 258         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 6272        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021368403 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.3       |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.5        |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | 0.00684     |\n",
      "|    reward               | 5.571633    |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 258         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 6290        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037306886 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.4       |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 3430        |\n",
      "|    policy_gradient_loss | 0.00297     |\n",
      "|    reward               | 2.9382074   |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 63.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 345         |\n",
      "|    time_elapsed         | 6309        |\n",
      "|    total_timesteps      | 706560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016520474 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.5       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 3440        |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    reward               | 1.6194625   |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 229         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 6327        |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012162193 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.5       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.6        |\n",
      "|    n_updates            | 3450        |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    reward               | 11.201586   |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 347         |\n",
      "|    time_elapsed         | 6346        |\n",
      "|    total_timesteps      | 710656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.04774504  |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.5       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 3460        |\n",
      "|    policy_gradient_loss | 0.00853     |\n",
      "|    reward               | 0.033276863 |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 96.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 348         |\n",
      "|    time_elapsed         | 6364        |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033526763 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.6       |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.9        |\n",
      "|    n_updates            | 3470        |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    reward               | -0.6166124  |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 6382        |\n",
      "|    total_timesteps      | 714752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032369673 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.6       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.6        |\n",
      "|    n_updates            | 3480        |\n",
      "|    policy_gradient_loss | 0.00148     |\n",
      "|    reward               | -0.26465198 |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 6400        |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032284267 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.7       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94.1        |\n",
      "|    n_updates            | 3490        |\n",
      "|    policy_gradient_loss | 0.000881    |\n",
      "|    reward               | -2.869502   |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 6418        |\n",
      "|    total_timesteps      | 718848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048302364 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.7       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 3500        |\n",
      "|    policy_gradient_loss | 0.00378     |\n",
      "|    reward               | 1.8554827   |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 31.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6661454.38\n",
      "total_reward: 5661454.38\n",
      "total_cost: 280826.75\n",
      "total_trades: 68344\n",
      "Sharpe: 0.901\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 352         |\n",
      "|    time_elapsed         | 6436        |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017856466 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.8       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.1        |\n",
      "|    n_updates            | 3510        |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    reward               | -1.4845273  |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 253         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 6455        |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018048752 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.8       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.1        |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    reward               | 10.045818   |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 354        |\n",
      "|    time_elapsed         | 6473       |\n",
      "|    total_timesteps      | 724992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03545022 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.9      |\n",
      "|    explained_variance   | 0.194      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.6       |\n",
      "|    n_updates            | 3530       |\n",
      "|    policy_gradient_loss | 0.00927    |\n",
      "|    reward               | -5.6315084 |\n",
      "|    std                  | 1.67       |\n",
      "|    value_loss           | 49.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 355         |\n",
      "|    time_elapsed         | 6491        |\n",
      "|    total_timesteps      | 727040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021751447 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.9       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 3540        |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    reward               | -1.8278058  |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 356        |\n",
      "|    time_elapsed         | 6509       |\n",
      "|    total_timesteps      | 729088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01814057 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56        |\n",
      "|    explained_variance   | 0.192      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 89.8       |\n",
      "|    n_updates            | 3550       |\n",
      "|    policy_gradient_loss | -0.00238   |\n",
      "|    reward               | -0.3588563 |\n",
      "|    std                  | 1.67       |\n",
      "|    value_loss           | 175        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 357        |\n",
      "|    time_elapsed         | 6528       |\n",
      "|    total_timesteps      | 731136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00458121 |\n",
      "|    clip_fraction        | 0.0118     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56        |\n",
      "|    explained_variance   | 0.288      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.2       |\n",
      "|    n_updates            | 3560       |\n",
      "|    policy_gradient_loss | -0.00717   |\n",
      "|    reward               | 0.06892813 |\n",
      "|    std                  | 1.67       |\n",
      "|    value_loss           | 205        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 6546        |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02047659  |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56         |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 3570        |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | -0.42756745 |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 359        |\n",
      "|    time_elapsed         | 6564       |\n",
      "|    total_timesteps      | 735232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02037938 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56        |\n",
      "|    explained_variance   | 0.174      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 169        |\n",
      "|    n_updates            | 3580       |\n",
      "|    policy_gradient_loss | -0.0021    |\n",
      "|    reward               | -1.7721014 |\n",
      "|    std                  | 1.68       |\n",
      "|    value_loss           | 258        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 6582        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017861102 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.1       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.8        |\n",
      "|    n_updates            | 3590        |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    reward               | -0.1858012  |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 263         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 6601        |\n",
      "|    total_timesteps      | 739328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019354837 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.1       |\n",
      "|    explained_variance   | 0.00524     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    reward               | -3.1540356  |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 362         |\n",
      "|    time_elapsed         | 6619        |\n",
      "|    total_timesteps      | 741376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025401883 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.1       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51          |\n",
      "|    n_updates            | 3610        |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    reward               | 0.045331404 |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 6637        |\n",
      "|    total_timesteps      | 743424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022102203 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.5        |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    reward               | -49.41359   |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 364         |\n",
      "|    time_elapsed         | 6659        |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014381783 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.9        |\n",
      "|    n_updates            | 3630        |\n",
      "|    policy_gradient_loss | 0.000759    |\n",
      "|    reward               | 2.4437168   |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 6678        |\n",
      "|    total_timesteps      | 747520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026600197 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 3640        |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    reward               | -0.9480903  |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 67          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8916076.58\n",
      "total_reward: 7916076.58\n",
      "total_cost: 267707.53\n",
      "total_trades: 68714\n",
      "Sharpe: 1.029\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 6697        |\n",
      "|    total_timesteps      | 749568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022960376 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 99.8        |\n",
      "|    n_updates            | 3650        |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    reward               | 1.0336801   |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 247         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 367         |\n",
      "|    time_elapsed         | 6715        |\n",
      "|    total_timesteps      | 751616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031024514 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 183         |\n",
      "|    n_updates            | 3660        |\n",
      "|    policy_gradient_loss | 0.00708     |\n",
      "|    reward               | 1.3846961   |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 271         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 368        |\n",
      "|    time_elapsed         | 6733       |\n",
      "|    total_timesteps      | 753664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02837979 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.2      |\n",
      "|    explained_variance   | 0.188      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 42.8       |\n",
      "|    n_updates            | 3670       |\n",
      "|    policy_gradient_loss | -0.00177   |\n",
      "|    reward               | 0.5757951  |\n",
      "|    std                  | 1.69       |\n",
      "|    value_loss           | 66.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 6751        |\n",
      "|    total_timesteps      | 755712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018899176 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98.1        |\n",
      "|    n_updates            | 3680        |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    reward               | -0.6371415  |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 259         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 6769        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016512074 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    reward               | -1.311277   |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 260         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 371         |\n",
      "|    time_elapsed         | 6787        |\n",
      "|    total_timesteps      | 759808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025389876 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.0587      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.2        |\n",
      "|    n_updates            | 3700        |\n",
      "|    policy_gradient_loss | -0.00224    |\n",
      "|    reward               | -2.1110983  |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 372        |\n",
      "|    time_elapsed         | 6806       |\n",
      "|    total_timesteps      | 761856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02647476 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.3      |\n",
      "|    explained_variance   | 0.142      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 56.6       |\n",
      "|    n_updates            | 3710       |\n",
      "|    policy_gradient_loss | -0.00407   |\n",
      "|    reward               | 1.8790717  |\n",
      "|    std                  | 1.7        |\n",
      "|    value_loss           | 201        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 6824        |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01389725  |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 188         |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    reward               | -0.30695495 |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 260         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 374         |\n",
      "|    time_elapsed         | 6843        |\n",
      "|    total_timesteps      | 765952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015278873 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.3        |\n",
      "|    n_updates            | 3730        |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    reward               | 2.601117    |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 375        |\n",
      "|    time_elapsed         | 6861       |\n",
      "|    total_timesteps      | 768000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02830936 |\n",
      "|    clip_fraction        | 0.305      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.4      |\n",
      "|    explained_variance   | 0.307      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.2       |\n",
      "|    n_updates            | 3740       |\n",
      "|    policy_gradient_loss | 0.000758   |\n",
      "|    reward               | 1.0857723  |\n",
      "|    std                  | 1.7        |\n",
      "|    value_loss           | 35.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 376         |\n",
      "|    time_elapsed         | 6879        |\n",
      "|    total_timesteps      | 770048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013674615 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.5       |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 3750        |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    reward               | 0.9977766   |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 242         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 6897        |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008647359 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.5       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 218         |\n",
      "|    n_updates            | 3760        |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    reward               | 13.046689   |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 6916        |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035625104 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.5       |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.5        |\n",
      "|    n_updates            | 3770        |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    reward               | -8.056996   |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 379         |\n",
      "|    time_elapsed         | 6934        |\n",
      "|    total_timesteps      | 776192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008229017 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.2        |\n",
      "|    n_updates            | 3780        |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    reward               | -0.21656033 |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 250         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7813594.22\n",
      "total_reward: 6813594.22\n",
      "total_cost: 258073.56\n",
      "total_trades: 66106\n",
      "Sharpe: 0.914\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 6952        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013039345 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 256         |\n",
      "|    n_updates            | 3790        |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    reward               | 0.27147815  |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 290         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 381          |\n",
      "|    time_elapsed         | 6970         |\n",
      "|    total_timesteps      | 780288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064940946 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -56.6        |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90           |\n",
      "|    n_updates            | 3800         |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    reward               | -1.154683    |\n",
      "|    std                  | 1.71         |\n",
      "|    value_loss           | 291          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 382        |\n",
      "|    time_elapsed         | 6988       |\n",
      "|    total_timesteps      | 782336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03409986 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.6      |\n",
      "|    explained_variance   | 0.347      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.5       |\n",
      "|    n_updates            | 3810       |\n",
      "|    policy_gradient_loss | -0.00405   |\n",
      "|    reward               | 1.0131077  |\n",
      "|    std                  | 1.71       |\n",
      "|    value_loss           | 33.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 7007        |\n",
      "|    total_timesteps      | 784384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006344696 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71          |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    reward               | 1.0989804   |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 230         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 384          |\n",
      "|    time_elapsed         | 7025         |\n",
      "|    total_timesteps      | 786432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050043194 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -56.6        |\n",
      "|    explained_variance   | 0.318        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 184          |\n",
      "|    n_updates            | 3830         |\n",
      "|    policy_gradient_loss | -0.00606     |\n",
      "|    reward               | 8.054197     |\n",
      "|    std                  | 1.71         |\n",
      "|    value_loss           | 291          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 7043        |\n",
      "|    total_timesteps      | 788480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033049308 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.1        |\n",
      "|    n_updates            | 3840        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 0.5116685   |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 62.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 386         |\n",
      "|    time_elapsed         | 7061        |\n",
      "|    total_timesteps      | 790528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008208393 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 238         |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    reward               | 1.0095458   |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 265         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 387         |\n",
      "|    time_elapsed         | 7079        |\n",
      "|    total_timesteps      | 792576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016243782 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 3860        |\n",
      "|    policy_gradient_loss | -0.00267    |\n",
      "|    reward               | -3.295376   |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 7098        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02805767  |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.8        |\n",
      "|    n_updates            | 3870        |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    reward               | -0.43978477 |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 389         |\n",
      "|    time_elapsed         | 7116        |\n",
      "|    total_timesteps      | 796672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029939488 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    reward               | -0.89187336 |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 7134        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026541432 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.2        |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | 0.000864    |\n",
      "|    reward               | 1.584912    |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 391         |\n",
      "|    time_elapsed         | 7152        |\n",
      "|    total_timesteps      | 800768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026837125 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | -9.73e-05   |\n",
      "|    reward               | -0.7711264  |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 7170        |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042927064 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | -0.0425     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 3910        |\n",
      "|    policy_gradient_loss | 0.000963    |\n",
      "|    reward               | 0.1981487   |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 7189        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039594963 |\n",
      "|    clip_fraction        | 0.414       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68          |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    reward               | -1.0811414  |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 7207        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030238837 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93          |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    reward               | -1.8663096  |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3409386.66\n",
      "total_reward: 2409386.66\n",
      "total_cost: 309840.59\n",
      "total_trades: 69079\n",
      "Sharpe: 0.631\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 395        |\n",
      "|    time_elapsed         | 7225       |\n",
      "|    total_timesteps      | 808960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03716263 |\n",
      "|    clip_fraction        | 0.373      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57        |\n",
      "|    explained_variance   | 0.302      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.4       |\n",
      "|    n_updates            | 3940       |\n",
      "|    policy_gradient_loss | 0.011      |\n",
      "|    reward               | 3.4428554  |\n",
      "|    std                  | 1.74       |\n",
      "|    value_loss           | 58         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 396         |\n",
      "|    time_elapsed         | 7243        |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031193627 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.1       |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 3950        |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    reward               | 1.3284514   |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 49.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 397        |\n",
      "|    time_elapsed         | 7261       |\n",
      "|    total_timesteps      | 813056     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03197374 |\n",
      "|    clip_fraction        | 0.294      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.2      |\n",
      "|    explained_variance   | 0.0752     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 50.3       |\n",
      "|    n_updates            | 3960       |\n",
      "|    policy_gradient_loss | -0.00505   |\n",
      "|    reward               | -0.4528241 |\n",
      "|    std                  | 1.74       |\n",
      "|    value_loss           | 110        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 398        |\n",
      "|    time_elapsed         | 7280       |\n",
      "|    total_timesteps      | 815104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04337831 |\n",
      "|    clip_fraction        | 0.41       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.2      |\n",
      "|    explained_variance   | 0.0533     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 117        |\n",
      "|    n_updates            | 3970       |\n",
      "|    policy_gradient_loss | 0.00333    |\n",
      "|    reward               | -6.062559  |\n",
      "|    std                  | 1.75       |\n",
      "|    value_loss           | 178        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 7298        |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039282463 |\n",
      "|    clip_fraction        | 0.4         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.3       |\n",
      "|    explained_variance   | 0.0765      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 3980        |\n",
      "|    policy_gradient_loss | 0.00311     |\n",
      "|    reward               | -3.642143   |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 7316        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026270218 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.4       |\n",
      "|    explained_variance   | 0.0321      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.4        |\n",
      "|    n_updates            | 3990        |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    reward               | 0.57164913  |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 401         |\n",
      "|    time_elapsed         | 7334        |\n",
      "|    total_timesteps      | 821248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025247078 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.5       |\n",
      "|    explained_variance   | 0.0763      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.8        |\n",
      "|    n_updates            | 4000        |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    reward               | -7.1186037  |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 402        |\n",
      "|    time_elapsed         | 7353       |\n",
      "|    total_timesteps      | 823296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03573095 |\n",
      "|    clip_fraction        | 0.338      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.6      |\n",
      "|    explained_variance   | 0.197      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.7       |\n",
      "|    n_updates            | 4010       |\n",
      "|    policy_gradient_loss | -0.00611   |\n",
      "|    reward               | 1.5236686  |\n",
      "|    std                  | 1.77       |\n",
      "|    value_loss           | 53.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 403         |\n",
      "|    time_elapsed         | 7372        |\n",
      "|    total_timesteps      | 825344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028991064 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.6       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.5        |\n",
      "|    n_updates            | 4020        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 1.1587261   |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 7390        |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030062588 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.0327      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.5        |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 6.84956     |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 405        |\n",
      "|    time_elapsed         | 7408       |\n",
      "|    total_timesteps      | 829440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02435064 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.8      |\n",
      "|    explained_variance   | 0.127      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 62.9       |\n",
      "|    n_updates            | 4040       |\n",
      "|    policy_gradient_loss | -0.00725   |\n",
      "|    reward               | 2.469379   |\n",
      "|    std                  | 1.79       |\n",
      "|    value_loss           | 160        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 406        |\n",
      "|    time_elapsed         | 7426       |\n",
      "|    total_timesteps      | 831488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02602733 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.9      |\n",
      "|    explained_variance   | 0.1        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.6       |\n",
      "|    n_updates            | 4050       |\n",
      "|    policy_gradient_loss | -0.00293   |\n",
      "|    reward               | 0.91474646 |\n",
      "|    std                  | 1.79       |\n",
      "|    value_loss           | 21.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 7444        |\n",
      "|    total_timesteps      | 833536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017042499 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.9       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.9        |\n",
      "|    n_updates            | 4060        |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    reward               | 3.1815488   |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 408         |\n",
      "|    time_elapsed         | 7462        |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025359843 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58         |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.9        |\n",
      "|    n_updates            | 4070        |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    reward               | 0.08749348  |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7638785.49\n",
      "total_reward: 6638785.49\n",
      "total_cost: 266609.45\n",
      "total_trades: 66963\n",
      "Sharpe: 1.007\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 409        |\n",
      "|    time_elapsed         | 7480       |\n",
      "|    total_timesteps      | 837632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03152749 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.1      |\n",
      "|    explained_variance   | 0.492      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.3       |\n",
      "|    n_updates            | 4080       |\n",
      "|    policy_gradient_loss | -0.00786   |\n",
      "|    reward               | -3.5515249 |\n",
      "|    std                  | 1.8        |\n",
      "|    value_loss           | 33.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 7498        |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021401513 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.2       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 135         |\n",
      "|    n_updates            | 4090        |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    reward               | 1.1253562   |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 411         |\n",
      "|    time_elapsed         | 7516        |\n",
      "|    total_timesteps      | 841728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022199253 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.2       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 4100        |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    reward               | 1.3127799   |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 7535        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027569711 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.2       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | 0.00103     |\n",
      "|    reward               | -1.000815   |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 64.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 413         |\n",
      "|    time_elapsed         | 7553        |\n",
      "|    total_timesteps      | 845824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016575672 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.7        |\n",
      "|    n_updates            | 4120        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | -0.97416675 |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 99.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 7571        |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018146742 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 4130        |\n",
      "|    policy_gradient_loss | 0.00396     |\n",
      "|    reward               | -1.0494202  |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 415        |\n",
      "|    time_elapsed         | 7589       |\n",
      "|    total_timesteps      | 849920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02696367 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.3      |\n",
      "|    explained_variance   | 0.194      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 69.6       |\n",
      "|    n_updates            | 4140       |\n",
      "|    policy_gradient_loss | -0.000636  |\n",
      "|    reward               | -1.4228158 |\n",
      "|    std                  | 1.82       |\n",
      "|    value_loss           | 162        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 416         |\n",
      "|    time_elapsed         | 7607        |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030772313 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.0186      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 4150        |\n",
      "|    policy_gradient_loss | 0.00624     |\n",
      "|    reward               | -1.1981298  |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 417        |\n",
      "|    time_elapsed         | 7625       |\n",
      "|    total_timesteps      | 854016     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01915651 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.4      |\n",
      "|    explained_variance   | 0.146      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 92         |\n",
      "|    n_updates            | 4160       |\n",
      "|    policy_gradient_loss | -0.00769   |\n",
      "|    reward               | -0.2734199 |\n",
      "|    std                  | 1.82       |\n",
      "|    value_loss           | 209        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 418        |\n",
      "|    time_elapsed         | 7643       |\n",
      "|    total_timesteps      | 856064     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02076545 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.5      |\n",
      "|    explained_variance   | 0.212      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 78.2       |\n",
      "|    n_updates            | 4170       |\n",
      "|    policy_gradient_loss | -0.00551   |\n",
      "|    reward               | 0.10068381 |\n",
      "|    std                  | 1.82       |\n",
      "|    value_loss           | 179        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 7662        |\n",
      "|    total_timesteps      | 858112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020010803 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.2        |\n",
      "|    n_updates            | 4180        |\n",
      "|    policy_gradient_loss | 0.000833    |\n",
      "|    reward               | 0.90873885  |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 70          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 420         |\n",
      "|    time_elapsed         | 7681        |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012981651 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.0744      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 149         |\n",
      "|    n_updates            | 4190        |\n",
      "|    policy_gradient_loss | -0.00851    |\n",
      "|    reward               | -1.1637614  |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 7699        |\n",
      "|    total_timesteps      | 862208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016475094 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.021       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    reward               | -0.67043483 |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 422         |\n",
      "|    time_elapsed         | 7718        |\n",
      "|    total_timesteps      | 864256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026095867 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | 0.00589     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 188         |\n",
      "|    n_updates            | 4210        |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    reward               | 2.7308762   |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4757038.52\n",
      "total_reward: 3757038.52\n",
      "total_cost: 258529.84\n",
      "total_trades: 65926\n",
      "Sharpe: 0.767\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 423         |\n",
      "|    time_elapsed         | 7736        |\n",
      "|    total_timesteps      | 866304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029236324 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | 0.0347      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.55        |\n",
      "|    n_updates            | 4220        |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | 0.6497889   |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 424         |\n",
      "|    time_elapsed         | 7754        |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026954018 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.2        |\n",
      "|    n_updates            | 4230        |\n",
      "|    policy_gradient_loss | 0.00689     |\n",
      "|    reward               | -2.1046147  |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 425        |\n",
      "|    time_elapsed         | 7772       |\n",
      "|    total_timesteps      | 870400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.023295   |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.8      |\n",
      "|    explained_variance   | 0.228      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 81.3       |\n",
      "|    n_updates            | 4240       |\n",
      "|    policy_gradient_loss | -0.00158   |\n",
      "|    reward               | -15.926885 |\n",
      "|    std                  | 1.84       |\n",
      "|    value_loss           | 176        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 7790        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017387258 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.8       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.3        |\n",
      "|    n_updates            | 4250        |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    reward               | 0.6602407   |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 75.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 427        |\n",
      "|    time_elapsed         | 7808       |\n",
      "|    total_timesteps      | 874496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01894575 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.8      |\n",
      "|    explained_variance   | 0.292      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 35         |\n",
      "|    n_updates            | 4260       |\n",
      "|    policy_gradient_loss | -0.00485   |\n",
      "|    reward               | -1.8309705 |\n",
      "|    std                  | 1.84       |\n",
      "|    value_loss           | 85.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 428         |\n",
      "|    time_elapsed         | 7827        |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026419977 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.8       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.2        |\n",
      "|    n_updates            | 4270        |\n",
      "|    policy_gradient_loss | -0.0022     |\n",
      "|    reward               | -10.0168085 |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 7845        |\n",
      "|    total_timesteps      | 878592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019528285 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.8       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.3        |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    reward               | -1.5178633  |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 430         |\n",
      "|    time_elapsed         | 7863        |\n",
      "|    total_timesteps      | 880640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030212749 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.9       |\n",
      "|    explained_variance   | -0.00233    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 4290        |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    reward               | -0.5850318  |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 431         |\n",
      "|    time_elapsed         | 7881        |\n",
      "|    total_timesteps      | 882688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016225621 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.9       |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.2        |\n",
      "|    n_updates            | 4300        |\n",
      "|    policy_gradient_loss | 0.000626    |\n",
      "|    reward               | -1.5198681  |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 432        |\n",
      "|    time_elapsed         | 7900       |\n",
      "|    total_timesteps      | 884736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01709301 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.9      |\n",
      "|    explained_variance   | 0.183      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 56         |\n",
      "|    n_updates            | 4310       |\n",
      "|    policy_gradient_loss | -0.0063    |\n",
      "|    reward               | 1.2831364  |\n",
      "|    std                  | 1.85       |\n",
      "|    value_loss           | 133        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 433         |\n",
      "|    time_elapsed         | 7918        |\n",
      "|    total_timesteps      | 886784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017375898 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.0786      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 4320        |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    reward               | -12.026177  |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 434         |\n",
      "|    time_elapsed         | 7936        |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025456615 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.5        |\n",
      "|    n_updates            | 4330        |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    reward               | 1.8251137   |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 90.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 435         |\n",
      "|    time_elapsed         | 7954        |\n",
      "|    total_timesteps      | 890880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020250402 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.7        |\n",
      "|    n_updates            | 4340        |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    reward               | -0.677027   |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 7972        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019506361 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    reward               | 3.4485068   |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 70.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3977363.41\n",
      "total_reward: 2977363.41\n",
      "total_cost: 231304.44\n",
      "total_trades: 62671\n",
      "Sharpe: 0.664\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 7990        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027070716 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    reward               | -2.7335272  |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 438        |\n",
      "|    time_elapsed         | 8009       |\n",
      "|    total_timesteps      | 897024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01880156 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.2      |\n",
      "|    explained_variance   | 0.451      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 47         |\n",
      "|    n_updates            | 4370       |\n",
      "|    policy_gradient_loss | -0.00424   |\n",
      "|    reward               | 0.62981766 |\n",
      "|    std                  | 1.87       |\n",
      "|    value_loss           | 86.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 439        |\n",
      "|    time_elapsed         | 8027       |\n",
      "|    total_timesteps      | 899072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02419016 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.2      |\n",
      "|    explained_variance   | 0.234      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 59.4       |\n",
      "|    n_updates            | 4380       |\n",
      "|    policy_gradient_loss | 0.00202    |\n",
      "|    reward               | 5.0635047  |\n",
      "|    std                  | 1.87       |\n",
      "|    value_loss           | 91         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 440        |\n",
      "|    time_elapsed         | 8045       |\n",
      "|    total_timesteps      | 901120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03018215 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.3      |\n",
      "|    explained_variance   | 0.158      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.8       |\n",
      "|    n_updates            | 4390       |\n",
      "|    policy_gradient_loss | -0.000782  |\n",
      "|    reward               | -1.8135966 |\n",
      "|    std                  | 1.88       |\n",
      "|    value_loss           | 32.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 441         |\n",
      "|    time_elapsed         | 8063        |\n",
      "|    total_timesteps      | 903168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017094482 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.3       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.7        |\n",
      "|    n_updates            | 4400        |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | 1.0192798   |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 442         |\n",
      "|    time_elapsed         | 8081        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021501964 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.4       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73          |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | -0.00552    |\n",
      "|    reward               | 8.341897    |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 443         |\n",
      "|    time_elapsed         | 8099        |\n",
      "|    total_timesteps      | 907264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015700337 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.5       |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.8        |\n",
      "|    n_updates            | 4420        |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    reward               | 5.1550026   |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 75.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 8117        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02433471  |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.5       |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    reward               | -0.41190377 |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 87.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 445         |\n",
      "|    time_elapsed         | 8135        |\n",
      "|    total_timesteps      | 911360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011011606 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.5       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.7        |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | -0.6204818  |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 446         |\n",
      "|    time_elapsed         | 8153        |\n",
      "|    total_timesteps      | 913408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021263761 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.5       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 4450        |\n",
      "|    policy_gradient_loss | 0.000246    |\n",
      "|    reward               | 2.2690387   |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 83.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 447         |\n",
      "|    time_elapsed         | 8172        |\n",
      "|    total_timesteps      | 915456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011600711 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | -0.148      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 4460        |\n",
      "|    policy_gradient_loss | -0.00253    |\n",
      "|    reward               | 0.06917988  |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 8190        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008472945 |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.1        |\n",
      "|    n_updates            | 4470        |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | 0.9965595   |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 84.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 449         |\n",
      "|    time_elapsed         | 8208        |\n",
      "|    total_timesteps      | 919552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020658799 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.7        |\n",
      "|    n_updates            | 4480        |\n",
      "|    policy_gradient_loss | -0.00171    |\n",
      "|    reward               | 13.463609   |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 450         |\n",
      "|    time_elapsed         | 8226        |\n",
      "|    total_timesteps      | 921600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026605323 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 4490        |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    reward               | -1.0331966  |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5978143.27\n",
      "total_reward: 4978143.27\n",
      "total_cost: 222241.75\n",
      "total_trades: 61359\n",
      "Sharpe: 0.836\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 8244        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022236502 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.0715      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | 0.000852    |\n",
      "|    reward               | 0.6639469   |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 83.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 452        |\n",
      "|    time_elapsed         | 8262       |\n",
      "|    total_timesteps      | 925696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01788443 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.7      |\n",
      "|    explained_variance   | 0.142      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 78.1       |\n",
      "|    n_updates            | 4510       |\n",
      "|    policy_gradient_loss | -0.00505   |\n",
      "|    reward               | -5.1556916 |\n",
      "|    std                  | 1.9        |\n",
      "|    value_loss           | 145        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 453         |\n",
      "|    time_elapsed         | 8280        |\n",
      "|    total_timesteps      | 927744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013798306 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 4520        |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | -3.0441816  |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 454        |\n",
      "|    time_elapsed         | 8298       |\n",
      "|    total_timesteps      | 929792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02239106 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.7      |\n",
      "|    explained_variance   | 0.241      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.7       |\n",
      "|    n_updates            | 4530       |\n",
      "|    policy_gradient_loss | 0.00224    |\n",
      "|    reward               | 0.22536263 |\n",
      "|    std                  | 1.91       |\n",
      "|    value_loss           | 42         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 455         |\n",
      "|    time_elapsed         | 8316        |\n",
      "|    total_timesteps      | 931840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012218401 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | -0.00491    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.7        |\n",
      "|    n_updates            | 4540        |\n",
      "|    policy_gradient_loss | -0.00606    |\n",
      "|    reward               | 1.2658726   |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 8335        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018655274 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.8        |\n",
      "|    n_updates            | 4550        |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    reward               | -10.383571  |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 94.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 8353        |\n",
      "|    total_timesteps      | 935936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026560869 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | -0.00258    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    reward               | -2.7413027  |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 8371        |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017623376 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 4570        |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | -9.571709   |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 56.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 459         |\n",
      "|    time_elapsed         | 8389        |\n",
      "|    total_timesteps      | 940032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028111922 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.9       |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.1        |\n",
      "|    n_updates            | 4580        |\n",
      "|    policy_gradient_loss | 0.000663    |\n",
      "|    reward               | 2.3040757   |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 85.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 460         |\n",
      "|    time_elapsed         | 8407        |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020816136 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60         |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 4590        |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    reward               | -1.1724362  |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 461          |\n",
      "|    time_elapsed         | 8425         |\n",
      "|    total_timesteps      | 944128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0145826675 |\n",
      "|    clip_fraction        | 0.166        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -60          |\n",
      "|    explained_variance   | 0.191        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.6         |\n",
      "|    n_updates            | 4600         |\n",
      "|    policy_gradient_loss | -0.00728     |\n",
      "|    reward               | -1.4635015   |\n",
      "|    std                  | 1.93         |\n",
      "|    value_loss           | 62.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 462         |\n",
      "|    time_elapsed         | 8443        |\n",
      "|    total_timesteps      | 946176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0203884   |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 4610        |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | -0.41972712 |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 76.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 8461        |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012041738 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.6        |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | -0.000199   |\n",
      "|    reward               | -1.1415387  |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 464         |\n",
      "|    time_elapsed         | 8480        |\n",
      "|    total_timesteps      | 950272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013905292 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | -0.0332     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 4630        |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    reward               | -0.89050543 |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3499446.72\n",
      "total_reward: 2499446.72\n",
      "total_cost: 229309.23\n",
      "total_trades: 63306\n",
      "Sharpe: 0.597\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 8498        |\n",
      "|    total_timesteps      | 952320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013479579 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.2       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.3        |\n",
      "|    n_updates            | 4640        |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    reward               | 1.8002925   |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 72.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 466        |\n",
      "|    time_elapsed         | 8516       |\n",
      "|    total_timesteps      | 954368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01305505 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.2      |\n",
      "|    explained_variance   | 0.296      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38         |\n",
      "|    n_updates            | 4650       |\n",
      "|    policy_gradient_loss | -0.00356   |\n",
      "|    reward               | -10.356603 |\n",
      "|    std                  | 1.94       |\n",
      "|    value_loss           | 85         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 467          |\n",
      "|    time_elapsed         | 8534         |\n",
      "|    total_timesteps      | 956416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01520511   |\n",
      "|    clip_fraction        | 0.208        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -60.2        |\n",
      "|    explained_variance   | 0.154        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.1         |\n",
      "|    n_updates            | 4660         |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    reward               | -0.096491285 |\n",
      "|    std                  | 1.94         |\n",
      "|    value_loss           | 59.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 468         |\n",
      "|    time_elapsed         | 8552        |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017300937 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 4670        |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    reward               | -1.0137984  |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 469         |\n",
      "|    time_elapsed         | 8571        |\n",
      "|    total_timesteps      | 960512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021183856 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | -0.3677257  |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 87.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 470         |\n",
      "|    time_elapsed         | 8588        |\n",
      "|    total_timesteps      | 962560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018315997 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.5        |\n",
      "|    n_updates            | 4690        |\n",
      "|    policy_gradient_loss | -0.0013     |\n",
      "|    reward               | -2.492555   |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 471        |\n",
      "|    time_elapsed         | 8606       |\n",
      "|    total_timesteps      | 964608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02902545 |\n",
      "|    clip_fraction        | 0.266      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.4      |\n",
      "|    explained_variance   | 0.116      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.51       |\n",
      "|    n_updates            | 4700       |\n",
      "|    policy_gradient_loss | -0.00577   |\n",
      "|    reward               | 0.10937062 |\n",
      "|    std                  | 1.96       |\n",
      "|    value_loss           | 25         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 472         |\n",
      "|    time_elapsed         | 8625        |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016761402 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.5       |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.4        |\n",
      "|    n_updates            | 4710        |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    reward               | 0.0708986   |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 69.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 473          |\n",
      "|    time_elapsed         | 8643         |\n",
      "|    total_timesteps      | 968704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018143883 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -60.5        |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.2         |\n",
      "|    n_updates            | 4720         |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | -0.4829785   |\n",
      "|    std                  | 1.96         |\n",
      "|    value_loss           | 76.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 474         |\n",
      "|    time_elapsed         | 8661        |\n",
      "|    total_timesteps      | 970752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010757656 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.5       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 4730        |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    reward               | 2.127039    |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 8679        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019902393 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.5       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.5        |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    reward               | -0.83224094 |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 58.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 8697        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018730598 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.5       |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 4750        |\n",
      "|    policy_gradient_loss | -0.00606    |\n",
      "|    reward               | -2.6690657  |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 74.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 477         |\n",
      "|    time_elapsed         | 8715        |\n",
      "|    total_timesteps      | 976896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019308161 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.6       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.4        |\n",
      "|    n_updates            | 4760        |\n",
      "|    policy_gradient_loss | -0.000621   |\n",
      "|    reward               | -1.1706338  |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 61.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 8733        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015894696 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.6       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    reward               | 1.5044473   |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 48.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3545257.59\n",
      "total_reward: 2545257.59\n",
      "total_cost: 236627.44\n",
      "total_trades: 64879\n",
      "Sharpe: 0.617\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 479         |\n",
      "|    time_elapsed         | 8751        |\n",
      "|    total_timesteps      | 980992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013344349 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.6       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 4780        |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | -4.1434054  |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 74.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 480          |\n",
      "|    time_elapsed         | 8769         |\n",
      "|    total_timesteps      | 983040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123056555 |\n",
      "|    clip_fraction        | 0.0876       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -60.7        |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.3         |\n",
      "|    n_updates            | 4790         |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    reward               | -2.789002    |\n",
      "|    std                  | 1.97         |\n",
      "|    value_loss           | 71.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 481         |\n",
      "|    time_elapsed         | 8787        |\n",
      "|    total_timesteps      | 985088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024411514 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | 0.0676      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 4800        |\n",
      "|    policy_gradient_loss | -0.000539   |\n",
      "|    reward               | 2.646586    |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 482        |\n",
      "|    time_elapsed         | 8806       |\n",
      "|    total_timesteps      | 987136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01539081 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.8      |\n",
      "|    explained_variance   | 0.193      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 49.9       |\n",
      "|    n_updates            | 4810       |\n",
      "|    policy_gradient_loss | -0.00482   |\n",
      "|    reward               | 0.31112495 |\n",
      "|    std                  | 1.98       |\n",
      "|    value_loss           | 89.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 483          |\n",
      "|    time_elapsed         | 8823         |\n",
      "|    total_timesteps      | 989184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110201165 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -60.8        |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.6         |\n",
      "|    n_updates            | 4820         |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    reward               | -11.118915   |\n",
      "|    std                  | 1.98         |\n",
      "|    value_loss           | 76.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 484         |\n",
      "|    time_elapsed         | 8842        |\n",
      "|    total_timesteps      | 991232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010746941 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.1        |\n",
      "|    n_updates            | 4830        |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | 1.1830091   |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 60          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 8866        |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015712243 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 4840        |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | 0.5569096   |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 486         |\n",
      "|    time_elapsed         | 8884        |\n",
      "|    total_timesteps      | 995328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019273896 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 4850        |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    reward               | 1.6206335   |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 68          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 8902        |\n",
      "|    total_timesteps      | 997376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015840225 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.4        |\n",
      "|    n_updates            | 4860        |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    reward               | -0.86612475 |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 82.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 8920        |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024314146 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 4870        |\n",
      "|    policy_gradient_loss | -0.000165   |\n",
      "|    reward               | 0.082875974 |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 489         |\n",
      "|    time_elapsed         | 8939        |\n",
      "|    total_timesteps      | 1001472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024541952 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 4880        |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    reward               | -1.0782616  |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 60          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 490         |\n",
      "|    time_elapsed         | 8957        |\n",
      "|    total_timesteps      | 1003520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015506568 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 4890        |\n",
      "|    policy_gradient_loss | -5.17e-05   |\n",
      "|    reward               | -2.8974652  |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 491         |\n",
      "|    time_elapsed         | 8975        |\n",
      "|    total_timesteps      | 1005568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024596222 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 4900        |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | 3.439072    |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 8993        |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030407669 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 4910        |\n",
      "|    policy_gradient_loss | 0.00118     |\n",
      "|    reward               | 3.719223    |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 58.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5089036.65\n",
      "total_reward: 4089036.65\n",
      "total_cost: 239357.23\n",
      "total_trades: 65164\n",
      "Sharpe: 0.785\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 493         |\n",
      "|    time_elapsed         | 9011        |\n",
      "|    total_timesteps      | 1009664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023319744 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.4        |\n",
      "|    n_updates            | 4920        |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    reward               | 0.009638102 |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 494        |\n",
      "|    time_elapsed         | 9029       |\n",
      "|    total_timesteps      | 1011712    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02441537 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.2      |\n",
      "|    explained_variance   | 0.358      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 61         |\n",
      "|    n_updates            | 4930       |\n",
      "|    policy_gradient_loss | 0.00262    |\n",
      "|    reward               | 0.7352959  |\n",
      "|    std                  | 2.01       |\n",
      "|    value_loss           | 84.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 9047        |\n",
      "|    total_timesteps      | 1013760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024475805 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.84        |\n",
      "|    n_updates            | 4940        |\n",
      "|    policy_gradient_loss | 0.00182     |\n",
      "|    reward               | -5.9520435  |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 496         |\n",
      "|    time_elapsed         | 9065        |\n",
      "|    total_timesteps      | 1015808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013380787 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 4950        |\n",
      "|    policy_gradient_loss | -0.00573    |\n",
      "|    reward               | 0.64080435  |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 497         |\n",
      "|    time_elapsed         | 9083        |\n",
      "|    total_timesteps      | 1017856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021940328 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 4960        |\n",
      "|    policy_gradient_loss | -0.00123    |\n",
      "|    reward               | 2.2451315   |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 70.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 498         |\n",
      "|    time_elapsed         | 9102        |\n",
      "|    total_timesteps      | 1019904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026502337 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.4       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 4970        |\n",
      "|    policy_gradient_loss | 0.00118     |\n",
      "|    reward               | 0.09763487  |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 499         |\n",
      "|    time_elapsed         | 9119        |\n",
      "|    total_timesteps      | 1021952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028070964 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.4       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 4980        |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    reward               | -0.49831137 |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 63.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 500         |\n",
      "|    time_elapsed         | 9137        |\n",
      "|    total_timesteps      | 1024000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015237752 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.4       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 4990        |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    reward               | -6.603652   |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 60.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 501         |\n",
      "|    time_elapsed         | 9156        |\n",
      "|    total_timesteps      | 1026048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019524183 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.5       |\n",
      "|    explained_variance   | -0.00681    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 5000        |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | -0.27268177 |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 502         |\n",
      "|    time_elapsed         | 9174        |\n",
      "|    total_timesteps      | 1028096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020611024 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.5       |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 5010        |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    reward               | 1.6350849   |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 503         |\n",
      "|    time_elapsed         | 9192        |\n",
      "|    total_timesteps      | 1030144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022356886 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.6       |\n",
      "|    explained_variance   | 0.019       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.8        |\n",
      "|    n_updates            | 5020        |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    reward               | 0.71800065  |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 504        |\n",
      "|    time_elapsed         | 9210       |\n",
      "|    total_timesteps      | 1032192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02092069 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.6      |\n",
      "|    explained_variance   | 0.101      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 95.5       |\n",
      "|    n_updates            | 5030       |\n",
      "|    policy_gradient_loss | -0.00411   |\n",
      "|    reward               | -2.059396  |\n",
      "|    std                  | 2.03       |\n",
      "|    value_loss           | 159        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 505         |\n",
      "|    time_elapsed         | 9229        |\n",
      "|    total_timesteps      | 1034240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016688468 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.6       |\n",
      "|    explained_variance   | 0.0766      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 5040        |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    reward               | -2.3658373  |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 506         |\n",
      "|    time_elapsed         | 9247        |\n",
      "|    total_timesteps      | 1036288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025154768 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.7       |\n",
      "|    explained_variance   | 0.0352      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.4        |\n",
      "|    n_updates            | 5050        |\n",
      "|    policy_gradient_loss | 0.000797    |\n",
      "|    reward               | -0.2752619  |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 90.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 507         |\n",
      "|    time_elapsed         | 9265        |\n",
      "|    total_timesteps      | 1038336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025354676 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.7       |\n",
      "|    explained_variance   | 0.0564      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 5060        |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    reward               | 5.942778    |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6449295.79\n",
      "total_reward: 5449295.79\n",
      "total_cost: 279663.10\n",
      "total_trades: 67228\n",
      "Sharpe: 0.950\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 508         |\n",
      "|    time_elapsed         | 9283        |\n",
      "|    total_timesteps      | 1040384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016249657 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.8       |\n",
      "|    explained_variance   | 0.047       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 5070        |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | 0.8338627   |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 56.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 509         |\n",
      "|    time_elapsed         | 9301        |\n",
      "|    total_timesteps      | 1042432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016794218 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.8       |\n",
      "|    explained_variance   | 0.0792      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.2        |\n",
      "|    n_updates            | 5080        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -0.21543956 |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 9319        |\n",
      "|    total_timesteps      | 1044480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01951469  |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.9       |\n",
      "|    explained_variance   | -0.0142     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 5090        |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | -0.30543283 |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 511         |\n",
      "|    time_elapsed         | 9337        |\n",
      "|    total_timesteps      | 1046528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015417691 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62         |\n",
      "|    explained_variance   | 0.0205      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94.8        |\n",
      "|    n_updates            | 5100        |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | -2.6914487  |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 512         |\n",
      "|    time_elapsed         | 9355        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029069163 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.1       |\n",
      "|    explained_variance   | 0.0135      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.46        |\n",
      "|    n_updates            | 5110        |\n",
      "|    policy_gradient_loss | 0.00381     |\n",
      "|    reward               | -0.9447293  |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 513         |\n",
      "|    time_elapsed         | 9373        |\n",
      "|    total_timesteps      | 1050624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02181713  |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.093       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.2        |\n",
      "|    n_updates            | 5120        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | -0.43958366 |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 514         |\n",
      "|    time_elapsed         | 9391        |\n",
      "|    total_timesteps      | 1052672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018266823 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.058       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.2        |\n",
      "|    n_updates            | 5130        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 4.444485    |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 515         |\n",
      "|    time_elapsed         | 9410        |\n",
      "|    total_timesteps      | 1054720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027753253 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 5140        |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | -3.1520836  |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 516         |\n",
      "|    time_elapsed         | 9428        |\n",
      "|    total_timesteps      | 1056768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012464103 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 5150        |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    reward               | -2.998221   |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 99.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 517         |\n",
      "|    time_elapsed         | 9446        |\n",
      "|    total_timesteps      | 1058816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013693722 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.9        |\n",
      "|    n_updates            | 5160        |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    reward               | -3.0832005  |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 518         |\n",
      "|    time_elapsed         | 9464        |\n",
      "|    total_timesteps      | 1060864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017714106 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.4        |\n",
      "|    n_updates            | 5170        |\n",
      "|    policy_gradient_loss | 0.00253     |\n",
      "|    reward               | 1.5522486   |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 79.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 519         |\n",
      "|    time_elapsed         | 9483        |\n",
      "|    total_timesteps      | 1062912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02469297  |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.4       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.66        |\n",
      "|    n_updates            | 5180        |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | -0.23623024 |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 520         |\n",
      "|    time_elapsed         | 9501        |\n",
      "|    total_timesteps      | 1064960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022701118 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.4       |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 5190        |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | -0.82087725 |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 82.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 521        |\n",
      "|    time_elapsed         | 9519       |\n",
      "|    total_timesteps      | 1067008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01902594 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.5      |\n",
      "|    explained_variance   | 0.13       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 102        |\n",
      "|    n_updates            | 5200       |\n",
      "|    policy_gradient_loss | 0.000146   |\n",
      "|    reward               | 3.1100411  |\n",
      "|    std                  | 2.1        |\n",
      "|    value_loss           | 191        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6343434.53\n",
      "total_reward: 5343434.53\n",
      "total_cost: 262042.55\n",
      "total_trades: 66836\n",
      "Sharpe: 0.989\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 522         |\n",
      "|    time_elapsed         | 9537        |\n",
      "|    total_timesteps      | 1069056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023890426 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 5210        |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    reward               | 0.6819852   |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 523         |\n",
      "|    time_elapsed         | 9555        |\n",
      "|    total_timesteps      | 1071104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018214352 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 5220        |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | 1.5182374   |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 524         |\n",
      "|    time_elapsed         | 9574        |\n",
      "|    total_timesteps      | 1073152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015261906 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | 0.0859      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94.8        |\n",
      "|    n_updates            | 5230        |\n",
      "|    policy_gradient_loss | -0.00205    |\n",
      "|    reward               | 1.3521352   |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 525         |\n",
      "|    time_elapsed         | 9592        |\n",
      "|    total_timesteps      | 1075200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024851881 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | -8.58e-05   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 5240        |\n",
      "|    policy_gradient_loss | 0.00832     |\n",
      "|    reward               | -0.47090724 |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 53.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 526         |\n",
      "|    time_elapsed         | 9610        |\n",
      "|    total_timesteps      | 1077248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034351535 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.6       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.9        |\n",
      "|    n_updates            | 5250        |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    reward               | 0.90930504  |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 83          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 9628        |\n",
      "|    total_timesteps      | 1079296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019248562 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.7       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 5260        |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    reward               | -1.7920097  |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 528         |\n",
      "|    time_elapsed         | 9646        |\n",
      "|    total_timesteps      | 1081344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027395925 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.7       |\n",
      "|    explained_variance   | 0.0532      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.5        |\n",
      "|    n_updates            | 5270        |\n",
      "|    policy_gradient_loss | 0.00334     |\n",
      "|    reward               | 1.8272058   |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 79.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 529         |\n",
      "|    time_elapsed         | 9664        |\n",
      "|    total_timesteps      | 1083392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037447326 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.8       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.3         |\n",
      "|    n_updates            | 5280        |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    reward               | 0.019018844 |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 530         |\n",
      "|    time_elapsed         | 9682        |\n",
      "|    total_timesteps      | 1085440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025438812 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.7        |\n",
      "|    n_updates            | 5290        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | -0.8538818  |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 9701        |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013637385 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 0.0933      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.3        |\n",
      "|    n_updates            | 5300        |\n",
      "|    policy_gradient_loss | 0.00574     |\n",
      "|    reward               | -0.5501211  |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 9719        |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010820545 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 5310        |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    reward               | 2.9430964   |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 533         |\n",
      "|    time_elapsed         | 9737        |\n",
      "|    total_timesteps      | 1091584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015263294 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.1        |\n",
      "|    n_updates            | 5320        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -0.39022347 |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 81.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 534         |\n",
      "|    time_elapsed         | 9755        |\n",
      "|    total_timesteps      | 1093632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012803348 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.4        |\n",
      "|    n_updates            | 5330        |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    reward               | -0.16592756 |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 535         |\n",
      "|    time_elapsed         | 9773        |\n",
      "|    total_timesteps      | 1095680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020768221 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.0105      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88.5        |\n",
      "|    n_updates            | 5340        |\n",
      "|    policy_gradient_loss | 0.00438     |\n",
      "|    reward               | 2.1523802   |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6355412.55\n",
      "total_reward: 5355412.55\n",
      "total_cost: 246550.32\n",
      "total_trades: 65363\n",
      "Sharpe: 0.919\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 536         |\n",
      "|    time_elapsed         | 9791        |\n",
      "|    total_timesteps      | 1097728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031795733 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.8         |\n",
      "|    n_updates            | 5350        |\n",
      "|    policy_gradient_loss | -0.00213    |\n",
      "|    reward               | 0.82280636  |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 537         |\n",
      "|    time_elapsed         | 9809        |\n",
      "|    total_timesteps      | 1099776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012959249 |\n",
      "|    clip_fraction        | 0.0828      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 5360        |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    reward               | -0.5295597  |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 538         |\n",
      "|    time_elapsed         | 9827        |\n",
      "|    total_timesteps      | 1101824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019436609 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.8        |\n",
      "|    n_updates            | 5370        |\n",
      "|    policy_gradient_loss | 0.00324     |\n",
      "|    reward               | -5.290881   |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 539        |\n",
      "|    time_elapsed         | 9845       |\n",
      "|    total_timesteps      | 1103872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01940339 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.1      |\n",
      "|    explained_variance   | 0.188      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.5       |\n",
      "|    n_updates            | 5380       |\n",
      "|    policy_gradient_loss | -0.00154   |\n",
      "|    reward               | 0.90189403 |\n",
      "|    std                  | 2.15       |\n",
      "|    value_loss           | 34.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 540         |\n",
      "|    time_elapsed         | 9864        |\n",
      "|    total_timesteps      | 1105920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018761374 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.2       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.3        |\n",
      "|    n_updates            | 5390        |\n",
      "|    policy_gradient_loss | -0.00102    |\n",
      "|    reward               | 0.5608838   |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 541         |\n",
      "|    time_elapsed         | 9882        |\n",
      "|    total_timesteps      | 1107968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011091422 |\n",
      "|    clip_fraction        | 0.0767      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.2       |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 86.5        |\n",
      "|    n_updates            | 5400        |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    reward               | -15.585507  |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 243         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 542        |\n",
      "|    time_elapsed         | 9900       |\n",
      "|    total_timesteps      | 1110016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01714696 |\n",
      "|    clip_fraction        | 0.0896     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.2      |\n",
      "|    explained_variance   | 0.214      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 61.3       |\n",
      "|    n_updates            | 5410       |\n",
      "|    policy_gradient_loss | -0.00279   |\n",
      "|    reward               | 3.926596   |\n",
      "|    std                  | 2.15       |\n",
      "|    value_loss           | 157        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 9918        |\n",
      "|    total_timesteps      | 1112064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038714394 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.2       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.96        |\n",
      "|    n_updates            | 5420        |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    reward               | 1.3037994   |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 544        |\n",
      "|    time_elapsed         | 9937       |\n",
      "|    total_timesteps      | 1114112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02067772 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.2      |\n",
      "|    explained_variance   | 0.536      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.6       |\n",
      "|    n_updates            | 5430       |\n",
      "|    policy_gradient_loss | -0.00667   |\n",
      "|    reward               | -1.3118846 |\n",
      "|    std                  | 2.16       |\n",
      "|    value_loss           | 93.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 545        |\n",
      "|    time_elapsed         | 9955       |\n",
      "|    total_timesteps      | 1116160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00901911 |\n",
      "|    clip_fraction        | 0.0684     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.3      |\n",
      "|    explained_variance   | 0.199      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 48.3       |\n",
      "|    n_updates            | 5440       |\n",
      "|    policy_gradient_loss | -0.00361   |\n",
      "|    reward               | 8.332984   |\n",
      "|    std                  | 2.16       |\n",
      "|    value_loss           | 243        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 546         |\n",
      "|    time_elapsed         | 9973        |\n",
      "|    total_timesteps      | 1118208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026207745 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.91        |\n",
      "|    n_updates            | 5450        |\n",
      "|    policy_gradient_loss | 0.00176     |\n",
      "|    reward               | -0.08598693 |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 547         |\n",
      "|    time_elapsed         | 9991        |\n",
      "|    total_timesteps      | 1120256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013604191 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 5460        |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    reward               | 4.0258765   |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 548         |\n",
      "|    time_elapsed         | 10009       |\n",
      "|    total_timesteps      | 1122304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022331562 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.9        |\n",
      "|    n_updates            | 5470        |\n",
      "|    policy_gradient_loss | 0.00237     |\n",
      "|    reward               | -3.4658847  |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 10027       |\n",
      "|    total_timesteps      | 1124352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012591986 |\n",
      "|    clip_fraction        | 0.0848      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.1        |\n",
      "|    n_updates            | 5480        |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    reward               | 2.6119592   |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 69.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7253029.67\n",
      "total_reward: 6253029.67\n",
      "total_cost: 255823.98\n",
      "total_trades: 65203\n",
      "Sharpe: 0.920\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 550         |\n",
      "|    time_elapsed         | 10045       |\n",
      "|    total_timesteps      | 1126400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022916164 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 5490        |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | -0.73970604 |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 551          |\n",
      "|    time_elapsed         | 10064        |\n",
      "|    total_timesteps      | 1128448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010906935  |\n",
      "|    clip_fraction        | 0.0738       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -63.4        |\n",
      "|    explained_variance   | 0.343        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.7         |\n",
      "|    n_updates            | 5500         |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    reward               | -0.049946867 |\n",
      "|    std                  | 2.17         |\n",
      "|    value_loss           | 199          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 552         |\n",
      "|    time_elapsed         | 10082       |\n",
      "|    total_timesteps      | 1130496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030740455 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.0522      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.3        |\n",
      "|    n_updates            | 5510        |\n",
      "|    policy_gradient_loss | 0.0038      |\n",
      "|    reward               | 2.352387    |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 10100       |\n",
      "|    total_timesteps      | 1132544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028101325 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 5520        |\n",
      "|    policy_gradient_loss | -0.00048    |\n",
      "|    reward               | -0.6921018  |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 554         |\n",
      "|    time_elapsed         | 10118       |\n",
      "|    total_timesteps      | 1134592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017359054 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.0943      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.8        |\n",
      "|    n_updates            | 5530        |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    reward               | 0.35725448  |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 555         |\n",
      "|    time_elapsed         | 10136       |\n",
      "|    total_timesteps      | 1136640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018147143 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.0867      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.6        |\n",
      "|    n_updates            | 5540        |\n",
      "|    policy_gradient_loss | -0.00133    |\n",
      "|    reward               | -3.1105874  |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 237         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 556         |\n",
      "|    time_elapsed         | 10155       |\n",
      "|    total_timesteps      | 1138688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016787425 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 5550        |\n",
      "|    policy_gradient_loss | 0.00243     |\n",
      "|    reward               | -2.5283933  |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 61.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 557         |\n",
      "|    time_elapsed         | 10173       |\n",
      "|    total_timesteps      | 1140736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022600729 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.6        |\n",
      "|    n_updates            | 5560        |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | -0.77406394 |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 558         |\n",
      "|    time_elapsed         | 10191       |\n",
      "|    total_timesteps      | 1142784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016666235 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.5        |\n",
      "|    n_updates            | 5570        |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    reward               | -0.4026533  |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 10209       |\n",
      "|    total_timesteps      | 1144832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024856623 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.7        |\n",
      "|    n_updates            | 5580        |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    reward               | -2.8008792  |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 560        |\n",
      "|    time_elapsed         | 10227      |\n",
      "|    total_timesteps      | 1146880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02225166 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.7      |\n",
      "|    explained_variance   | 0.402      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.7       |\n",
      "|    n_updates            | 5590       |\n",
      "|    policy_gradient_loss | -0.00566   |\n",
      "|    reward               | 1.7023115  |\n",
      "|    std                  | 2.19       |\n",
      "|    value_loss           | 30.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 561         |\n",
      "|    time_elapsed         | 10245       |\n",
      "|    total_timesteps      | 1148928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016628906 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.4        |\n",
      "|    n_updates            | 5600        |\n",
      "|    policy_gradient_loss | -0.00195    |\n",
      "|    reward               | 0.48445016  |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 205         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 562         |\n",
      "|    time_elapsed         | 10264       |\n",
      "|    total_timesteps      | 1150976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024370812 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.6        |\n",
      "|    n_updates            | 5610        |\n",
      "|    policy_gradient_loss | 0.000135    |\n",
      "|    reward               | 1.8843703   |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 75.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 563         |\n",
      "|    time_elapsed         | 10283       |\n",
      "|    total_timesteps      | 1153024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015358638 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 5620        |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    reward               | -1.911938   |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5023896.00\n",
      "total_reward: 4023896.00\n",
      "total_cost: 265538.50\n",
      "total_trades: 65364\n",
      "Sharpe: 0.825\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 564         |\n",
      "|    time_elapsed         | 10301       |\n",
      "|    total_timesteps      | 1155072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017117245 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.6        |\n",
      "|    n_updates            | 5630        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 1.468826    |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 98          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 565        |\n",
      "|    time_elapsed         | 10320      |\n",
      "|    total_timesteps      | 1157120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02117847 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.8      |\n",
      "|    explained_variance   | 0.331      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 46.9       |\n",
      "|    n_updates            | 5640       |\n",
      "|    policy_gradient_loss | -0.0044    |\n",
      "|    reward               | -25.209867 |\n",
      "|    std                  | 2.21       |\n",
      "|    value_loss           | 117        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 566         |\n",
      "|    time_elapsed         | 10339       |\n",
      "|    total_timesteps      | 1159168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039382022 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.1        |\n",
      "|    n_updates            | 5650        |\n",
      "|    policy_gradient_loss | 0.0095      |\n",
      "|    reward               | -1.4824846  |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 567         |\n",
      "|    time_elapsed         | 10357       |\n",
      "|    total_timesteps      | 1161216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040080473 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 5660        |\n",
      "|    policy_gradient_loss | -0.00877    |\n",
      "|    reward               | -3.9092782  |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 59.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 568         |\n",
      "|    time_elapsed         | 10375       |\n",
      "|    total_timesteps      | 1163264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013119788 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 5670        |\n",
      "|    policy_gradient_loss | -9.55e-05   |\n",
      "|    reward               | -0.3509838  |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 569         |\n",
      "|    time_elapsed         | 10393       |\n",
      "|    total_timesteps      | 1165312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018536596 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.1       |\n",
      "|    explained_variance   | 0.0471      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.4        |\n",
      "|    n_updates            | 5680        |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    reward               | -4.9807825  |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 570        |\n",
      "|    time_elapsed         | 10411      |\n",
      "|    total_timesteps      | 1167360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01999224 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.2      |\n",
      "|    explained_variance   | 0.332      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.4       |\n",
      "|    n_updates            | 5690       |\n",
      "|    policy_gradient_loss | -0.00152   |\n",
      "|    reward               | -1.5185913 |\n",
      "|    std                  | 2.23       |\n",
      "|    value_loss           | 46.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 571         |\n",
      "|    time_elapsed         | 10430       |\n",
      "|    total_timesteps      | 1169408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017784504 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52          |\n",
      "|    n_updates            | 5700        |\n",
      "|    policy_gradient_loss | -0.00768    |\n",
      "|    reward               | 1.2076336   |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 572         |\n",
      "|    time_elapsed         | 10448       |\n",
      "|    total_timesteps      | 1171456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013051658 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.3        |\n",
      "|    n_updates            | 5710        |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    reward               | -6.007149   |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 573         |\n",
      "|    time_elapsed         | 10466       |\n",
      "|    total_timesteps      | 1173504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020361625 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.0904      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 5720        |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    reward               | -1.3540791  |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 82.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 574        |\n",
      "|    time_elapsed         | 10484      |\n",
      "|    total_timesteps      | 1175552    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02206831 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.3      |\n",
      "|    explained_variance   | 0.322      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 41.4       |\n",
      "|    n_updates            | 5730       |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    reward               | -2.0956032 |\n",
      "|    std                  | 2.24       |\n",
      "|    value_loss           | 113        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 575         |\n",
      "|    time_elapsed         | 10502       |\n",
      "|    total_timesteps      | 1177600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018033702 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 5740        |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    reward               | 0.3349462   |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 576         |\n",
      "|    time_elapsed         | 10520       |\n",
      "|    total_timesteps      | 1179648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019852338 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.7        |\n",
      "|    n_updates            | 5750        |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    reward               | -1.0853729  |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 198         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 577         |\n",
      "|    time_elapsed         | 10539       |\n",
      "|    total_timesteps      | 1181696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026075788 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | -0.0326     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.59        |\n",
      "|    n_updates            | 5760        |\n",
      "|    policy_gradient_loss | -0.00169    |\n",
      "|    reward               | 0.7451424   |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 22.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6213331.70\n",
      "total_reward: 5213331.70\n",
      "total_cost: 294629.33\n",
      "total_trades: 67728\n",
      "Sharpe: 0.970\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 578         |\n",
      "|    time_elapsed         | 10557       |\n",
      "|    total_timesteps      | 1183744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017899472 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.3        |\n",
      "|    n_updates            | 5770        |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    reward               | -0.14472091 |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 93.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 579         |\n",
      "|    time_elapsed         | 10575       |\n",
      "|    total_timesteps      | 1185792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027888246 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.3        |\n",
      "|    n_updates            | 5780        |\n",
      "|    policy_gradient_loss | 0.000484    |\n",
      "|    reward               | -10.496907  |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 580         |\n",
      "|    time_elapsed         | 10594       |\n",
      "|    total_timesteps      | 1187840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023566436 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 5790        |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | 2.0350218   |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 65.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 581         |\n",
      "|    time_elapsed         | 10612       |\n",
      "|    total_timesteps      | 1189888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018681757 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 5800        |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    reward               | 1.5542071   |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 582         |\n",
      "|    time_elapsed         | 10630       |\n",
      "|    total_timesteps      | 1191936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014981583 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.7        |\n",
      "|    n_updates            | 5810        |\n",
      "|    policy_gradient_loss | -0.00654    |\n",
      "|    reward               | -1.5250275  |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 583         |\n",
      "|    time_elapsed         | 10648       |\n",
      "|    total_timesteps      | 1193984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018764194 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.9        |\n",
      "|    n_updates            | 5820        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | -4.8033385  |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 584         |\n",
      "|    time_elapsed         | 10667       |\n",
      "|    total_timesteps      | 1196032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027288057 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.48        |\n",
      "|    n_updates            | 5830        |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | 0.20235664  |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 585         |\n",
      "|    time_elapsed         | 10685       |\n",
      "|    total_timesteps      | 1198080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014110433 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.8        |\n",
      "|    n_updates            | 5840        |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | 0.5956332   |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 586         |\n",
      "|    time_elapsed         | 10704       |\n",
      "|    total_timesteps      | 1200128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011821557 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59          |\n",
      "|    n_updates            | 5850        |\n",
      "|    policy_gradient_loss | -0.00257    |\n",
      "|    reward               | -1.5782415  |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 90.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 587         |\n",
      "|    time_elapsed         | 10722       |\n",
      "|    total_timesteps      | 1202176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024368491 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 5860        |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    reward               | -0.07740012 |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 588         |\n",
      "|    time_elapsed         | 10740       |\n",
      "|    total_timesteps      | 1204224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022619944 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 5870        |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    reward               | -0.4774063  |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 47.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 589         |\n",
      "|    time_elapsed         | 10758       |\n",
      "|    total_timesteps      | 1206272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015221788 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 5880        |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | -7.6313734  |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 57          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 590         |\n",
      "|    time_elapsed         | 10777       |\n",
      "|    total_timesteps      | 1208320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028366482 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 5890        |\n",
      "|    policy_gradient_loss | 0.00674     |\n",
      "|    reward               | 4.353243    |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 591         |\n",
      "|    time_elapsed         | 10795       |\n",
      "|    total_timesteps      | 1210368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02132386  |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 5900        |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    reward               | -0.75441694 |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 58.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6588258.53\n",
      "total_reward: 5588258.53\n",
      "total_cost: 286849.95\n",
      "total_trades: 68043\n",
      "Sharpe: 0.944\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 592         |\n",
      "|    time_elapsed         | 10813       |\n",
      "|    total_timesteps      | 1212416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012101398 |\n",
      "|    clip_fraction        | 0.0812      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65         |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 5910        |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    reward               | 0.12491215  |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 593         |\n",
      "|    time_elapsed         | 10832       |\n",
      "|    total_timesteps      | 1214464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008091284 |\n",
      "|    clip_fraction        | 0.0554      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65         |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.3        |\n",
      "|    n_updates            | 5920        |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    reward               | 6.1718535   |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 594         |\n",
      "|    time_elapsed         | 10850       |\n",
      "|    total_timesteps      | 1216512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027168866 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65         |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 5930        |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    reward               | -5.2241154  |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 595         |\n",
      "|    time_elapsed         | 10868       |\n",
      "|    total_timesteps      | 1218560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014578801 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 5940        |\n",
      "|    policy_gradient_loss | -0.00123    |\n",
      "|    reward               | -3.2040572  |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 596         |\n",
      "|    time_elapsed         | 10886       |\n",
      "|    total_timesteps      | 1220608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024587704 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.7        |\n",
      "|    n_updates            | 5950        |\n",
      "|    policy_gradient_loss | 9.74e-05    |\n",
      "|    reward               | 1.1452295   |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 10905       |\n",
      "|    total_timesteps      | 1222656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026503796 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 5960        |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    reward               | 0.57584953  |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 61.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 598         |\n",
      "|    time_elapsed         | 10924       |\n",
      "|    total_timesteps      | 1224704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014952749 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 5970        |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    reward               | 3.2461503   |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 599          |\n",
      "|    time_elapsed         | 10942        |\n",
      "|    total_timesteps      | 1226752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052058734 |\n",
      "|    clip_fraction        | 0.0463       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -65.2        |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.5         |\n",
      "|    n_updates            | 5980         |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | 1.0020119    |\n",
      "|    std                  | 2.31         |\n",
      "|    value_loss           | 151          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 600         |\n",
      "|    time_elapsed         | 10960       |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036977753 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.0482      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.7        |\n",
      "|    n_updates            | 5990        |\n",
      "|    policy_gradient_loss | 0.00356     |\n",
      "|    reward               | 2.9108381   |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 601         |\n",
      "|    time_elapsed         | 10979       |\n",
      "|    total_timesteps      | 1230848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040232655 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.95        |\n",
      "|    n_updates            | 6000        |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    reward               | -2.5100489  |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 602         |\n",
      "|    time_elapsed         | 10997       |\n",
      "|    total_timesteps      | 1232896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021818103 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56          |\n",
      "|    n_updates            | 6010        |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | 1.3625171   |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 11015       |\n",
      "|    total_timesteps      | 1234944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020547017 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98.8        |\n",
      "|    n_updates            | 6020        |\n",
      "|    policy_gradient_loss | -0.00226    |\n",
      "|    reward               | 4.3748765   |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 604        |\n",
      "|    time_elapsed         | 11033      |\n",
      "|    total_timesteps      | 1236992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03012425 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.4      |\n",
      "|    explained_variance   | 0.145      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.2       |\n",
      "|    n_updates            | 6030       |\n",
      "|    policy_gradient_loss | -0.000152  |\n",
      "|    reward               | 7.960809   |\n",
      "|    std                  | 2.33       |\n",
      "|    value_loss           | 54.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 605         |\n",
      "|    time_elapsed         | 11051       |\n",
      "|    total_timesteps      | 1239040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025231251 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.7        |\n",
      "|    n_updates            | 6040        |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    reward               | 0.12795337  |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 606         |\n",
      "|    time_elapsed         | 11070       |\n",
      "|    total_timesteps      | 1241088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020650897 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.6        |\n",
      "|    n_updates            | 6050        |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | -1.6877013  |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6177351.23\n",
      "total_reward: 5177351.23\n",
      "total_cost: 336474.89\n",
      "total_trades: 70135\n",
      "Sharpe: 0.985\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 11088       |\n",
      "|    total_timesteps      | 1243136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018909063 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.6        |\n",
      "|    n_updates            | 6060        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.9720761   |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 608         |\n",
      "|    time_elapsed         | 11106       |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040860638 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.42        |\n",
      "|    n_updates            | 6070        |\n",
      "|    policy_gradient_loss | 0.00214     |\n",
      "|    reward               | 1.4221027   |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 609         |\n",
      "|    time_elapsed         | 11124       |\n",
      "|    total_timesteps      | 1247232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020974534 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 6080        |\n",
      "|    policy_gradient_loss | -0.00205    |\n",
      "|    reward               | -0.9875141  |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 66.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 610         |\n",
      "|    time_elapsed         | 11143       |\n",
      "|    total_timesteps      | 1249280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015794614 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.4        |\n",
      "|    n_updates            | 6090        |\n",
      "|    policy_gradient_loss | -0.000993   |\n",
      "|    reward               | 4.0663505   |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 97.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 611         |\n",
      "|    time_elapsed         | 11161       |\n",
      "|    total_timesteps      | 1251328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026128111 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 6100        |\n",
      "|    policy_gradient_loss | -0.00104    |\n",
      "|    reward               | 1.0318348   |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 612        |\n",
      "|    time_elapsed         | 11179      |\n",
      "|    total_timesteps      | 1253376    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02299693 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.8      |\n",
      "|    explained_variance   | 0.184      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 90         |\n",
      "|    n_updates            | 6110       |\n",
      "|    policy_gradient_loss | -0.00717   |\n",
      "|    reward               | 3.2134159  |\n",
      "|    std                  | 2.36       |\n",
      "|    value_loss           | 103        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 613         |\n",
      "|    time_elapsed         | 11197       |\n",
      "|    total_timesteps      | 1255424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018884886 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 6120        |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    reward               | 5.6614623   |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 614        |\n",
      "|    time_elapsed         | 11216      |\n",
      "|    total_timesteps      | 1257472    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01867927 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.9      |\n",
      "|    explained_variance   | 0.52       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.3       |\n",
      "|    n_updates            | 6130       |\n",
      "|    policy_gradient_loss | -0.00485   |\n",
      "|    reward               | 0.2327972  |\n",
      "|    std                  | 2.37       |\n",
      "|    value_loss           | 63.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 11234       |\n",
      "|    total_timesteps      | 1259520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015833449 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.2        |\n",
      "|    n_updates            | 6140        |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    reward               | 2.1834095   |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 78.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 616         |\n",
      "|    time_elapsed         | 11252       |\n",
      "|    total_timesteps      | 1261568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015700698 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.2        |\n",
      "|    n_updates            | 6150        |\n",
      "|    policy_gradient_loss | -0.00614    |\n",
      "|    reward               | 0.8651097   |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 11270       |\n",
      "|    total_timesteps      | 1263616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011643105 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 6160        |\n",
      "|    policy_gradient_loss | 0.000882    |\n",
      "|    reward               | 5.2966256   |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 618         |\n",
      "|    time_elapsed         | 11288       |\n",
      "|    total_timesteps      | 1265664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027487703 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 6170        |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    reward               | -0.14121439 |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 619         |\n",
      "|    time_elapsed         | 11306       |\n",
      "|    total_timesteps      | 1267712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010729817 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 6180        |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | 0.5331025   |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 620         |\n",
      "|    time_elapsed         | 11324       |\n",
      "|    total_timesteps      | 1269760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014198779 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.2        |\n",
      "|    n_updates            | 6190        |\n",
      "|    policy_gradient_loss | 0.000242    |\n",
      "|    reward               | 0.44756442  |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8517816.97\n",
      "total_reward: 7517816.97\n",
      "total_cost: 275544.67\n",
      "total_trades: 66856\n",
      "Sharpe: 1.089\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 621         |\n",
      "|    time_elapsed         | 11342       |\n",
      "|    total_timesteps      | 1271808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021441694 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | -0.0111     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 6200        |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | 0.7024116   |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 56.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 622         |\n",
      "|    time_elapsed         | 11360       |\n",
      "|    total_timesteps      | 1273856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019113991 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.3       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 6210        |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | 0.10360431  |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 623         |\n",
      "|    time_elapsed         | 11378       |\n",
      "|    total_timesteps      | 1275904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025021419 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.3       |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 169         |\n",
      "|    n_updates            | 6220        |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    reward               | 0.85458076  |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 624         |\n",
      "|    time_elapsed         | 11397       |\n",
      "|    total_timesteps      | 1277952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018482545 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.4       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 6230        |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    reward               | -0.34549022 |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 625          |\n",
      "|    time_elapsed         | 11415        |\n",
      "|    total_timesteps      | 1280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.038179025  |\n",
      "|    clip_fraction        | 0.336        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.4        |\n",
      "|    explained_variance   | 0.134        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.67         |\n",
      "|    n_updates            | 6240         |\n",
      "|    policy_gradient_loss | 0.000947     |\n",
      "|    reward               | -0.006541294 |\n",
      "|    std                  | 2.41         |\n",
      "|    value_loss           | 19.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 626          |\n",
      "|    time_elapsed         | 11433        |\n",
      "|    total_timesteps      | 1282048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.02016169   |\n",
      "|    clip_fraction        | 0.221        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.5        |\n",
      "|    explained_variance   | 0.0741       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.8         |\n",
      "|    n_updates            | 6250         |\n",
      "|    policy_gradient_loss | -0.00956     |\n",
      "|    reward               | -0.067422174 |\n",
      "|    std                  | 2.42         |\n",
      "|    value_loss           | 157          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 627          |\n",
      "|    time_elapsed         | 11451        |\n",
      "|    total_timesteps      | 1284096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0150732305 |\n",
      "|    clip_fraction        | 0.0873       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.6        |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.9         |\n",
      "|    n_updates            | 6260         |\n",
      "|    policy_gradient_loss | -0.00802     |\n",
      "|    reward               | 5.6029496    |\n",
      "|    std                  | 2.42         |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 628         |\n",
      "|    time_elapsed         | 11469       |\n",
      "|    total_timesteps      | 1286144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020417305 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.6       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 6270        |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | 5.082873    |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 629         |\n",
      "|    time_elapsed         | 11488       |\n",
      "|    total_timesteps      | 1288192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01830546  |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 6280        |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    reward               | -0.47234243 |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 630         |\n",
      "|    time_elapsed         | 11506       |\n",
      "|    total_timesteps      | 1290240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019730994 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98.2        |\n",
      "|    n_updates            | 6290        |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    reward               | -3.707233   |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 224         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 11524       |\n",
      "|    total_timesteps      | 1292288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015716506 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.1        |\n",
      "|    n_updates            | 6300        |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    reward               | -0.9644358  |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 632         |\n",
      "|    time_elapsed         | 11542       |\n",
      "|    total_timesteps      | 1294336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030063534 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.8       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 6310        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -0.12683824 |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 633        |\n",
      "|    time_elapsed         | 11560      |\n",
      "|    total_timesteps      | 1296384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03724096 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.8      |\n",
      "|    explained_variance   | 0.0303     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 58.7       |\n",
      "|    n_updates            | 6320       |\n",
      "|    policy_gradient_loss | -0.00768   |\n",
      "|    reward               | 0.44248992 |\n",
      "|    std                  | 2.44       |\n",
      "|    value_loss           | 148        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 634         |\n",
      "|    time_elapsed         | 11586       |\n",
      "|    total_timesteps      | 1298432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015354183 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.8       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.6        |\n",
      "|    n_updates            | 6330        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -3.1476812  |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6103582.63\n",
      "total_reward: 5103582.63\n",
      "total_cost: 372918.10\n",
      "total_trades: 72756\n",
      "Sharpe: 0.927\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 635         |\n",
      "|    time_elapsed         | 11604       |\n",
      "|    total_timesteps      | 1300480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032443304 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.0274      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 6340        |\n",
      "|    policy_gradient_loss | 0.00134     |\n",
      "|    reward               | 5.4641657   |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 636         |\n",
      "|    time_elapsed         | 11623       |\n",
      "|    total_timesteps      | 1302528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019815344 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.0335      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 6350        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 1.2616712   |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 637         |\n",
      "|    time_elapsed         | 11641       |\n",
      "|    total_timesteps      | 1304576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018721009 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 186         |\n",
      "|    n_updates            | 6360        |\n",
      "|    policy_gradient_loss | -0.00814    |\n",
      "|    reward               | -2.6749773  |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 638         |\n",
      "|    time_elapsed         | 11659       |\n",
      "|    total_timesteps      | 1306624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028036129 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 6370        |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    reward               | 3.7631822   |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 639         |\n",
      "|    time_elapsed         | 11678       |\n",
      "|    total_timesteps      | 1308672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021999698 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 6380        |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    reward               | -0.12646884 |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 63.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 640         |\n",
      "|    time_elapsed         | 11696       |\n",
      "|    total_timesteps      | 1310720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022145953 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.2        |\n",
      "|    n_updates            | 6390        |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    reward               | 1.1427112   |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 641        |\n",
      "|    time_elapsed         | 11714      |\n",
      "|    total_timesteps      | 1312768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01394226 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.1      |\n",
      "|    explained_variance   | 0.0194     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 55.3       |\n",
      "|    n_updates            | 6400       |\n",
      "|    policy_gradient_loss | -0.00653   |\n",
      "|    reward               | -2.1332276 |\n",
      "|    std                  | 2.47       |\n",
      "|    value_loss           | 159        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 642         |\n",
      "|    time_elapsed         | 11732       |\n",
      "|    total_timesteps      | 1314816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026309837 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.1       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.78        |\n",
      "|    n_updates            | 6410        |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    reward               | 1.8431044   |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 643         |\n",
      "|    time_elapsed         | 11751       |\n",
      "|    total_timesteps      | 1316864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016247403 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.1       |\n",
      "|    explained_variance   | 0.0467      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.2        |\n",
      "|    n_updates            | 6420        |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    reward               | -0.05254293 |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 644         |\n",
      "|    time_elapsed         | 11769       |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019079551 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.024       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.1        |\n",
      "|    n_updates            | 6430        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | 2.3103328   |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 645         |\n",
      "|    time_elapsed         | 11787       |\n",
      "|    total_timesteps      | 1320960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020616598 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 6440        |\n",
      "|    policy_gradient_loss | -0.00133    |\n",
      "|    reward               | -3.000215   |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 646         |\n",
      "|    time_elapsed         | 11805       |\n",
      "|    total_timesteps      | 1323008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022099074 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.3       |\n",
      "|    explained_variance   | 0.0963      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.1        |\n",
      "|    n_updates            | 6450        |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | 0.28984866  |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 73.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 647        |\n",
      "|    time_elapsed         | 11824      |\n",
      "|    total_timesteps      | 1325056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01803172 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.3      |\n",
      "|    explained_variance   | 0.0139     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 69.5       |\n",
      "|    n_updates            | 6460       |\n",
      "|    policy_gradient_loss | -0.00768   |\n",
      "|    reward               | 1.1130157  |\n",
      "|    std                  | 2.49       |\n",
      "|    value_loss           | 143        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 648         |\n",
      "|    time_elapsed         | 11842       |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029166648 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.0399      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.7        |\n",
      "|    n_updates            | 6470        |\n",
      "|    policy_gradient_loss | 0.000405    |\n",
      "|    reward               | 0.7346248   |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4707952.43\n",
      "total_reward: 3707952.43\n",
      "total_cost: 336349.97\n",
      "total_trades: 69942\n",
      "Sharpe: 0.808\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 649         |\n",
      "|    time_elapsed         | 11860       |\n",
      "|    total_timesteps      | 1329152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032297548 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.5       |\n",
      "|    explained_variance   | -0.00486    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.86        |\n",
      "|    n_updates            | 6480        |\n",
      "|    policy_gradient_loss | -0.00873    |\n",
      "|    reward               | -0.8135993  |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 650         |\n",
      "|    time_elapsed         | 11878       |\n",
      "|    total_timesteps      | 1331200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01804613  |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.0137      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.8        |\n",
      "|    n_updates            | 6490        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    reward               | -0.19694158 |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 90          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 651        |\n",
      "|    time_elapsed         | 11896      |\n",
      "|    total_timesteps      | 1333248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01892128 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.6      |\n",
      "|    explained_variance   | 0.0751     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.4       |\n",
      "|    n_updates            | 6500       |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    reward               | -0.9307416 |\n",
      "|    std                  | 2.52       |\n",
      "|    value_loss           | 124        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 652         |\n",
      "|    time_elapsed         | 11914       |\n",
      "|    total_timesteps      | 1335296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023475919 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | 0.0524      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 6510        |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    reward               | 1.2393299   |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 62.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 11932       |\n",
      "|    total_timesteps      | 1337344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015718706 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | 0.0278      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.4        |\n",
      "|    n_updates            | 6520        |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    reward               | 1.4186004   |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 11950       |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024980366 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | 0.0391      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.1        |\n",
      "|    n_updates            | 6530        |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    reward               | 27.490704   |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 655         |\n",
      "|    time_elapsed         | 11968       |\n",
      "|    total_timesteps      | 1341440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019473694 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.0182      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.7        |\n",
      "|    n_updates            | 6540        |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    reward               | -2.3421352  |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 656         |\n",
      "|    time_elapsed         | 11986       |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017137596 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 6550        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    reward               | 0.046391305 |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 657         |\n",
      "|    time_elapsed         | 12005       |\n",
      "|    total_timesteps      | 1345536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01783368  |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.0956      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61          |\n",
      "|    n_updates            | 6560        |\n",
      "|    policy_gradient_loss | -0.000759   |\n",
      "|    reward               | -0.06186256 |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 207         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 658         |\n",
      "|    time_elapsed         | 12023       |\n",
      "|    total_timesteps      | 1347584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015929323 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.0468      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.3        |\n",
      "|    n_updates            | 6570        |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    reward               | 4.6242714   |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 12041       |\n",
      "|    total_timesteps      | 1349632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013689337 |\n",
      "|    clip_fraction        | 0.0882      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.00116     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.65        |\n",
      "|    n_updates            | 6580        |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    reward               | -2.239685   |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 660         |\n",
      "|    time_elapsed         | 12060       |\n",
      "|    total_timesteps      | 1351680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017600294 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.0649      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 6590        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    reward               | -1.3705804  |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 76.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 661         |\n",
      "|    time_elapsed         | 12078       |\n",
      "|    total_timesteps      | 1353728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016764995 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 6600        |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    reward               | -6.5004478  |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 662         |\n",
      "|    time_elapsed         | 12096       |\n",
      "|    total_timesteps      | 1355776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01780273  |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.0642      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31          |\n",
      "|    n_updates            | 6610        |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    reward               | 0.065795235 |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 82.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6867782.45\n",
      "total_reward: 5867782.45\n",
      "total_cost: 303172.30\n",
      "total_trades: 67905\n",
      "Sharpe: 0.998\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 663          |\n",
      "|    time_elapsed         | 12114        |\n",
      "|    total_timesteps      | 1357824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014999199  |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.2        |\n",
      "|    explained_variance   | 0.0799       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93.6         |\n",
      "|    n_updates            | 6620         |\n",
      "|    policy_gradient_loss | -0.00832     |\n",
      "|    reward               | -0.099463746 |\n",
      "|    std                  | 2.56         |\n",
      "|    value_loss           | 153          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 664         |\n",
      "|    time_elapsed         | 12133       |\n",
      "|    total_timesteps      | 1359872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013498095 |\n",
      "|    clip_fraction        | 0.0849      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.2       |\n",
      "|    explained_variance   | 0.0439      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.8        |\n",
      "|    n_updates            | 6630        |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    reward               | 0.50784034  |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 665         |\n",
      "|    time_elapsed         | 12151       |\n",
      "|    total_timesteps      | 1361920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015065111 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.2       |\n",
      "|    explained_variance   | 0.0584      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.8        |\n",
      "|    n_updates            | 6640        |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    reward               | 0.006698384 |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 225         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 12169       |\n",
      "|    total_timesteps      | 1363968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020231452 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.2       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.48        |\n",
      "|    n_updates            | 6650        |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    reward               | 1.4809687   |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 667         |\n",
      "|    time_elapsed         | 12188       |\n",
      "|    total_timesteps      | 1366016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015584131 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | 0.0923      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.2        |\n",
      "|    n_updates            | 6660        |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    reward               | -0.19123995 |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 668        |\n",
      "|    time_elapsed         | 12206      |\n",
      "|    total_timesteps      | 1368064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01484355 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.3      |\n",
      "|    explained_variance   | 0.184      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 189        |\n",
      "|    n_updates            | 6670       |\n",
      "|    policy_gradient_loss | -0.00491   |\n",
      "|    reward               | -0.3941561 |\n",
      "|    std                  | 2.57       |\n",
      "|    value_loss           | 150        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 669         |\n",
      "|    time_elapsed         | 12224       |\n",
      "|    total_timesteps      | 1370112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017395902 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 6680        |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    reward               | 1.3927196   |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 670         |\n",
      "|    time_elapsed         | 12242       |\n",
      "|    total_timesteps      | 1372160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021539744 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 6690        |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    reward               | 0.76322234  |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 99.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 671         |\n",
      "|    time_elapsed         | 12261       |\n",
      "|    total_timesteps      | 1374208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020349491 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 159         |\n",
      "|    n_updates            | 6700        |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    reward               | -0.25954095 |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 258         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 672         |\n",
      "|    time_elapsed         | 12280       |\n",
      "|    total_timesteps      | 1376256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011049578 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 86.1        |\n",
      "|    n_updates            | 6710        |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    reward               | 0.8271587   |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 12298       |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020703426 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 6720        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | 0.7402468   |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 674        |\n",
      "|    time_elapsed         | 12316      |\n",
      "|    total_timesteps      | 1380352    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01149834 |\n",
      "|    clip_fraction        | 0.068      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.5      |\n",
      "|    explained_variance   | 0.301      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 81.1       |\n",
      "|    n_updates            | 6730       |\n",
      "|    policy_gradient_loss | -0.00814   |\n",
      "|    reward               | 0.4530674  |\n",
      "|    std                  | 2.59       |\n",
      "|    value_loss           | 164        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 675         |\n",
      "|    time_elapsed         | 12334       |\n",
      "|    total_timesteps      | 1382400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012261503 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 186         |\n",
      "|    n_updates            | 6740        |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    reward               | 6.8451033   |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 255         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 676         |\n",
      "|    time_elapsed         | 12353       |\n",
      "|    total_timesteps      | 1384448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023315886 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 6750        |\n",
      "|    policy_gradient_loss | 0.00159     |\n",
      "|    reward               | -4.2563314  |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9003628.68\n",
      "total_reward: 8003628.68\n",
      "total_cost: 288355.24\n",
      "total_trades: 67035\n",
      "Sharpe: 1.083\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 677         |\n",
      "|    time_elapsed         | 12371       |\n",
      "|    total_timesteps      | 1386496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012054946 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.6        |\n",
      "|    n_updates            | 6760        |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    reward               | -0.61415523 |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 678         |\n",
      "|    time_elapsed         | 12389       |\n",
      "|    total_timesteps      | 1388544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009628184 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.7       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 6770        |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    reward               | -2.814923   |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 242         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 679         |\n",
      "|    time_elapsed         | 12407       |\n",
      "|    total_timesteps      | 1390592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028554957 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.7       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.8        |\n",
      "|    n_updates            | 6780        |\n",
      "|    policy_gradient_loss | -0.000866   |\n",
      "|    reward               | -0.81776774 |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 93.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 680          |\n",
      "|    time_elapsed         | 12425        |\n",
      "|    total_timesteps      | 1392640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0147600435 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.8        |\n",
      "|    explained_variance   | 0.221        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 146          |\n",
      "|    n_updates            | 6790         |\n",
      "|    policy_gradient_loss | -0.00842     |\n",
      "|    reward               | -0.7004046   |\n",
      "|    std                  | 2.62         |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 681         |\n",
      "|    time_elapsed         | 12444       |\n",
      "|    total_timesteps      | 1394688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024729561 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 6800        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 1.4099752   |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 682          |\n",
      "|    time_elapsed         | 12462        |\n",
      "|    total_timesteps      | 1396736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0156177115 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.8        |\n",
      "|    explained_variance   | 0.205        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.1         |\n",
      "|    n_updates            | 6810         |\n",
      "|    policy_gradient_loss | -0.00648     |\n",
      "|    reward               | 2.298221     |\n",
      "|    std                  | 2.62         |\n",
      "|    value_loss           | 194          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 683         |\n",
      "|    time_elapsed         | 12480       |\n",
      "|    total_timesteps      | 1398784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022978254 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 6820        |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    reward               | 3.3020651   |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 684         |\n",
      "|    time_elapsed         | 12498       |\n",
      "|    total_timesteps      | 1400832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013730014 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 6830        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 0.12349735  |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 685         |\n",
      "|    time_elapsed         | 12516       |\n",
      "|    total_timesteps      | 1402880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018279303 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.2        |\n",
      "|    n_updates            | 6840        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 0.50685364  |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 686         |\n",
      "|    time_elapsed         | 12534       |\n",
      "|    total_timesteps      | 1404928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025580628 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.0816      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 6850        |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    reward               | 2.2916253   |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 687         |\n",
      "|    time_elapsed         | 12552       |\n",
      "|    total_timesteps      | 1406976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016555175 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.1       |\n",
      "|    explained_variance   | 0.0531      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.7        |\n",
      "|    n_updates            | 6860        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | 0.9880565   |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 85.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 688         |\n",
      "|    time_elapsed         | 12571       |\n",
      "|    total_timesteps      | 1409024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017055422 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.2       |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.1        |\n",
      "|    n_updates            | 6870        |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    reward               | 1.9522816   |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 689         |\n",
      "|    time_elapsed         | 12590       |\n",
      "|    total_timesteps      | 1411072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014523032 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.2       |\n",
      "|    explained_variance   | 0.0209      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 6880        |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    reward               | 0.80311483  |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 690         |\n",
      "|    time_elapsed         | 12608       |\n",
      "|    total_timesteps      | 1413120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021125847 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 6890        |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    reward               | -1.2611942  |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5358264.56\n",
      "total_reward: 4358264.56\n",
      "total_cost: 348095.65\n",
      "total_trades: 70270\n",
      "Sharpe: 0.848\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 691         |\n",
      "|    time_elapsed         | 12627       |\n",
      "|    total_timesteps      | 1415168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015114891 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.4       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.9        |\n",
      "|    n_updates            | 6900        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 0.48545927  |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 692         |\n",
      "|    time_elapsed         | 12646       |\n",
      "|    total_timesteps      | 1417216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022987276 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.7        |\n",
      "|    n_updates            | 6910        |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    reward               | 1.8680915   |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 12664       |\n",
      "|    total_timesteps      | 1419264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013330054 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 6920        |\n",
      "|    policy_gradient_loss | -0.00992    |\n",
      "|    reward               | 2.272812    |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 694         |\n",
      "|    time_elapsed         | 12683       |\n",
      "|    total_timesteps      | 1421312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012494905 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | -0.0169     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.6        |\n",
      "|    n_updates            | 6930        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | -1.1297868  |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 695         |\n",
      "|    time_elapsed         | 12701       |\n",
      "|    total_timesteps      | 1423360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017119622 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.6        |\n",
      "|    n_updates            | 6940        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | 0.014257127 |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 98.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 696         |\n",
      "|    time_elapsed         | 12719       |\n",
      "|    total_timesteps      | 1425408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018274697 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.7        |\n",
      "|    n_updates            | 6950        |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    reward               | -1.3266878  |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 697         |\n",
      "|    time_elapsed         | 12738       |\n",
      "|    total_timesteps      | 1427456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028257068 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.0128      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.23        |\n",
      "|    n_updates            | 6960        |\n",
      "|    policy_gradient_loss | -0.00768    |\n",
      "|    reward               | 0.7766497   |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 12756       |\n",
      "|    total_timesteps      | 1429504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013416668 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.8        |\n",
      "|    n_updates            | 6970        |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    reward               | 0.5096924   |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 699         |\n",
      "|    time_elapsed         | 12774       |\n",
      "|    total_timesteps      | 1431552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012255192 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.2        |\n",
      "|    n_updates            | 6980        |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    reward               | -1.613804   |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 700         |\n",
      "|    time_elapsed         | 12792       |\n",
      "|    total_timesteps      | 1433600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019853942 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.0531      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 6990        |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    reward               | -2.0066407  |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 701          |\n",
      "|    time_elapsed         | 12810        |\n",
      "|    total_timesteps      | 1435648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0139318835 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.9        |\n",
      "|    explained_variance   | 0.0226       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32           |\n",
      "|    n_updates            | 7000         |\n",
      "|    policy_gradient_loss | -0.00856     |\n",
      "|    reward               | -6.3098483   |\n",
      "|    std                  | 2.72         |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 702         |\n",
      "|    time_elapsed         | 12829       |\n",
      "|    total_timesteps      | 1437696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015357887 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.9        |\n",
      "|    n_updates            | 7010        |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    reward               | 5.00736     |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 703         |\n",
      "|    time_elapsed         | 12847       |\n",
      "|    total_timesteps      | 1439744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019197859 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 7020        |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    reward               | 0.86554533  |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 60.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 704         |\n",
      "|    time_elapsed         | 12865       |\n",
      "|    total_timesteps      | 1441792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017984137 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 7030        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -1.610492   |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 92.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3458271.80\n",
      "total_reward: 2458271.80\n",
      "total_cost: 320339.81\n",
      "total_trades: 69312\n",
      "Sharpe: 0.651\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 705         |\n",
      "|    time_elapsed         | 12884       |\n",
      "|    total_timesteps      | 1443840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010956315 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.6        |\n",
      "|    n_updates            | 7040        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 0.4530093   |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 91          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 706         |\n",
      "|    time_elapsed         | 12902       |\n",
      "|    total_timesteps      | 1445888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024166944 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 7050        |\n",
      "|    policy_gradient_loss | -0.000952   |\n",
      "|    reward               | 1.4801538   |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 76.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 707         |\n",
      "|    time_elapsed         | 12920       |\n",
      "|    total_timesteps      | 1447936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025265634 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | -0.0813     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 7060        |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    reward               | 0.4221892   |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 708         |\n",
      "|    time_elapsed         | 12939       |\n",
      "|    total_timesteps      | 1449984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024646152 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 7070        |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | 0.64318305  |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 63.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 709         |\n",
      "|    time_elapsed         | 12957       |\n",
      "|    total_timesteps      | 1452032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019279368 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.2       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 7080        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.24248365 |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 57.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 12975       |\n",
      "|    total_timesteps      | 1454080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019967856 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.2       |\n",
      "|    explained_variance   | -0.107      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 7090        |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    reward               | 0.328784    |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 711         |\n",
      "|    time_elapsed         | 12993       |\n",
      "|    total_timesteps      | 1456128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024534166 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 7100        |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    reward               | -0.10711321 |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 42.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 712         |\n",
      "|    time_elapsed         | 13012       |\n",
      "|    total_timesteps      | 1458176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01777308  |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.2        |\n",
      "|    n_updates            | 7110        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -0.33497837 |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 79.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 713          |\n",
      "|    time_elapsed         | 13030        |\n",
      "|    total_timesteps      | 1460224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.02423661   |\n",
      "|    clip_fraction        | 0.218        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.5        |\n",
      "|    explained_variance   | 0.42         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.7         |\n",
      "|    n_updates            | 7120         |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    reward               | -0.019864406 |\n",
      "|    std                  | 2.78         |\n",
      "|    value_loss           | 64           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 13048       |\n",
      "|    total_timesteps      | 1462272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013791618 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.79        |\n",
      "|    n_updates            | 7130        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.8173294  |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 715         |\n",
      "|    time_elapsed         | 13066       |\n",
      "|    total_timesteps      | 1464320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010314616 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 7140        |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    reward               | 1.5591073   |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 75.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 716        |\n",
      "|    time_elapsed         | 13084      |\n",
      "|    total_timesteps      | 1466368    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01881222 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.6      |\n",
      "|    explained_variance   | 0.385      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24         |\n",
      "|    n_updates            | 7150       |\n",
      "|    policy_gradient_loss | -0.00971   |\n",
      "|    reward               | -8.680523  |\n",
      "|    std                  | 2.79       |\n",
      "|    value_loss           | 68.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 717         |\n",
      "|    time_elapsed         | 13103       |\n",
      "|    total_timesteps      | 1468416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012415693 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.6       |\n",
      "|    explained_variance   | 0.0297      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 7160        |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    reward               | 0.5476797   |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 718         |\n",
      "|    time_elapsed         | 13122       |\n",
      "|    total_timesteps      | 1470464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010475666 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.6       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 7170        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -2.0545392  |\n",
      "|    std                  | 2.8         |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 719          |\n",
      "|    time_elapsed         | 13140        |\n",
      "|    total_timesteps      | 1472512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126384925 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.7        |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 7180         |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | 16.393412    |\n",
      "|    std                  | 2.81         |\n",
      "|    value_loss           | 69.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3022532.32\n",
      "total_reward: 2022532.32\n",
      "total_cost: 270344.62\n",
      "total_trades: 65621\n",
      "Sharpe: 0.563\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 720         |\n",
      "|    time_elapsed         | 13158       |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015154821 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 7190        |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    reward               | -0.07876038 |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 73.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 721         |\n",
      "|    time_elapsed         | 13177       |\n",
      "|    total_timesteps      | 1476608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013039906 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.12        |\n",
      "|    n_updates            | 7200        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 1.0993135   |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 722         |\n",
      "|    time_elapsed         | 13195       |\n",
      "|    total_timesteps      | 1478656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014516445 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 7210        |\n",
      "|    policy_gradient_loss | -0.00937    |\n",
      "|    reward               | -3.66419    |\n",
      "|    std                  | 2.82        |\n",
      "|    value_loss           | 72.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 723         |\n",
      "|    time_elapsed         | 13214       |\n",
      "|    total_timesteps      | 1480704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017218841 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.4        |\n",
      "|    n_updates            | 7220        |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    reward               | -1.8525672  |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 69.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 724         |\n",
      "|    time_elapsed         | 13232       |\n",
      "|    total_timesteps      | 1482752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016302178 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | -0.0409     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 7230        |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    reward               | 2.1069553   |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 725         |\n",
      "|    time_elapsed         | 13250       |\n",
      "|    total_timesteps      | 1484800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015051133 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 7240        |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    reward               | 0.32903787  |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 65.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 726        |\n",
      "|    time_elapsed         | 13268      |\n",
      "|    total_timesteps      | 1486848    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02159487 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71        |\n",
      "|    explained_variance   | 0.517      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.6       |\n",
      "|    n_updates            | 7250       |\n",
      "|    policy_gradient_loss | -0.00738   |\n",
      "|    reward               | 0.915761   |\n",
      "|    std                  | 2.83       |\n",
      "|    value_loss           | 81         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 727        |\n",
      "|    time_elapsed         | 13286      |\n",
      "|    total_timesteps      | 1488896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01250473 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71        |\n",
      "|    explained_variance   | 0.0996     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.3       |\n",
      "|    n_updates            | 7260       |\n",
      "|    policy_gradient_loss | -0.00605   |\n",
      "|    reward               | 0.5726754  |\n",
      "|    std                  | 2.83       |\n",
      "|    value_loss           | 42.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 728         |\n",
      "|    time_elapsed         | 13304       |\n",
      "|    total_timesteps      | 1490944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010366884 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 7270        |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    reward               | 0.46447587  |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 72.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 729        |\n",
      "|    time_elapsed         | 13322      |\n",
      "|    total_timesteps      | 1492992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00444294 |\n",
      "|    clip_fraction        | 0.0225     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.1      |\n",
      "|    explained_variance   | 0.635      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 39.5       |\n",
      "|    n_updates            | 7280       |\n",
      "|    policy_gradient_loss | -0.00411   |\n",
      "|    reward               | -1.7409394 |\n",
      "|    std                  | 2.84       |\n",
      "|    value_loss           | 70.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 730         |\n",
      "|    time_elapsed         | 13340       |\n",
      "|    total_timesteps      | 1495040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009893944 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63          |\n",
      "|    n_updates            | 7290        |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    reward               | 1.6410266   |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 84.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 731         |\n",
      "|    time_elapsed         | 13358       |\n",
      "|    total_timesteps      | 1497088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019282937 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | -0.131      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 7300        |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    reward               | -0.12878478 |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 732        |\n",
      "|    time_elapsed         | 13377      |\n",
      "|    total_timesteps      | 1499136    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00928467 |\n",
      "|    clip_fraction        | 0.0871     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.2      |\n",
      "|    explained_variance   | 0.354      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 63.8       |\n",
      "|    n_updates            | 7310       |\n",
      "|    policy_gradient_loss | -0.00633   |\n",
      "|    reward               | 0.08496167 |\n",
      "|    std                  | 2.85       |\n",
      "|    value_loss           | 102        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 733          |\n",
      "|    time_elapsed         | 13395        |\n",
      "|    total_timesteps      | 1501184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0132734915 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.2        |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.4         |\n",
      "|    n_updates            | 7320         |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    reward               | -1.645839    |\n",
      "|    std                  | 2.86         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2951650.13\n",
      "total_reward: 1951650.13\n",
      "total_cost: 211043.84\n",
      "total_trades: 62102\n",
      "Sharpe: 0.514\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 734         |\n",
      "|    time_elapsed         | 13413       |\n",
      "|    total_timesteps      | 1503232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013500194 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.3       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 7330        |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    reward               | -1.9952525  |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 50.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 735         |\n",
      "|    time_elapsed         | 13431       |\n",
      "|    total_timesteps      | 1505280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015868114 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 7340        |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    reward               | -0.6067002  |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 69.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 736          |\n",
      "|    time_elapsed         | 13449        |\n",
      "|    total_timesteps      | 1507328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013843609  |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.5        |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.9         |\n",
      "|    n_updates            | 7350         |\n",
      "|    policy_gradient_loss | -0.00679     |\n",
      "|    reward               | -0.054825507 |\n",
      "|    std                  | 2.88         |\n",
      "|    value_loss           | 86.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 737         |\n",
      "|    time_elapsed         | 13467       |\n",
      "|    total_timesteps      | 1509376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009541219 |\n",
      "|    clip_fraction        | 0.0511      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.5       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.3        |\n",
      "|    n_updates            | 7360        |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    reward               | 1.3143172   |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 99.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 738         |\n",
      "|    time_elapsed         | 13486       |\n",
      "|    total_timesteps      | 1511424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017851274 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.6       |\n",
      "|    explained_variance   | -0.0235     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 7370        |\n",
      "|    policy_gradient_loss | -0.00937    |\n",
      "|    reward               | -1.8183017  |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 739         |\n",
      "|    time_elapsed         | 13504       |\n",
      "|    total_timesteps      | 1513472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008600362 |\n",
      "|    clip_fraction        | 0.0751      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.6       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.8        |\n",
      "|    n_updates            | 7380        |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    reward               | -0.06325792 |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 86.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 740          |\n",
      "|    time_elapsed         | 13522        |\n",
      "|    total_timesteps      | 1515520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074590556 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.6        |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.5         |\n",
      "|    n_updates            | 7390         |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    reward               | 3.8379283    |\n",
      "|    std                  | 2.9          |\n",
      "|    value_loss           | 92.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 741         |\n",
      "|    time_elapsed         | 13540       |\n",
      "|    total_timesteps      | 1517568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014962925 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.0433      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 7400        |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    reward               | -1.5710394  |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 742          |\n",
      "|    time_elapsed         | 13558        |\n",
      "|    total_timesteps      | 1519616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014176615  |\n",
      "|    clip_fraction        | 0.0934       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.7        |\n",
      "|    explained_variance   | 0.096        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 7410         |\n",
      "|    policy_gradient_loss | -0.00887     |\n",
      "|    reward               | -0.060561236 |\n",
      "|    std                  | 2.9          |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 743         |\n",
      "|    time_elapsed         | 13577       |\n",
      "|    total_timesteps      | 1521664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008404518 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.1        |\n",
      "|    n_updates            | 7420        |\n",
      "|    policy_gradient_loss | -0.0005     |\n",
      "|    reward               | -12.798916  |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 744         |\n",
      "|    time_elapsed         | 13595       |\n",
      "|    total_timesteps      | 1523712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013304715 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 7430        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -1.8194804  |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 89.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 745         |\n",
      "|    time_elapsed         | 13613       |\n",
      "|    total_timesteps      | 1525760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018043056 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.8       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 7440        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -0.22101225 |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 746         |\n",
      "|    time_elapsed         | 13631       |\n",
      "|    total_timesteps      | 1527808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013049565 |\n",
      "|    clip_fraction        | 0.0931      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.8       |\n",
      "|    explained_variance   | 0.0729      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 7450        |\n",
      "|    policy_gradient_loss | -0.00873    |\n",
      "|    reward               | -0.5442695  |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 747         |\n",
      "|    time_elapsed         | 13649       |\n",
      "|    total_timesteps      | 1529856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018674787 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.9       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.2        |\n",
      "|    n_updates            | 7460        |\n",
      "|    policy_gradient_loss | -0.00873    |\n",
      "|    reward               | 3.2868063   |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3150776.67\n",
      "total_reward: 2150776.67\n",
      "total_cost: 219596.52\n",
      "total_trades: 63261\n",
      "Sharpe: 0.526\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 748         |\n",
      "|    time_elapsed         | 13667       |\n",
      "|    total_timesteps      | 1531904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009708744 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 7470        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.06283268 |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 749         |\n",
      "|    time_elapsed         | 13686       |\n",
      "|    total_timesteps      | 1533952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007999188 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 7480        |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    reward               | -4.515778   |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 94.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 750          |\n",
      "|    time_elapsed         | 13704        |\n",
      "|    total_timesteps      | 1536000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057265945 |\n",
      "|    clip_fraction        | 0.0351       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72          |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.4         |\n",
      "|    n_updates            | 7490         |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    reward               | 4.1332283    |\n",
      "|    std                  | 2.93         |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 751         |\n",
      "|    time_elapsed         | 13722       |\n",
      "|    total_timesteps      | 1538048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010905148 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.0171      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.6        |\n",
      "|    n_updates            | 7500        |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    reward               | 0.3630011   |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 61.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 752         |\n",
      "|    time_elapsed         | 13740       |\n",
      "|    total_timesteps      | 1540096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010209238 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 7510        |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    reward               | -1.0766516  |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 76.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 753         |\n",
      "|    time_elapsed         | 13758       |\n",
      "|    total_timesteps      | 1542144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010899917 |\n",
      "|    clip_fraction        | 0.0712      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.8        |\n",
      "|    n_updates            | 7520        |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | 0.3105278   |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 97.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 754         |\n",
      "|    time_elapsed         | 13776       |\n",
      "|    total_timesteps      | 1544192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009450036 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.5        |\n",
      "|    n_updates            | 7530        |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    reward               | 1.1386768   |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 755         |\n",
      "|    time_elapsed         | 13794       |\n",
      "|    total_timesteps      | 1546240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017397419 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.0123      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 7540        |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    reward               | 0.8288772   |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 35.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 756         |\n",
      "|    time_elapsed         | 13812       |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011864712 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 7550        |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    reward               | -0.61113375 |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 79.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 757         |\n",
      "|    time_elapsed         | 13830       |\n",
      "|    total_timesteps      | 1550336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015626786 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.8        |\n",
      "|    n_updates            | 7560        |\n",
      "|    policy_gradient_loss | -0.00912    |\n",
      "|    reward               | 2.475365    |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 758         |\n",
      "|    time_elapsed         | 13849       |\n",
      "|    total_timesteps      | 1552384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008549821 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 7570        |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    reward               | -1.6441907  |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 759         |\n",
      "|    time_elapsed         | 13867       |\n",
      "|    total_timesteps      | 1554432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008956173 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.9        |\n",
      "|    n_updates            | 7580        |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    reward               | 0.4292696   |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 70.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 760          |\n",
      "|    time_elapsed         | 13885        |\n",
      "|    total_timesteps      | 1556480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046649226 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.3        |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.8         |\n",
      "|    n_updates            | 7590         |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    reward               | 0.6200235    |\n",
      "|    std                  | 2.96         |\n",
      "|    value_loss           | 89.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 761          |\n",
      "|    time_elapsed         | 13903        |\n",
      "|    total_timesteps      | 1558528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020629843 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.3        |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 89           |\n",
      "|    n_updates            | 7600         |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    reward               | -3.460415    |\n",
      "|    std                  | 2.96         |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3253252.46\n",
      "total_reward: 2253252.46\n",
      "total_cost: 190586.26\n",
      "total_trades: 60684\n",
      "Sharpe: 0.535\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 112       |\n",
      "|    iterations           | 762       |\n",
      "|    time_elapsed         | 13922     |\n",
      "|    total_timesteps      | 1560576   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0178869 |\n",
      "|    clip_fraction        | 0.228     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -72.3     |\n",
      "|    explained_variance   | 0.00966   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 18.4      |\n",
      "|    n_updates            | 7610      |\n",
      "|    policy_gradient_loss | -0.0122   |\n",
      "|    reward               | 5.471556  |\n",
      "|    std                  | 2.96      |\n",
      "|    value_loss           | 43.7      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 763         |\n",
      "|    time_elapsed         | 13940       |\n",
      "|    total_timesteps      | 1562624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010521637 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 7620        |\n",
      "|    policy_gradient_loss | -0.000417   |\n",
      "|    reward               | -3.4535098  |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 96.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 764         |\n",
      "|    time_elapsed         | 13958       |\n",
      "|    total_timesteps      | 1564672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002562685 |\n",
      "|    clip_fraction        | 0.00723     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 7630        |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    reward               | -4.464369   |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 765          |\n",
      "|    time_elapsed         | 13976        |\n",
      "|    total_timesteps      | 1566720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116696805 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.4        |\n",
      "|    explained_variance   | 0.144        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 7640         |\n",
      "|    policy_gradient_loss | -0.00878     |\n",
      "|    reward               | 1.1763898    |\n",
      "|    std                  | 2.97         |\n",
      "|    value_loss           | 41           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 766         |\n",
      "|    time_elapsed         | 13994       |\n",
      "|    total_timesteps      | 1568768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006823174 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.1        |\n",
      "|    n_updates            | 7650        |\n",
      "|    policy_gradient_loss | -0.00345    |\n",
      "|    reward               | 0.6421477   |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 91.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 767         |\n",
      "|    time_elapsed         | 14012       |\n",
      "|    total_timesteps      | 1570816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004766189 |\n",
      "|    clip_fraction        | 0.00933     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.5        |\n",
      "|    n_updates            | 7660        |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    reward               | 28.556015   |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 768         |\n",
      "|    time_elapsed         | 14030       |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006960569 |\n",
      "|    clip_fraction        | 0.0669      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.5        |\n",
      "|    n_updates            | 7670        |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    reward               | 1.5376008   |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 80.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 769         |\n",
      "|    time_elapsed         | 14048       |\n",
      "|    total_timesteps      | 1574912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008285185 |\n",
      "|    clip_fraction        | 0.0452      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.0523      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.3        |\n",
      "|    n_updates            | 7680        |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    reward               | 0.7988942   |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 77.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 770         |\n",
      "|    time_elapsed         | 14067       |\n",
      "|    total_timesteps      | 1576960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007605492 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.2        |\n",
      "|    n_updates            | 7690        |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    reward               | 1.1921067   |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 84.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 771         |\n",
      "|    time_elapsed         | 14086       |\n",
      "|    total_timesteps      | 1579008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002866704 |\n",
      "|    clip_fraction        | 0.00303     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.8        |\n",
      "|    n_updates            | 7700        |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    reward               | -4.1367717  |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 772         |\n",
      "|    time_elapsed         | 14104       |\n",
      "|    total_timesteps      | 1581056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010934664 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.0933      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 7710        |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    reward               | -1.2575563  |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 773          |\n",
      "|    time_elapsed         | 14123        |\n",
      "|    total_timesteps      | 1583104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062713916 |\n",
      "|    clip_fraction        | 0.0412       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.5        |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60           |\n",
      "|    n_updates            | 7720         |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    reward               | -1.0183675   |\n",
      "|    std                  | 2.99         |\n",
      "|    value_loss           | 123          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 774          |\n",
      "|    time_elapsed         | 14141        |\n",
      "|    total_timesteps      | 1585152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038809841 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.5        |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.1         |\n",
      "|    n_updates            | 7730         |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    reward               | 4.4569645    |\n",
      "|    std                  | 2.99         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 775          |\n",
      "|    time_elapsed         | 14159        |\n",
      "|    total_timesteps      | 1587200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070069972 |\n",
      "|    clip_fraction        | 0.0615       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.6        |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 7740         |\n",
      "|    policy_gradient_loss | -0.00742     |\n",
      "|    reward               | 4.1726737    |\n",
      "|    std                  | 2.99         |\n",
      "|    value_loss           | 71.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3021557.78\n",
      "total_reward: 2021557.78\n",
      "total_cost: 136690.07\n",
      "total_trades: 56119\n",
      "Sharpe: 0.500\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 776         |\n",
      "|    time_elapsed         | 14177       |\n",
      "|    total_timesteps      | 1589248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018866587 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.6       |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 7750        |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    reward               | 0.4082505   |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 78.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 777          |\n",
      "|    time_elapsed         | 14194        |\n",
      "|    total_timesteps      | 1591296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058466187 |\n",
      "|    clip_fraction        | 0.023        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.6        |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.3         |\n",
      "|    n_updates            | 7760         |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    reward               | 0.7205624    |\n",
      "|    std                  | 3            |\n",
      "|    value_loss           | 96           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 778         |\n",
      "|    time_elapsed         | 14212       |\n",
      "|    total_timesteps      | 1593344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012516699 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.6       |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.4        |\n",
      "|    n_updates            | 7770        |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | -1.8711017  |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 779         |\n",
      "|    time_elapsed         | 14231       |\n",
      "|    total_timesteps      | 1595392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029257763 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 7780        |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    reward               | -1.6494195  |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 780         |\n",
      "|    time_elapsed         | 14249       |\n",
      "|    total_timesteps      | 1597440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010481928 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 7790        |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    reward               | 1.5848936   |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 87.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 781         |\n",
      "|    time_elapsed         | 14267       |\n",
      "|    total_timesteps      | 1599488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003909173 |\n",
      "|    clip_fraction        | 0.0212      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.8        |\n",
      "|    n_updates            | 7800        |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    reward               | -1.4598932  |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 782        |\n",
      "|    time_elapsed         | 14285      |\n",
      "|    total_timesteps      | 1601536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0157918  |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.8      |\n",
      "|    explained_variance   | 0.369      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.3       |\n",
      "|    n_updates            | 7810       |\n",
      "|    policy_gradient_loss | -0.00241   |\n",
      "|    reward               | -1.1502758 |\n",
      "|    std                  | 3.02       |\n",
      "|    value_loss           | 48.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 783         |\n",
      "|    time_elapsed         | 14303       |\n",
      "|    total_timesteps      | 1603584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010530277 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.9        |\n",
      "|    n_updates            | 7820        |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    reward               | 1.119403    |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 76.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 784          |\n",
      "|    time_elapsed         | 14321        |\n",
      "|    total_timesteps      | 1605632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049655917 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.9        |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 7830         |\n",
      "|    policy_gradient_loss | -0.007       |\n",
      "|    reward               | 0.87876594   |\n",
      "|    std                  | 3.02         |\n",
      "|    value_loss           | 74.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 785         |\n",
      "|    time_elapsed         | 14339       |\n",
      "|    total_timesteps      | 1607680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007229752 |\n",
      "|    clip_fraction        | 0.0186      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65          |\n",
      "|    n_updates            | 7840        |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    reward               | -1.44299    |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 94.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 786         |\n",
      "|    time_elapsed         | 14357       |\n",
      "|    total_timesteps      | 1609728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018869981 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 7850        |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | 0.838996    |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 787         |\n",
      "|    time_elapsed         | 14375       |\n",
      "|    total_timesteps      | 1611776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013937948 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32          |\n",
      "|    n_updates            | 7860        |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    reward               | -1.5243777  |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 64.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 788         |\n",
      "|    time_elapsed         | 14393       |\n",
      "|    total_timesteps      | 1613824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010879947 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 7870        |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    reward               | 0.901975    |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 76.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 789         |\n",
      "|    time_elapsed         | 14411       |\n",
      "|    total_timesteps      | 1615872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02160386  |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.0774      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 7880        |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    reward               | -0.82360905 |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2678229.82\n",
      "total_reward: 1678229.82\n",
      "total_cost: 222045.83\n",
      "total_trades: 62413\n",
      "Sharpe: 0.469\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 790         |\n",
      "|    time_elapsed         | 14430       |\n",
      "|    total_timesteps      | 1617920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012079533 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 7890        |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    reward               | -0.5322855  |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 72.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 791         |\n",
      "|    time_elapsed         | 14448       |\n",
      "|    total_timesteps      | 1619968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006931857 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 7900        |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    reward               | 2.4290345   |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 60          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 792         |\n",
      "|    time_elapsed         | 14466       |\n",
      "|    total_timesteps      | 1622016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007942351 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 7910        |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | 2.145385    |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 42.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 793         |\n",
      "|    time_elapsed         | 14484       |\n",
      "|    total_timesteps      | 1624064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022553936 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 7920        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -0.50416183 |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 794         |\n",
      "|    time_elapsed         | 14502       |\n",
      "|    total_timesteps      | 1626112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014140073 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.1       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 7930        |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    reward               | -0.297109   |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 795         |\n",
      "|    time_elapsed         | 14520       |\n",
      "|    total_timesteps      | 1628160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010722121 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.1       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 7940        |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    reward               | -0.4012671  |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 80.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 796         |\n",
      "|    time_elapsed         | 14538       |\n",
      "|    total_timesteps      | 1630208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021608002 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.1       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 7950        |\n",
      "|    policy_gradient_loss | -0.00366    |\n",
      "|    reward               | -0.39968786 |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 797         |\n",
      "|    time_elapsed         | 14556       |\n",
      "|    total_timesteps      | 1632256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017102297 |\n",
      "|    clip_fraction        | 0.0832      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.2       |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 7960        |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    reward               | 0.5632295   |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 66.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 798         |\n",
      "|    time_elapsed         | 14574       |\n",
      "|    total_timesteps      | 1634304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010759496 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.2       |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.3        |\n",
      "|    n_updates            | 7970        |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    reward               | 4.206252    |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 90.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 799        |\n",
      "|    time_elapsed         | 14593      |\n",
      "|    total_timesteps      | 1636352    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01682945 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.3      |\n",
      "|    explained_variance   | 0.303      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 33.3       |\n",
      "|    n_updates            | 7980       |\n",
      "|    policy_gradient_loss | -0.00574   |\n",
      "|    reward               | -1.0690958 |\n",
      "|    std                  | 3.07       |\n",
      "|    value_loss           | 62         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 800         |\n",
      "|    time_elapsed         | 14611       |\n",
      "|    total_timesteps      | 1638400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015094169 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.3       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 7990        |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    reward               | 0.46871743  |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 67.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 801         |\n",
      "|    time_elapsed         | 14629       |\n",
      "|    total_timesteps      | 1640448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009206981 |\n",
      "|    clip_fraction        | 0.0747      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 8000        |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | -2.797888   |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 80.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 802         |\n",
      "|    time_elapsed         | 14647       |\n",
      "|    total_timesteps      | 1642496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006890959 |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38          |\n",
      "|    n_updates            | 8010        |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    reward               | -0.63127434 |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 803         |\n",
      "|    time_elapsed         | 14665       |\n",
      "|    total_timesteps      | 1644544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016248338 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.0152      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 8020        |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    reward               | -2.49219    |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 31.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2740629.49\n",
      "total_reward: 1740629.49\n",
      "total_cost: 135981.54\n",
      "total_trades: 54973\n",
      "Sharpe: 0.461\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 804          |\n",
      "|    time_elapsed         | 14683        |\n",
      "|    total_timesteps      | 1646592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062276926 |\n",
      "|    clip_fraction        | 0.0374       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.4        |\n",
      "|    explained_variance   | 0.707        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.2         |\n",
      "|    n_updates            | 8030         |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    reward               | 0.5971626    |\n",
      "|    std                  | 3.08         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 805         |\n",
      "|    time_elapsed         | 14701       |\n",
      "|    total_timesteps      | 1648640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010084853 |\n",
      "|    clip_fraction        | 0.0752      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.9        |\n",
      "|    n_updates            | 8040        |\n",
      "|    policy_gradient_loss | -0.00215    |\n",
      "|    reward               | 0.7740459   |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 90.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 806         |\n",
      "|    time_elapsed         | 14719       |\n",
      "|    total_timesteps      | 1650688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015575543 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 8050        |\n",
      "|    policy_gradient_loss | -0.00256    |\n",
      "|    reward               | 2.1217804   |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 807         |\n",
      "|    time_elapsed         | 14738       |\n",
      "|    total_timesteps      | 1652736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009754101 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.5       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 8060        |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | 0.9648369   |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 69.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 808        |\n",
      "|    time_elapsed         | 14756      |\n",
      "|    total_timesteps      | 1654784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00772827 |\n",
      "|    clip_fraction        | 0.0517     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.5      |\n",
      "|    explained_variance   | 0.712      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.6       |\n",
      "|    n_updates            | 8070       |\n",
      "|    policy_gradient_loss | -0.00463   |\n",
      "|    reward               | 5.036237   |\n",
      "|    std                  | 3.09       |\n",
      "|    value_loss           | 104        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 809         |\n",
      "|    time_elapsed         | 14774       |\n",
      "|    total_timesteps      | 1656832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007523602 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.5       |\n",
      "|    explained_variance   | 0.813       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 8080        |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    reward               | 3.2406368   |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 63.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 810        |\n",
      "|    time_elapsed         | 14792      |\n",
      "|    total_timesteps      | 1658880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01223119 |\n",
      "|    clip_fraction        | 0.0687     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.5      |\n",
      "|    explained_variance   | 0.262      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.2       |\n",
      "|    n_updates            | 8090       |\n",
      "|    policy_gradient_loss | -0.00805   |\n",
      "|    reward               | 0.6825419  |\n",
      "|    std                  | 3.09       |\n",
      "|    value_loss           | 26.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 811         |\n",
      "|    time_elapsed         | 14810       |\n",
      "|    total_timesteps      | 1660928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013073497 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.5       |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 8100        |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    reward               | 1.6833664   |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 812        |\n",
      "|    time_elapsed         | 14828      |\n",
      "|    total_timesteps      | 1662976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01870294 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.5      |\n",
      "|    explained_variance   | 0.776      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25         |\n",
      "|    n_updates            | 8110       |\n",
      "|    policy_gradient_loss | -0.00066   |\n",
      "|    reward               | 3.388636   |\n",
      "|    std                  | 3.1        |\n",
      "|    value_loss           | 57.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 813         |\n",
      "|    time_elapsed         | 14846       |\n",
      "|    total_timesteps      | 1665024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014418215 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 8120        |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | 1.0898439   |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 31.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 814        |\n",
      "|    time_elapsed         | 14865      |\n",
      "|    total_timesteps      | 1667072    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00926378 |\n",
      "|    clip_fraction        | 0.0605     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.6      |\n",
      "|    explained_variance   | 0.589      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.3       |\n",
      "|    n_updates            | 8130       |\n",
      "|    policy_gradient_loss | -0.00606   |\n",
      "|    reward               | 3.8081524  |\n",
      "|    std                  | 3.1        |\n",
      "|    value_loss           | 62.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 815         |\n",
      "|    time_elapsed         | 14883       |\n",
      "|    total_timesteps      | 1669120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012390638 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.6        |\n",
      "|    n_updates            | 8140        |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    reward               | -0.27280194 |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 65.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 816          |\n",
      "|    time_elapsed         | 14901        |\n",
      "|    total_timesteps      | 1671168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031410824 |\n",
      "|    clip_fraction        | 0.00776      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.6        |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 8150         |\n",
      "|    policy_gradient_loss | -0.00472     |\n",
      "|    reward               | -0.70825034  |\n",
      "|    std                  | 3.1          |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 817         |\n",
      "|    time_elapsed         | 14919       |\n",
      "|    total_timesteps      | 1673216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015141518 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | 0.78        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 8160        |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    reward               | -0.34657568 |\n",
      "|    std                  | 3.11        |\n",
      "|    value_loss           | 42.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2843833.51\n",
      "total_reward: 1843833.51\n",
      "total_cost: 135874.91\n",
      "total_trades: 55740\n",
      "Sharpe: 0.481\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 818         |\n",
      "|    time_elapsed         | 14937       |\n",
      "|    total_timesteps      | 1675264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008201093 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 8170        |\n",
      "|    policy_gradient_loss | -0.0037     |\n",
      "|    reward               | 1.3520983   |\n",
      "|    std                  | 3.11        |\n",
      "|    value_loss           | 42.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 819         |\n",
      "|    time_elapsed         | 14955       |\n",
      "|    total_timesteps      | 1677312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011519156 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.2        |\n",
      "|    n_updates            | 8180        |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | -0.939524   |\n",
      "|    std                  | 3.11        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 820         |\n",
      "|    time_elapsed         | 14973       |\n",
      "|    total_timesteps      | 1679360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015922965 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.8       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 8190        |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    reward               | 0.33086327  |\n",
      "|    std                  | 3.12        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 821          |\n",
      "|    time_elapsed         | 14991        |\n",
      "|    total_timesteps      | 1681408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060543134 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.8        |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.4         |\n",
      "|    n_updates            | 8200         |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    reward               | -1.6805164   |\n",
      "|    std                  | 3.12         |\n",
      "|    value_loss           | 68.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 822        |\n",
      "|    time_elapsed         | 15009      |\n",
      "|    total_timesteps      | 1683456    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00906796 |\n",
      "|    clip_fraction        | 0.0516     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.8      |\n",
      "|    explained_variance   | 0.554      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.9       |\n",
      "|    n_updates            | 8210       |\n",
      "|    policy_gradient_loss | -0.00595   |\n",
      "|    reward               | 3.4614248  |\n",
      "|    std                  | 3.13       |\n",
      "|    value_loss           | 88.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 823          |\n",
      "|    time_elapsed         | 15027        |\n",
      "|    total_timesteps      | 1685504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073702866 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.9        |\n",
      "|    explained_variance   | 0.211        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 8220         |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    reward               | -1.2139134   |\n",
      "|    std                  | 3.13         |\n",
      "|    value_loss           | 41.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 824         |\n",
      "|    time_elapsed         | 15056       |\n",
      "|    total_timesteps      | 1687552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015649512 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 8230        |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    reward               | 0.42186278  |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 825         |\n",
      "|    time_elapsed         | 15074       |\n",
      "|    total_timesteps      | 1689600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007997379 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 8240        |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    reward               | -2.1217332  |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 58          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 826         |\n",
      "|    time_elapsed         | 15092       |\n",
      "|    total_timesteps      | 1691648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014322497 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.7        |\n",
      "|    n_updates            | 8250        |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    reward               | 1.9854075   |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 56.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 827         |\n",
      "|    time_elapsed         | 15110       |\n",
      "|    total_timesteps      | 1693696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024551837 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 8260        |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    reward               | 0.4050989   |\n",
      "|    std                  | 3.14        |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 828         |\n",
      "|    time_elapsed         | 15128       |\n",
      "|    total_timesteps      | 1695744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011314316 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 8270        |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    reward               | -0.25632602 |\n",
      "|    std                  | 3.15        |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 829         |\n",
      "|    time_elapsed         | 15146       |\n",
      "|    total_timesteps      | 1697792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009092482 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 8280        |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    reward               | 5.358131    |\n",
      "|    std                  | 3.15        |\n",
      "|    value_loss           | 51.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 830         |\n",
      "|    time_elapsed         | 15164       |\n",
      "|    total_timesteps      | 1699840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003038288 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 8290        |\n",
      "|    policy_gradient_loss | -0.00345    |\n",
      "|    reward               | -3.5203664  |\n",
      "|    std                  | 3.15        |\n",
      "|    value_loss           | 47.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 831         |\n",
      "|    time_elapsed         | 15183       |\n",
      "|    total_timesteps      | 1701888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010021219 |\n",
      "|    clip_fraction        | 0.0769      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 8300        |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    reward               | 2.5604658   |\n",
      "|    std                  | 3.15        |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 832         |\n",
      "|    time_elapsed         | 15200       |\n",
      "|    total_timesteps      | 1703936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008839907 |\n",
      "|    clip_fraction        | 0.0511      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 8310        |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    reward               | -3.6407573  |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1871754.19\n",
      "total_reward: 871754.19\n",
      "total_cost: 168900.42\n",
      "total_trades: 57776\n",
      "Sharpe: 0.340\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 833         |\n",
      "|    time_elapsed         | 15218       |\n",
      "|    total_timesteps      | 1705984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014993152 |\n",
      "|    clip_fraction        | 0.0812      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 8320        |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    reward               | 0.43701306  |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 834         |\n",
      "|    time_elapsed         | 15236       |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020231124 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.2       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.24        |\n",
      "|    n_updates            | 8330        |\n",
      "|    policy_gradient_loss | -0.00154    |\n",
      "|    reward               | -1.9307508  |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 835         |\n",
      "|    time_elapsed         | 15254       |\n",
      "|    total_timesteps      | 1710080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016001696 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.2       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 8340        |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    reward               | 1.6998084   |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 67          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 836         |\n",
      "|    time_elapsed         | 15272       |\n",
      "|    total_timesteps      | 1712128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008490054 |\n",
      "|    clip_fraction        | 0.0633      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 8350        |\n",
      "|    policy_gradient_loss | -0.00144    |\n",
      "|    reward               | -1.8293625  |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 64.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 837         |\n",
      "|    time_elapsed         | 15290       |\n",
      "|    total_timesteps      | 1714176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008822011 |\n",
      "|    clip_fraction        | 0.0718      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 8360        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -1.3647736  |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 838         |\n",
      "|    time_elapsed         | 15309       |\n",
      "|    total_timesteps      | 1716224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010379583 |\n",
      "|    clip_fraction        | 0.0678      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 8370        |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    reward               | 2.733456    |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 839        |\n",
      "|    time_elapsed         | 15327      |\n",
      "|    total_timesteps      | 1718272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0225958  |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.3      |\n",
      "|    explained_variance   | 0.734      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.2       |\n",
      "|    n_updates            | 8380       |\n",
      "|    policy_gradient_loss | -0.00354   |\n",
      "|    reward               | 0.74336344 |\n",
      "|    std                  | 3.18       |\n",
      "|    value_loss           | 41.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 840         |\n",
      "|    time_elapsed         | 15345       |\n",
      "|    total_timesteps      | 1720320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011281958 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 8390        |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    reward               | 0.856889    |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 841         |\n",
      "|    time_elapsed         | 15363       |\n",
      "|    total_timesteps      | 1722368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012961657 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 8400        |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    reward               | 0.4345657   |\n",
      "|    std                  | 3.19        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 842         |\n",
      "|    time_elapsed         | 15382       |\n",
      "|    total_timesteps      | 1724416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012092716 |\n",
      "|    clip_fraction        | 0.0633      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 8410        |\n",
      "|    policy_gradient_loss | -0.0051     |\n",
      "|    reward               | -3.3298423  |\n",
      "|    std                  | 3.19        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 843         |\n",
      "|    time_elapsed         | 15400       |\n",
      "|    total_timesteps      | 1726464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017047167 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 8420        |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | 0.20683263  |\n",
      "|    std                  | 3.19        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 844         |\n",
      "|    time_elapsed         | 15418       |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014909766 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.36        |\n",
      "|    n_updates            | 8430        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | -0.25062463 |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 845         |\n",
      "|    time_elapsed         | 15437       |\n",
      "|    total_timesteps      | 1730560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014200496 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 8440        |\n",
      "|    policy_gradient_loss | -0.00881    |\n",
      "|    reward               | -1.6324843  |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 846         |\n",
      "|    time_elapsed         | 15455       |\n",
      "|    total_timesteps      | 1732608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010110715 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 8450        |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | 4.114003    |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2173278.84\n",
      "total_reward: 1173278.84\n",
      "total_cost: 151281.39\n",
      "total_trades: 56130\n",
      "Sharpe: 0.392\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 847         |\n",
      "|    time_elapsed         | 15473       |\n",
      "|    total_timesteps      | 1734656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012081502 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 8460        |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    reward               | 0.03188432  |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 848         |\n",
      "|    time_elapsed         | 15491       |\n",
      "|    total_timesteps      | 1736704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013748762 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.6       |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 8470        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 2.2909913   |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 849        |\n",
      "|    time_elapsed         | 15510      |\n",
      "|    total_timesteps      | 1738752    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01709143 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.7      |\n",
      "|    explained_variance   | 0.589      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12         |\n",
      "|    n_updates            | 8480       |\n",
      "|    policy_gradient_loss | -0.00603   |\n",
      "|    reward               | -1.2741655 |\n",
      "|    std                  | 3.22       |\n",
      "|    value_loss           | 44.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 850         |\n",
      "|    time_elapsed         | 15528       |\n",
      "|    total_timesteps      | 1740800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014251619 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.4        |\n",
      "|    n_updates            | 8490        |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    reward               | -4.3959255  |\n",
      "|    std                  | 3.23        |\n",
      "|    value_loss           | 80.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 851         |\n",
      "|    time_elapsed         | 15546       |\n",
      "|    total_timesteps      | 1742848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025859248 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 8500        |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    reward               | 0.37458068  |\n",
      "|    std                  | 3.24        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 852         |\n",
      "|    time_elapsed         | 15564       |\n",
      "|    total_timesteps      | 1744896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016911846 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 8510        |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    reward               | -1.9097992  |\n",
      "|    std                  | 3.24        |\n",
      "|    value_loss           | 68.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 853        |\n",
      "|    time_elapsed         | 15583      |\n",
      "|    total_timesteps      | 1746944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01040206 |\n",
      "|    clip_fraction        | 0.0882     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.9      |\n",
      "|    explained_variance   | 0.683      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.6       |\n",
      "|    n_updates            | 8520       |\n",
      "|    policy_gradient_loss | -0.0022    |\n",
      "|    reward               | 0.19156791 |\n",
      "|    std                  | 3.24       |\n",
      "|    value_loss           | 57.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 854         |\n",
      "|    time_elapsed         | 15601       |\n",
      "|    total_timesteps      | 1748992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014427707 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 8530        |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    reward               | -0.5580295  |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 855         |\n",
      "|    time_elapsed         | 15619       |\n",
      "|    total_timesteps      | 1751040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015431196 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75         |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 8540        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 0.98218226  |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 76.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 856         |\n",
      "|    time_elapsed         | 15637       |\n",
      "|    total_timesteps      | 1753088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015118148 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75         |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.1        |\n",
      "|    n_updates            | 8550        |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    reward               | -11.4516115 |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 857         |\n",
      "|    time_elapsed         | 15655       |\n",
      "|    total_timesteps      | 1755136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024956895 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 8560        |\n",
      "|    policy_gradient_loss | 0.00259     |\n",
      "|    reward               | 2.8603153   |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 77.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 858         |\n",
      "|    time_elapsed         | 15673       |\n",
      "|    total_timesteps      | 1757184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020369086 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | -0.0919     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 8570        |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    reward               | 3.08018     |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 859         |\n",
      "|    time_elapsed         | 15691       |\n",
      "|    total_timesteps      | 1759232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008183236 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 8580        |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    reward               | -0.9177956  |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 67.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 860         |\n",
      "|    time_elapsed         | 15709       |\n",
      "|    total_timesteps      | 1761280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011361159 |\n",
      "|    clip_fraction        | 0.096       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.5        |\n",
      "|    n_updates            | 8590        |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    reward               | 1.2128187   |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2046213.35\n",
      "total_reward: 1046213.35\n",
      "total_cost: 162665.55\n",
      "total_trades: 57022\n",
      "Sharpe: 0.373\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 15727       |\n",
      "|    total_timesteps      | 1763328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012064176 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 8600        |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    reward               | 1.6286978   |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 862         |\n",
      "|    time_elapsed         | 15746       |\n",
      "|    total_timesteps      | 1765376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017793128 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 8610        |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    reward               | -2.773258   |\n",
      "|    std                  | 3.28        |\n",
      "|    value_loss           | 46.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 863         |\n",
      "|    time_elapsed         | 15764       |\n",
      "|    total_timesteps      | 1767424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011071116 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.5        |\n",
      "|    n_updates            | 8620        |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    reward               | 4.231535    |\n",
      "|    std                  | 3.28        |\n",
      "|    value_loss           | 77.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 864         |\n",
      "|    time_elapsed         | 15782       |\n",
      "|    total_timesteps      | 1769472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022512928 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.3       |\n",
      "|    explained_variance   | 0.0344      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 8630        |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    reward               | -1.431828   |\n",
      "|    std                  | 3.29        |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 865         |\n",
      "|    time_elapsed         | 15801       |\n",
      "|    total_timesteps      | 1771520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01719277  |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.4       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 8640        |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    reward               | -0.80281425 |\n",
      "|    std                  | 3.29        |\n",
      "|    value_loss           | 89.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 866        |\n",
      "|    time_elapsed         | 15819      |\n",
      "|    total_timesteps      | 1773568    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01261708 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.4      |\n",
      "|    explained_variance   | 0.404      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.6       |\n",
      "|    n_updates            | 8650       |\n",
      "|    policy_gradient_loss | -0.00768   |\n",
      "|    reward               | 0.49900433 |\n",
      "|    std                  | 3.3        |\n",
      "|    value_loss           | 110        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 867          |\n",
      "|    time_elapsed         | 15838        |\n",
      "|    total_timesteps      | 1775616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103193335 |\n",
      "|    clip_fraction        | 0.0569       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.4        |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.2         |\n",
      "|    n_updates            | 8660         |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    reward               | 0.41481188   |\n",
      "|    std                  | 3.3          |\n",
      "|    value_loss           | 99.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 868         |\n",
      "|    time_elapsed         | 15856       |\n",
      "|    total_timesteps      | 1777664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018095229 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.48        |\n",
      "|    n_updates            | 8670        |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | -0.72601193 |\n",
      "|    std                  | 3.32        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 869          |\n",
      "|    time_elapsed         | 15875        |\n",
      "|    total_timesteps      | 1779712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007958671  |\n",
      "|    clip_fraction        | 0.0638       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.5        |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 8680         |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    reward               | -0.042649906 |\n",
      "|    std                  | 3.32         |\n",
      "|    value_loss           | 75.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 870        |\n",
      "|    time_elapsed         | 15893      |\n",
      "|    total_timesteps      | 1781760    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01057956 |\n",
      "|    clip_fraction        | 0.0993     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.6      |\n",
      "|    explained_variance   | 0.31       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 45.2       |\n",
      "|    n_updates            | 8690       |\n",
      "|    policy_gradient_loss | -0.00767   |\n",
      "|    reward               | 0.62486786 |\n",
      "|    std                  | 3.32       |\n",
      "|    value_loss           | 94.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 871         |\n",
      "|    time_elapsed         | 15911       |\n",
      "|    total_timesteps      | 1783808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016596287 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 8700        |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    reward               | 0.920814    |\n",
      "|    std                  | 3.33        |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 872         |\n",
      "|    time_elapsed         | 15929       |\n",
      "|    total_timesteps      | 1785856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019125443 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 8710        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 1.7847638   |\n",
      "|    std                  | 3.33        |\n",
      "|    value_loss           | 92.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 873         |\n",
      "|    time_elapsed         | 15948       |\n",
      "|    total_timesteps      | 1787904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016079674 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.5        |\n",
      "|    n_updates            | 8720        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -0.5011299  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 874         |\n",
      "|    time_elapsed         | 15966       |\n",
      "|    total_timesteps      | 1789952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011225626 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 8730        |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | -0.45590606 |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2595359.31\n",
      "total_reward: 1595359.31\n",
      "total_cost: 162170.48\n",
      "total_trades: 56254\n",
      "Sharpe: 0.455\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 875         |\n",
      "|    time_elapsed         | 15985       |\n",
      "|    total_timesteps      | 1792000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015250811 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.0939      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.87        |\n",
      "|    n_updates            | 8740        |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    reward               | 1.5980495   |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 876         |\n",
      "|    time_elapsed         | 16003       |\n",
      "|    total_timesteps      | 1794048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011460686 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 8750        |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    reward               | 1.563753    |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 99.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 877         |\n",
      "|    time_elapsed         | 16021       |\n",
      "|    total_timesteps      | 1796096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012372579 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 8760        |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    reward               | -0.79361236 |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 878         |\n",
      "|    time_elapsed         | 16040       |\n",
      "|    total_timesteps      | 1798144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015647292 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 8770        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -0.04574909 |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 879         |\n",
      "|    time_elapsed         | 16058       |\n",
      "|    total_timesteps      | 1800192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012535587 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.1        |\n",
      "|    n_updates            | 8780        |\n",
      "|    policy_gradient_loss | -0.00745    |\n",
      "|    reward               | 1.2843192   |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 85.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 880         |\n",
      "|    time_elapsed         | 16076       |\n",
      "|    total_timesteps      | 1802240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009055752 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.3        |\n",
      "|    n_updates            | 8790        |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    reward               | 1.8927125   |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 881         |\n",
      "|    time_elapsed         | 16094       |\n",
      "|    total_timesteps      | 1804288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009901265 |\n",
      "|    clip_fraction        | 0.0795      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 8800        |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | -2.5904942  |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 61          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 882         |\n",
      "|    time_elapsed         | 16113       |\n",
      "|    total_timesteps      | 1806336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018134303 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 8810        |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | -0.25020263 |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 69.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 883         |\n",
      "|    time_elapsed         | 16131       |\n",
      "|    total_timesteps      | 1808384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008524378 |\n",
      "|    clip_fraction        | 0.06        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76         |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.2        |\n",
      "|    n_updates            | 8820        |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    reward               | 0.7204581   |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 884          |\n",
      "|    time_elapsed         | 16149        |\n",
      "|    total_timesteps      | 1810432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039541726 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76          |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39           |\n",
      "|    n_updates            | 8830         |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | 2.897072     |\n",
      "|    std                  | 3.37         |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 16167       |\n",
      "|    total_timesteps      | 1812480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018321171 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76         |\n",
      "|    explained_variance   | 0.0974      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.62        |\n",
      "|    n_updates            | 8840        |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    reward               | 4.3336625   |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 22.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 886         |\n",
      "|    time_elapsed         | 16185       |\n",
      "|    total_timesteps      | 1814528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010789413 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 8850        |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    reward               | -2.1622562  |\n",
      "|    std                  | 3.38        |\n",
      "|    value_loss           | 88.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 887         |\n",
      "|    time_elapsed         | 16203       |\n",
      "|    total_timesteps      | 1816576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008614533 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 8860        |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    reward               | 5.1328626   |\n",
      "|    std                  | 3.38        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 888         |\n",
      "|    time_elapsed         | 16221       |\n",
      "|    total_timesteps      | 1818624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012699267 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 8870        |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    reward               | 0.5811841   |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 55.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2534700.65\n",
      "total_reward: 1534700.65\n",
      "total_cost: 163891.24\n",
      "total_trades: 56787\n",
      "Sharpe: 0.447\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 889          |\n",
      "|    time_elapsed         | 16240        |\n",
      "|    total_timesteps      | 1820672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149621945 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.2        |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.9         |\n",
      "|    n_updates            | 8880         |\n",
      "|    policy_gradient_loss | -0.00892     |\n",
      "|    reward               | -0.19816422  |\n",
      "|    std                  | 3.4          |\n",
      "|    value_loss           | 71.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 890         |\n",
      "|    time_elapsed         | 16258       |\n",
      "|    total_timesteps      | 1822720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010686059 |\n",
      "|    clip_fraction        | 0.0974      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.5        |\n",
      "|    n_updates            | 8890        |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    reward               | -0.5062603  |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 86.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 891         |\n",
      "|    time_elapsed         | 16276       |\n",
      "|    total_timesteps      | 1824768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012094859 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.1        |\n",
      "|    n_updates            | 8900        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -0.14415349 |\n",
      "|    std                  | 3.42        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 892         |\n",
      "|    time_elapsed         | 16294       |\n",
      "|    total_timesteps      | 1826816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022161607 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.27        |\n",
      "|    n_updates            | 8910        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 0.8039108   |\n",
      "|    std                  | 3.42        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 893          |\n",
      "|    time_elapsed         | 16313        |\n",
      "|    total_timesteps      | 1828864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111960955 |\n",
      "|    clip_fraction        | 0.0845       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.5        |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 8920         |\n",
      "|    policy_gradient_loss | -0.0131      |\n",
      "|    reward               | 0.118808955  |\n",
      "|    std                  | 3.43         |\n",
      "|    value_loss           | 86           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 894         |\n",
      "|    time_elapsed         | 16331       |\n",
      "|    total_timesteps      | 1830912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010919527 |\n",
      "|    clip_fraction        | 0.0798      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.5        |\n",
      "|    n_updates            | 8930        |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    reward               | -1.4240639  |\n",
      "|    std                  | 3.43        |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 112       |\n",
      "|    iterations           | 895       |\n",
      "|    time_elapsed         | 16349     |\n",
      "|    total_timesteps      | 1832960   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0256226 |\n",
      "|    clip_fraction        | 0.227     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -76.5     |\n",
      "|    explained_variance   | 0.0554    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 24        |\n",
      "|    n_updates            | 8940      |\n",
      "|    policy_gradient_loss | -0.00606  |\n",
      "|    reward               | -1.934744 |\n",
      "|    std                  | 3.43      |\n",
      "|    value_loss           | 42.3      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 896          |\n",
      "|    time_elapsed         | 16367        |\n",
      "|    total_timesteps      | 1835008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0125911925 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.6        |\n",
      "|    explained_variance   | 0.189        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26           |\n",
      "|    n_updates            | 8950         |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    reward               | 0.62417233   |\n",
      "|    std                  | 3.44         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 897         |\n",
      "|    time_elapsed         | 16385       |\n",
      "|    total_timesteps      | 1837056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009614753 |\n",
      "|    clip_fraction        | 0.0634      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81          |\n",
      "|    n_updates            | 8960        |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    reward               | -12.51001   |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 898          |\n",
      "|    time_elapsed         | 16404        |\n",
      "|    total_timesteps      | 1839104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028880206 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.6        |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35           |\n",
      "|    n_updates            | 8970         |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    reward               | 0.5206967    |\n",
      "|    std                  | 3.44         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 899         |\n",
      "|    time_elapsed         | 16422       |\n",
      "|    total_timesteps      | 1841152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020097084 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 0.0544      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.77        |\n",
      "|    n_updates            | 8980        |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | -1.6256495  |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 900         |\n",
      "|    time_elapsed         | 16440       |\n",
      "|    total_timesteps      | 1843200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008035094 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 8990        |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    reward               | 0.5896665   |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 88.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 901         |\n",
      "|    time_elapsed         | 16459       |\n",
      "|    total_timesteps      | 1845248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012516523 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39          |\n",
      "|    n_updates            | 9000        |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    reward               | -0.2840509  |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 85.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 902         |\n",
      "|    time_elapsed         | 16477       |\n",
      "|    total_timesteps      | 1847296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014585793 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 9010        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -0.80240154 |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2715211.90\n",
      "total_reward: 1715211.90\n",
      "total_cost: 187205.48\n",
      "total_trades: 58907\n",
      "Sharpe: 0.475\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 903         |\n",
      "|    time_elapsed         | 16495       |\n",
      "|    total_timesteps      | 1849344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011253763 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.6        |\n",
      "|    n_updates            | 9020        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | -1.1285318  |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 77          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 904         |\n",
      "|    time_elapsed         | 16514       |\n",
      "|    total_timesteps      | 1851392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011447427 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.5        |\n",
      "|    n_updates            | 9030        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -0.57314926 |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 78.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 905         |\n",
      "|    time_elapsed         | 16532       |\n",
      "|    total_timesteps      | 1853440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01627578  |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 9040        |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    reward               | -0.15238403 |\n",
      "|    std                  | 3.48        |\n",
      "|    value_loss           | 57.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 906         |\n",
      "|    time_elapsed         | 16550       |\n",
      "|    total_timesteps      | 1855488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015079139 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 9050        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.3638212   |\n",
      "|    std                  | 3.48        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 907         |\n",
      "|    time_elapsed         | 16568       |\n",
      "|    total_timesteps      | 1857536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016214525 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 9060        |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    reward               | 0.4868598   |\n",
      "|    std                  | 3.48        |\n",
      "|    value_loss           | 60          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 908         |\n",
      "|    time_elapsed         | 16586       |\n",
      "|    total_timesteps      | 1859584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016199237 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.0777      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 9070        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | 5.6340523   |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 909         |\n",
      "|    time_elapsed         | 16605       |\n",
      "|    total_timesteps      | 1861632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018471675 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 9080        |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | -1.5139081  |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 910         |\n",
      "|    time_elapsed         | 16623       |\n",
      "|    total_timesteps      | 1863680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012113305 |\n",
      "|    clip_fraction        | 0.0898      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 9090        |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    reward               | 0.13848874  |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 911         |\n",
      "|    time_elapsed         | 16641       |\n",
      "|    total_timesteps      | 1865728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014275141 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.5        |\n",
      "|    n_updates            | 9100        |\n",
      "|    policy_gradient_loss | -0.00554    |\n",
      "|    reward               | -15.087168  |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 912         |\n",
      "|    time_elapsed         | 16660       |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014662043 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 9110        |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | 3.2730484   |\n",
      "|    std                  | 3.5         |\n",
      "|    value_loss           | 47          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 913         |\n",
      "|    time_elapsed         | 16677       |\n",
      "|    total_timesteps      | 1869824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015725505 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.9        |\n",
      "|    n_updates            | 9120        |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    reward               | 0.6868402   |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 914         |\n",
      "|    time_elapsed         | 16695       |\n",
      "|    total_timesteps      | 1871872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012247033 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 9130        |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    reward               | 0.61936736  |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 915         |\n",
      "|    time_elapsed         | 16714       |\n",
      "|    total_timesteps      | 1873920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009572869 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.9        |\n",
      "|    n_updates            | 9140        |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | 0.32512307  |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 916         |\n",
      "|    time_elapsed         | 16732       |\n",
      "|    total_timesteps      | 1875968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021748774 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 9150        |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | -0.11630439 |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6629613.97\n",
      "total_reward: 5629613.97\n",
      "total_cost: 253784.83\n",
      "total_trades: 62062\n",
      "Sharpe: 0.936\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 917         |\n",
      "|    time_elapsed         | 16750       |\n",
      "|    total_timesteps      | 1878016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017774682 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 9160        |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | 0.43810087  |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 918        |\n",
      "|    time_elapsed         | 16768      |\n",
      "|    total_timesteps      | 1880064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01237095 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.3      |\n",
      "|    explained_variance   | 0.412      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 93.9       |\n",
      "|    n_updates            | 9170       |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    reward               | 3.1924782  |\n",
      "|    std                  | 3.53       |\n",
      "|    value_loss           | 134        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 919         |\n",
      "|    time_elapsed         | 16786       |\n",
      "|    total_timesteps      | 1882112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012950361 |\n",
      "|    clip_fraction        | 0.0633      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 9180        |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    reward               | -2.4627874  |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 920         |\n",
      "|    time_elapsed         | 16804       |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013418655 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 9190        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 0.5119183   |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 921        |\n",
      "|    time_elapsed         | 16823      |\n",
      "|    total_timesteps      | 1886208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01642128 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.3      |\n",
      "|    explained_variance   | 0.581      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 90         |\n",
      "|    n_updates            | 9200       |\n",
      "|    policy_gradient_loss | -0.00658   |\n",
      "|    reward               | -6.9549427 |\n",
      "|    std                  | 3.53       |\n",
      "|    value_loss           | 141        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 922         |\n",
      "|    time_elapsed         | 16841       |\n",
      "|    total_timesteps      | 1888256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007968251 |\n",
      "|    clip_fraction        | 0.0815      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.4       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.6        |\n",
      "|    n_updates            | 9210        |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    reward               | 0.9911164   |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 923         |\n",
      "|    time_elapsed         | 16859       |\n",
      "|    total_timesteps      | 1890304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015839467 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.4       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.78        |\n",
      "|    n_updates            | 9220        |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    reward               | 0.054868035 |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 924         |\n",
      "|    time_elapsed         | 16877       |\n",
      "|    total_timesteps      | 1892352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024765115 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.5       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.4        |\n",
      "|    n_updates            | 9230        |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | -1.8715034  |\n",
      "|    std                  | 3.55        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 925         |\n",
      "|    time_elapsed         | 16895       |\n",
      "|    total_timesteps      | 1894400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015304904 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.6       |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.2        |\n",
      "|    n_updates            | 9240        |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    reward               | 0.5538503   |\n",
      "|    std                  | 3.57        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 926         |\n",
      "|    time_elapsed         | 16914       |\n",
      "|    total_timesteps      | 1896448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019651085 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 9250        |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    reward               | 2.4720447   |\n",
      "|    std                  | 3.57        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 927         |\n",
      "|    time_elapsed         | 16932       |\n",
      "|    total_timesteps      | 1898496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014228279 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.8        |\n",
      "|    n_updates            | 9260        |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    reward               | 2.1163168   |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 928         |\n",
      "|    time_elapsed         | 16951       |\n",
      "|    total_timesteps      | 1900544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011947247 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.8       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 9270        |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    reward               | 2.2677248   |\n",
      "|    std                  | 3.59        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 929         |\n",
      "|    time_elapsed         | 16969       |\n",
      "|    total_timesteps      | 1902592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012722687 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.1        |\n",
      "|    n_updates            | 9280        |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    reward               | 3.8914835   |\n",
      "|    std                  | 3.6         |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 930          |\n",
      "|    time_elapsed         | 16987        |\n",
      "|    total_timesteps      | 1904640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120662935 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.9        |\n",
      "|    explained_variance   | 0.216        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.1         |\n",
      "|    n_updates            | 9290         |\n",
      "|    policy_gradient_loss | -0.00796     |\n",
      "|    reward               | 0.46982825   |\n",
      "|    std                  | 3.6          |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8494290.38\n",
      "total_reward: 7494290.38\n",
      "total_cost: 237020.97\n",
      "total_trades: 62207\n",
      "Sharpe: 1.039\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 931        |\n",
      "|    time_elapsed         | 17005      |\n",
      "|    total_timesteps      | 1906688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01786105 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.9      |\n",
      "|    explained_variance   | 0.371      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 53.3       |\n",
      "|    n_updates            | 9300       |\n",
      "|    policy_gradient_loss | -0.0106    |\n",
      "|    reward               | -0.3848268 |\n",
      "|    std                  | 3.61       |\n",
      "|    value_loss           | 113        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 932         |\n",
      "|    time_elapsed         | 17023       |\n",
      "|    total_timesteps      | 1908736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010064599 |\n",
      "|    clip_fraction        | 0.0663      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.9        |\n",
      "|    n_updates            | 9310        |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    reward               | -0.17330992 |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 933         |\n",
      "|    time_elapsed         | 17041       |\n",
      "|    total_timesteps      | 1910784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013403755 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.08        |\n",
      "|    n_updates            | 9320        |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    reward               | -1.3481951  |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 934         |\n",
      "|    time_elapsed         | 17059       |\n",
      "|    total_timesteps      | 1912832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007845871 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 9330        |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    reward               | 0.796201    |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 935          |\n",
      "|    time_elapsed         | 17077        |\n",
      "|    total_timesteps      | 1914880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051106624 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -78.1        |\n",
      "|    explained_variance   | 0.262        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 87.2         |\n",
      "|    n_updates            | 9340         |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | 5.1279306    |\n",
      "|    std                  | 3.62         |\n",
      "|    value_loss           | 176          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 936         |\n",
      "|    time_elapsed         | 17095       |\n",
      "|    total_timesteps      | 1916928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013315899 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 9350        |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | -3.5935185  |\n",
      "|    std                  | 3.63        |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 937         |\n",
      "|    time_elapsed         | 17114       |\n",
      "|    total_timesteps      | 1918976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010272455 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 9360        |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    reward               | -0.4068613  |\n",
      "|    std                  | 3.63        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 938         |\n",
      "|    time_elapsed         | 17132       |\n",
      "|    total_timesteps      | 1921024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015021573 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.5        |\n",
      "|    n_updates            | 9370        |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    reward               | -0.1301031  |\n",
      "|    std                  | 3.64        |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 939         |\n",
      "|    time_elapsed         | 17151       |\n",
      "|    total_timesteps      | 1923072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005745175 |\n",
      "|    clip_fraction        | 0.0358      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 9380        |\n",
      "|    policy_gradient_loss | -0.00254    |\n",
      "|    reward               | -0.34679854 |\n",
      "|    std                  | 3.64        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 940         |\n",
      "|    time_elapsed         | 17169       |\n",
      "|    total_timesteps      | 1925120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012854021 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.53        |\n",
      "|    n_updates            | 9390        |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    reward               | 1.0097972   |\n",
      "|    std                  | 3.64        |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 941          |\n",
      "|    time_elapsed         | 17187        |\n",
      "|    total_timesteps      | 1927168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062864777 |\n",
      "|    clip_fraction        | 0.0623       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -78.3        |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 9400         |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | -0.050012358 |\n",
      "|    std                  | 3.65         |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 942         |\n",
      "|    time_elapsed         | 17205       |\n",
      "|    total_timesteps      | 1929216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012578218 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.3        |\n",
      "|    n_updates            | 9410        |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | 5.2475905   |\n",
      "|    std                  | 3.65        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 943         |\n",
      "|    time_elapsed         | 17223       |\n",
      "|    total_timesteps      | 1931264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012749617 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 9420        |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | -0.54620665 |\n",
      "|    std                  | 3.65        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 944         |\n",
      "|    time_elapsed         | 17242       |\n",
      "|    total_timesteps      | 1933312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013199776 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.7        |\n",
      "|    n_updates            | 9430        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 0.14554194  |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 945        |\n",
      "|    time_elapsed         | 17260      |\n",
      "|    total_timesteps      | 1935360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01159981 |\n",
      "|    clip_fraction        | 0.0808     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.4      |\n",
      "|    explained_variance   | 0.465      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 61         |\n",
      "|    n_updates            | 9440       |\n",
      "|    policy_gradient_loss | -0.00806   |\n",
      "|    reward               | -3.1447263 |\n",
      "|    std                  | 3.67       |\n",
      "|    value_loss           | 113        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6229248.25\n",
      "total_reward: 5229248.25\n",
      "total_cost: 163199.40\n",
      "total_trades: 56786\n",
      "Sharpe: 0.959\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 946         |\n",
      "|    time_elapsed         | 17279       |\n",
      "|    total_timesteps      | 1937408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011212349 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.6        |\n",
      "|    n_updates            | 9450        |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    reward               | 0.8346079   |\n",
      "|    std                  | 3.67        |\n",
      "|    value_loss           | 95          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 947         |\n",
      "|    time_elapsed         | 17299       |\n",
      "|    total_timesteps      | 1939456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013186118 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.72        |\n",
      "|    n_updates            | 9460        |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    reward               | 0.6044269   |\n",
      "|    std                  | 3.68        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 948         |\n",
      "|    time_elapsed         | 17317       |\n",
      "|    total_timesteps      | 1941504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016957575 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.4        |\n",
      "|    n_updates            | 9470        |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    reward               | 0.33136594  |\n",
      "|    std                  | 3.68        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 949         |\n",
      "|    time_elapsed         | 17337       |\n",
      "|    total_timesteps      | 1943552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008244956 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.6       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 9480        |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    reward               | 0.99474925  |\n",
      "|    std                  | 3.68        |\n",
      "|    value_loss           | 72.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 950         |\n",
      "|    time_elapsed         | 17356       |\n",
      "|    total_timesteps      | 1945600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009826066 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.6       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.89        |\n",
      "|    n_updates            | 9490        |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    reward               | -0.31769907 |\n",
      "|    std                  | 3.69        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 951         |\n",
      "|    time_elapsed         | 17375       |\n",
      "|    total_timesteps      | 1947648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010020404 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 9500        |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | 2.1881547   |\n",
      "|    std                  | 3.7         |\n",
      "|    value_loss           | 88.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 952         |\n",
      "|    time_elapsed         | 17394       |\n",
      "|    total_timesteps      | 1949696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014436698 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.1        |\n",
      "|    n_updates            | 9510        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 7.1278625   |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 953         |\n",
      "|    time_elapsed         | 17413       |\n",
      "|    total_timesteps      | 1951744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011585027 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 9520        |\n",
      "|    policy_gradient_loss | -0.00779    |\n",
      "|    reward               | -0.89651924 |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 17432       |\n",
      "|    total_timesteps      | 1953792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010154474 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 9530        |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    reward               | 0.7367875   |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 80.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 955         |\n",
      "|    time_elapsed         | 17451       |\n",
      "|    total_timesteps      | 1955840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008117024 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 9540        |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    reward               | 0.17978145  |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 956         |\n",
      "|    time_elapsed         | 17470       |\n",
      "|    total_timesteps      | 1957888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008325274 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 232         |\n",
      "|    n_updates            | 9550        |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | 2.2334862   |\n",
      "|    std                  | 3.72        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 957        |\n",
      "|    time_elapsed         | 17489      |\n",
      "|    total_timesteps      | 1959936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01982925 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.9      |\n",
      "|    explained_variance   | 0.555      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.9        |\n",
      "|    n_updates            | 9560       |\n",
      "|    policy_gradient_loss | -0.00354   |\n",
      "|    reward               | 1.526376   |\n",
      "|    std                  | 3.73       |\n",
      "|    value_loss           | 21.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 958         |\n",
      "|    time_elapsed         | 17507       |\n",
      "|    total_timesteps      | 1961984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016022222 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.9       |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58          |\n",
      "|    n_updates            | 9570        |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    reward               | -0.36341634 |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 959         |\n",
      "|    time_elapsed         | 17526       |\n",
      "|    total_timesteps      | 1964032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012577148 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 9580        |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | -0.37086505 |\n",
      "|    std                  | 3.74        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6810275.50\n",
      "total_reward: 5810275.50\n",
      "total_cost: 190652.18\n",
      "total_trades: 58566\n",
      "Sharpe: 0.914\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 960         |\n",
      "|    time_elapsed         | 17545       |\n",
      "|    total_timesteps      | 1966080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012246896 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 9590        |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | 0.503261    |\n",
      "|    std                  | 3.74        |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 961          |\n",
      "|    time_elapsed         | 17564        |\n",
      "|    total_timesteps      | 1968128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107281245 |\n",
      "|    clip_fraction        | 0.0912       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.1        |\n",
      "|    explained_variance   | 0.197        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42           |\n",
      "|    n_updates            | 9600         |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    reward               | -2.2643616   |\n",
      "|    std                  | 3.75         |\n",
      "|    value_loss           | 122          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 962          |\n",
      "|    time_elapsed         | 17583        |\n",
      "|    total_timesteps      | 1970176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108361095 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.1        |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.9         |\n",
      "|    n_updates            | 9610         |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    reward               | -0.06896325  |\n",
      "|    std                  | 3.76         |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 963         |\n",
      "|    time_elapsed         | 17601       |\n",
      "|    total_timesteps      | 1972224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015040702 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.2       |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.8        |\n",
      "|    n_updates            | 9620        |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    reward               | 1.350591    |\n",
      "|    std                  | 3.77        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 964         |\n",
      "|    time_elapsed         | 17620       |\n",
      "|    total_timesteps      | 1974272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021346917 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 9630        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.8237893  |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 965          |\n",
      "|    time_elapsed         | 17639        |\n",
      "|    total_timesteps      | 1976320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056236577 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.4        |\n",
      "|    explained_variance   | 0.42         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 121          |\n",
      "|    n_updates            | 9640         |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    reward               | 0.5904655    |\n",
      "|    std                  | 3.8          |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 966         |\n",
      "|    time_elapsed         | 17658       |\n",
      "|    total_timesteps      | 1978368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009781364 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.8        |\n",
      "|    n_updates            | 9650        |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    reward               | -0.54348624 |\n",
      "|    std                  | 3.8         |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 967         |\n",
      "|    time_elapsed         | 17678       |\n",
      "|    total_timesteps      | 1980416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012292778 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 9660        |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | 1.3269107   |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 968         |\n",
      "|    time_elapsed         | 17697       |\n",
      "|    total_timesteps      | 1982464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007912479 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 9670        |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    reward               | 0.048869047 |\n",
      "|    std                  | 3.8         |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 969         |\n",
      "|    time_elapsed         | 17716       |\n",
      "|    total_timesteps      | 1984512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010190723 |\n",
      "|    clip_fraction        | 0.0913      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.5       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 9680        |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    reward               | 3.407753    |\n",
      "|    std                  | 3.8         |\n",
      "|    value_loss           | 92.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 970        |\n",
      "|    time_elapsed         | 17735      |\n",
      "|    total_timesteps      | 1986560    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01192068 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -79.5      |\n",
      "|    explained_variance   | 0.359      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38.3       |\n",
      "|    n_updates            | 9690       |\n",
      "|    policy_gradient_loss | -0.00562   |\n",
      "|    reward               | 1.1145254  |\n",
      "|    std                  | 3.81       |\n",
      "|    value_loss           | 65.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 971         |\n",
      "|    time_elapsed         | 17754       |\n",
      "|    total_timesteps      | 1988608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010726495 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.5       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 9700        |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | -1.6998156  |\n",
      "|    std                  | 3.81        |\n",
      "|    value_loss           | 56.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 972         |\n",
      "|    time_elapsed         | 17772       |\n",
      "|    total_timesteps      | 1990656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008901713 |\n",
      "|    clip_fraction        | 0.0904      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.7        |\n",
      "|    n_updates            | 9710        |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | 0.9616664   |\n",
      "|    std                  | 3.82        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 973         |\n",
      "|    time_elapsed         | 17791       |\n",
      "|    total_timesteps      | 1992704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010807493 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 123         |\n",
      "|    n_updates            | 9720        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -12.734062  |\n",
      "|    std                  | 3.82        |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7029397.03\n",
      "total_reward: 6029397.03\n",
      "total_cost: 160846.71\n",
      "total_trades: 55806\n",
      "Sharpe: 0.902\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 974         |\n",
      "|    time_elapsed         | 17811       |\n",
      "|    total_timesteps      | 1994752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011110265 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 9730        |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    reward               | -0.7671149  |\n",
      "|    std                  | 3.83        |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 975         |\n",
      "|    time_elapsed         | 17830       |\n",
      "|    total_timesteps      | 1996800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00965399  |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.7        |\n",
      "|    n_updates            | 9740        |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    reward               | 0.052073713 |\n",
      "|    std                  | 3.83        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 976         |\n",
      "|    time_elapsed         | 17849       |\n",
      "|    total_timesteps      | 1998848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011826612 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35          |\n",
      "|    n_updates            | 9750        |\n",
      "|    policy_gradient_loss | -0.00956    |\n",
      "|    reward               | -18.891918  |\n",
      "|    std                  | 3.83        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 977         |\n",
      "|    time_elapsed         | 17868       |\n",
      "|    total_timesteps      | 2000896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009144504 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 9760        |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    reward               | 0.26481345  |\n",
      "|    std                  | 3.83        |\n",
      "|    value_loss           | 80.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 978         |\n",
      "|    time_elapsed         | 17887       |\n",
      "|    total_timesteps      | 2002944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012182642 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52          |\n",
      "|    n_updates            | 9770        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 1.3611294   |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 979          |\n",
      "|    time_elapsed         | 17905        |\n",
      "|    total_timesteps      | 2004992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012843367  |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.7        |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.1         |\n",
      "|    n_updates            | 9780         |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    reward               | -0.060118623 |\n",
      "|    std                  | 3.84         |\n",
      "|    value_loss           | 166          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 980         |\n",
      "|    time_elapsed         | 17925       |\n",
      "|    total_timesteps      | 2007040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011012614 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.2        |\n",
      "|    n_updates            | 9790        |\n",
      "|    policy_gradient_loss | -0.00865    |\n",
      "|    reward               | 2.274314    |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 981          |\n",
      "|    time_elapsed         | 17944        |\n",
      "|    total_timesteps      | 2009088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015984116  |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.8        |\n",
      "|    explained_variance   | 0.824        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.44         |\n",
      "|    n_updates            | 9800         |\n",
      "|    policy_gradient_loss | -0.00697     |\n",
      "|    reward               | 0.0019166889 |\n",
      "|    std                  | 3.86         |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 982         |\n",
      "|    time_elapsed         | 17962       |\n",
      "|    total_timesteps      | 2011136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0086774   |\n",
      "|    clip_fraction        | 0.0634      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.8        |\n",
      "|    n_updates            | 9810        |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    reward               | -0.04677628 |\n",
      "|    std                  | 3.86        |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 983         |\n",
      "|    time_elapsed         | 17981       |\n",
      "|    total_timesteps      | 2013184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011049962 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 9820        |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | -2.0441153  |\n",
      "|    std                  | 3.86        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 984         |\n",
      "|    time_elapsed         | 18000       |\n",
      "|    total_timesteps      | 2015232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012169542 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 9830        |\n",
      "|    policy_gradient_loss | -0.00657    |\n",
      "|    reward               | -0.9543752  |\n",
      "|    std                  | 3.87        |\n",
      "|    value_loss           | 51.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 985         |\n",
      "|    time_elapsed         | 18019       |\n",
      "|    total_timesteps      | 2017280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009490365 |\n",
      "|    clip_fraction        | 0.0834      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.5        |\n",
      "|    n_updates            | 9840        |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | 0.037796304 |\n",
      "|    std                  | 3.87        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 986          |\n",
      "|    time_elapsed         | 18038        |\n",
      "|    total_timesteps      | 2019328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111697875 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80          |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.8         |\n",
      "|    n_updates            | 9850         |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | -0.14668871  |\n",
      "|    std                  | 3.87         |\n",
      "|    value_loss           | 177          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 987         |\n",
      "|    time_elapsed         | 18057       |\n",
      "|    total_timesteps      | 2021376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008924227 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 9860        |\n",
      "|    policy_gradient_loss | -0.00881    |\n",
      "|    reward               | -0.9847013  |\n",
      "|    std                  | 3.87        |\n",
      "|    value_loss           | 166         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8886825.41\n",
      "total_reward: 7886825.41\n",
      "total_cost: 158615.89\n",
      "total_trades: 56382\n",
      "Sharpe: 0.962\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 988         |\n",
      "|    time_elapsed         | 18075       |\n",
      "|    total_timesteps      | 2023424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015372555 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 9870        |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    reward               | 0.61204857  |\n",
      "|    std                  | 3.88        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 989         |\n",
      "|    time_elapsed         | 18094       |\n",
      "|    total_timesteps      | 2025472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013074424 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.5        |\n",
      "|    n_updates            | 9880        |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    reward               | 0.2098615   |\n",
      "|    std                  | 3.88        |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 990         |\n",
      "|    time_elapsed         | 18113       |\n",
      "|    total_timesteps      | 2027520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007736617 |\n",
      "|    clip_fraction        | 0.0946      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.8        |\n",
      "|    n_updates            | 9890        |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    reward               | 3.571264    |\n",
      "|    std                  | 3.88        |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 991         |\n",
      "|    time_elapsed         | 18132       |\n",
      "|    total_timesteps      | 2029568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011201459 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 9900        |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    reward               | 0.3790013   |\n",
      "|    std                  | 3.89        |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 992         |\n",
      "|    time_elapsed         | 18150       |\n",
      "|    total_timesteps      | 2031616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016116474 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.2       |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 9910        |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | -1.8970546  |\n",
      "|    std                  | 3.9         |\n",
      "|    value_loss           | 236         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 993         |\n",
      "|    time_elapsed         | 18169       |\n",
      "|    total_timesteps      | 2033664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012102412 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.2       |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.4        |\n",
      "|    n_updates            | 9920        |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    reward               | 14.092044   |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 246         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 994         |\n",
      "|    time_elapsed         | 18189       |\n",
      "|    total_timesteps      | 2035712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011870699 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.3       |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.9        |\n",
      "|    n_updates            | 9930        |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | 0.36321315  |\n",
      "|    std                  | 3.92        |\n",
      "|    value_loss           | 88.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 995         |\n",
      "|    time_elapsed         | 18208       |\n",
      "|    total_timesteps      | 2037760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012825979 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.3       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.4        |\n",
      "|    n_updates            | 9940        |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    reward               | -1.3246195  |\n",
      "|    std                  | 3.92        |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 996         |\n",
      "|    time_elapsed         | 18226       |\n",
      "|    total_timesteps      | 2039808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013257375 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.3       |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.5        |\n",
      "|    n_updates            | 9950        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 1.0165895   |\n",
      "|    std                  | 3.92        |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 997         |\n",
      "|    time_elapsed         | 18245       |\n",
      "|    total_timesteps      | 2041856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006308576 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 9960        |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    reward               | -25.067192  |\n",
      "|    std                  | 3.93        |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 998         |\n",
      "|    time_elapsed         | 18264       |\n",
      "|    total_timesteps      | 2043904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015245618 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 9970        |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | -2.4181461  |\n",
      "|    std                  | 3.94        |\n",
      "|    value_loss           | 44.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 999         |\n",
      "|    time_elapsed         | 18283       |\n",
      "|    total_timesteps      | 2045952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008577175 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 9980        |\n",
      "|    policy_gradient_loss | -0.00991    |\n",
      "|    reward               | -0.8189064  |\n",
      "|    std                  | 3.93        |\n",
      "|    value_loss           | 292         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1000        |\n",
      "|    time_elapsed         | 18301       |\n",
      "|    total_timesteps      | 2048000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016566414 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.5       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 163         |\n",
      "|    n_updates            | 9990        |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    reward               | 0.019637547 |\n",
      "|    std                  | 3.94        |\n",
      "|    value_loss           | 247         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1001        |\n",
      "|    time_elapsed         | 18320       |\n",
      "|    total_timesteps      | 2050048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010492396 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.5       |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 10000       |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    reward               | -1.1078324  |\n",
      "|    std                  | 3.95        |\n",
      "|    value_loss           | 78.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9401939.45\n",
      "total_reward: 8401939.45\n",
      "total_cost: 189097.92\n",
      "total_trades: 59039\n",
      "Sharpe: 0.995\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1002        |\n",
      "|    time_elapsed         | 18339       |\n",
      "|    total_timesteps      | 2052096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010855235 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71          |\n",
      "|    n_updates            | 10010       |\n",
      "|    policy_gradient_loss | -0.00909    |\n",
      "|    reward               | -1.0128304  |\n",
      "|    std                  | 3.96        |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1003        |\n",
      "|    time_elapsed         | 18358       |\n",
      "|    total_timesteps      | 2054144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014423484 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.6        |\n",
      "|    n_updates            | 10020       |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | 0.28320587  |\n",
      "|    std                  | 3.96        |\n",
      "|    value_loss           | 216         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1004        |\n",
      "|    time_elapsed         | 18376       |\n",
      "|    total_timesteps      | 2056192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010223435 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.5        |\n",
      "|    n_updates            | 10030       |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    reward               | 2.4174092   |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 268         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1005        |\n",
      "|    time_elapsed         | 18395       |\n",
      "|    total_timesteps      | 2058240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012256915 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.7       |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 10040       |\n",
      "|    policy_gradient_loss | -0.00545    |\n",
      "|    reward               | 3.4251707   |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1006        |\n",
      "|    time_elapsed         | 18414       |\n",
      "|    total_timesteps      | 2060288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013332896 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.7       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 10050       |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    reward               | -1.5412732  |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 240         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1007         |\n",
      "|    time_elapsed         | 18432        |\n",
      "|    total_timesteps      | 2062336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108081205 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80.7        |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 115          |\n",
      "|    n_updates            | 10060        |\n",
      "|    policy_gradient_loss | -0.00549     |\n",
      "|    reward               | -3.937319    |\n",
      "|    std                  | 3.98         |\n",
      "|    value_loss           | 229          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1008         |\n",
      "|    time_elapsed         | 18451        |\n",
      "|    total_timesteps      | 2064384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0136485975 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80.8        |\n",
      "|    explained_variance   | 0.788        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30           |\n",
      "|    n_updates            | 10070        |\n",
      "|    policy_gradient_loss | -0.00833     |\n",
      "|    reward               | 0.17033617   |\n",
      "|    std                  | 3.99         |\n",
      "|    value_loss           | 63.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1009         |\n",
      "|    time_elapsed         | 18471        |\n",
      "|    total_timesteps      | 2066432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113233505 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80.9        |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.6         |\n",
      "|    n_updates            | 10080        |\n",
      "|    policy_gradient_loss | -0.00895     |\n",
      "|    reward               | -0.71998656  |\n",
      "|    std                  | 4            |\n",
      "|    value_loss           | 212          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1010        |\n",
      "|    time_elapsed         | 18489       |\n",
      "|    total_timesteps      | 2068480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012731446 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.9       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.7        |\n",
      "|    n_updates            | 10090       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 34.00545    |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 273         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1011        |\n",
      "|    time_elapsed         | 18508       |\n",
      "|    total_timesteps      | 2070528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010957707 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 10100       |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    reward               | -2.2497075  |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 250         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1012        |\n",
      "|    time_elapsed         | 18526       |\n",
      "|    total_timesteps      | 2072576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013017598 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 10110       |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    reward               | -0.82170695 |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 40.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1013       |\n",
      "|    time_elapsed         | 18545      |\n",
      "|    total_timesteps      | 2074624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01007453 |\n",
      "|    clip_fraction        | 0.0987     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81        |\n",
      "|    explained_variance   | 0.78       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 184        |\n",
      "|    n_updates            | 10120      |\n",
      "|    policy_gradient_loss | -0.00415   |\n",
      "|    reward               | -1.7106763 |\n",
      "|    std                  | 4.01       |\n",
      "|    value_loss           | 240        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1014       |\n",
      "|    time_elapsed         | 18564      |\n",
      "|    total_timesteps      | 2076672    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00835113 |\n",
      "|    clip_fraction        | 0.0395     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81        |\n",
      "|    explained_variance   | 0.681      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 74.2       |\n",
      "|    n_updates            | 10130      |\n",
      "|    policy_gradient_loss | -0.00583   |\n",
      "|    reward               | -4.816522  |\n",
      "|    std                  | 4.02       |\n",
      "|    value_loss           | 337        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1015        |\n",
      "|    time_elapsed         | 18582       |\n",
      "|    total_timesteps      | 2078720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013184656 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.1       |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 10140       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    reward               | -0.18516558 |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 56.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9843002.09\n",
      "total_reward: 8843002.09\n",
      "total_cost: 186460.92\n",
      "total_trades: 59354\n",
      "Sharpe: 0.999\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1016        |\n",
      "|    time_elapsed         | 18601       |\n",
      "|    total_timesteps      | 2080768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011836615 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.1       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.7        |\n",
      "|    n_updates            | 10150       |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    reward               | 0.4942004   |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 231         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1017        |\n",
      "|    time_elapsed         | 18619       |\n",
      "|    total_timesteps      | 2082816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008153035 |\n",
      "|    clip_fraction        | 0.0413      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.6        |\n",
      "|    n_updates            | 10160       |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    reward               | 2.6469438   |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 241         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1018       |\n",
      "|    time_elapsed         | 18638      |\n",
      "|    total_timesteps      | 2084864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01874055 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.2      |\n",
      "|    explained_variance   | 0.85       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 43.2       |\n",
      "|    n_updates            | 10170      |\n",
      "|    policy_gradient_loss | -0.00315   |\n",
      "|    reward               | -2.3029764 |\n",
      "|    std                  | 4.04       |\n",
      "|    value_loss           | 93.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1019        |\n",
      "|    time_elapsed         | 18657       |\n",
      "|    total_timesteps      | 2086912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011997446 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44          |\n",
      "|    n_updates            | 10180       |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    reward               | 0.7933926   |\n",
      "|    std                  | 4.06        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1020        |\n",
      "|    time_elapsed         | 18676       |\n",
      "|    total_timesteps      | 2088960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010060695 |\n",
      "|    clip_fraction        | 0.0734      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 10190       |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    reward               | -0.18434618 |\n",
      "|    std                  | 4.06        |\n",
      "|    value_loss           | 255         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1021         |\n",
      "|    time_elapsed         | 18695        |\n",
      "|    total_timesteps      | 2091008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090534445 |\n",
      "|    clip_fraction        | 0.0837       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.3        |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.9         |\n",
      "|    n_updates            | 10200        |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    reward               | 1.8221699    |\n",
      "|    std                  | 4.06         |\n",
      "|    value_loss           | 277          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1022        |\n",
      "|    time_elapsed         | 18713       |\n",
      "|    total_timesteps      | 2093056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012897406 |\n",
      "|    clip_fraction        | 0.0897      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 10210       |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    reward               | -1.5941358  |\n",
      "|    std                  | 4.06        |\n",
      "|    value_loss           | 61.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1023        |\n",
      "|    time_elapsed         | 18732       |\n",
      "|    total_timesteps      | 2095104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010169604 |\n",
      "|    clip_fraction        | 0.0858      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 211         |\n",
      "|    n_updates            | 10220       |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    reward               | -0.15142125 |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 340         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1024         |\n",
      "|    time_elapsed         | 18751        |\n",
      "|    total_timesteps      | 2097152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058584567 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.4        |\n",
      "|    explained_variance   | 0.707        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 147          |\n",
      "|    n_updates            | 10230        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    reward               | -22.162903   |\n",
      "|    std                  | 4.07         |\n",
      "|    value_loss           | 283          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1025        |\n",
      "|    time_elapsed         | 18770       |\n",
      "|    total_timesteps      | 2099200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009435077 |\n",
      "|    clip_fraction        | 0.0698      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.4        |\n",
      "|    n_updates            | 10240       |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    reward               | 8.834074    |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 98.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1026         |\n",
      "|    time_elapsed         | 18789        |\n",
      "|    total_timesteps      | 2101248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009892112  |\n",
      "|    clip_fraction        | 0.0824       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.5        |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 148          |\n",
      "|    n_updates            | 10250        |\n",
      "|    policy_gradient_loss | -0.00781     |\n",
      "|    reward               | -0.084624544 |\n",
      "|    std                  | 4.08         |\n",
      "|    value_loss           | 212          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1027        |\n",
      "|    time_elapsed         | 18807       |\n",
      "|    total_timesteps      | 2103296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015227196 |\n",
      "|    clip_fraction        | 0.0913      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 10260       |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    reward               | 0.59959877  |\n",
      "|    std                  | 4.09        |\n",
      "|    value_loss           | 306         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1028       |\n",
      "|    time_elapsed         | 18826      |\n",
      "|    total_timesteps      | 2105344    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01081954 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.6      |\n",
      "|    explained_variance   | 0.597      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 71         |\n",
      "|    n_updates            | 10270      |\n",
      "|    policy_gradient_loss | -0.00561   |\n",
      "|    reward               | 5.0243173  |\n",
      "|    std                  | 4.09       |\n",
      "|    value_loss           | 366        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1029        |\n",
      "|    time_elapsed         | 18845       |\n",
      "|    total_timesteps      | 2107392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013831187 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 10280       |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    reward               | 0.39760426  |\n",
      "|    std                  | 4.1         |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10857587.41\n",
      "total_reward: 9857587.41\n",
      "total_cost: 160383.17\n",
      "total_trades: 57803\n",
      "Sharpe: 1.020\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1030        |\n",
      "|    time_elapsed         | 18863       |\n",
      "|    total_timesteps      | 2109440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033277716 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 300         |\n",
      "|    n_updates            | 10290       |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    reward               | -0.07043918 |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 283         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1031        |\n",
      "|    time_elapsed         | 18882       |\n",
      "|    total_timesteps      | 2111488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008085909 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 10300       |\n",
      "|    policy_gradient_loss | -0.00523    |\n",
      "|    reward               | -0.27155018 |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 285         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1032        |\n",
      "|    time_elapsed         | 18901       |\n",
      "|    total_timesteps      | 2113536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009462163 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.1        |\n",
      "|    n_updates            | 10310       |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | 1.2473266   |\n",
      "|    std                  | 4.12        |\n",
      "|    value_loss           | 74          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1033        |\n",
      "|    time_elapsed         | 18920       |\n",
      "|    total_timesteps      | 2115584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012452476 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 10320       |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    reward               | 0.96479934  |\n",
      "|    std                  | 4.12        |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1034        |\n",
      "|    time_elapsed         | 18939       |\n",
      "|    total_timesteps      | 2117632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008701015 |\n",
      "|    clip_fraction        | 0.0428      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.8       |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 10330       |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    reward               | 37.07904    |\n",
      "|    std                  | 4.12        |\n",
      "|    value_loss           | 292         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1035       |\n",
      "|    time_elapsed         | 18957      |\n",
      "|    total_timesteps      | 2119680    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00824579 |\n",
      "|    clip_fraction        | 0.0848     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.8      |\n",
      "|    explained_variance   | 0.688      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 96.7       |\n",
      "|    n_updates            | 10340      |\n",
      "|    policy_gradient_loss | -0.00726   |\n",
      "|    reward               | -1.3477185 |\n",
      "|    std                  | 4.13       |\n",
      "|    value_loss           | 246        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1036        |\n",
      "|    time_elapsed         | 18976       |\n",
      "|    total_timesteps      | 2121728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013397593 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.8       |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 10350       |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    reward               | -0.12943445 |\n",
      "|    std                  | 4.13        |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1037        |\n",
      "|    time_elapsed         | 18994       |\n",
      "|    total_timesteps      | 2123776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016227227 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.6        |\n",
      "|    n_updates            | 10360       |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    reward               | 0.32030335  |\n",
      "|    std                  | 4.14        |\n",
      "|    value_loss           | 271         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1038        |\n",
      "|    time_elapsed         | 19013       |\n",
      "|    total_timesteps      | 2125824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013332974 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 123         |\n",
      "|    n_updates            | 10370       |\n",
      "|    policy_gradient_loss | -0.00657    |\n",
      "|    reward               | -0.14541648 |\n",
      "|    std                  | 4.14        |\n",
      "|    value_loss           | 263         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1039       |\n",
      "|    time_elapsed         | 19032      |\n",
      "|    total_timesteps      | 2127872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01521973 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82        |\n",
      "|    explained_variance   | 0.837      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.9       |\n",
      "|    n_updates            | 10380      |\n",
      "|    policy_gradient_loss | -0.00746   |\n",
      "|    reward               | -1.2775924 |\n",
      "|    std                  | 4.15       |\n",
      "|    value_loss           | 42.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1040       |\n",
      "|    time_elapsed         | 19051      |\n",
      "|    total_timesteps      | 2129920    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01005157 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82        |\n",
      "|    explained_variance   | 0.767      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 106        |\n",
      "|    n_updates            | 10390      |\n",
      "|    policy_gradient_loss | -0.00812   |\n",
      "|    reward               | -1.1822058 |\n",
      "|    std                  | 4.16       |\n",
      "|    value_loss           | 211        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1041        |\n",
      "|    time_elapsed         | 19069       |\n",
      "|    total_timesteps      | 2131968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012272979 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 282         |\n",
      "|    n_updates            | 10400       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 1.4435244   |\n",
      "|    std                  | 4.17        |\n",
      "|    value_loss           | 307         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1042        |\n",
      "|    time_elapsed         | 19088       |\n",
      "|    total_timesteps      | 2134016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010465307 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 10410       |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    reward               | -0.9894307  |\n",
      "|    std                  | 4.17        |\n",
      "|    value_loss           | 89.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1043        |\n",
      "|    time_elapsed         | 19106       |\n",
      "|    total_timesteps      | 2136064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012696108 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.9        |\n",
      "|    n_updates            | 10420       |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | -0.3690692  |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10083135.56\n",
      "total_reward: 9083135.56\n",
      "total_cost: 184233.78\n",
      "total_trades: 58852\n",
      "Sharpe: 1.031\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1044       |\n",
      "|    time_elapsed         | 19125      |\n",
      "|    total_timesteps      | 2138112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01195707 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.2      |\n",
      "|    explained_variance   | 0.77       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 120        |\n",
      "|    n_updates            | 10430      |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    reward               | 0.95184577 |\n",
      "|    std                  | 4.18       |\n",
      "|    value_loss           | 260        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1045        |\n",
      "|    time_elapsed         | 19143       |\n",
      "|    total_timesteps      | 2140160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016624367 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 10440       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 0.12388588  |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1046        |\n",
      "|    time_elapsed         | 19162       |\n",
      "|    total_timesteps      | 2142208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013980875 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 10450       |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | -0.29968184 |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1047        |\n",
      "|    time_elapsed         | 19181       |\n",
      "|    total_timesteps      | 2144256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011785416 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53          |\n",
      "|    n_updates            | 10460       |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    reward               | -1.1300762  |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1048        |\n",
      "|    time_elapsed         | 19200       |\n",
      "|    total_timesteps      | 2146304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012413059 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 10470       |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    reward               | 0.6215828   |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 229         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1049        |\n",
      "|    time_elapsed         | 19218       |\n",
      "|    total_timesteps      | 2148352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017357625 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.8        |\n",
      "|    n_updates            | 10480       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -3.094596   |\n",
      "|    std                  | 4.2         |\n",
      "|    value_loss           | 70.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1050       |\n",
      "|    time_elapsed         | 19237      |\n",
      "|    total_timesteps      | 2150400    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01329245 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.3      |\n",
      "|    explained_variance   | 0.518      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 43.4       |\n",
      "|    n_updates            | 10490      |\n",
      "|    policy_gradient_loss | -0.00966   |\n",
      "|    reward               | -1.0931683 |\n",
      "|    std                  | 4.21       |\n",
      "|    value_loss           | 195        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1051        |\n",
      "|    time_elapsed         | 19256       |\n",
      "|    total_timesteps      | 2152448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007706687 |\n",
      "|    clip_fraction        | 0.07        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.4       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.6        |\n",
      "|    n_updates            | 10500       |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    reward               | 0.23542954  |\n",
      "|    std                  | 4.21        |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1052        |\n",
      "|    time_elapsed         | 19275       |\n",
      "|    total_timesteps      | 2154496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010596838 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.4       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.7        |\n",
      "|    n_updates            | 10510       |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    reward               | -0.66884404 |\n",
      "|    std                  | 4.22        |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1053        |\n",
      "|    time_elapsed         | 19294       |\n",
      "|    total_timesteps      | 2156544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018457174 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 10520       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -0.9326179  |\n",
      "|    std                  | 4.23        |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1054        |\n",
      "|    time_elapsed         | 19312       |\n",
      "|    total_timesteps      | 2158592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010953659 |\n",
      "|    clip_fraction        | 0.0977      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.7        |\n",
      "|    n_updates            | 10530       |\n",
      "|    policy_gradient_loss | -0.0071     |\n",
      "|    reward               | 0.5283726   |\n",
      "|    std                  | 4.24        |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1055        |\n",
      "|    time_elapsed         | 19331       |\n",
      "|    total_timesteps      | 2160640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007225302 |\n",
      "|    clip_fraction        | 0.0757      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.6       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 10540       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    reward               | 14.871294   |\n",
      "|    std                  | 4.25        |\n",
      "|    value_loss           | 267         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1056        |\n",
      "|    time_elapsed         | 19363       |\n",
      "|    total_timesteps      | 2162688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005899183 |\n",
      "|    clip_fraction        | 0.0279      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.6       |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 10550       |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    reward               | -1.8349998  |\n",
      "|    std                  | 4.26        |\n",
      "|    value_loss           | 57.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1057        |\n",
      "|    time_elapsed         | 19382       |\n",
      "|    total_timesteps      | 2164736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010372303 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.4        |\n",
      "|    n_updates            | 10560       |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    reward               | -1.0397137  |\n",
      "|    std                  | 4.26        |\n",
      "|    value_loss           | 190         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1058        |\n",
      "|    time_elapsed         | 19400       |\n",
      "|    total_timesteps      | 2166784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011189124 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 10570       |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    reward               | -61.902493  |\n",
      "|    std                  | 4.26        |\n",
      "|    value_loss           | 222         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9834015.66\n",
      "total_reward: 8834015.66\n",
      "total_cost: 152073.27\n",
      "total_trades: 57388\n",
      "Sharpe: 1.035\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1059        |\n",
      "|    time_elapsed         | 19419       |\n",
      "|    total_timesteps      | 2168832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008806499 |\n",
      "|    clip_fraction        | 0.0641      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 311         |\n",
      "|    n_updates            | 10580       |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    reward               | -1.484345   |\n",
      "|    std                  | 4.27        |\n",
      "|    value_loss           | 293         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1060         |\n",
      "|    time_elapsed         | 19438        |\n",
      "|    total_timesteps      | 2170880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0128005445 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.8        |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 10590        |\n",
      "|    policy_gradient_loss | -0.0098      |\n",
      "|    reward               | -0.12971886  |\n",
      "|    std                  | 4.27         |\n",
      "|    value_loss           | 70.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1061         |\n",
      "|    time_elapsed         | 19456        |\n",
      "|    total_timesteps      | 2172928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012131998  |\n",
      "|    clip_fraction        | 0.0986       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.8        |\n",
      "|    explained_variance   | 0.783        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.1         |\n",
      "|    n_updates            | 10600        |\n",
      "|    policy_gradient_loss | -0.00787     |\n",
      "|    reward               | 0.0016164482 |\n",
      "|    std                  | 4.28         |\n",
      "|    value_loss           | 224          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1062        |\n",
      "|    time_elapsed         | 19475       |\n",
      "|    total_timesteps      | 2174976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008429445 |\n",
      "|    clip_fraction        | 0.0599      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.9        |\n",
      "|    n_updates            | 10610       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | -4.8045497  |\n",
      "|    std                  | 4.29        |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1063        |\n",
      "|    time_elapsed         | 19494       |\n",
      "|    total_timesteps      | 2177024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011157694 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 10620       |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    reward               | 2.058371    |\n",
      "|    std                  | 4.3         |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1064        |\n",
      "|    time_elapsed         | 19512       |\n",
      "|    total_timesteps      | 2179072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015667837 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83         |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.1        |\n",
      "|    n_updates            | 10630       |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    reward               | 0.79139316  |\n",
      "|    std                  | 4.31        |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1065        |\n",
      "|    time_elapsed         | 19532       |\n",
      "|    total_timesteps      | 2181120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006004888 |\n",
      "|    clip_fraction        | 0.0527      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83         |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 10640       |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | 6.643481    |\n",
      "|    std                  | 4.32        |\n",
      "|    value_loss           | 222         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1066        |\n",
      "|    time_elapsed         | 19551       |\n",
      "|    total_timesteps      | 2183168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00938189  |\n",
      "|    clip_fraction        | 0.0608      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.1       |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.5        |\n",
      "|    n_updates            | 10650       |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    reward               | -0.28468645 |\n",
      "|    std                  | 4.32        |\n",
      "|    value_loss           | 88.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1067         |\n",
      "|    time_elapsed         | 19570        |\n",
      "|    total_timesteps      | 2185216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0130389845 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.1        |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.5         |\n",
      "|    n_updates            | 10660        |\n",
      "|    policy_gradient_loss | -0.00763     |\n",
      "|    reward               | -1.092245    |\n",
      "|    std                  | 4.33         |\n",
      "|    value_loss           | 174          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1068        |\n",
      "|    time_elapsed         | 19588       |\n",
      "|    total_timesteps      | 2187264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010453958 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.3        |\n",
      "|    n_updates            | 10670       |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    reward               | -1.7189324  |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 209         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1069        |\n",
      "|    time_elapsed         | 19607       |\n",
      "|    total_timesteps      | 2189312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009123791 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.5        |\n",
      "|    n_updates            | 10680       |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    reward               | 1.5970441   |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 299         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1070        |\n",
      "|    time_elapsed         | 19626       |\n",
      "|    total_timesteps      | 2191360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011553248 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.39        |\n",
      "|    n_updates            | 10690       |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | 1.2578372   |\n",
      "|    std                  | 4.34        |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1071        |\n",
      "|    time_elapsed         | 19645       |\n",
      "|    total_timesteps      | 2193408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016252236 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.5        |\n",
      "|    n_updates            | 10700       |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    reward               | 0.93223584  |\n",
      "|    std                  | 4.35        |\n",
      "|    value_loss           | 224         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1072        |\n",
      "|    time_elapsed         | 19663       |\n",
      "|    total_timesteps      | 2195456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010634622 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.7        |\n",
      "|    n_updates            | 10710       |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | 11.716282   |\n",
      "|    std                  | 4.35        |\n",
      "|    value_loss           | 271         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10392368.18\n",
      "total_reward: 9392368.18\n",
      "total_cost: 158685.27\n",
      "total_trades: 58581\n",
      "Sharpe: 1.042\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1073        |\n",
      "|    time_elapsed         | 19682       |\n",
      "|    total_timesteps      | 2197504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004181508 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 10720       |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    reward               | 1.5001243   |\n",
      "|    std                  | 4.35        |\n",
      "|    value_loss           | 74          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1074        |\n",
      "|    time_elapsed         | 19701       |\n",
      "|    total_timesteps      | 2199552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013169693 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95          |\n",
      "|    n_updates            | 10730       |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    reward               | 3.0063994   |\n",
      "|    std                  | 4.36        |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1075         |\n",
      "|    time_elapsed         | 19720        |\n",
      "|    total_timesteps      | 2201600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124253025 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.3        |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 199          |\n",
      "|    n_updates            | 10740        |\n",
      "|    policy_gradient_loss | -0.0085      |\n",
      "|    reward               | 0.45956525   |\n",
      "|    std                  | 4.37         |\n",
      "|    value_loss           | 275          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1076        |\n",
      "|    time_elapsed         | 19739       |\n",
      "|    total_timesteps      | 2203648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011685487 |\n",
      "|    clip_fraction        | 0.0737      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 10750       |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    reward               | 0.68329865  |\n",
      "|    std                  | 4.38        |\n",
      "|    value_loss           | 286         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1077        |\n",
      "|    time_elapsed         | 19757       |\n",
      "|    total_timesteps      | 2205696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007975018 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.5       |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 10760       |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    reward               | 1.0922917   |\n",
      "|    std                  | 4.38        |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1078        |\n",
      "|    time_elapsed         | 19777       |\n",
      "|    total_timesteps      | 2207744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015029876 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.5       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.4        |\n",
      "|    n_updates            | 10770       |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    reward               | 0.2721647   |\n",
      "|    std                  | 4.39        |\n",
      "|    value_loss           | 289         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1079       |\n",
      "|    time_elapsed         | 19798      |\n",
      "|    total_timesteps      | 2209792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01010623 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.6      |\n",
      "|    explained_variance   | 0.708      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 179        |\n",
      "|    n_updates            | 10780      |\n",
      "|    policy_gradient_loss | -0.00914   |\n",
      "|    reward               | 1.992259   |\n",
      "|    std                  | 4.4        |\n",
      "|    value_loss           | 318        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1080        |\n",
      "|    time_elapsed         | 19817       |\n",
      "|    total_timesteps      | 2211840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010710526 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.6       |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 10790       |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    reward               | -0.2791337  |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 75.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1081        |\n",
      "|    time_elapsed         | 19835       |\n",
      "|    total_timesteps      | 2213888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013594638 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44          |\n",
      "|    n_updates            | 10800       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 0.33887327  |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 301         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1082         |\n",
      "|    time_elapsed         | 19854        |\n",
      "|    total_timesteps      | 2215936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151121635 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.7        |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 135          |\n",
      "|    n_updates            | 10810        |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    reward               | -0.9731553   |\n",
      "|    std                  | 4.42         |\n",
      "|    value_loss           | 380          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1083        |\n",
      "|    time_elapsed         | 19873       |\n",
      "|    total_timesteps      | 2217984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009569029 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.8        |\n",
      "|    n_updates            | 10820       |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    reward               | -3.008909   |\n",
      "|    std                  | 4.42        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1084        |\n",
      "|    time_elapsed         | 19892       |\n",
      "|    total_timesteps      | 2220032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012377333 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.5        |\n",
      "|    n_updates            | 10830       |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    reward               | 0.006345196 |\n",
      "|    std                  | 4.42        |\n",
      "|    value_loss           | 222         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1085        |\n",
      "|    time_elapsed         | 19910       |\n",
      "|    total_timesteps      | 2222080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014692439 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94          |\n",
      "|    n_updates            | 10840       |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    reward               | 0.22618477  |\n",
      "|    std                  | 4.44        |\n",
      "|    value_loss           | 290         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1086        |\n",
      "|    time_elapsed         | 19929       |\n",
      "|    total_timesteps      | 2224128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008778814 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 10850       |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    reward               | -2.5716364  |\n",
      "|    std                  | 4.45        |\n",
      "|    value_loss           | 354         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10600962.57\n",
      "total_reward: 9600962.57\n",
      "total_cost: 146319.86\n",
      "total_trades: 58940\n",
      "Sharpe: 1.037\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1087        |\n",
      "|    time_elapsed         | 19948       |\n",
      "|    total_timesteps      | 2226176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012781713 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 10860       |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    reward               | 2.9879296   |\n",
      "|    std                  | 4.46        |\n",
      "|    value_loss           | 51.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1088        |\n",
      "|    time_elapsed         | 19967       |\n",
      "|    total_timesteps      | 2228224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011889176 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 10870       |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    reward               | -1.7402325  |\n",
      "|    std                  | 4.47        |\n",
      "|    value_loss           | 272         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1089         |\n",
      "|    time_elapsed         | 19986        |\n",
      "|    total_timesteps      | 2230272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0118742185 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.1        |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 101          |\n",
      "|    n_updates            | 10880        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | 9.997702     |\n",
      "|    std                  | 4.48         |\n",
      "|    value_loss           | 336          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1090        |\n",
      "|    time_elapsed         | 20005       |\n",
      "|    total_timesteps      | 2232320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013280023 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43          |\n",
      "|    n_updates            | 10890       |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    reward               | -0.7286014  |\n",
      "|    std                  | 4.49        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1091        |\n",
      "|    time_elapsed         | 20024       |\n",
      "|    total_timesteps      | 2234368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022723109 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.2       |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 10900       |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    reward               | -1.6874644  |\n",
      "|    std                  | 4.5         |\n",
      "|    value_loss           | 266         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1092        |\n",
      "|    time_elapsed         | 20043       |\n",
      "|    total_timesteps      | 2236416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008318246 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.2       |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 10910       |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    reward               | -1.1168641  |\n",
      "|    std                  | 4.5         |\n",
      "|    value_loss           | 347         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1093        |\n",
      "|    time_elapsed         | 20061       |\n",
      "|    total_timesteps      | 2238464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008831227 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94          |\n",
      "|    n_updates            | 10920       |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    reward               | -2.6701856  |\n",
      "|    std                  | 4.5         |\n",
      "|    value_loss           | 374         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1094        |\n",
      "|    time_elapsed         | 20081       |\n",
      "|    total_timesteps      | 2240512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012879906 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 10930       |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    reward               | 2.8875327   |\n",
      "|    std                  | 4.51        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1095        |\n",
      "|    time_elapsed         | 20101       |\n",
      "|    total_timesteps      | 2242560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009670369 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.1        |\n",
      "|    n_updates            | 10940       |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    reward               | -0.46874738 |\n",
      "|    std                  | 4.52        |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1096        |\n",
      "|    time_elapsed         | 20120       |\n",
      "|    total_timesteps      | 2244608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005594805 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.2        |\n",
      "|    n_updates            | 10950       |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    reward               | -11.241672  |\n",
      "|    std                  | 4.52        |\n",
      "|    value_loss           | 256         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1097        |\n",
      "|    time_elapsed         | 20138       |\n",
      "|    total_timesteps      | 2246656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009444242 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 10960       |\n",
      "|    policy_gradient_loss | -0.00681    |\n",
      "|    reward               | -0.4292646  |\n",
      "|    std                  | 4.53        |\n",
      "|    value_loss           | 80.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1098        |\n",
      "|    time_elapsed         | 20157       |\n",
      "|    total_timesteps      | 2248704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01560562  |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 10970       |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    reward               | -0.10147195 |\n",
      "|    std                  | 4.54        |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1099        |\n",
      "|    time_elapsed         | 20176       |\n",
      "|    total_timesteps      | 2250752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007857818 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 10980       |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | 10.985432   |\n",
      "|    std                  | 4.55        |\n",
      "|    value_loss           | 229         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1100        |\n",
      "|    time_elapsed         | 20195       |\n",
      "|    total_timesteps      | 2252800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007828027 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 264         |\n",
      "|    n_updates            | 10990       |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    reward               | 0.11912834  |\n",
      "|    std                  | 4.55        |\n",
      "|    value_loss           | 263         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10743186.45\n",
      "total_reward: 9743186.45\n",
      "total_cost: 192058.76\n",
      "total_trades: 60973\n",
      "Sharpe: 1.067\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1101        |\n",
      "|    time_elapsed         | 20214       |\n",
      "|    total_timesteps      | 2254848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011310076 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 11000       |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    reward               | 4.361568    |\n",
      "|    std                  | 4.56        |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1102        |\n",
      "|    time_elapsed         | 20232       |\n",
      "|    total_timesteps      | 2256896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008603337 |\n",
      "|    clip_fraction        | 0.0727      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 11010       |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    reward               | 0.43911317  |\n",
      "|    std                  | 4.56        |\n",
      "|    value_loss           | 249         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1103        |\n",
      "|    time_elapsed         | 20251       |\n",
      "|    total_timesteps      | 2258944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007323419 |\n",
      "|    clip_fraction        | 0.0376      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 11020       |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    reward               | 7.930118    |\n",
      "|    std                  | 4.56        |\n",
      "|    value_loss           | 290         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1104        |\n",
      "|    time_elapsed         | 20270       |\n",
      "|    total_timesteps      | 2260992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013277577 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 11030       |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    reward               | 3.847456    |\n",
      "|    std                  | 4.57        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1105         |\n",
      "|    time_elapsed         | 20289        |\n",
      "|    total_timesteps      | 2263040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088560805 |\n",
      "|    clip_fraction        | 0.067        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.7        |\n",
      "|    explained_variance   | 0.795        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82.2         |\n",
      "|    n_updates            | 11040        |\n",
      "|    policy_gradient_loss | -0.0072      |\n",
      "|    reward               | -3.9687898   |\n",
      "|    std                  | 4.57         |\n",
      "|    value_loss           | 214          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1106          |\n",
      "|    time_elapsed         | 20308         |\n",
      "|    total_timesteps      | 2265088       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008596523   |\n",
      "|    clip_fraction        | 0.0401        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -84.7         |\n",
      "|    explained_variance   | 0.78          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 116           |\n",
      "|    n_updates            | 11050         |\n",
      "|    policy_gradient_loss | -0.00573      |\n",
      "|    reward               | -0.0011269437 |\n",
      "|    std                  | 4.58          |\n",
      "|    value_loss           | 280           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1107        |\n",
      "|    time_elapsed         | 20326       |\n",
      "|    total_timesteps      | 2267136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007012535 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.3        |\n",
      "|    n_updates            | 11060       |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    reward               | 1.7811632   |\n",
      "|    std                  | 4.59        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1108        |\n",
      "|    time_elapsed         | 20345       |\n",
      "|    total_timesteps      | 2269184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009183986 |\n",
      "|    clip_fraction        | 0.0751      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 11070       |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    reward               | 2.3723981   |\n",
      "|    std                  | 4.6         |\n",
      "|    value_loss           | 255         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1109        |\n",
      "|    time_elapsed         | 20364       |\n",
      "|    total_timesteps      | 2271232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010119747 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.8        |\n",
      "|    n_updates            | 11080       |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    reward               | 0.06831667  |\n",
      "|    std                  | 4.6         |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1110         |\n",
      "|    time_elapsed         | 20382        |\n",
      "|    total_timesteps      | 2273280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067437664 |\n",
      "|    clip_fraction        | 0.047        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.8        |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.2         |\n",
      "|    n_updates            | 11090        |\n",
      "|    policy_gradient_loss | -0.00759     |\n",
      "|    reward               | 8.985672     |\n",
      "|    std                  | 4.6          |\n",
      "|    value_loss           | 244          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1111        |\n",
      "|    time_elapsed         | 20401       |\n",
      "|    total_timesteps      | 2275328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015213983 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 11100       |\n",
      "|    policy_gradient_loss | -0.00779    |\n",
      "|    reward               | -0.47877643 |\n",
      "|    std                  | 4.6         |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1112        |\n",
      "|    time_elapsed         | 20421       |\n",
      "|    total_timesteps      | 2277376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011025848 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.9       |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 232         |\n",
      "|    n_updates            | 11110       |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    reward               | -1.6202753  |\n",
      "|    std                  | 4.62        |\n",
      "|    value_loss           | 242         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1113        |\n",
      "|    time_elapsed         | 20440       |\n",
      "|    total_timesteps      | 2279424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004875413 |\n",
      "|    clip_fraction        | 0.0197      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.9       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.7        |\n",
      "|    n_updates            | 11120       |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | 6.2230225   |\n",
      "|    std                  | 4.62        |\n",
      "|    value_loss           | 242         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1114        |\n",
      "|    time_elapsed         | 20460       |\n",
      "|    total_timesteps      | 2281472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011287966 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51          |\n",
      "|    n_updates            | 11130       |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | 2.3281765   |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 84.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11469109.18\n",
      "total_reward: 10469109.18\n",
      "total_cost: 138744.16\n",
      "total_trades: 57736\n",
      "Sharpe: 1.066\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1115        |\n",
      "|    time_elapsed         | 20479       |\n",
      "|    total_timesteps      | 2283520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011378831 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 11140       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -1.3534863  |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1116        |\n",
      "|    time_elapsed         | 20497       |\n",
      "|    total_timesteps      | 2285568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008965729 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.9        |\n",
      "|    n_updates            | 11150       |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    reward               | 1.2344652   |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 339         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1117        |\n",
      "|    time_elapsed         | 20516       |\n",
      "|    total_timesteps      | 2287616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008137545 |\n",
      "|    clip_fraction        | 0.0449      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.9        |\n",
      "|    n_updates            | 11160       |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | 3.3621342   |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 325         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1118        |\n",
      "|    time_elapsed         | 20535       |\n",
      "|    total_timesteps      | 2289664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015162185 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.1       |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 11170       |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    reward               | -0.72144    |\n",
      "|    std                  | 4.64        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1119        |\n",
      "|    time_elapsed         | 20554       |\n",
      "|    total_timesteps      | 2291712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009727478 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.1       |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 11180       |\n",
      "|    policy_gradient_loss | -0.00943    |\n",
      "|    reward               | 0.07512517  |\n",
      "|    std                  | 4.65        |\n",
      "|    value_loss           | 269         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1120        |\n",
      "|    time_elapsed         | 20573       |\n",
      "|    total_timesteps      | 2293760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005240365 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.1        |\n",
      "|    n_updates            | 11190       |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    reward               | 1.9802135   |\n",
      "|    std                  | 4.65        |\n",
      "|    value_loss           | 292         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1121        |\n",
      "|    time_elapsed         | 20592       |\n",
      "|    total_timesteps      | 2295808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008943552 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.4        |\n",
      "|    n_updates            | 11200       |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    reward               | -6.743629   |\n",
      "|    std                  | 4.66        |\n",
      "|    value_loss           | 83.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1122        |\n",
      "|    time_elapsed         | 20610       |\n",
      "|    total_timesteps      | 2297856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014367746 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 258         |\n",
      "|    n_updates            | 11210       |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    reward               | 0.19765846  |\n",
      "|    std                  | 4.68        |\n",
      "|    value_loss           | 261         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1123        |\n",
      "|    time_elapsed         | 20629       |\n",
      "|    total_timesteps      | 2299904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006373888 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.8        |\n",
      "|    n_updates            | 11220       |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    reward               | 9.928569    |\n",
      "|    std                  | 4.68        |\n",
      "|    value_loss           | 307         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1124        |\n",
      "|    time_elapsed         | 20648       |\n",
      "|    total_timesteps      | 2301952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008249741 |\n",
      "|    clip_fraction        | 0.0408      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.5        |\n",
      "|    n_updates            | 11230       |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    reward               | 2.5931416   |\n",
      "|    std                  | 4.69        |\n",
      "|    value_loss           | 304         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1125        |\n",
      "|    time_elapsed         | 20667       |\n",
      "|    total_timesteps      | 2304000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007934358 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 11240       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    reward               | 1.6750263   |\n",
      "|    std                  | 4.7         |\n",
      "|    value_loss           | 49.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1126        |\n",
      "|    time_elapsed         | 20685       |\n",
      "|    total_timesteps      | 2306048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009997465 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.9        |\n",
      "|    n_updates            | 11250       |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    reward               | 0.19689839  |\n",
      "|    std                  | 4.7         |\n",
      "|    value_loss           | 291         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1127         |\n",
      "|    time_elapsed         | 20704        |\n",
      "|    total_timesteps      | 2308096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092668515 |\n",
      "|    clip_fraction        | 0.0618       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.5        |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 203          |\n",
      "|    n_updates            | 11260        |\n",
      "|    policy_gradient_loss | -0.00752     |\n",
      "|    reward               | -2.7640505   |\n",
      "|    std                  | 4.71         |\n",
      "|    value_loss           | 302          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1128        |\n",
      "|    time_elapsed         | 20723       |\n",
      "|    total_timesteps      | 2310144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017225072 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.5       |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 11270       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | 3.6032946   |\n",
      "|    std                  | 4.71        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11951886.41\n",
      "total_reward: 10951886.41\n",
      "total_cost: 153649.32\n",
      "total_trades: 58581\n",
      "Sharpe: 1.106\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1129        |\n",
      "|    time_elapsed         | 20742       |\n",
      "|    total_timesteps      | 2312192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011812368 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.5       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 214         |\n",
      "|    n_updates            | 11280       |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    reward               | -3.8507252  |\n",
      "|    std                  | 4.72        |\n",
      "|    value_loss           | 262         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1130        |\n",
      "|    time_elapsed         | 20762       |\n",
      "|    total_timesteps      | 2314240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009887514 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 11290       |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    reward               | 1.0318809   |\n",
      "|    std                  | 4.72        |\n",
      "|    value_loss           | 308         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1131          |\n",
      "|    time_elapsed         | 20782         |\n",
      "|    total_timesteps      | 2316288       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012564704   |\n",
      "|    clip_fraction        | 0.114         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -85.6         |\n",
      "|    explained_variance   | 0.753         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 56.6          |\n",
      "|    n_updates            | 11300         |\n",
      "|    policy_gradient_loss | -0.0118       |\n",
      "|    reward               | -0.0045206663 |\n",
      "|    std                  | 4.73          |\n",
      "|    value_loss           | 111           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1132         |\n",
      "|    time_elapsed         | 20801        |\n",
      "|    total_timesteps      | 2318336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010638665  |\n",
      "|    clip_fraction        | 0.0729       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.6        |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.1         |\n",
      "|    n_updates            | 11310        |\n",
      "|    policy_gradient_loss | -0.00695     |\n",
      "|    reward               | -0.075905085 |\n",
      "|    std                  | 4.74         |\n",
      "|    value_loss           | 224          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1133        |\n",
      "|    time_elapsed         | 20820       |\n",
      "|    total_timesteps      | 2320384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008176839 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.5        |\n",
      "|    n_updates            | 11320       |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    reward               | 1.1481001   |\n",
      "|    std                  | 4.75        |\n",
      "|    value_loss           | 322         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1134        |\n",
      "|    time_elapsed         | 20838       |\n",
      "|    total_timesteps      | 2322432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005128353 |\n",
      "|    clip_fraction        | 0.0214      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 11330       |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    reward               | -15.409184  |\n",
      "|    std                  | 4.75        |\n",
      "|    value_loss           | 298         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1135        |\n",
      "|    time_elapsed         | 20857       |\n",
      "|    total_timesteps      | 2324480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013573156 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 11340       |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    reward               | 0.03682819  |\n",
      "|    std                  | 4.77        |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1136        |\n",
      "|    time_elapsed         | 20876       |\n",
      "|    total_timesteps      | 2326528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010907786 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.9       |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 208         |\n",
      "|    n_updates            | 11350       |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    reward               | -0.12869172 |\n",
      "|    std                  | 4.78        |\n",
      "|    value_loss           | 297         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1137        |\n",
      "|    time_elapsed         | 20895       |\n",
      "|    total_timesteps      | 2328576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011263356 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86         |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 226         |\n",
      "|    n_updates            | 11360       |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    reward               | -0.94482493 |\n",
      "|    std                  | 4.79        |\n",
      "|    value_loss           | 300         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1138        |\n",
      "|    time_elapsed         | 20913       |\n",
      "|    total_timesteps      | 2330624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013730047 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.1       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.2        |\n",
      "|    n_updates            | 11370       |\n",
      "|    policy_gradient_loss | -0.00975    |\n",
      "|    reward               | 3.8519137   |\n",
      "|    std                  | 4.81        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1139        |\n",
      "|    time_elapsed         | 20932       |\n",
      "|    total_timesteps      | 2332672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013023656 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.1       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.5        |\n",
      "|    n_updates            | 11380       |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    reward               | 0.6860532   |\n",
      "|    std                  | 4.81        |\n",
      "|    value_loss           | 316         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1140        |\n",
      "|    time_elapsed         | 20951       |\n",
      "|    total_timesteps      | 2334720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007321622 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.1       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 213         |\n",
      "|    n_updates            | 11390       |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    reward               | -0.7659623  |\n",
      "|    std                  | 4.81        |\n",
      "|    value_loss           | 317         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1141        |\n",
      "|    time_elapsed         | 20969       |\n",
      "|    total_timesteps      | 2336768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009893707 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.2       |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 11400       |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    reward               | 1.6305299   |\n",
      "|    std                  | 4.82        |\n",
      "|    value_loss           | 304         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1142        |\n",
      "|    time_elapsed         | 20988       |\n",
      "|    total_timesteps      | 2338816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010509097 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.2       |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 11410       |\n",
      "|    policy_gradient_loss | -0.00943    |\n",
      "|    reward               | -0.19919327 |\n",
      "|    std                  | 4.81        |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11563459.14\n",
      "total_reward: 10563459.14\n",
      "total_cost: 126219.05\n",
      "total_trades: 56081\n",
      "Sharpe: 1.101\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1143        |\n",
      "|    time_elapsed         | 21007       |\n",
      "|    total_timesteps      | 2340864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010025185 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.2       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 206         |\n",
      "|    n_updates            | 11420       |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    reward               | -0.28585345 |\n",
      "|    std                  | 4.82        |\n",
      "|    value_loss           | 293         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1144       |\n",
      "|    time_elapsed         | 21025      |\n",
      "|    total_timesteps      | 2342912    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01248174 |\n",
      "|    clip_fraction        | 0.0961     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.2      |\n",
      "|    explained_variance   | 0.707      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 137        |\n",
      "|    n_updates            | 11430      |\n",
      "|    policy_gradient_loss | -0.00904   |\n",
      "|    reward               | 16.151402  |\n",
      "|    std                  | 4.82       |\n",
      "|    value_loss           | 313        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1145        |\n",
      "|    time_elapsed         | 21044       |\n",
      "|    total_timesteps      | 2344960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010852696 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.2       |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 11440       |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    reward               | -0.6059698  |\n",
      "|    std                  | 4.83        |\n",
      "|    value_loss           | 57.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1146        |\n",
      "|    time_elapsed         | 21062       |\n",
      "|    total_timesteps      | 2347008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011046762 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.3       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 11450       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | -0.03835746 |\n",
      "|    std                  | 4.83        |\n",
      "|    value_loss           | 246         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1147         |\n",
      "|    time_elapsed         | 21081        |\n",
      "|    total_timesteps      | 2349056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071006883 |\n",
      "|    clip_fraction        | 0.0529       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.3        |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 179          |\n",
      "|    n_updates            | 11460        |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    reward               | 55.640602    |\n",
      "|    std                  | 4.84         |\n",
      "|    value_loss           | 345          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1148        |\n",
      "|    time_elapsed         | 21099       |\n",
      "|    total_timesteps      | 2351104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013244782 |\n",
      "|    clip_fraction        | 0.0753      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.3       |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 11470       |\n",
      "|    policy_gradient_loss | -0.00896    |\n",
      "|    reward               | -3.1541138  |\n",
      "|    std                  | 4.85        |\n",
      "|    value_loss           | 234         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1149         |\n",
      "|    time_elapsed         | 21118        |\n",
      "|    total_timesteps      | 2353152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0131569095 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.4        |\n",
      "|    explained_variance   | 0.827        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 11480        |\n",
      "|    policy_gradient_loss | -0.00913     |\n",
      "|    reward               | -7.7088795   |\n",
      "|    std                  | 4.87         |\n",
      "|    value_loss           | 49.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1150         |\n",
      "|    time_elapsed         | 21137        |\n",
      "|    total_timesteps      | 2355200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077239242 |\n",
      "|    clip_fraction        | 0.0554       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.5        |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 272          |\n",
      "|    n_updates            | 11490        |\n",
      "|    policy_gradient_loss | -0.00754     |\n",
      "|    reward               | 0.733752     |\n",
      "|    std                  | 4.88         |\n",
      "|    value_loss           | 363          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1151        |\n",
      "|    time_elapsed         | 21156       |\n",
      "|    total_timesteps      | 2357248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010922745 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.6       |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 86.3        |\n",
      "|    n_updates            | 11500       |\n",
      "|    policy_gradient_loss | -0.00946    |\n",
      "|    reward               | -9.714485   |\n",
      "|    std                  | 4.89        |\n",
      "|    value_loss           | 343         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1152        |\n",
      "|    time_elapsed         | 21175       |\n",
      "|    total_timesteps      | 2359296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012092406 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 11510       |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    reward               | 9.156246    |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1153        |\n",
      "|    time_elapsed         | 21193       |\n",
      "|    total_timesteps      | 2361344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010695547 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.9        |\n",
      "|    n_updates            | 11520       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | -6.5797634  |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 281         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1154        |\n",
      "|    time_elapsed         | 21212       |\n",
      "|    total_timesteps      | 2363392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006368766 |\n",
      "|    clip_fraction        | 0.0355      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 11530       |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    reward               | -9.449912   |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 326         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1155        |\n",
      "|    time_elapsed         | 21230       |\n",
      "|    total_timesteps      | 2365440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008221143 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.8       |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.8        |\n",
      "|    n_updates            | 11540       |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    reward               | -2.4217062  |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1156        |\n",
      "|    time_elapsed         | 21249       |\n",
      "|    total_timesteps      | 2367488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013007626 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.8       |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 11550       |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    reward               | -0.1145659  |\n",
      "|    std                  | 4.93        |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11569069.26\n",
      "total_reward: 10569069.26\n",
      "total_cost: 135391.08\n",
      "total_trades: 57345\n",
      "Sharpe: 1.096\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1157       |\n",
      "|    time_elapsed         | 21268      |\n",
      "|    total_timesteps      | 2369536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00971864 |\n",
      "|    clip_fraction        | 0.0748     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.8      |\n",
      "|    explained_variance   | 0.811      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 90.4       |\n",
      "|    n_updates            | 11560      |\n",
      "|    policy_gradient_loss | -0.00565   |\n",
      "|    reward               | 0.30796847 |\n",
      "|    std                  | 4.93       |\n",
      "|    value_loss           | 299        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1158        |\n",
      "|    time_elapsed         | 21287       |\n",
      "|    total_timesteps      | 2371584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007727764 |\n",
      "|    clip_fraction        | 0.0254      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 287         |\n",
      "|    n_updates            | 11570       |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    reward               | -0.62724686 |\n",
      "|    std                  | 4.94        |\n",
      "|    value_loss           | 331         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1159        |\n",
      "|    time_elapsed         | 21305       |\n",
      "|    total_timesteps      | 2373632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008649363 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 11580       |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    reward               | 0.59295183  |\n",
      "|    std                  | 4.94        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1160        |\n",
      "|    time_elapsed         | 21324       |\n",
      "|    total_timesteps      | 2375680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010588098 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87         |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 196         |\n",
      "|    n_updates            | 11590       |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | 0.03731978  |\n",
      "|    std                  | 4.96        |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1161         |\n",
      "|    time_elapsed         | 21343        |\n",
      "|    total_timesteps      | 2377728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067056273 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87          |\n",
      "|    explained_variance   | 0.753        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 86           |\n",
      "|    n_updates            | 11600        |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | 0.83737105   |\n",
      "|    std                  | 4.97         |\n",
      "|    value_loss           | 299          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1162        |\n",
      "|    time_elapsed         | 21362       |\n",
      "|    total_timesteps      | 2379776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008829891 |\n",
      "|    clip_fraction        | 0.052       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.7        |\n",
      "|    n_updates            | 11610       |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    reward               | 5.163127    |\n",
      "|    std                  | 4.97        |\n",
      "|    value_loss           | 85.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1163        |\n",
      "|    time_elapsed         | 21380       |\n",
      "|    total_timesteps      | 2381824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009119008 |\n",
      "|    clip_fraction        | 0.0812      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 163         |\n",
      "|    n_updates            | 11620       |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    reward               | 0.23477241  |\n",
      "|    std                  | 4.98        |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1164        |\n",
      "|    time_elapsed         | 21399       |\n",
      "|    total_timesteps      | 2383872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010109387 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 11630       |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    reward               | -0.7316148  |\n",
      "|    std                  | 4.98        |\n",
      "|    value_loss           | 278         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1165        |\n",
      "|    time_elapsed         | 21418       |\n",
      "|    total_timesteps      | 2385920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006713097 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.2       |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57          |\n",
      "|    n_updates            | 11640       |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    reward               | 2.525762    |\n",
      "|    std                  | 4.98        |\n",
      "|    value_loss           | 261         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1166        |\n",
      "|    time_elapsed         | 21437       |\n",
      "|    total_timesteps      | 2387968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013891993 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.2       |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 11650       |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    reward               | -2.134131   |\n",
      "|    std                  | 5           |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1167        |\n",
      "|    time_elapsed         | 21455       |\n",
      "|    total_timesteps      | 2390016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009702993 |\n",
      "|    clip_fraction        | 0.0846      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.3       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.5        |\n",
      "|    n_updates            | 11660       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.08708663 |\n",
      "|    std                  | 5.02        |\n",
      "|    value_loss           | 275         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1168       |\n",
      "|    time_elapsed         | 21474      |\n",
      "|    total_timesteps      | 2392064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01162581 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.4      |\n",
      "|    explained_variance   | 0.68       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 262        |\n",
      "|    n_updates            | 11670      |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    reward               | 8.112345   |\n",
      "|    std                  | 5.03       |\n",
      "|    value_loss           | 271        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1169        |\n",
      "|    time_elapsed         | 21493       |\n",
      "|    total_timesteps      | 2394112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012288971 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.4       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 11680       |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | 5.034403    |\n",
      "|    std                  | 5.05        |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1170        |\n",
      "|    time_elapsed         | 21512       |\n",
      "|    total_timesteps      | 2396160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010433258 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.5       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.8        |\n",
      "|    n_updates            | 11690       |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    reward               | 2.413246    |\n",
      "|    std                  | 5.06        |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1171        |\n",
      "|    time_elapsed         | 21531       |\n",
      "|    total_timesteps      | 2398208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011622978 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.8        |\n",
      "|    n_updates            | 11700       |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    reward               | -16.993484  |\n",
      "|    std                  | 5.07        |\n",
      "|    value_loss           | 247         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11096184.63\n",
      "total_reward: 10096184.63\n",
      "total_cost: 123077.83\n",
      "total_trades: 56666\n",
      "Sharpe: 1.119\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1172        |\n",
      "|    time_elapsed         | 21550       |\n",
      "|    total_timesteps      | 2400256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011041915 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91          |\n",
      "|    n_updates            | 11710       |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    reward               | -0.6132646  |\n",
      "|    std                  | 5.08        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1173         |\n",
      "|    time_elapsed         | 21569        |\n",
      "|    total_timesteps      | 2402304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0137167815 |\n",
      "|    clip_fraction        | 0.0973       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.7        |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 11720        |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    reward               | 2.5588644    |\n",
      "|    std                  | 5.08         |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1174        |\n",
      "|    time_elapsed         | 21588       |\n",
      "|    total_timesteps      | 2404352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006642181 |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.7       |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77          |\n",
      "|    n_updates            | 11730       |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    reward               | -0.92771083 |\n",
      "|    std                  | 5.08        |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1175        |\n",
      "|    time_elapsed         | 21606       |\n",
      "|    total_timesteps      | 2406400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009788404 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.7       |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 11740       |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    reward               | -8.242686   |\n",
      "|    std                  | 5.09        |\n",
      "|    value_loss           | 279         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1176        |\n",
      "|    time_elapsed         | 21625       |\n",
      "|    total_timesteps      | 2408448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009799597 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.8       |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 11750       |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    reward               | 2.7604663   |\n",
      "|    std                  | 5.12        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1177        |\n",
      "|    time_elapsed         | 21645       |\n",
      "|    total_timesteps      | 2410496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011814767 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.9       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.6        |\n",
      "|    n_updates            | 11760       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -0.89979357 |\n",
      "|    std                  | 5.12        |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1178        |\n",
      "|    time_elapsed         | 21663       |\n",
      "|    total_timesteps      | 2412544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008378923 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 11770       |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | -4.860862   |\n",
      "|    std                  | 5.13        |\n",
      "|    value_loss           | 198         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 1179      |\n",
      "|    time_elapsed         | 21682     |\n",
      "|    total_timesteps      | 2414592   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0075169 |\n",
      "|    clip_fraction        | 0.0551    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -88       |\n",
      "|    explained_variance   | 0.865     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 35.7      |\n",
      "|    n_updates            | 11780     |\n",
      "|    policy_gradient_loss | -0.00468  |\n",
      "|    reward               | 2.448963  |\n",
      "|    std                  | 5.13      |\n",
      "|    value_loss           | 73        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1180        |\n",
      "|    time_elapsed         | 21700       |\n",
      "|    total_timesteps      | 2416640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013157684 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.1        |\n",
      "|    n_updates            | 11790       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -0.11616575 |\n",
      "|    std                  | 5.15        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1181         |\n",
      "|    time_elapsed         | 21719        |\n",
      "|    total_timesteps      | 2418688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065768813 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.1        |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 180          |\n",
      "|    n_updates            | 11800        |\n",
      "|    policy_gradient_loss | -0.00868     |\n",
      "|    reward               | -1.3483272   |\n",
      "|    std                  | 5.15         |\n",
      "|    value_loss           | 248          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1182        |\n",
      "|    time_elapsed         | 21738       |\n",
      "|    total_timesteps      | 2420736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007797313 |\n",
      "|    clip_fraction        | 0.0448      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83          |\n",
      "|    n_updates            | 11810       |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    reward               | 0.006224545 |\n",
      "|    std                  | 5.15        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1183        |\n",
      "|    time_elapsed         | 21757       |\n",
      "|    total_timesteps      | 2422784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012965729 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 11820       |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | -1.7394431  |\n",
      "|    std                  | 5.16        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1184        |\n",
      "|    time_elapsed         | 21776       |\n",
      "|    total_timesteps      | 2424832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011967737 |\n",
      "|    clip_fraction        | 0.0959      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 11830       |\n",
      "|    policy_gradient_loss | -0.00743    |\n",
      "|    reward               | 0.054053266 |\n",
      "|    std                  | 5.17        |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1185        |\n",
      "|    time_elapsed         | 21795       |\n",
      "|    total_timesteps      | 2426880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005879879 |\n",
      "|    clip_fraction        | 0.0237      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 11840       |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    reward               | 0.80349123  |\n",
      "|    std                  | 5.17        |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10648132.48\n",
      "total_reward: 9648132.48\n",
      "total_cost: 115784.89\n",
      "total_trades: 56672\n",
      "Sharpe: 1.107\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1186        |\n",
      "|    time_elapsed         | 21814       |\n",
      "|    total_timesteps      | 2428928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013607387 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.3       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 11850       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -1.89158    |\n",
      "|    std                  | 5.18        |\n",
      "|    value_loss           | 67.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1187        |\n",
      "|    time_elapsed         | 21832       |\n",
      "|    total_timesteps      | 2430976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011735573 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.3       |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 11860       |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    reward               | -0.1357088  |\n",
      "|    std                  | 5.19        |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1188        |\n",
      "|    time_elapsed         | 21852       |\n",
      "|    total_timesteps      | 2433024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006837487 |\n",
      "|    clip_fraction        | 0.0334      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.4       |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.1        |\n",
      "|    n_updates            | 11870       |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    reward               | -0.8209044  |\n",
      "|    std                  | 5.2         |\n",
      "|    value_loss           | 260         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1189         |\n",
      "|    time_elapsed         | 21871        |\n",
      "|    total_timesteps      | 2435072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051281564 |\n",
      "|    clip_fraction        | 0.00923      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.4        |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 11880        |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    reward               | -1.1871014   |\n",
      "|    std                  | 5.2          |\n",
      "|    value_loss           | 351          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1190        |\n",
      "|    time_elapsed         | 21889       |\n",
      "|    total_timesteps      | 2437120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011931257 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.4       |\n",
      "|    explained_variance   | 0.825       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 11890       |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | 0.2510237   |\n",
      "|    std                  | 5.2         |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1191        |\n",
      "|    time_elapsed         | 21908       |\n",
      "|    total_timesteps      | 2439168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010008721 |\n",
      "|    clip_fraction        | 0.0704      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.4       |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 211         |\n",
      "|    n_updates            | 11900       |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    reward               | -1.0228711  |\n",
      "|    std                  | 5.21        |\n",
      "|    value_loss           | 267         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1192       |\n",
      "|    time_elapsed         | 21927      |\n",
      "|    total_timesteps      | 2441216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00885354 |\n",
      "|    clip_fraction        | 0.0608     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88.5      |\n",
      "|    explained_variance   | 0.693      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 242        |\n",
      "|    n_updates            | 11910      |\n",
      "|    policy_gradient_loss | -0.00571   |\n",
      "|    reward               | 3.1923146  |\n",
      "|    std                  | 5.22       |\n",
      "|    value_loss           | 357        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1193        |\n",
      "|    time_elapsed         | 21945       |\n",
      "|    total_timesteps      | 2443264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011253051 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 11920       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | -1.3792232  |\n",
      "|    std                  | 5.22        |\n",
      "|    value_loss           | 55.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1194        |\n",
      "|    time_elapsed         | 21964       |\n",
      "|    total_timesteps      | 2445312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005873545 |\n",
      "|    clip_fraction        | 0.0385      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 11930       |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | -0.52470917 |\n",
      "|    std                  | 5.22        |\n",
      "|    value_loss           | 324         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1195        |\n",
      "|    time_elapsed         | 21983       |\n",
      "|    total_timesteps      | 2447360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005952414 |\n",
      "|    clip_fraction        | 0.0333      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | 0.81        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.9        |\n",
      "|    n_updates            | 11940       |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    reward               | 8.249437    |\n",
      "|    std                  | 5.22        |\n",
      "|    value_loss           | 330         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1196        |\n",
      "|    time_elapsed         | 22001       |\n",
      "|    total_timesteps      | 2449408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011043285 |\n",
      "|    clip_fraction        | 0.0753      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.9        |\n",
      "|    n_updates            | 11950       |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    reward               | 1.2487092   |\n",
      "|    std                  | 5.24        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1197        |\n",
      "|    time_elapsed         | 22020       |\n",
      "|    total_timesteps      | 2451456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011742619 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.6       |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 169         |\n",
      "|    n_updates            | 11960       |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    reward               | 0.19422162  |\n",
      "|    std                  | 5.25        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1198        |\n",
      "|    time_elapsed         | 22039       |\n",
      "|    total_timesteps      | 2453504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010054924 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.7       |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 11970       |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    reward               | -0.5486023  |\n",
      "|    std                  | 5.26        |\n",
      "|    value_loss           | 262         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1199         |\n",
      "|    time_elapsed         | 22058        |\n",
      "|    total_timesteps      | 2455552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064488873 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.7        |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.9         |\n",
      "|    n_updates            | 11980        |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    reward               | -16.818722   |\n",
      "|    std                  | 5.26         |\n",
      "|    value_loss           | 243          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8857663.01\n",
      "total_reward: 7857663.01\n",
      "total_cost: 78028.56\n",
      "total_trades: 53735\n",
      "Sharpe: 1.026\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1200        |\n",
      "|    time_elapsed         | 22076       |\n",
      "|    total_timesteps      | 2457600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008664251 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.7       |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 11990       |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | 1.7598183   |\n",
      "|    std                  | 5.27        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1201        |\n",
      "|    time_elapsed         | 22095       |\n",
      "|    total_timesteps      | 2459648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015483098 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 12000       |\n",
      "|    policy_gradient_loss | -0.00814    |\n",
      "|    reward               | 0.9365849   |\n",
      "|    std                  | 5.28        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1202         |\n",
      "|    time_elapsed         | 22114        |\n",
      "|    total_timesteps      | 2461696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062850583 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.8        |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.3         |\n",
      "|    n_updates            | 12010        |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    reward               | 6.1956463    |\n",
      "|    std                  | 5.28         |\n",
      "|    value_loss           | 208          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1203        |\n",
      "|    time_elapsed         | 22132       |\n",
      "|    total_timesteps      | 2463744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009611044 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.1        |\n",
      "|    n_updates            | 12020       |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    reward               | 7.681916    |\n",
      "|    std                  | 5.28        |\n",
      "|    value_loss           | 74.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1204         |\n",
      "|    time_elapsed         | 22151        |\n",
      "|    total_timesteps      | 2465792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012836306  |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.9        |\n",
      "|    explained_variance   | 0.755        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 162          |\n",
      "|    n_updates            | 12030        |\n",
      "|    policy_gradient_loss | -0.00966     |\n",
      "|    reward               | -0.028841648 |\n",
      "|    std                  | 5.29         |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1205         |\n",
      "|    time_elapsed         | 22170        |\n",
      "|    total_timesteps      | 2467840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105423685 |\n",
      "|    clip_fraction        | 0.0642       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.9        |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 172          |\n",
      "|    n_updates            | 12040        |\n",
      "|    policy_gradient_loss | -0.00784     |\n",
      "|    reward               | 0.40000162   |\n",
      "|    std                  | 5.3          |\n",
      "|    value_loss           | 254          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1206        |\n",
      "|    time_elapsed         | 22188       |\n",
      "|    total_timesteps      | 2469888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007533674 |\n",
      "|    clip_fraction        | 0.0399      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.9       |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.6        |\n",
      "|    n_updates            | 12050       |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | 0.19944337  |\n",
      "|    std                  | 5.3         |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1207        |\n",
      "|    time_elapsed         | 22207       |\n",
      "|    total_timesteps      | 2471936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013393133 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.9       |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.12        |\n",
      "|    n_updates            | 12060       |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    reward               | -0.22404832 |\n",
      "|    std                  | 5.3         |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1208        |\n",
      "|    time_elapsed         | 22226       |\n",
      "|    total_timesteps      | 2473984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016373398 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89         |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.2        |\n",
      "|    n_updates            | 12070       |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    reward               | -0.7227906  |\n",
      "|    std                  | 5.31        |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1209         |\n",
      "|    time_elapsed         | 22245        |\n",
      "|    total_timesteps      | 2476032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064862296 |\n",
      "|    clip_fraction        | 0.0466       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89          |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 253          |\n",
      "|    n_updates            | 12080        |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    reward               | -21.660965   |\n",
      "|    std                  | 5.32         |\n",
      "|    value_loss           | 326          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1210         |\n",
      "|    time_elapsed         | 22264        |\n",
      "|    total_timesteps      | 2478080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101028755 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89          |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.5         |\n",
      "|    n_updates            | 12090        |\n",
      "|    policy_gradient_loss | -0.00666     |\n",
      "|    reward               | -5.042977    |\n",
      "|    std                  | 5.32         |\n",
      "|    value_loss           | 81.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1211        |\n",
      "|    time_elapsed         | 22282       |\n",
      "|    total_timesteps      | 2480128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012495315 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 225         |\n",
      "|    n_updates            | 12100       |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    reward               | 0.3291709   |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 210         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1212        |\n",
      "|    time_elapsed         | 22300       |\n",
      "|    total_timesteps      | 2482176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013133271 |\n",
      "|    clip_fraction        | 0.0727      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 12110       |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | 25.761845   |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 344         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1213        |\n",
      "|    time_elapsed         | 22319       |\n",
      "|    total_timesteps      | 2484224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009412551 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 203         |\n",
      "|    n_updates            | 12120       |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    reward               | 2.6681402   |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 391         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11848830.48\n",
      "total_reward: 10848830.48\n",
      "total_cost: 94149.33\n",
      "total_trades: 55562\n",
      "Sharpe: 1.088\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1214       |\n",
      "|    time_elapsed         | 22338      |\n",
      "|    total_timesteps      | 2486272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01873065 |\n",
      "|    clip_fraction        | 0.195      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -89.3      |\n",
      "|    explained_variance   | 0.786      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.6       |\n",
      "|    n_updates            | 12130      |\n",
      "|    policy_gradient_loss | -0.0068    |\n",
      "|    reward               | 1.41958    |\n",
      "|    std                  | 5.37       |\n",
      "|    value_loss           | 39.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1215        |\n",
      "|    time_elapsed         | 22357       |\n",
      "|    total_timesteps      | 2488320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00443992  |\n",
      "|    clip_fraction        | 0.0161      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.3       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 12140       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | -0.97283655 |\n",
      "|    std                  | 5.37        |\n",
      "|    value_loss           | 349         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1216        |\n",
      "|    time_elapsed         | 22376       |\n",
      "|    total_timesteps      | 2490368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003336179 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.3       |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 12150       |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    reward               | 5.7499013   |\n",
      "|    std                  | 5.37        |\n",
      "|    value_loss           | 330         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1217         |\n",
      "|    time_elapsed         | 22395        |\n",
      "|    total_timesteps      | 2492416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073257214 |\n",
      "|    clip_fraction        | 0.0267       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.3        |\n",
      "|    explained_variance   | 0.897        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 12160        |\n",
      "|    policy_gradient_loss | -0.00622     |\n",
      "|    reward               | 2.2615776    |\n",
      "|    std                  | 5.38         |\n",
      "|    value_loss           | 61.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1218        |\n",
      "|    time_elapsed         | 22413       |\n",
      "|    total_timesteps      | 2494464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011074811 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 209         |\n",
      "|    n_updates            | 12170       |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    reward               | 4.16586     |\n",
      "|    std                  | 5.38        |\n",
      "|    value_loss           | 313         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1219        |\n",
      "|    time_elapsed         | 22433       |\n",
      "|    total_timesteps      | 2496512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004209849 |\n",
      "|    clip_fraction        | 0.00742     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 192         |\n",
      "|    n_updates            | 12180       |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | -4.772146   |\n",
      "|    std                  | 5.38        |\n",
      "|    value_loss           | 275         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1220       |\n",
      "|    time_elapsed         | 22452      |\n",
      "|    total_timesteps      | 2498560    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01020788 |\n",
      "|    clip_fraction        | 0.0981     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -89.4      |\n",
      "|    explained_variance   | 0.75       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 44.5       |\n",
      "|    n_updates            | 12190      |\n",
      "|    policy_gradient_loss | -0.00845   |\n",
      "|    reward               | 2.8883767  |\n",
      "|    std                  | 5.39       |\n",
      "|    value_loss           | 108        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1221        |\n",
      "|    time_elapsed         | 22471       |\n",
      "|    total_timesteps      | 2500608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013665134 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.4        |\n",
      "|    n_updates            | 12200       |\n",
      "|    policy_gradient_loss | -0.00951    |\n",
      "|    reward               | 0.023244066 |\n",
      "|    std                  | 5.39        |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1222        |\n",
      "|    time_elapsed         | 22489       |\n",
      "|    total_timesteps      | 2502656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008138851 |\n",
      "|    clip_fraction        | 0.0492      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 279         |\n",
      "|    n_updates            | 12210       |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    reward               | -0.34009287 |\n",
      "|    std                  | 5.39        |\n",
      "|    value_loss           | 307         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1223        |\n",
      "|    time_elapsed         | 22508       |\n",
      "|    total_timesteps      | 2504704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008615132 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 195         |\n",
      "|    n_updates            | 12220       |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    reward               | 0.2504404   |\n",
      "|    std                  | 5.4         |\n",
      "|    value_loss           | 431         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1224         |\n",
      "|    time_elapsed         | 22527        |\n",
      "|    total_timesteps      | 2506752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148686785 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.5        |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 12230        |\n",
      "|    policy_gradient_loss | -0.0082      |\n",
      "|    reward               | 1.8637633    |\n",
      "|    std                  | 5.4          |\n",
      "|    value_loss           | 37.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1225        |\n",
      "|    time_elapsed         | 22545       |\n",
      "|    total_timesteps      | 2508800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010982098 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 165         |\n",
      "|    n_updates            | 12240       |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    reward               | 1.3605199   |\n",
      "|    std                  | 5.4         |\n",
      "|    value_loss           | 263         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1226         |\n",
      "|    time_elapsed         | 22564        |\n",
      "|    total_timesteps      | 2510848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028062402 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.5        |\n",
      "|    explained_variance   | 0.35         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 121          |\n",
      "|    n_updates            | 12250        |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    reward               | -6.0701976   |\n",
      "|    std                  | 5.4          |\n",
      "|    value_loss           | 299          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1227       |\n",
      "|    time_elapsed         | 22582      |\n",
      "|    total_timesteps      | 2512896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00951791 |\n",
      "|    clip_fraction        | 0.0911     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -89.5      |\n",
      "|    explained_variance   | 0.628      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70         |\n",
      "|    n_updates            | 12260      |\n",
      "|    policy_gradient_loss | -0.00943   |\n",
      "|    reward               | -2.0163398 |\n",
      "|    std                  | 5.41       |\n",
      "|    value_loss           | 115        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11413332.04\n",
      "total_reward: 10413332.04\n",
      "total_cost: 69749.39\n",
      "total_trades: 53595\n",
      "Sharpe: 1.068\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1228         |\n",
      "|    time_elapsed         | 22601        |\n",
      "|    total_timesteps      | 2514944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100227995 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.5        |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 140          |\n",
      "|    n_updates            | 12270        |\n",
      "|    policy_gradient_loss | -0.00713     |\n",
      "|    reward               | 3.3482685    |\n",
      "|    std                  | 5.41         |\n",
      "|    value_loss           | 305          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1229        |\n",
      "|    time_elapsed         | 22620       |\n",
      "|    total_timesteps      | 2516992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007301609 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.7        |\n",
      "|    n_updates            | 12280       |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    reward               | -0.06957192 |\n",
      "|    std                  | 5.41        |\n",
      "|    value_loss           | 310         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1230         |\n",
      "|    time_elapsed         | 22639        |\n",
      "|    total_timesteps      | 2519040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056757214 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.6        |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 225          |\n",
      "|    n_updates            | 12290        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    reward               | -4.9656305   |\n",
      "|    std                  | 5.41         |\n",
      "|    value_loss           | 379          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1231        |\n",
      "|    time_elapsed         | 22657       |\n",
      "|    total_timesteps      | 2521088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012212006 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 12300       |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | 2.1535313   |\n",
      "|    std                  | 5.43        |\n",
      "|    value_loss           | 43          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1232        |\n",
      "|    time_elapsed         | 22676       |\n",
      "|    total_timesteps      | 2523136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008782545 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 12310       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | -0.21355885 |\n",
      "|    std                  | 5.43        |\n",
      "|    value_loss           | 335         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1233         |\n",
      "|    time_elapsed         | 22694        |\n",
      "|    total_timesteps      | 2525184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034314403 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.7        |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 270          |\n",
      "|    n_updates            | 12320        |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    reward               | -21.301933   |\n",
      "|    std                  | 5.44         |\n",
      "|    value_loss           | 431          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1234         |\n",
      "|    time_elapsed         | 22713        |\n",
      "|    total_timesteps      | 2527232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074566463 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.7        |\n",
      "|    explained_variance   | 0.757        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.3         |\n",
      "|    n_updates            | 12330        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | 1.3672135    |\n",
      "|    std                  | 5.44         |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1235        |\n",
      "|    time_elapsed         | 22732       |\n",
      "|    total_timesteps      | 2529280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011495812 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.7       |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 212         |\n",
      "|    n_updates            | 12340       |\n",
      "|    policy_gradient_loss | -0.0095     |\n",
      "|    reward               | -1.5589747  |\n",
      "|    std                  | 5.45        |\n",
      "|    value_loss           | 314         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1236        |\n",
      "|    time_elapsed         | 22750       |\n",
      "|    total_timesteps      | 2531328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008445296 |\n",
      "|    clip_fraction        | 0.0418      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.8       |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 12350       |\n",
      "|    policy_gradient_loss | -0.0095     |\n",
      "|    reward               | 20.631247   |\n",
      "|    std                  | 5.46        |\n",
      "|    value_loss           | 335         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1237         |\n",
      "|    time_elapsed         | 22769        |\n",
      "|    total_timesteps      | 2533376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076516382 |\n",
      "|    clip_fraction        | 0.0471       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.8        |\n",
      "|    explained_variance   | 0.75         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 211          |\n",
      "|    n_updates            | 12360        |\n",
      "|    policy_gradient_loss | -0.00723     |\n",
      "|    reward               | 4.2939       |\n",
      "|    std                  | 5.46         |\n",
      "|    value_loss           | 336          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1238        |\n",
      "|    time_elapsed         | 22788       |\n",
      "|    total_timesteps      | 2535424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012127918 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.9       |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 12370       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 1.1092699   |\n",
      "|    std                  | 5.49        |\n",
      "|    value_loss           | 64          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1239       |\n",
      "|    time_elapsed         | 22806      |\n",
      "|    total_timesteps      | 2537472    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01119073 |\n",
      "|    clip_fraction        | 0.0771     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -90        |\n",
      "|    explained_variance   | 0.822      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 106        |\n",
      "|    n_updates            | 12380      |\n",
      "|    policy_gradient_loss | -0.00728   |\n",
      "|    reward               | 0.45551968 |\n",
      "|    std                  | 5.49       |\n",
      "|    value_loss           | 273        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1240        |\n",
      "|    time_elapsed         | 22825       |\n",
      "|    total_timesteps      | 2539520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008397514 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90         |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 12390       |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    reward               | -5.1284823  |\n",
      "|    std                  | 5.5         |\n",
      "|    value_loss           | 382         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1241        |\n",
      "|    time_elapsed         | 22844       |\n",
      "|    total_timesteps      | 2541568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015607004 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90         |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 12400       |\n",
      "|    policy_gradient_loss | -0.00993    |\n",
      "|    reward               | 7.1811566   |\n",
      "|    std                  | 5.51        |\n",
      "|    value_loss           | 58.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10718493.61\n",
      "total_reward: 9718493.61\n",
      "total_cost: 72697.29\n",
      "total_trades: 53353\n",
      "Sharpe: 1.030\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1242       |\n",
      "|    time_elapsed         | 22862      |\n",
      "|    total_timesteps      | 2543616    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00800241 |\n",
      "|    clip_fraction        | 0.0524     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -90.1      |\n",
      "|    explained_variance   | 0.792      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 152        |\n",
      "|    n_updates            | 12410      |\n",
      "|    policy_gradient_loss | -0.00685   |\n",
      "|    reward               | 2.423202   |\n",
      "|    std                  | 5.52       |\n",
      "|    value_loss           | 312        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 1243      |\n",
      "|    time_elapsed         | 22881     |\n",
      "|    total_timesteps      | 2545664   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.010086  |\n",
      "|    clip_fraction        | 0.0798    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -90.1     |\n",
      "|    explained_variance   | 0.78      |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 93        |\n",
      "|    n_updates            | 12420     |\n",
      "|    policy_gradient_loss | -0.00996  |\n",
      "|    reward               | -9.095057 |\n",
      "|    std                  | 5.52      |\n",
      "|    value_loss           | 288       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1244        |\n",
      "|    time_elapsed         | 22900       |\n",
      "|    total_timesteps      | 2547712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008633859 |\n",
      "|    clip_fraction        | 0.0492      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.81        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.5        |\n",
      "|    n_updates            | 12430       |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    reward               | -1.0014812  |\n",
      "|    std                  | 5.53        |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1245        |\n",
      "|    time_elapsed         | 22918       |\n",
      "|    total_timesteps      | 2549760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012836324 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 167         |\n",
      "|    n_updates            | 12440       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 1.8914185   |\n",
      "|    std                  | 5.53        |\n",
      "|    value_loss           | 224         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1246        |\n",
      "|    time_elapsed         | 22937       |\n",
      "|    total_timesteps      | 2551808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016690765 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 12450       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | -1.1342169  |\n",
      "|    std                  | 5.53        |\n",
      "|    value_loss           | 385         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1247        |\n",
      "|    time_elapsed         | 22956       |\n",
      "|    total_timesteps      | 2553856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007352813 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 232         |\n",
      "|    n_updates            | 12460       |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    reward               | -2.0723417  |\n",
      "|    std                  | 5.54        |\n",
      "|    value_loss           | 346         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1248        |\n",
      "|    time_elapsed         | 22975       |\n",
      "|    total_timesteps      | 2555904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009404969 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.3       |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 12470       |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    reward               | 0.52513105  |\n",
      "|    std                  | 5.55        |\n",
      "|    value_loss           | 48.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1249        |\n",
      "|    time_elapsed         | 22994       |\n",
      "|    total_timesteps      | 2557952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008534418 |\n",
      "|    clip_fraction        | 0.0788      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.3       |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 232         |\n",
      "|    n_updates            | 12480       |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    reward               | -0.13926111 |\n",
      "|    std                  | 5.56        |\n",
      "|    value_loss           | 352         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1250         |\n",
      "|    time_elapsed         | 23013        |\n",
      "|    total_timesteps      | 2560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057639177 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.3        |\n",
      "|    explained_variance   | 0.75         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 234          |\n",
      "|    n_updates            | 12490        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    reward               | -1.3633426   |\n",
      "|    std                  | 5.56         |\n",
      "|    value_loss           | 400          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1251        |\n",
      "|    time_elapsed         | 23033       |\n",
      "|    total_timesteps      | 2562048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009911141 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72          |\n",
      "|    n_updates            | 12500       |\n",
      "|    policy_gradient_loss | -0.00833    |\n",
      "|    reward               | 9.278692    |\n",
      "|    std                  | 5.58        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1252        |\n",
      "|    time_elapsed         | 23052       |\n",
      "|    total_timesteps      | 2564096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011747388 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.5       |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 195         |\n",
      "|    n_updates            | 12510       |\n",
      "|    policy_gradient_loss | -0.00895    |\n",
      "|    reward               | 1.8665905   |\n",
      "|    std                  | 5.59        |\n",
      "|    value_loss           | 255         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1253        |\n",
      "|    time_elapsed         | 23071       |\n",
      "|    total_timesteps      | 2566144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007978465 |\n",
      "|    clip_fraction        | 0.0467      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.5       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 207         |\n",
      "|    n_updates            | 12520       |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    reward               | -0.5030634  |\n",
      "|    std                  | 5.59        |\n",
      "|    value_loss           | 371         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1254        |\n",
      "|    time_elapsed         | 23089       |\n",
      "|    total_timesteps      | 2568192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002119328 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.5       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 155         |\n",
      "|    n_updates            | 12530       |\n",
      "|    policy_gradient_loss | -0.00187    |\n",
      "|    reward               | 1.0682112   |\n",
      "|    std                  | 5.6         |\n",
      "|    value_loss           | 440         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1255        |\n",
      "|    time_elapsed         | 23108       |\n",
      "|    total_timesteps      | 2570240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006285592 |\n",
      "|    clip_fraction        | 0.0258      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.5       |\n",
      "|    explained_variance   | 0.823       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 12540       |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    reward               | -0.24028103 |\n",
      "|    std                  | 5.61        |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 12213877.26\n",
      "total_reward: 11213877.26\n",
      "total_cost: 86522.71\n",
      "total_trades: 53706\n",
      "Sharpe: 1.110\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1256        |\n",
      "|    time_elapsed         | 23127       |\n",
      "|    total_timesteps      | 2572288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009775617 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.6       |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 12550       |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    reward               | -0.58099586 |\n",
      "|    std                  | 5.62        |\n",
      "|    value_loss           | 361         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1257        |\n",
      "|    time_elapsed         | 23145       |\n",
      "|    total_timesteps      | 2574336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006082953 |\n",
      "|    clip_fraction        | 0.0206      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.6       |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 194         |\n",
      "|    n_updates            | 12560       |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | 9.031668    |\n",
      "|    std                  | 5.62        |\n",
      "|    value_loss           | 370         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1258        |\n",
      "|    time_elapsed         | 23164       |\n",
      "|    total_timesteps      | 2576384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008701368 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.7       |\n",
      "|    explained_variance   | 0.9         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 12570       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | 0.08679875  |\n",
      "|    std                  | 5.63        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1259        |\n",
      "|    time_elapsed         | 23183       |\n",
      "|    total_timesteps      | 2578432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012542118 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.7       |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 12580       |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    reward               | 0.22496329  |\n",
      "|    std                  | 5.65        |\n",
      "|    value_loss           | 307         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1260        |\n",
      "|    time_elapsed         | 23202       |\n",
      "|    total_timesteps      | 2580480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004803893 |\n",
      "|    clip_fraction        | 0.00605     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.8       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 12590       |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    reward               | 120.608734  |\n",
      "|    std                  | 5.66        |\n",
      "|    value_loss           | 334         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1261       |\n",
      "|    time_elapsed         | 23221      |\n",
      "|    total_timesteps      | 2582528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01007252 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -90.8      |\n",
      "|    explained_variance   | 0.783      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 135        |\n",
      "|    n_updates            | 12600      |\n",
      "|    policy_gradient_loss | -0.00611   |\n",
      "|    reward               | -1.7129855 |\n",
      "|    std                  | 5.66       |\n",
      "|    value_loss           | 308        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1262        |\n",
      "|    time_elapsed         | 23239       |\n",
      "|    total_timesteps      | 2584576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012385569 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 12610       |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | 2.4266114   |\n",
      "|    std                  | 5.68        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1263        |\n",
      "|    time_elapsed         | 23258       |\n",
      "|    total_timesteps      | 2586624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011917349 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 220         |\n",
      "|    n_updates            | 12620       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 1.1271008   |\n",
      "|    std                  | 5.68        |\n",
      "|    value_loss           | 426         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1264        |\n",
      "|    time_elapsed         | 23277       |\n",
      "|    total_timesteps      | 2588672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006613167 |\n",
      "|    clip_fraction        | 0.0249      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 12630       |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    reward               | -13.327122  |\n",
      "|    std                  | 5.69        |\n",
      "|    value_loss           | 371         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1265        |\n",
      "|    time_elapsed         | 23296       |\n",
      "|    total_timesteps      | 2590720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011017367 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.5        |\n",
      "|    n_updates            | 12640       |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    reward               | -0.48308948 |\n",
      "|    std                  | 5.7         |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1266         |\n",
      "|    time_elapsed         | 23315        |\n",
      "|    total_timesteps      | 2592768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088038985 |\n",
      "|    clip_fraction        | 0.0662       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91          |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 177          |\n",
      "|    n_updates            | 12650        |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    reward               | 1.8064634    |\n",
      "|    std                  | 5.7          |\n",
      "|    value_loss           | 410          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1267        |\n",
      "|    time_elapsed         | 23334       |\n",
      "|    total_timesteps      | 2594816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010326696 |\n",
      "|    clip_fraction        | 0.0799      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 227         |\n",
      "|    n_updates            | 12660       |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    reward               | -6.267223   |\n",
      "|    std                  | 5.71        |\n",
      "|    value_loss           | 342         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1268        |\n",
      "|    time_elapsed         | 23352       |\n",
      "|    total_timesteps      | 2596864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009945255 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.3        |\n",
      "|    n_updates            | 12670       |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    reward               | -0.86423814 |\n",
      "|    std                  | 5.71        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1269        |\n",
      "|    time_elapsed         | 23371       |\n",
      "|    total_timesteps      | 2598912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009914733 |\n",
      "|    clip_fraction        | 0.0773      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 155         |\n",
      "|    n_updates            | 12680       |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    reward               | -1.8292115  |\n",
      "|    std                  | 5.73        |\n",
      "|    value_loss           | 225         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11567226.63\n",
      "total_reward: 10567226.63\n",
      "total_cost: 129549.64\n",
      "total_trades: 56315\n",
      "Sharpe: 1.113\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1270         |\n",
      "|    time_elapsed         | 23390        |\n",
      "|    total_timesteps      | 2600960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0130627705 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.2        |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 96.4         |\n",
      "|    n_updates            | 12690        |\n",
      "|    policy_gradient_loss | -0.0129      |\n",
      "|    reward               | 1.1328595    |\n",
      "|    std                  | 5.74         |\n",
      "|    value_loss           | 370          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1271        |\n",
      "|    time_elapsed         | 23409       |\n",
      "|    total_timesteps      | 2603008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008619982 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.2       |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 237         |\n",
      "|    n_updates            | 12700       |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    reward               | 2.5064719   |\n",
      "|    std                  | 5.74        |\n",
      "|    value_loss           | 325         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1272        |\n",
      "|    time_elapsed         | 23427       |\n",
      "|    total_timesteps      | 2605056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012064243 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.2       |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 12710       |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    reward               | 0.9332239   |\n",
      "|    std                  | 5.76        |\n",
      "|    value_loss           | 54.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1273        |\n",
      "|    time_elapsed         | 23446       |\n",
      "|    total_timesteps      | 2607104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010987351 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 12720       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 0.5643308   |\n",
      "|    std                  | 5.77        |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1274        |\n",
      "|    time_elapsed         | 23465       |\n",
      "|    total_timesteps      | 2609152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008371767 |\n",
      "|    clip_fraction        | 0.0418      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.7        |\n",
      "|    n_updates            | 12730       |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | 0.14651372  |\n",
      "|    std                  | 5.77        |\n",
      "|    value_loss           | 325         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1275        |\n",
      "|    time_elapsed         | 23483       |\n",
      "|    total_timesteps      | 2611200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012692589 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 12740       |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    reward               | 20.348705   |\n",
      "|    std                  | 5.78        |\n",
      "|    value_loss           | 58          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1276        |\n",
      "|    time_elapsed         | 23502       |\n",
      "|    total_timesteps      | 2613248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014677038 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.803       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 12750       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 1.1011077   |\n",
      "|    std                  | 5.8         |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1277        |\n",
      "|    time_elapsed         | 23520       |\n",
      "|    total_timesteps      | 2615296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011274323 |\n",
      "|    clip_fraction        | 0.085       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.5        |\n",
      "|    n_updates            | 12760       |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    reward               | 0.43157503  |\n",
      "|    std                  | 5.81        |\n",
      "|    value_loss           | 309         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1278        |\n",
      "|    time_elapsed         | 23540       |\n",
      "|    total_timesteps      | 2617344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012350274 |\n",
      "|    clip_fraction        | 0.0591      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.6       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 12770       |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    reward               | 1.4571158   |\n",
      "|    std                  | 5.82        |\n",
      "|    value_loss           | 326         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1279        |\n",
      "|    time_elapsed         | 23559       |\n",
      "|    total_timesteps      | 2619392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011866526 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.6       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.37        |\n",
      "|    n_updates            | 12780       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 0.24120657  |\n",
      "|    std                  | 5.83        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1280       |\n",
      "|    time_elapsed         | 23578      |\n",
      "|    total_timesteps      | 2621440    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00990583 |\n",
      "|    clip_fraction        | 0.0536     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.7      |\n",
      "|    explained_variance   | 0.838      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 92.7       |\n",
      "|    n_updates            | 12790      |\n",
      "|    policy_gradient_loss | -0.00772   |\n",
      "|    reward               | 0.9485953  |\n",
      "|    std                  | 5.84       |\n",
      "|    value_loss           | 238        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1281        |\n",
      "|    time_elapsed         | 23597       |\n",
      "|    total_timesteps      | 2623488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008103963 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.7       |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 12800       |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    reward               | 3.5603366   |\n",
      "|    std                  | 5.85        |\n",
      "|    value_loss           | 278         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1282         |\n",
      "|    time_elapsed         | 23616        |\n",
      "|    total_timesteps      | 2625536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101617575 |\n",
      "|    clip_fraction        | 0.0887       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.8        |\n",
      "|    explained_variance   | 0.886        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.6         |\n",
      "|    n_updates            | 12810        |\n",
      "|    policy_gradient_loss | -0.009       |\n",
      "|    reward               | 2.2718718    |\n",
      "|    std                  | 5.85         |\n",
      "|    value_loss           | 53           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1283        |\n",
      "|    time_elapsed         | 23634       |\n",
      "|    total_timesteps      | 2627584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012394957 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.8       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 247         |\n",
      "|    n_updates            | 12820       |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    reward               | -3.023237   |\n",
      "|    std                  | 5.86        |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1284        |\n",
      "|    time_elapsed         | 23653       |\n",
      "|    total_timesteps      | 2629632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007584869 |\n",
      "|    clip_fraction        | 0.0526      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.8       |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 12830       |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    reward               | -11.693506  |\n",
      "|    std                  | 5.87        |\n",
      "|    value_loss           | 213         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8857665.97\n",
      "total_reward: 7857665.97\n",
      "total_cost: 98587.56\n",
      "total_trades: 53626\n",
      "Sharpe: 1.042\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1285        |\n",
      "|    time_elapsed         | 23672       |\n",
      "|    total_timesteps      | 2631680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007849654 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.9       |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.2        |\n",
      "|    n_updates            | 12840       |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    reward               | 3.1531491   |\n",
      "|    std                  | 5.87        |\n",
      "|    value_loss           | 88.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1286        |\n",
      "|    time_elapsed         | 23691       |\n",
      "|    total_timesteps      | 2633728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007948073 |\n",
      "|    clip_fraction        | 0.0426      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.9       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 99.5        |\n",
      "|    n_updates            | 12850       |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    reward               | 1.7674109   |\n",
      "|    std                  | 5.88        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1287        |\n",
      "|    time_elapsed         | 23709       |\n",
      "|    total_timesteps      | 2635776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012385657 |\n",
      "|    clip_fraction        | 0.0926      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.9       |\n",
      "|    explained_variance   | 0.83        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.2        |\n",
      "|    n_updates            | 12860       |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    reward               | -0.2177567  |\n",
      "|    std                  | 5.89        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1288        |\n",
      "|    time_elapsed         | 23728       |\n",
      "|    total_timesteps      | 2637824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008572772 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 206         |\n",
      "|    n_updates            | 12870       |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    reward               | 9.284846    |\n",
      "|    std                  | 5.9         |\n",
      "|    value_loss           | 267         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1289        |\n",
      "|    time_elapsed         | 23746       |\n",
      "|    total_timesteps      | 2639872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012046192 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 12880       |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    reward               | -4.134213   |\n",
      "|    std                  | 5.91        |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1290         |\n",
      "|    time_elapsed         | 23765        |\n",
      "|    total_timesteps      | 2641920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009441717  |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.1        |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 89.5         |\n",
      "|    n_updates            | 12890        |\n",
      "|    policy_gradient_loss | -0.00737     |\n",
      "|    reward               | -0.024422478 |\n",
      "|    std                  | 5.92         |\n",
      "|    value_loss           | 215          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1291        |\n",
      "|    time_elapsed         | 23783       |\n",
      "|    total_timesteps      | 2643968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003831498 |\n",
      "|    clip_fraction        | 0.00488     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 12900       |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    reward               | -1.370498   |\n",
      "|    std                  | 5.93        |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1292        |\n",
      "|    time_elapsed         | 23802       |\n",
      "|    total_timesteps      | 2646016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011494255 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.6        |\n",
      "|    n_updates            | 12910       |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | -4.518193   |\n",
      "|    std                  | 5.93        |\n",
      "|    value_loss           | 91.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1293        |\n",
      "|    time_elapsed         | 23821       |\n",
      "|    total_timesteps      | 2648064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007241386 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.5        |\n",
      "|    n_updates            | 12920       |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    reward               | -3.4678435  |\n",
      "|    std                  | 5.95        |\n",
      "|    value_loss           | 238         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1294        |\n",
      "|    time_elapsed         | 23840       |\n",
      "|    total_timesteps      | 2650112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008149443 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 12930       |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    reward               | 0.3711319   |\n",
      "|    std                  | 5.95        |\n",
      "|    value_loss           | 296         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1295         |\n",
      "|    time_elapsed         | 23859        |\n",
      "|    total_timesteps      | 2652160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005109587  |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.2        |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 121          |\n",
      "|    n_updates            | 12940        |\n",
      "|    policy_gradient_loss | -0.00501     |\n",
      "|    reward               | -0.114861056 |\n",
      "|    std                  | 5.95         |\n",
      "|    value_loss           | 311          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1296        |\n",
      "|    time_elapsed         | 23878       |\n",
      "|    total_timesteps      | 2654208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011997092 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | 0.784       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 12950       |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    reward               | -1.1022496  |\n",
      "|    std                  | 5.95        |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1297        |\n",
      "|    time_elapsed         | 23896       |\n",
      "|    total_timesteps      | 2656256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010482943 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.1        |\n",
      "|    n_updates            | 12960       |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | 3.0149057   |\n",
      "|    std                  | 5.96        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1298       |\n",
      "|    time_elapsed         | 23915      |\n",
      "|    total_timesteps      | 2658304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00994687 |\n",
      "|    clip_fraction        | 0.0531     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.3      |\n",
      "|    explained_variance   | 0.719      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 116        |\n",
      "|    n_updates            | 12970      |\n",
      "|    policy_gradient_loss | -0.00806   |\n",
      "|    reward               | 5.084104   |\n",
      "|    std                  | 5.97       |\n",
      "|    value_loss           | 236        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10648163.67\n",
      "total_reward: 9648163.67\n",
      "total_cost: 83179.09\n",
      "total_trades: 52215\n",
      "Sharpe: 1.064\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1299        |\n",
      "|    time_elapsed         | 23934       |\n",
      "|    total_timesteps      | 2660352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008634193 |\n",
      "|    clip_fraction        | 0.0811      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 12980       |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    reward               | -1.874473   |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1300         |\n",
      "|    time_elapsed         | 23952        |\n",
      "|    total_timesteps      | 2662400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146391215 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.4        |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.8         |\n",
      "|    n_updates            | 12990        |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    reward               | -1.1905475   |\n",
      "|    std                  | 5.98         |\n",
      "|    value_loss           | 229          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1301         |\n",
      "|    time_elapsed         | 23971        |\n",
      "|    total_timesteps      | 2664448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020756437 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.4        |\n",
      "|    explained_variance   | 0.742        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82.1         |\n",
      "|    n_updates            | 13000        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    reward               | -25.01596    |\n",
      "|    std                  | 5.98         |\n",
      "|    value_loss           | 281          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1302         |\n",
      "|    time_elapsed         | 23990        |\n",
      "|    total_timesteps      | 2666496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094770305 |\n",
      "|    clip_fraction        | 0.0385       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.4        |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 184          |\n",
      "|    n_updates            | 13010        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    reward               | 1.714297     |\n",
      "|    std                  | 5.98         |\n",
      "|    value_loss           | 373          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1303        |\n",
      "|    time_elapsed         | 24009       |\n",
      "|    total_timesteps      | 2668544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013449846 |\n",
      "|    clip_fraction        | 0.056       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 13020       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | -2.408258   |\n",
      "|    std                  | 6           |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1304        |\n",
      "|    time_elapsed         | 24028       |\n",
      "|    total_timesteps      | 2670592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011185781 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 234         |\n",
      "|    n_updates            | 13030       |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    reward               | -1.4929973  |\n",
      "|    std                  | 6.01        |\n",
      "|    value_loss           | 324         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1305        |\n",
      "|    time_elapsed         | 24046       |\n",
      "|    total_timesteps      | 2672640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006863858 |\n",
      "|    clip_fraction        | 0.0257      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 198         |\n",
      "|    n_updates            | 13040       |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    reward               | -4.712098   |\n",
      "|    std                  | 6.01        |\n",
      "|    value_loss           | 452         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1306        |\n",
      "|    time_elapsed         | 24065       |\n",
      "|    total_timesteps      | 2674688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008692357 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.6       |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 13050       |\n",
      "|    policy_gradient_loss | -0.00917    |\n",
      "|    reward               | -0.8800757  |\n",
      "|    std                  | 6.03        |\n",
      "|    value_loss           | 64.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1307        |\n",
      "|    time_elapsed         | 24084       |\n",
      "|    total_timesteps      | 2676736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011730701 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.6       |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 13060       |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | 3.1276348   |\n",
      "|    std                  | 6.03        |\n",
      "|    value_loss           | 351         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1308        |\n",
      "|    time_elapsed         | 24102       |\n",
      "|    total_timesteps      | 2678784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004283662 |\n",
      "|    clip_fraction        | 0.0198      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.6       |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 13070       |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    reward               | -1.9588066  |\n",
      "|    std                  | 6.03        |\n",
      "|    value_loss           | 410         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1309        |\n",
      "|    time_elapsed         | 24120       |\n",
      "|    total_timesteps      | 2680832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008291384 |\n",
      "|    clip_fraction        | 0.0475      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.5        |\n",
      "|    n_updates            | 13080       |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    reward               | -0.2861224  |\n",
      "|    std                  | 6.04        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1310        |\n",
      "|    time_elapsed         | 24140       |\n",
      "|    total_timesteps      | 2682880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009885002 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 302         |\n",
      "|    n_updates            | 13090       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | 0.5267104   |\n",
      "|    std                  | 6.05        |\n",
      "|    value_loss           | 287         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1311        |\n",
      "|    time_elapsed         | 24158       |\n",
      "|    total_timesteps      | 2684928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010817789 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.8       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 296         |\n",
      "|    n_updates            | 13100       |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    reward               | -0.5770491  |\n",
      "|    std                  | 6.05        |\n",
      "|    value_loss           | 405         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1312         |\n",
      "|    time_elapsed         | 24177        |\n",
      "|    total_timesteps      | 2686976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111433305 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.8        |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 284          |\n",
      "|    n_updates            | 13110        |\n",
      "|    policy_gradient_loss | -0.00861     |\n",
      "|    reward               | 1.7902713    |\n",
      "|    std                  | 6.06         |\n",
      "|    value_loss           | 461          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 12190250.84\n",
      "total_reward: 11190250.84\n",
      "total_cost: 109113.84\n",
      "total_trades: 53982\n",
      "Sharpe: 1.109\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1313        |\n",
      "|    time_elapsed         | 24196       |\n",
      "|    total_timesteps      | 2689024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010045596 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.8       |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 13120       |\n",
      "|    policy_gradient_loss | -0.00962    |\n",
      "|    reward               | 0.25443766  |\n",
      "|    std                  | 6.07        |\n",
      "|    value_loss           | 54.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1314        |\n",
      "|    time_elapsed         | 24214       |\n",
      "|    total_timesteps      | 2691072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008950159 |\n",
      "|    clip_fraction        | 0.0976      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 13130       |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    reward               | 1.5039265   |\n",
      "|    std                  | 6.08        |\n",
      "|    value_loss           | 359         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1315        |\n",
      "|    time_elapsed         | 24233       |\n",
      "|    total_timesteps      | 2693120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009274936 |\n",
      "|    clip_fraction        | 0.0621      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 210         |\n",
      "|    n_updates            | 13140       |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    reward               | 2.5939085   |\n",
      "|    std                  | 6.09        |\n",
      "|    value_loss           | 435         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1316        |\n",
      "|    time_elapsed         | 24252       |\n",
      "|    total_timesteps      | 2695168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009916717 |\n",
      "|    clip_fraction        | 0.0411      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.8        |\n",
      "|    n_updates            | 13150       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | -9.145902   |\n",
      "|    std                  | 6.1         |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1317         |\n",
      "|    time_elapsed         | 24271        |\n",
      "|    total_timesteps      | 2697216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126861995 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93          |\n",
      "|    explained_variance   | 0.681        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 180          |\n",
      "|    n_updates            | 13160        |\n",
      "|    policy_gradient_loss | -0.00899     |\n",
      "|    reward               | -2.0405462   |\n",
      "|    std                  | 6.1          |\n",
      "|    value_loss           | 320          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1318        |\n",
      "|    time_elapsed         | 24290       |\n",
      "|    total_timesteps      | 2699264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010201463 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 13170       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | -0.1697655  |\n",
      "|    std                  | 6.11        |\n",
      "|    value_loss           | 399         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1319        |\n",
      "|    time_elapsed         | 24308       |\n",
      "|    total_timesteps      | 2701312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013341357 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.5        |\n",
      "|    n_updates            | 13180       |\n",
      "|    policy_gradient_loss | -0.00946    |\n",
      "|    reward               | 2.272491    |\n",
      "|    std                  | 6.12        |\n",
      "|    value_loss           | 384         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1320         |\n",
      "|    time_elapsed         | 24327        |\n",
      "|    total_timesteps      | 2703360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098854285 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.1        |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 13190        |\n",
      "|    policy_gradient_loss | -0.00804     |\n",
      "|    reward               | -2.5892751   |\n",
      "|    std                  | 6.13         |\n",
      "|    value_loss           | 39.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1321        |\n",
      "|    time_elapsed         | 24346       |\n",
      "|    total_timesteps      | 2705408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007895943 |\n",
      "|    clip_fraction        | 0.0501      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.2       |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 13200       |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    reward               | 1.7074403   |\n",
      "|    std                  | 6.14        |\n",
      "|    value_loss           | 303         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1322        |\n",
      "|    time_elapsed         | 24364       |\n",
      "|    total_timesteps      | 2707456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010755995 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.2       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 271         |\n",
      "|    n_updates            | 13210       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 13.559825   |\n",
      "|    std                  | 6.15        |\n",
      "|    value_loss           | 341         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1323        |\n",
      "|    time_elapsed         | 24383       |\n",
      "|    total_timesteps      | 2709504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010941372 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.3       |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 13220       |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    reward               | -0.694789   |\n",
      "|    std                  | 6.15        |\n",
      "|    value_loss           | 67.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1324        |\n",
      "|    time_elapsed         | 24402       |\n",
      "|    total_timesteps      | 2711552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009707674 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.3       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 195         |\n",
      "|    n_updates            | 13230       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 0.09404934  |\n",
      "|    std                  | 6.16        |\n",
      "|    value_loss           | 280         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1325         |\n",
      "|    time_elapsed         | 24420        |\n",
      "|    total_timesteps      | 2713600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032832003 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.4        |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 129          |\n",
      "|    n_updates            | 13240        |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    reward               | -14.86384    |\n",
      "|    std                  | 6.17         |\n",
      "|    value_loss           | 313          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1326         |\n",
      "|    time_elapsed         | 24440        |\n",
      "|    total_timesteps      | 2715648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032665264 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.4        |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 150          |\n",
      "|    n_updates            | 13250        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    reward               | 2.6854966    |\n",
      "|    std                  | 6.17         |\n",
      "|    value_loss           | 311          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 12122504.18\n",
      "total_reward: 11122504.18\n",
      "total_cost: 100753.76\n",
      "total_trades: 53510\n",
      "Sharpe: 1.114\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1327        |\n",
      "|    time_elapsed         | 24458       |\n",
      "|    total_timesteps      | 2717696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010073019 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.4       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 13260       |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    reward               | -2.1068263  |\n",
      "|    std                  | 6.17        |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1328         |\n",
      "|    time_elapsed         | 24477        |\n",
      "|    total_timesteps      | 2719744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010309577 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.4        |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 97.5         |\n",
      "|    n_updates            | 13270        |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    reward               | 1.3028541    |\n",
      "|    std                  | 6.17         |\n",
      "|    value_loss           | 334          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1329        |\n",
      "|    time_elapsed         | 24496       |\n",
      "|    total_timesteps      | 2721792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007418148 |\n",
      "|    clip_fraction        | 0.0311      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.4       |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.8        |\n",
      "|    n_updates            | 13280       |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    reward               | 1.9927227   |\n",
      "|    std                  | 6.18        |\n",
      "|    value_loss           | 346         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1330         |\n",
      "|    time_elapsed         | 24515        |\n",
      "|    total_timesteps      | 2723840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068818377 |\n",
      "|    clip_fraction        | 0.0586       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.4        |\n",
      "|    explained_variance   | 0.788        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.9         |\n",
      "|    n_updates            | 13290        |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    reward               | -3.772037    |\n",
      "|    std                  | 6.19         |\n",
      "|    value_loss           | 47.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1331         |\n",
      "|    time_elapsed         | 24533        |\n",
      "|    total_timesteps      | 2725888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062894626 |\n",
      "|    clip_fraction        | 0.0357       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.5        |\n",
      "|    explained_variance   | 0.828        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 13300        |\n",
      "|    policy_gradient_loss | -0.00487     |\n",
      "|    reward               | 0.8288335    |\n",
      "|    std                  | 6.19         |\n",
      "|    value_loss           | 270          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1332         |\n",
      "|    time_elapsed         | 24552        |\n",
      "|    total_timesteps      | 2727936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059178574 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.5        |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 129          |\n",
      "|    n_updates            | 13310        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -1.9448402   |\n",
      "|    std                  | 6.2          |\n",
      "|    value_loss           | 333          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1333        |\n",
      "|    time_elapsed         | 24570       |\n",
      "|    total_timesteps      | 2729984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005317003 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.5       |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.4        |\n",
      "|    n_updates            | 13320       |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    reward               | 5.371357    |\n",
      "|    std                  | 6.2         |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1334        |\n",
      "|    time_elapsed         | 24590       |\n",
      "|    total_timesteps      | 2732032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011345813 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.5       |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.3        |\n",
      "|    n_updates            | 13330       |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    reward               | -1.7425699  |\n",
      "|    std                  | 6.2         |\n",
      "|    value_loss           | 235         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1335       |\n",
      "|    time_elapsed         | 24608      |\n",
      "|    total_timesteps      | 2734080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00959935 |\n",
      "|    clip_fraction        | 0.0763     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.6      |\n",
      "|    explained_variance   | 0.8        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 190        |\n",
      "|    n_updates            | 13340      |\n",
      "|    policy_gradient_loss | -0.00965   |\n",
      "|    reward               | 0.25031176 |\n",
      "|    std                  | 6.22       |\n",
      "|    value_loss           | 326        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1336        |\n",
      "|    time_elapsed         | 24627       |\n",
      "|    total_timesteps      | 2736128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011505776 |\n",
      "|    clip_fraction        | 0.0826      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 264         |\n",
      "|    n_updates            | 13350       |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    reward               | -8.0523405  |\n",
      "|    std                  | 6.22        |\n",
      "|    value_loss           | 371         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1337        |\n",
      "|    time_elapsed         | 24646       |\n",
      "|    total_timesteps      | 2738176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010227496 |\n",
      "|    clip_fraction        | 0.0995      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.839       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 13360       |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    reward               | -0.7355328  |\n",
      "|    std                  | 6.24        |\n",
      "|    value_loss           | 49.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1338        |\n",
      "|    time_elapsed         | 24665       |\n",
      "|    total_timesteps      | 2740224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010331857 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.7       |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.3        |\n",
      "|    n_updates            | 13370       |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | -1.607616   |\n",
      "|    std                  | 6.24        |\n",
      "|    value_loss           | 294         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1339        |\n",
      "|    time_elapsed         | 24683       |\n",
      "|    total_timesteps      | 2742272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009401109 |\n",
      "|    clip_fraction        | 0.0723      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.7       |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 156         |\n",
      "|    n_updates            | 13380       |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    reward               | -3.5749822  |\n",
      "|    std                  | 6.25        |\n",
      "|    value_loss           | 371         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1340        |\n",
      "|    time_elapsed         | 24702       |\n",
      "|    total_timesteps      | 2744320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008200452 |\n",
      "|    clip_fraction        | 0.0499      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.1        |\n",
      "|    n_updates            | 13390       |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    reward               | 1.0689877   |\n",
      "|    std                  | 6.26        |\n",
      "|    value_loss           | 83.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10967240.81\n",
      "total_reward: 9967240.81\n",
      "total_cost: 104351.01\n",
      "total_trades: 52788\n",
      "Sharpe: 1.084\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1341        |\n",
      "|    time_elapsed         | 24721       |\n",
      "|    total_timesteps      | 2746368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010944484 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.9        |\n",
      "|    n_updates            | 13400       |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    reward               | -0.3005614  |\n",
      "|    std                  | 6.28        |\n",
      "|    value_loss           | 263         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1342        |\n",
      "|    time_elapsed         | 24740       |\n",
      "|    total_timesteps      | 2748416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009963097 |\n",
      "|    clip_fraction        | 0.0495      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.9       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 187         |\n",
      "|    n_updates            | 13410       |\n",
      "|    policy_gradient_loss | -0.00834    |\n",
      "|    reward               | 0.49707106  |\n",
      "|    std                  | 6.28        |\n",
      "|    value_loss           | 302         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1343       |\n",
      "|    time_elapsed         | 24758      |\n",
      "|    total_timesteps      | 2750464    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00888701 |\n",
      "|    clip_fraction        | 0.0762     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.9      |\n",
      "|    explained_variance   | 0.741      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 144        |\n",
      "|    n_updates            | 13420      |\n",
      "|    policy_gradient_loss | -0.00927   |\n",
      "|    reward               | 1.8283502  |\n",
      "|    std                  | 6.29       |\n",
      "|    value_loss           | 379        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1344        |\n",
      "|    time_elapsed         | 24777       |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010805425 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 13430       |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    reward               | -2.0675852  |\n",
      "|    std                  | 6.3         |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1345         |\n",
      "|    time_elapsed         | 24796        |\n",
      "|    total_timesteps      | 2754560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074557285 |\n",
      "|    clip_fraction        | 0.0363       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94          |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 97.6         |\n",
      "|    n_updates            | 13440        |\n",
      "|    policy_gradient_loss | -0.00887     |\n",
      "|    reward               | 0.8279346    |\n",
      "|    std                  | 6.31         |\n",
      "|    value_loss           | 346          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1346        |\n",
      "|    time_elapsed         | 24834       |\n",
      "|    total_timesteps      | 2756608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008167359 |\n",
      "|    clip_fraction        | 0.0503      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 290         |\n",
      "|    n_updates            | 13450       |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    reward               | -7.9945946  |\n",
      "|    std                  | 6.32        |\n",
      "|    value_loss           | 380         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1347        |\n",
      "|    time_elapsed         | 24853       |\n",
      "|    total_timesteps      | 2758656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012383716 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 13460       |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | 1.3981831   |\n",
      "|    std                  | 6.33        |\n",
      "|    value_loss           | 66.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1348         |\n",
      "|    time_elapsed         | 24871        |\n",
      "|    total_timesteps      | 2760704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061396686 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.1        |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 120          |\n",
      "|    n_updates            | 13470        |\n",
      "|    policy_gradient_loss | -0.00619     |\n",
      "|    reward               | 1.028555     |\n",
      "|    std                  | 6.33         |\n",
      "|    value_loss           | 309          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1349         |\n",
      "|    time_elapsed         | 24890        |\n",
      "|    total_timesteps      | 2762752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066572786 |\n",
      "|    clip_fraction        | 0.0324       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.1        |\n",
      "|    explained_variance   | 0.753        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 186          |\n",
      "|    n_updates            | 13480        |\n",
      "|    policy_gradient_loss | -0.0078      |\n",
      "|    reward               | -34.83261    |\n",
      "|    std                  | 6.34         |\n",
      "|    value_loss           | 295          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1350        |\n",
      "|    time_elapsed         | 24909       |\n",
      "|    total_timesteps      | 2764800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009007428 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.2       |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.9        |\n",
      "|    n_updates            | 13490       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | -2.1573317  |\n",
      "|    std                  | 6.34        |\n",
      "|    value_loss           | 351         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1351        |\n",
      "|    time_elapsed         | 24927       |\n",
      "|    total_timesteps      | 2766848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009742064 |\n",
      "|    clip_fraction        | 0.0662      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.2       |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.4        |\n",
      "|    n_updates            | 13500       |\n",
      "|    policy_gradient_loss | -0.00818    |\n",
      "|    reward               | -1.6387334  |\n",
      "|    std                  | 6.36        |\n",
      "|    value_loss           | 80.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1352         |\n",
      "|    time_elapsed         | 24946        |\n",
      "|    total_timesteps      | 2768896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072505684 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.2        |\n",
      "|    explained_variance   | 0.821        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 374          |\n",
      "|    n_updates            | 13510        |\n",
      "|    policy_gradient_loss | -0.00877     |\n",
      "|    reward               | -0.31746417  |\n",
      "|    std                  | 6.36         |\n",
      "|    value_loss           | 327          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1353        |\n",
      "|    time_elapsed         | 24964       |\n",
      "|    total_timesteps      | 2770944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007578505 |\n",
      "|    clip_fraction        | 0.081       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.2       |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 220         |\n",
      "|    n_updates            | 13520       |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | -3.4847524  |\n",
      "|    std                  | 6.36        |\n",
      "|    value_loss           | 352         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1354        |\n",
      "|    time_elapsed         | 24983       |\n",
      "|    total_timesteps      | 2772992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009533382 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 13530       |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    reward               | -1.530763   |\n",
      "|    std                  | 6.38        |\n",
      "|    value_loss           | 70.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11748919.29\n",
      "total_reward: 10748919.29\n",
      "total_cost: 81912.04\n",
      "total_trades: 51137\n",
      "Sharpe: 1.103\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1355        |\n",
      "|    time_elapsed         | 25002       |\n",
      "|    total_timesteps      | 2775040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011987424 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81          |\n",
      "|    n_updates            | 13540       |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    reward               | -0.6203093  |\n",
      "|    std                  | 6.38        |\n",
      "|    value_loss           | 311         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1356        |\n",
      "|    time_elapsed         | 25021       |\n",
      "|    total_timesteps      | 2777088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013087457 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.9        |\n",
      "|    n_updates            | 13550       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | 0.55496967  |\n",
      "|    std                  | 6.39        |\n",
      "|    value_loss           | 328         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1357        |\n",
      "|    time_elapsed         | 25040       |\n",
      "|    total_timesteps      | 2779136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006328903 |\n",
      "|    clip_fraction        | 0.0358      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.4       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.1        |\n",
      "|    n_updates            | 13560       |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | 1.4398785   |\n",
      "|    std                  | 6.4         |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1358        |\n",
      "|    time_elapsed         | 25058       |\n",
      "|    total_timesteps      | 2781184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009052895 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.4       |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 13570       |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    reward               | 0.22304723  |\n",
      "|    std                  | 6.41        |\n",
      "|    value_loss           | 288         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1359        |\n",
      "|    time_elapsed         | 25077       |\n",
      "|    total_timesteps      | 2783232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009511258 |\n",
      "|    clip_fraction        | 0.0757      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.4       |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 195         |\n",
      "|    n_updates            | 13580       |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    reward               | -0.6563529  |\n",
      "|    std                  | 6.4         |\n",
      "|    value_loss           | 300         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1360         |\n",
      "|    time_elapsed         | 25096        |\n",
      "|    total_timesteps      | 2785280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072868047 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.4        |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 148          |\n",
      "|    n_updates            | 13590        |\n",
      "|    policy_gradient_loss | -0.00548     |\n",
      "|    reward               | -0.090520985 |\n",
      "|    std                  | 6.41         |\n",
      "|    value_loss           | 355          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1361        |\n",
      "|    time_elapsed         | 25115       |\n",
      "|    total_timesteps      | 2787328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010686507 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 13600       |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    reward               | -2.2888422  |\n",
      "|    std                  | 6.43        |\n",
      "|    value_loss           | 47.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1362        |\n",
      "|    time_elapsed         | 25134       |\n",
      "|    total_timesteps      | 2789376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011955483 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 242         |\n",
      "|    n_updates            | 13610       |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    reward               | 1.9506803   |\n",
      "|    std                  | 6.44        |\n",
      "|    value_loss           | 455         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1363         |\n",
      "|    time_elapsed         | 25153        |\n",
      "|    total_timesteps      | 2791424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065799737 |\n",
      "|    clip_fraction        | 0.0325       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.6        |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 344          |\n",
      "|    n_updates            | 13620        |\n",
      "|    policy_gradient_loss | -0.00473     |\n",
      "|    reward               | 3.5214305    |\n",
      "|    std                  | 6.45         |\n",
      "|    value_loss           | 423          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1364        |\n",
      "|    time_elapsed         | 25172       |\n",
      "|    total_timesteps      | 2793472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010941317 |\n",
      "|    clip_fraction        | 0.0525      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.6       |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.8        |\n",
      "|    n_updates            | 13630       |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    reward               | 0.3560995   |\n",
      "|    std                  | 6.44        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1365        |\n",
      "|    time_elapsed         | 25191       |\n",
      "|    total_timesteps      | 2795520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009314952 |\n",
      "|    clip_fraction        | 0.0693      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.6       |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 13640       |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    reward               | 0.5931364   |\n",
      "|    std                  | 6.46        |\n",
      "|    value_loss           | 314         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1366        |\n",
      "|    time_elapsed         | 25210       |\n",
      "|    total_timesteps      | 2797568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011154907 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.7       |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.9        |\n",
      "|    n_updates            | 13650       |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    reward               | -1.078767   |\n",
      "|    std                  | 6.45        |\n",
      "|    value_loss           | 367         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1367         |\n",
      "|    time_elapsed         | 25229        |\n",
      "|    total_timesteps      | 2799616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044715926 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.7        |\n",
      "|    explained_variance   | 0.742        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 141          |\n",
      "|    n_updates            | 13660        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | 2.9831994    |\n",
      "|    std                  | 6.46         |\n",
      "|    value_loss           | 365          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1368        |\n",
      "|    time_elapsed         | 25248       |\n",
      "|    total_timesteps      | 2801664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011715344 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.7       |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 13670       |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    reward               | -3.637301   |\n",
      "|    std                  | 6.47        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 13030191.40\n",
      "total_reward: 12030191.40\n",
      "total_cost: 79190.79\n",
      "total_trades: 50974\n",
      "Sharpe: 1.109\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1369        |\n",
      "|    time_elapsed         | 25266       |\n",
      "|    total_timesteps      | 2803712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010274349 |\n",
      "|    clip_fraction        | 0.0849      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.7       |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.8        |\n",
      "|    n_updates            | 13680       |\n",
      "|    policy_gradient_loss | -0.00956    |\n",
      "|    reward               | -0.23436522 |\n",
      "|    std                  | 6.48        |\n",
      "|    value_loss           | 360         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1370        |\n",
      "|    time_elapsed         | 25285       |\n",
      "|    total_timesteps      | 2805760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008545931 |\n",
      "|    clip_fraction        | 0.0341      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 236         |\n",
      "|    n_updates            | 13690       |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    reward               | -6.9036903  |\n",
      "|    std                  | 6.49        |\n",
      "|    value_loss           | 443         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1371         |\n",
      "|    time_elapsed         | 25304        |\n",
      "|    total_timesteps      | 2807808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077422517 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.8        |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.4         |\n",
      "|    n_updates            | 13700        |\n",
      "|    policy_gradient_loss | -0.00866     |\n",
      "|    reward               | -1.9432739   |\n",
      "|    std                  | 6.49         |\n",
      "|    value_loss           | 69.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1372        |\n",
      "|    time_elapsed         | 25323       |\n",
      "|    total_timesteps      | 2809856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011303737 |\n",
      "|    clip_fraction        | 0.0815      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 205         |\n",
      "|    n_updates            | 13710       |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    reward               | -0.96302336 |\n",
      "|    std                  | 6.51        |\n",
      "|    value_loss           | 323         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1373        |\n",
      "|    time_elapsed         | 25342       |\n",
      "|    total_timesteps      | 2811904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007982072 |\n",
      "|    clip_fraction        | 0.032       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.9       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.8        |\n",
      "|    n_updates            | 13720       |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    reward               | -16.391552  |\n",
      "|    std                  | 6.52        |\n",
      "|    value_loss           | 375         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1374       |\n",
      "|    time_elapsed         | 25361      |\n",
      "|    total_timesteps      | 2813952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00583387 |\n",
      "|    clip_fraction        | 0.0274     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.9      |\n",
      "|    explained_variance   | 0.794      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 162        |\n",
      "|    n_updates            | 13730      |\n",
      "|    policy_gradient_loss | -0.00548   |\n",
      "|    reward               | 1.3134292  |\n",
      "|    std                  | 6.53       |\n",
      "|    value_loss           | 205        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1375        |\n",
      "|    time_elapsed         | 25380       |\n",
      "|    total_timesteps      | 2816000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010226945 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95         |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.9        |\n",
      "|    n_updates            | 13740       |\n",
      "|    policy_gradient_loss | -0.00992    |\n",
      "|    reward               | -2.0190017  |\n",
      "|    std                  | 6.55        |\n",
      "|    value_loss           | 186         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1376        |\n",
      "|    time_elapsed         | 25398       |\n",
      "|    total_timesteps      | 2818048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008171221 |\n",
      "|    clip_fraction        | 0.0446      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.1       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 193         |\n",
      "|    n_updates            | 13750       |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | 0.17260183  |\n",
      "|    std                  | 6.56        |\n",
      "|    value_loss           | 417         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1377        |\n",
      "|    time_elapsed         | 25417       |\n",
      "|    total_timesteps      | 2820096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004017135 |\n",
      "|    clip_fraction        | 0.0118      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.1       |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 294         |\n",
      "|    n_updates            | 13760       |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    reward               | -3.3702273  |\n",
      "|    std                  | 6.56        |\n",
      "|    value_loss           | 454         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1378        |\n",
      "|    time_elapsed         | 25436       |\n",
      "|    total_timesteps      | 2822144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008043256 |\n",
      "|    clip_fraction        | 0.035       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.1       |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 13770       |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | 2.1918015   |\n",
      "|    std                  | 6.58        |\n",
      "|    value_loss           | 59.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1379        |\n",
      "|    time_elapsed         | 25455       |\n",
      "|    total_timesteps      | 2824192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011102961 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 216         |\n",
      "|    n_updates            | 13780       |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    reward               | -1.5735942  |\n",
      "|    std                  | 6.59        |\n",
      "|    value_loss           | 365         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1380        |\n",
      "|    time_elapsed         | 25473       |\n",
      "|    total_timesteps      | 2826240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009585692 |\n",
      "|    clip_fraction        | 0.0883      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 13790       |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | -1.8180214  |\n",
      "|    std                  | 6.6         |\n",
      "|    value_loss           | 414         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1381         |\n",
      "|    time_elapsed         | 25492        |\n",
      "|    total_timesteps      | 2828288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040639546 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.3        |\n",
      "|    explained_variance   | 0.882        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.3         |\n",
      "|    n_updates            | 13800        |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    reward               | -3.7633362   |\n",
      "|    std                  | 6.61         |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1382        |\n",
      "|    time_elapsed         | 25511       |\n",
      "|    total_timesteps      | 2830336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011541095 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 213         |\n",
      "|    n_updates            | 13810       |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    reward               | -1.9113907  |\n",
      "|    std                  | 6.61        |\n",
      "|    value_loss           | 299         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 13133679.33\n",
      "total_reward: 12133679.33\n",
      "total_cost: 74062.29\n",
      "total_trades: 50540\n",
      "Sharpe: 1.100\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1383         |\n",
      "|    time_elapsed         | 25529        |\n",
      "|    total_timesteps      | 2832384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076620416 |\n",
      "|    clip_fraction        | 0.0446       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.3        |\n",
      "|    explained_variance   | 0.808        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.1         |\n",
      "|    n_updates            | 13820        |\n",
      "|    policy_gradient_loss | -0.00799     |\n",
      "|    reward               | 0.6657819    |\n",
      "|    std                  | 6.61         |\n",
      "|    value_loss           | 387          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1384         |\n",
      "|    time_elapsed         | 25548        |\n",
      "|    total_timesteps      | 2834432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103849415 |\n",
      "|    clip_fraction        | 0.0601       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.3        |\n",
      "|    explained_variance   | 0.761        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 135          |\n",
      "|    n_updates            | 13830        |\n",
      "|    policy_gradient_loss | -0.00806     |\n",
      "|    reward               | 4.8431535    |\n",
      "|    std                  | 6.62         |\n",
      "|    value_loss           | 440          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1385        |\n",
      "|    time_elapsed         | 25567       |\n",
      "|    total_timesteps      | 2836480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009194845 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 13840       |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    reward               | -3.2161763  |\n",
      "|    std                  | 6.63        |\n",
      "|    value_loss           | 52.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1386        |\n",
      "|    time_elapsed         | 25585       |\n",
      "|    total_timesteps      | 2838528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011249466 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95          |\n",
      "|    n_updates            | 13850       |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    reward               | -0.849902   |\n",
      "|    std                  | 6.63        |\n",
      "|    value_loss           | 280         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1387         |\n",
      "|    time_elapsed         | 25604        |\n",
      "|    total_timesteps      | 2840576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062238537 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.4        |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 235          |\n",
      "|    n_updates            | 13860        |\n",
      "|    policy_gradient_loss | -0.00639     |\n",
      "|    reward               | -2.506799    |\n",
      "|    std                  | 6.64         |\n",
      "|    value_loss           | 392          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1388        |\n",
      "|    time_elapsed         | 25623       |\n",
      "|    total_timesteps      | 2842624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010003667 |\n",
      "|    clip_fraction        | 0.0869      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.5       |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.6        |\n",
      "|    n_updates            | 13870       |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    reward               | 1.6766331   |\n",
      "|    std                  | 6.64        |\n",
      "|    value_loss           | 97.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1389        |\n",
      "|    time_elapsed         | 25642       |\n",
      "|    total_timesteps      | 2844672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009448656 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.5       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 306         |\n",
      "|    n_updates            | 13880       |\n",
      "|    policy_gradient_loss | -0.00942    |\n",
      "|    reward               | 0.05906209  |\n",
      "|    std                  | 6.66        |\n",
      "|    value_loss           | 305         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1390        |\n",
      "|    time_elapsed         | 25661       |\n",
      "|    total_timesteps      | 2846720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008524053 |\n",
      "|    clip_fraction        | 0.0524      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.6       |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 186         |\n",
      "|    n_updates            | 13890       |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    reward               | -0.33743864 |\n",
      "|    std                  | 6.67        |\n",
      "|    value_loss           | 441         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1391        |\n",
      "|    time_elapsed         | 25680       |\n",
      "|    total_timesteps      | 2848768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009741826 |\n",
      "|    clip_fraction        | 0.0444      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.6       |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 155         |\n",
      "|    n_updates            | 13900       |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    reward               | 0.07327293  |\n",
      "|    std                  | 6.68        |\n",
      "|    value_loss           | 367         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1392        |\n",
      "|    time_elapsed         | 25699       |\n",
      "|    total_timesteps      | 2850816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011738788 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.7       |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 13910       |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    reward               | 0.19893882  |\n",
      "|    std                  | 6.7         |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1393        |\n",
      "|    time_elapsed         | 25717       |\n",
      "|    total_timesteps      | 2852864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010145005 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.7       |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 13920       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 0.1868764   |\n",
      "|    std                  | 6.7         |\n",
      "|    value_loss           | 379         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1394        |\n",
      "|    time_elapsed         | 25736       |\n",
      "|    total_timesteps      | 2854912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007141116 |\n",
      "|    clip_fraction        | 0.035       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.7       |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.4        |\n",
      "|    n_updates            | 13930       |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    reward               | 0.5926822   |\n",
      "|    std                  | 6.7         |\n",
      "|    value_loss           | 372         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1395         |\n",
      "|    time_elapsed         | 25755        |\n",
      "|    total_timesteps      | 2856960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104316175 |\n",
      "|    clip_fraction        | 0.0853       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.8        |\n",
      "|    explained_variance   | 0.809        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 13940        |\n",
      "|    policy_gradient_loss | -0.00982     |\n",
      "|    reward               | 0.3948691    |\n",
      "|    std                  | 6.71         |\n",
      "|    value_loss           | 73.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1396         |\n",
      "|    time_elapsed         | 25774        |\n",
      "|    total_timesteps      | 2859008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069585703 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.8        |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 274          |\n",
      "|    n_updates            | 13950        |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    reward               | 0.3518007    |\n",
      "|    std                  | 6.72         |\n",
      "|    value_loss           | 355          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1397        |\n",
      "|    time_elapsed         | 25793       |\n",
      "|    total_timesteps      | 2861056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004654727 |\n",
      "|    clip_fraction        | 0.0131      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.8       |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 186         |\n",
      "|    n_updates            | 13960       |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    reward               | 13.730814   |\n",
      "|    std                  | 6.72        |\n",
      "|    value_loss           | 351         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11191845.71\n",
      "total_reward: 10191845.71\n",
      "total_cost: 63480.23\n",
      "total_trades: 49844\n",
      "Sharpe: 1.033\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1398         |\n",
      "|    time_elapsed         | 25812        |\n",
      "|    total_timesteps      | 2863104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097403815 |\n",
      "|    clip_fraction        | 0.0756       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.9        |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.3         |\n",
      "|    n_updates            | 13970        |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    reward               | 0.6044829    |\n",
      "|    std                  | 6.73         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1399        |\n",
      "|    time_elapsed         | 25830       |\n",
      "|    total_timesteps      | 2865152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011309831 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.1        |\n",
      "|    n_updates            | 13980       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | 0.027649097 |\n",
      "|    std                  | 6.75        |\n",
      "|    value_loss           | 227         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1400        |\n",
      "|    time_elapsed         | 25849       |\n",
      "|    total_timesteps      | 2867200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008100462 |\n",
      "|    clip_fraction        | 0.0712      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96         |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 13990       |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    reward               | 2.0538073   |\n",
      "|    std                  | 6.75        |\n",
      "|    value_loss           | 314         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1401        |\n",
      "|    time_elapsed         | 25868       |\n",
      "|    total_timesteps      | 2869248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008589952 |\n",
      "|    clip_fraction        | 0.0358      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96         |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 14000       |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    reward               | 12.611982   |\n",
      "|    std                  | 6.75        |\n",
      "|    value_loss           | 392         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1402        |\n",
      "|    time_elapsed         | 25887       |\n",
      "|    total_timesteps      | 2871296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008500322 |\n",
      "|    clip_fraction        | 0.0583      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96         |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 14010       |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    reward               | -2.654953   |\n",
      "|    std                  | 6.77        |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1403        |\n",
      "|    time_elapsed         | 25906       |\n",
      "|    total_timesteps      | 2873344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011415539 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.1       |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 241         |\n",
      "|    n_updates            | 14020       |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    reward               | -0.71971613 |\n",
      "|    std                  | 6.79        |\n",
      "|    value_loss           | 319         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1404         |\n",
      "|    time_elapsed         | 25925        |\n",
      "|    total_timesteps      | 2875392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066793384 |\n",
      "|    clip_fraction        | 0.0259       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.1        |\n",
      "|    explained_variance   | 0.809        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 14030        |\n",
      "|    policy_gradient_loss | -0.00714     |\n",
      "|    reward               | -2.243836    |\n",
      "|    std                  | 6.79         |\n",
      "|    value_loss           | 288          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1405        |\n",
      "|    time_elapsed         | 25944       |\n",
      "|    total_timesteps      | 2877440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008741507 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | 0.9         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56          |\n",
      "|    n_updates            | 14040       |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | 3.5904346   |\n",
      "|    std                  | 6.82        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1406         |\n",
      "|    time_elapsed         | 25963        |\n",
      "|    total_timesteps      | 2879488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013125449  |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.3        |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 105          |\n",
      "|    n_updates            | 14050        |\n",
      "|    policy_gradient_loss | -0.00944     |\n",
      "|    reward               | -0.036382142 |\n",
      "|    std                  | 6.83         |\n",
      "|    value_loss           | 267          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1407         |\n",
      "|    time_elapsed         | 25982        |\n",
      "|    total_timesteps      | 2881536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095800795 |\n",
      "|    clip_fraction        | 0.0475       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.3        |\n",
      "|    explained_variance   | 0.812        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 227          |\n",
      "|    n_updates            | 14060        |\n",
      "|    policy_gradient_loss | -0.00636     |\n",
      "|    reward               | 0.38225695   |\n",
      "|    std                  | 6.84         |\n",
      "|    value_loss           | 305          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1408        |\n",
      "|    time_elapsed         | 26001       |\n",
      "|    total_timesteps      | 2883584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006994993 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.3       |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 14070       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | -4.7812133  |\n",
      "|    std                  | 6.85        |\n",
      "|    value_loss           | 344         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1409         |\n",
      "|    time_elapsed         | 26019        |\n",
      "|    total_timesteps      | 2885632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035156284 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.3        |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.1         |\n",
      "|    n_updates            | 14080        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    reward               | 4.81053      |\n",
      "|    std                  | 6.85         |\n",
      "|    value_loss           | 50.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1410        |\n",
      "|    time_elapsed         | 26038       |\n",
      "|    total_timesteps      | 2887680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009829925 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.4       |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 200         |\n",
      "|    n_updates            | 14090       |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    reward               | -0.3569859  |\n",
      "|    std                  | 6.87        |\n",
      "|    value_loss           | 305         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1411       |\n",
      "|    time_elapsed         | 26057      |\n",
      "|    total_timesteps      | 2889728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01223091 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96.5      |\n",
      "|    explained_variance   | 0.737      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 184        |\n",
      "|    n_updates            | 14100      |\n",
      "|    policy_gradient_loss | -0.00468   |\n",
      "|    reward               | -4.3015027 |\n",
      "|    std                  | 6.88       |\n",
      "|    value_loss           | 333        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11324379.99\n",
      "total_reward: 10324379.99\n",
      "total_cost: 56510.73\n",
      "total_trades: 49500\n",
      "Sharpe: 1.038\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1412        |\n",
      "|    time_elapsed         | 26075       |\n",
      "|    total_timesteps      | 2891776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008601442 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.5       |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 14110       |\n",
      "|    policy_gradient_loss | -0.00745    |\n",
      "|    reward               | -5.30438    |\n",
      "|    std                  | 6.89        |\n",
      "|    value_loss           | 77.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1413        |\n",
      "|    time_elapsed         | 26094       |\n",
      "|    total_timesteps      | 2893824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015913991 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.5       |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 14120       |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    reward               | 0.7266367   |\n",
      "|    std                  | 6.89        |\n",
      "|    value_loss           | 266         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1414        |\n",
      "|    time_elapsed         | 26112       |\n",
      "|    total_timesteps      | 2895872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010434038 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 333         |\n",
      "|    n_updates            | 14130       |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    reward               | 12.316019   |\n",
      "|    std                  | 6.9         |\n",
      "|    value_loss           | 365         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1415        |\n",
      "|    time_elapsed         | 26131       |\n",
      "|    total_timesteps      | 2897920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009972935 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 14140       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 1.137876    |\n",
      "|    std                  | 6.91        |\n",
      "|    value_loss           | 371         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1416        |\n",
      "|    time_elapsed         | 26150       |\n",
      "|    total_timesteps      | 2899968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009490951 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 14150       |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | 1.8056893   |\n",
      "|    std                  | 6.92        |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1417        |\n",
      "|    time_elapsed         | 26169       |\n",
      "|    total_timesteps      | 2902016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010951366 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 14160       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -4.088838   |\n",
      "|    std                  | 6.93        |\n",
      "|    value_loss           | 392         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1418         |\n",
      "|    time_elapsed         | 26188        |\n",
      "|    total_timesteps      | 2904064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047808383 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.7        |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90.3         |\n",
      "|    n_updates            | 14170        |\n",
      "|    policy_gradient_loss | -0.00508     |\n",
      "|    reward               | -11.717487   |\n",
      "|    std                  | 6.93         |\n",
      "|    value_loss           | 434          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1419       |\n",
      "|    time_elapsed         | 26208      |\n",
      "|    total_timesteps      | 2906112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00614163 |\n",
      "|    clip_fraction        | 0.0595     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96.7      |\n",
      "|    explained_variance   | 0.894      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.5       |\n",
      "|    n_updates            | 14180      |\n",
      "|    policy_gradient_loss | -0.00758   |\n",
      "|    reward               | -3.2409148 |\n",
      "|    std                  | 6.94       |\n",
      "|    value_loss           | 59.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1420        |\n",
      "|    time_elapsed         | 26227       |\n",
      "|    total_timesteps      | 2908160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007518172 |\n",
      "|    clip_fraction        | 0.0324      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.8       |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 172         |\n",
      "|    n_updates            | 14190       |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    reward               | 2.567857    |\n",
      "|    std                  | 6.94        |\n",
      "|    value_loss           | 333         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1421         |\n",
      "|    time_elapsed         | 26246        |\n",
      "|    total_timesteps      | 2910208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053515797 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.8        |\n",
      "|    explained_variance   | 0.769        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 244          |\n",
      "|    n_updates            | 14200        |\n",
      "|    policy_gradient_loss | -0.0065      |\n",
      "|    reward               | 10.06739     |\n",
      "|    std                  | 6.94         |\n",
      "|    value_loss           | 420          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1422        |\n",
      "|    time_elapsed         | 26265       |\n",
      "|    total_timesteps      | 2912256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008531871 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.8       |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.6        |\n",
      "|    n_updates            | 14210       |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    reward               | -4.8757453  |\n",
      "|    std                  | 6.95        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1423         |\n",
      "|    time_elapsed         | 26283        |\n",
      "|    total_timesteps      | 2914304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070625017 |\n",
      "|    clip_fraction        | 0.0299       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.8        |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.8         |\n",
      "|    n_updates            | 14220        |\n",
      "|    policy_gradient_loss | -0.00678     |\n",
      "|    reward               | -0.17125073  |\n",
      "|    std                  | 6.97         |\n",
      "|    value_loss           | 299          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1424        |\n",
      "|    time_elapsed         | 26302       |\n",
      "|    total_timesteps      | 2916352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007368731 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.9       |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 14230       |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    reward               | 2.5154538   |\n",
      "|    std                  | 6.97        |\n",
      "|    value_loss           | 401         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1425         |\n",
      "|    time_elapsed         | 26321        |\n",
      "|    total_timesteps      | 2918400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060957707 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.9        |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 87.9         |\n",
      "|    n_updates            | 14240        |\n",
      "|    policy_gradient_loss | -0.00524     |\n",
      "|    reward               | -2.854555    |\n",
      "|    std                  | 6.97         |\n",
      "|    value_loss           | 412          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 13252622.49\n",
      "total_reward: 12252622.49\n",
      "total_cost: 78719.77\n",
      "total_trades: 51873\n",
      "Sharpe: 1.108\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1426         |\n",
      "|    time_elapsed         | 26340        |\n",
      "|    total_timesteps      | 2920448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069693737 |\n",
      "|    clip_fraction        | 0.0646       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.9        |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 14250        |\n",
      "|    policy_gradient_loss | -0.00692     |\n",
      "|    reward               | 1.2216791    |\n",
      "|    std                  | 6.98         |\n",
      "|    value_loss           | 58.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1427        |\n",
      "|    time_elapsed         | 26359       |\n",
      "|    total_timesteps      | 2922496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009047443 |\n",
      "|    clip_fraction        | 0.0609      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 194         |\n",
      "|    n_updates            | 14260       |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    reward               | 0.08271289  |\n",
      "|    std                  | 6.99        |\n",
      "|    value_loss           | 379         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1428         |\n",
      "|    time_elapsed         | 26378        |\n",
      "|    total_timesteps      | 2924544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063935616 |\n",
      "|    clip_fraction        | 0.0401       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97          |\n",
      "|    explained_variance   | 0.769        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 225          |\n",
      "|    n_updates            | 14270        |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    reward               | -8.561681    |\n",
      "|    std                  | 7            |\n",
      "|    value_loss           | 369          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1429       |\n",
      "|    time_elapsed         | 26397      |\n",
      "|    total_timesteps      | 2926592    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00923367 |\n",
      "|    clip_fraction        | 0.055      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.1      |\n",
      "|    explained_variance   | 0.875      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 46.1       |\n",
      "|    n_updates            | 14280      |\n",
      "|    policy_gradient_loss | -0.00764   |\n",
      "|    reward               | -6.1291094 |\n",
      "|    std                  | 7.02       |\n",
      "|    value_loss           | 97.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1430        |\n",
      "|    time_elapsed         | 26416       |\n",
      "|    total_timesteps      | 2928640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005029856 |\n",
      "|    clip_fraction        | 0.0124      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.1       |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 99.3        |\n",
      "|    n_updates            | 14290       |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    reward               | 2.0121539   |\n",
      "|    std                  | 7.02        |\n",
      "|    value_loss           | 278         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1431        |\n",
      "|    time_elapsed         | 26434       |\n",
      "|    total_timesteps      | 2930688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008389041 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.1       |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 14300       |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    reward               | 0.15509568  |\n",
      "|    std                  | 7.03        |\n",
      "|    value_loss           | 330         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1432         |\n",
      "|    time_elapsed         | 26453        |\n",
      "|    total_timesteps      | 2932736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074249865 |\n",
      "|    clip_fraction        | 0.045        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.2        |\n",
      "|    explained_variance   | 0.763        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 14310        |\n",
      "|    policy_gradient_loss | -0.00794     |\n",
      "|    reward               | -2.198152    |\n",
      "|    std                  | 7.04         |\n",
      "|    value_loss           | 331          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1433        |\n",
      "|    time_elapsed         | 26472       |\n",
      "|    total_timesteps      | 2934784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010311857 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.2       |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 14320       |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | 4.9869194   |\n",
      "|    std                  | 7.05        |\n",
      "|    value_loss           | 44.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1434        |\n",
      "|    time_elapsed         | 26491       |\n",
      "|    total_timesteps      | 2936832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010401938 |\n",
      "|    clip_fraction        | 0.0546      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 14330       |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    reward               | 0.17443559  |\n",
      "|    std                  | 7.06        |\n",
      "|    value_loss           | 366         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1435         |\n",
      "|    time_elapsed         | 26511        |\n",
      "|    total_timesteps      | 2938880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077057923 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.3        |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 277          |\n",
      "|    n_updates            | 14340        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    reward               | -9.769753    |\n",
      "|    std                  | 7.06         |\n",
      "|    value_loss           | 477          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1436        |\n",
      "|    time_elapsed         | 26530       |\n",
      "|    total_timesteps      | 2940928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008949986 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.5        |\n",
      "|    n_updates            | 14350       |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    reward               | 0.018034779 |\n",
      "|    std                  | 7.07        |\n",
      "|    value_loss           | 88.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1437         |\n",
      "|    time_elapsed         | 26548        |\n",
      "|    total_timesteps      | 2942976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098427255 |\n",
      "|    clip_fraction        | 0.0715       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.3        |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 14360        |\n",
      "|    policy_gradient_loss | -0.00793     |\n",
      "|    reward               | -0.9845131   |\n",
      "|    std                  | 7.07         |\n",
      "|    value_loss           | 385          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1438        |\n",
      "|    time_elapsed         | 26567       |\n",
      "|    total_timesteps      | 2945024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008543575 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 221         |\n",
      "|    n_updates            | 14370       |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    reward               | -46.818726  |\n",
      "|    std                  | 7.07        |\n",
      "|    value_loss           | 405         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1439        |\n",
      "|    time_elapsed         | 26586       |\n",
      "|    total_timesteps      | 2947072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007772715 |\n",
      "|    clip_fraction        | 0.028       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.4       |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.3        |\n",
      "|    n_updates            | 14380       |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    reward               | -1.9911336  |\n",
      "|    std                  | 7.08        |\n",
      "|    value_loss           | 371         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11930537.06\n",
      "total_reward: 10930537.06\n",
      "total_cost: 72015.23\n",
      "total_trades: 51875\n",
      "Sharpe: 1.036\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1440        |\n",
      "|    time_elapsed         | 26605       |\n",
      "|    total_timesteps      | 2949120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010388884 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.4       |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 14390       |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    reward               | 1.933992    |\n",
      "|    std                  | 7.08        |\n",
      "|    value_loss           | 76.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1441        |\n",
      "|    time_elapsed         | 26624       |\n",
      "|    total_timesteps      | 2951168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007977153 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.4       |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 14400       |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    reward               | 1.3978895   |\n",
      "|    std                  | 7.1         |\n",
      "|    value_loss           | 326         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1442         |\n",
      "|    time_elapsed         | 26643        |\n",
      "|    total_timesteps      | 2953216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071030147 |\n",
      "|    clip_fraction        | 0.0419       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.5        |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.6         |\n",
      "|    n_updates            | 14410        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    reward               | 1.9463125    |\n",
      "|    std                  | 7.1          |\n",
      "|    value_loss           | 399          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1443        |\n",
      "|    time_elapsed         | 26662       |\n",
      "|    total_timesteps      | 2955264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010664695 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.885       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.7        |\n",
      "|    n_updates            | 14420       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -3.0751307  |\n",
      "|    std                  | 7.11        |\n",
      "|    value_loss           | 57.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1444        |\n",
      "|    time_elapsed         | 26681       |\n",
      "|    total_timesteps      | 2957312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010228303 |\n",
      "|    clip_fraction        | 0.0628      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 272         |\n",
      "|    n_updates            | 14430       |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    reward               | 1.6729802   |\n",
      "|    std                  | 7.12        |\n",
      "|    value_loss           | 336         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1445         |\n",
      "|    time_elapsed         | 26700        |\n",
      "|    total_timesteps      | 2959360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047152396 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.5        |\n",
      "|    explained_variance   | 0.707        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 166          |\n",
      "|    n_updates            | 14440        |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    reward               | 13.282072    |\n",
      "|    std                  | 7.12         |\n",
      "|    value_loss           | 420          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1446        |\n",
      "|    time_elapsed         | 26719       |\n",
      "|    total_timesteps      | 2961408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00554762  |\n",
      "|    clip_fraction        | 0.0228      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.7        |\n",
      "|    n_updates            | 14450       |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    reward               | -0.17268887 |\n",
      "|    std                  | 7.12        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1447         |\n",
      "|    time_elapsed         | 26738        |\n",
      "|    total_timesteps      | 2963456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069418433 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.5        |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 103          |\n",
      "|    n_updates            | 14460        |\n",
      "|    policy_gradient_loss | -0.00696     |\n",
      "|    reward               | 0.3271519    |\n",
      "|    std                  | 7.12         |\n",
      "|    value_loss           | 358          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1448        |\n",
      "|    time_elapsed         | 26757       |\n",
      "|    total_timesteps      | 2965504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01190377  |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.6       |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 183         |\n",
      "|    n_updates            | 14470       |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | -0.13950826 |\n",
      "|    std                  | 7.13        |\n",
      "|    value_loss           | 351         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1449        |\n",
      "|    time_elapsed         | 26776       |\n",
      "|    total_timesteps      | 2967552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008139359 |\n",
      "|    clip_fraction        | 0.0493      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.6       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 347         |\n",
      "|    n_updates            | 14480       |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | 1.8714646   |\n",
      "|    std                  | 7.15        |\n",
      "|    value_loss           | 404         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1450        |\n",
      "|    time_elapsed         | 26795       |\n",
      "|    total_timesteps      | 2969600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009224123 |\n",
      "|    clip_fraction        | 0.0576      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.7       |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 14490       |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    reward               | 1.4022182   |\n",
      "|    std                  | 7.16        |\n",
      "|    value_loss           | 57          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1451        |\n",
      "|    time_elapsed         | 26813       |\n",
      "|    total_timesteps      | 2971648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010568603 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.7       |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 170         |\n",
      "|    n_updates            | 14500       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -0.4498973  |\n",
      "|    std                  | 7.17        |\n",
      "|    value_loss           | 336         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1452         |\n",
      "|    time_elapsed         | 26832        |\n",
      "|    total_timesteps      | 2973696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040513007 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.7        |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 153          |\n",
      "|    n_updates            | 14510        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    reward               | 0.8136697    |\n",
      "|    std                  | 7.18         |\n",
      "|    value_loss           | 430          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 1453       |\n",
      "|    time_elapsed         | 26851      |\n",
      "|    total_timesteps      | 2975744    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01121716 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.8      |\n",
      "|    explained_variance   | 0.855      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 58.4       |\n",
      "|    n_updates            | 14520      |\n",
      "|    policy_gradient_loss | -0.00854   |\n",
      "|    reward               | 3.429231   |\n",
      "|    std                  | 7.19       |\n",
      "|    value_loss           | 100        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 12301183.27\n",
      "total_reward: 11301183.27\n",
      "total_cost: 71222.59\n",
      "total_trades: 51405\n",
      "Sharpe: 1.064\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1454        |\n",
      "|    time_elapsed         | 26870       |\n",
      "|    total_timesteps      | 2977792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011839855 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51          |\n",
      "|    n_updates            | 14530       |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    reward               | -3.065158   |\n",
      "|    std                  | 7.21        |\n",
      "|    value_loss           | 300         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1455        |\n",
      "|    time_elapsed         | 26889       |\n",
      "|    total_timesteps      | 2979840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017007763 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 170         |\n",
      "|    n_updates            | 14540       |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    reward               | 0.9268548   |\n",
      "|    std                  | 7.23        |\n",
      "|    value_loss           | 388         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1456        |\n",
      "|    time_elapsed         | 26908       |\n",
      "|    total_timesteps      | 2981888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011538021 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98         |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 416         |\n",
      "|    n_updates            | 14550       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -1.5790951  |\n",
      "|    std                  | 7.25        |\n",
      "|    value_loss           | 453         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1457        |\n",
      "|    time_elapsed         | 26926       |\n",
      "|    total_timesteps      | 2983936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009099068 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 14560       |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    reward               | 2.147797    |\n",
      "|    std                  | 7.26        |\n",
      "|    value_loss           | 57.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1458        |\n",
      "|    time_elapsed         | 26945       |\n",
      "|    total_timesteps      | 2985984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011864899 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 14570       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 1.0395787   |\n",
      "|    std                  | 7.27        |\n",
      "|    value_loss           | 414         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1459        |\n",
      "|    time_elapsed         | 26963       |\n",
      "|    total_timesteps      | 2988032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011674362 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.2       |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 187         |\n",
      "|    n_updates            | 14580       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -14.761862  |\n",
      "|    std                  | 7.28        |\n",
      "|    value_loss           | 413         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1460        |\n",
      "|    time_elapsed         | 26983       |\n",
      "|    total_timesteps      | 2990080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010851471 |\n",
      "|    clip_fraction        | 0.0659      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.2       |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.4        |\n",
      "|    n_updates            | 14590       |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    reward               | -2.8793833  |\n",
      "|    std                  | 7.29        |\n",
      "|    value_loss           | 74.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1461        |\n",
      "|    time_elapsed         | 27001       |\n",
      "|    total_timesteps      | 2992128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008457181 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.2       |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 334         |\n",
      "|    n_updates            | 14600       |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    reward               | 0.5410391   |\n",
      "|    std                  | 7.3         |\n",
      "|    value_loss           | 370         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1462         |\n",
      "|    time_elapsed         | 27020        |\n",
      "|    total_timesteps      | 2994176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054403115 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.2        |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 243          |\n",
      "|    n_updates            | 14610        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    reward               | 62.660576    |\n",
      "|    std                  | 7.3          |\n",
      "|    value_loss           | 378          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1463        |\n",
      "|    time_elapsed         | 27039       |\n",
      "|    total_timesteps      | 2996224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009091219 |\n",
      "|    clip_fraction        | 0.0704      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.3       |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 14620       |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    reward               | -2.6357727  |\n",
      "|    std                  | 7.31        |\n",
      "|    value_loss           | 214         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1464        |\n",
      "|    time_elapsed         | 27058       |\n",
      "|    total_timesteps      | 2998272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00626445  |\n",
      "|    clip_fraction        | 0.0169      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.3       |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.9        |\n",
      "|    n_updates            | 14630       |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    reward               | -0.26307622 |\n",
      "|    std                  | 7.31        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1465         |\n",
      "|    time_elapsed         | 27077        |\n",
      "|    total_timesteps      | 3000320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072313645 |\n",
      "|    clip_fraction        | 0.0433       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.3        |\n",
      "|    explained_variance   | 0.823        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 109          |\n",
      "|    n_updates            | 14640        |\n",
      "|    policy_gradient_loss | -0.0071      |\n",
      "|    reward               | 0.830812     |\n",
      "|    std                  | 7.32         |\n",
      "|    value_loss           | 332          |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# model_ppo2.load('42')\n",
    "print('load')\n",
    "trained_ppo2 = agent_con.train_model(model=model_ppo2, \n",
    "                             tb_log_name=\"6\",\n",
    "                             total_timesteps=3000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Model 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xwOhVjqRkCdM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "K8RSdKCckJyH"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23766/4244563930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_sac = agent.train_model(model=model_sac, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sac'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              total_timesteps=60000)\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         )\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;31m# Special case when the user passes `gradient_steps=0`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgradient_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# Select action according to policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                 \u001b[0mnext_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# Compute the next Q values: min over all critics targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mnext_q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/policies.py\u001b[0m in \u001b[0;36maction_log_prob\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_dist_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# return action and associated log prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mlog_prob_from_params\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mactions_from_params\u001b[0;34m(self, mean_actions, log_std, deterministic)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Update the proba distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"SquashedDiagGaussianDistribution\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSquashedDiagGaussianDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m    151\u001b[0m         \u001b[0maction_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     raise ValueError(\n\u001b[1;32m     56\u001b[0m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at 2020-07-01. We use the DDPG model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEv5KGC8h1jE"
   },
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be greater than the maximum of insample turbulence data, if current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "efwBi84ch1jE"
   },
   "outputs": [],
   "source": [
    "data_risk_indicator = processed_full[(processed_full.date<'2020-07-01') & (processed_full.date>='2009-01-01')]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n",
    "\n",
    "trained_ppo2.save('61')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "VHZMBpSqh1jG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       18.824245\n",
       "std         8.489311\n",
       "min         9.140000\n",
       "25%        13.330000\n",
       "50%        16.139999\n",
       "75%        21.309999\n",
       "max        82.690002\n",
       "Name: vix, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "BDkszkMloRWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.40400183105453"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.quantile(0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "AL7hs7svnNWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       34.574233\n",
       "std        43.787150\n",
       "min         0.000000\n",
       "25%        14.966105\n",
       "50%        24.124290\n",
       "75%        39.162080\n",
       "max       652.505555\n",
       "Name: turbulence, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "N78hfHckoqJ9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276.45132359815483"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.quantile(0.996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trade\n",
    "\n",
    "DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "cIqoV0GSI52v"
   },
   "outputs": [],
   "source": [
    "#trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "W_XNgGsBMeVw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "eLOnL5eYh1jR"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trained_ppo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27012/536458364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     environment = e_trade_gym)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m df_account_value, df_actions = DRLAgent.DRL_prediction(\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_ppo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     environment = e_trade_gym)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trained_ppo' is not defined"
     ]
    }
   ],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERxw3KqLkcP4"
   },
   "outputs": [],
   "source": [
    "df_account_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yRkNguY5yvp"
   },
   "outputs": [],
   "source": [
    "df_account_value.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFlK5hNbWVFk"
   },
   "outputs": [],
   "source": [
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nzkr9yv-AdV_"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkV-LB66iwhD"
   },
   "outputs": [],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qg1kvfemrrQH"
   },
   "outputs": [],
   "source": [
    "df_account_value.loc[0,'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tt1bzL5OrsTa"
   },
   "outputs": [],
   "source": [
    "df_account_value.loc[len(df_account_value)-1,'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKRGftSS7pNM"
   },
   "outputs": [],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "BzBaE63H3RLc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value2, df_actions2 = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo2, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ZYeOjax-7H_5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.386150\n",
      "Cumulative returns     0.545541\n",
      "Annual volatility      0.157681\n",
      "Sharpe ratio           2.156949\n",
      "Calmar ratio           4.012154\n",
      "Stability              0.942059\n",
      "Max drawdown          -0.096245\n",
      "Omega ratio            1.451933\n",
      "Sortino ratio          3.334725\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.063878\n",
      "Daily value at risk   -0.018516\n",
      "dtype: float64\n",
      "==============Get Baseline Stats===========\n",
      "Annual return          0.269722\n",
      "Cumulative returns     0.374922\n",
      "Annual volatility      0.139083\n",
      "Sharpe ratio           1.792302\n",
      "Calmar ratio           3.020136\n",
      "Stability              0.919220\n",
      "Max drawdown          -0.089308\n",
      "Omega ratio            1.347571\n",
      "Sortino ratio          2.655481\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.052781\n",
      "Daily value at risk   -0.016534\n",
      "dtype: float64\n",
      "==============Compare to DJIA===========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2020-07-01</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2021-10-28</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>16</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>38.615%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>54.554%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>15.768%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-9.625%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-1.852%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.62</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.14</td>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>2021-10-20</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.07</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>2020-12-02</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.88</td>\n",
       "      <td>2021-05-07</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.73</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stress Events</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Normal</th>\n",
       "      <td>0.13%</td>\n",
       "      <td>-4.00%</td>\n",
       "      <td>4.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x5184 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value2)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'2.csv')\n",
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value2.loc[0,'date'],\n",
    "        end = df_account_value2.loc[len(df_account_value2)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n",
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value2, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value2.loc[0,'date'],\n",
    "             baseline_end = df_account_value2.loc[len(df_account_value2)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Uy5_PTmOh1hj",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_StockTrading_NeurIPS_2018.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
